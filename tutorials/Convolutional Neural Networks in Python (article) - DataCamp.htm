<!DOCTYPE html>
<!-- saved from url=(0081)https://www.datacamp.com/community/tutorials/convolutional-neural-networks-python -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><style type="text/css">@charset "UTF-8";[ng\:cloak],[ng-cloak],[data-ng-cloak],[x-ng-cloak],.ng-cloak,.x-ng-cloak,.ng-hide:not(.ng-hide-animate){display:none !important;}ng\:form{display:block;}.ng-animate-shim{visibility:hidden;}.ng-anchor{position:absolute;}</style><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" class="next-head"><meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" class="next-head"><meta name="google-site-verification" content="NXbTi7gyLQESV4NIskeE9Ka0Am8KjAtzg5gm8g38HbU" class="next-head"><meta name="keywords" content="convolutional neural network python" class="next-head"><meta name="description" content="In this tutorial, you’ll learn how to implement Convolutional Neural Networks (CNNs) in Python with Keras, and how to overcome overfitting with dropout." class="next-head"><title class="next-head">Convolutional Neural Networks in Python (article) - DataCamp</title><link rel="canonical" href="https://www.datacamp.com/community/tutorials/convolutional-neural-networks-python" class="next-head"><link rel="author" href="https://plus.google.com/u/0/+Datacamp/" class="next-head"><link rel="shortcut icon" type="image/x-icon" href="https://cdn.datacamp.com/main-app/assets/favicon-335cd0394b32102a39221d79e5fd7e51078e6d32a0c8aea59676a6869f84e9d8.ico" class="next-head"><link rel="chrome-webstore-item" href="https://chrome.google.com/webstore/detail/lbbhbkehmgbndgfdbncbmikooblghdbi" class="next-head"><meta property="og:title" content="Convolutional Neural Networks in Python" class="next-head"><meta property="og:image" content="http://datacamp-community.s3.amazonaws.com/2f48e07c-3c50-4bd7-bbba-1dc6edfd5e90" class="next-head"><meta property="og:url" content="https://www.datacamp.com/community/tutorials/convolutional-neural-networks-python" class="next-head"><meta property="og:type" content="article" class="next-head"><meta property="og:published_time" content="2017-12-05T14:50:24.171Z" class="next-head"><meta property="og:author" content="Aditya Sharma" class="next-head"><meta property="og:description" content="In this tutorial, you’ll learn how to implement Convolutional Neural Networks (CNNs) in Python with Keras, and how to overcome overfitting with dropout." class="next-head"><meta property="og:site_name" content="DataCamp Community" class="next-head"><meta name="twitter:title" content="Convolutional Neural Networks in Python" class="next-head"><meta name="twitter:description" content="In this tutorial, you’ll learn how to implement Convolutional Neural Networks (CNNs) in Python with Keras, and how to overcome overfitting with dropout." class="next-head"><meta name="twitter:card" content="summary" class="next-head"><meta name="twitter:site" content="@DataCamp" class="next-head"><meta name="twitter:creator" content="@DataCamp" class="next-head"><meta name="twitter:domain" content="www.datacamp.com" class="next-head"><meta name="twitter:image" content="http://datacamp-community.s3.amazonaws.com/2f48e07c-3c50-4bd7-bbba-1dc6edfd5e90" class="next-head"><meta name="twitter:image:width" content="1200" class="next-head"><meta name="twitter:image:height" content="628" class="next-head"><meta name="twitter:image:alt" content="Convolutional Neural Networks in Python" class="next-head"><meta name="article:publisher" content="https://www.facebook.com/DataCamp-726282547396228" class="next-head"><meta name="fb:app_id" content="726282547396228" class="next-head"><script type="text/javascript" async="" src="./Convolutional Neural Networks in Python (article) - DataCamp_files/linkid.js"></script><script type="text/javascript" async="" src="./Convolutional Neural Networks in Python (article) - DataCamp_files/ga.js"></script><script async="" src="./Convolutional Neural Networks in Python (article) - DataCamp_files/obtp.js" type="text/javascript"></script><script async="" src="./Convolutional Neural Networks in Python (article) - DataCamp_files/qevents.js"></script><script async="" src="./Convolutional Neural Networks in Python (article) - DataCamp_files/fs.js"></script><script src="./Convolutional Neural Networks in Python (article) - DataCamp_files/286618111707433" async=""></script><script async="" src="./Convolutional Neural Networks in Python (article) - DataCamp_files/fbevents.js"></script><script type="text/javascript" async="" src="./Convolutional Neural Networks in Python (article) - DataCamp_files/insight.min.js"></script><script type="text/javascript" async="" src="./Convolutional Neural Networks in Python (article) - DataCamp_files/analytics.js"></script><script async="" src="./Convolutional Neural Networks in Python (article) - DataCamp_files/get-loader.js"></script><script async="" src="./Convolutional Neural Networks in Python (article) - DataCamp_files/BuKMCyKUvvyXZkMi44LjI.js"></script><script async="" src="./Convolutional Neural Networks in Python (article) - DataCamp_files/gtm.js"></script><script class="next-head">
      (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
      new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
      j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
      'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
      })(window,document,'script','dataLayer','GTM-TGGWB2P');
    </script><link rel="preload" href="./Convolutional Neural Networks in Python (article) - DataCamp_files/tutorial.js" as="script"><link rel="preload" href="./Convolutional Neural Networks in Python (article) - DataCamp_files/_error.js" as="script"><link rel="preload" href="./Convolutional Neural Networks in Python (article) - DataCamp_files/app.js" as="script"><style id="__jsx-2090414051">.Logo.jsx-2090414051{-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;}
.Logo__image.jsx-2090414051{display:block;width:122px;height:28px;margin-left:8px;}
.Logo__image.jsx-2090414051 svg{fill:#FFFFFF;}
@media (min-width:800px) and (min-height:650px){.Logo.jsx-2090414051{height:59px;}.Logo__image.jsx-2090414051{margin:17px auto 0;}}</style><style id="__jsx-2803075824">.SidebarMenu.jsx-2803075824{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;position:fixed;z-index:300;width:100vw;height:50px;background-image: linear-gradient(207deg, #2388B0, #33AACC);}
.Layout--banner .SidebarMenu.jsx-2803075824{top:55px;}
.icon.jsx-2803075824{text-align:right;}
.icon.jsx-2803075824 svg{margin-right:9px;width:20px;height:20px;fill:#FFFFFF;}
@media (min-width:800px) and (min-height:650px){.SidebarMenu.jsx-2803075824{z-index:200;width:220px;top:0;left:0;background-image:none;}.Layout--banner .SidebarMenu.jsx-2803075824{top:80px;}}</style><style id="__jsx-2919104997">.Menu.jsx-2919104997{-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;margin-top:50px;}
.Layout--banner .Menu.jsx-2919104997{margin-top:105px;}
.Layout--openMenu .Menu.jsx-2919104997{min-height:calc(100vh - 50px - 134px);}
.Layout--openMenu.Layout--banner .Menu.jsx-2919104997{min-height:calc(100vh - 105px - 134px);}
.section.jsx-2919104997{margin-bottom:20px;}
.section.jsx-2919104997 h5.jsx-2919104997{margin:0;padding-left:17px;font-size:13px;-webkit-letter-spacing:3.3px;-moz-letter-spacing:3.3px;-ms-letter-spacing:3.3px;letter-spacing:3.3px;line-height:36px;text-align:left;text-transform:uppercase;background-color:#195B73;color:#7ECCE2;}
.item.jsx-2919104997{margin-bottom:1px;padding-left:12px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-align-content:center;-ms-flex-line-pack:center;align-content:center;font-size:15px;-webkit-letter-spacing:0.2px;-moz-letter-spacing:0.2px;-ms-letter-spacing:0.2px;letter-spacing:0.2px;line-height:40px;text-decoration:none;color:#FFFFFF;}
.statusIcon.jsx-2919104997{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-self:center;-ms-flex-item-align:center;align-self:center;padding:10px;}
.active.jsx-2919104997{background-color:#55AECB;}
a.jsx-2919104997:hover{background-color:#55AECB;}
.image.jsx-2919104997{margin-top:2px;-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;width:30px;height:30px;text-align:center;}
.image.jsx-2919104997 svg{fill:#195B73;}
.active.jsx-2919104997 svg,a.jsx-2919104997:hover svg{fill:#FFFFFF;}
.text.jsx-2919104997{-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;}
.subMenu.jsx-2919104997{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}
@media (min-width:800px) and (min-height:650px){.Menu.jsx-2919104997{position:fixed;width:220px;margin-top:50px;}.Layout--banner .Menu.jsx-2919104997{margin-top:130px;}.section.jsx-2919104997 h5.jsx-2919104997{padding-left:0;text-align:center;}}</style><style id="__jsx-322537325">.Button.jsx-322537325{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;height:33px;margin:auto 5px;padding:0 15px;font-size:13px;font-weight:bold;-webkit-letter-spacing:0.2px;-moz-letter-spacing:0.2px;-ms-letter-spacing:0.2px;letter-spacing:0.2px;white-space:nowrap;color:#3A3A3A;border:1px solid transparent;border-radius:4px;background-color:transparent;cursor:pointer;outline:none;}
.Button.jsx-322537325::before,.Button.jsx-322537325::after{content:'';-webkit-flex:1 0 auto;-ms-flex:1 0 auto;flex:1 0 auto;}
.icon.jsx-322537325{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;min-height:20px;}
.icon.jsx-322537325 svg{-webkit-flex:1 1 0;-ms-flex:1 1 0;flex:1 1 0;height:20px;-webkit-align-self:center;-ms-flex-item-align:center;align-self:center;fill:#33AACC;}
.greyIcon.jsx-322537325 .icon.jsx-322537325 svg{min-width:16px;min-height:16px;fill:#3A3A3A;}
.same.jsx-322537325 .icon.jsx-322537325{min-width:13px;height:13px;margin-right:5px;}
.same.jsx-322537325 .icon.jsx-322537325 svg{height:13px;}
.Button.jsx-322537325:disabled,.Button.jsx-322537325:hover.jsx-322537325:disabled{color:#D1D3D8;background-color:#E6EAEB;}
.primary.jsx-322537325{background-color:#FFC844;}
.primary.jsx-322537325:hover{background-color:#FBE28D;}
.secondary.jsx-322537325{color:#FFFFFF;background-color:#33AACC;}
.secondary.jsx-322537325:hover{background-color:#7ECCE2;}
.red.jsx-322537325{color:#FFFFFF;background-color:#FE5C5C;}
.green.jsx-322537325{height:35px;color:#FFFFFF;background-color:#FFFFFF;}
.green.jsx-322537325 .icon.jsx-322537325 svg{fill:#36D57D;width:35px;height:35px;}
.grey.jsx-322537325{color:#3D4251;background-color:#D1D3D8;}
.grey.jsx-322537325:hover{color:#3D4251;background-color:#E6EAEB;}
.big.jsx-322537325{font-size:15px;height:42px;}
.extra.jsx-322537325{font-size:17px;height:45px;}
.border.jsx-322537325{border:1px solid #E3E7E8;}
.border.jsx-322537325:hover{border:1px solid #33AACC;}
.seeAll.jsx-322537325{border:1px solid #33AACC;}
.seeAll.jsx-322537325:hover{border:1px solid #FFC844;}
.iconButton.jsx-322537325:hover{color:#33AACC;}
.minWidth.jsx-322537325{min-width:85px;}
.noPadding.jsx-322537325{padding:0;}
@media (min-width:800px) and (min-height:650px){.icon.jsx-322537325{min-width:13px;height:13px;margin-right:5px;}.icon.jsx-322537325 svg{height:13px;}.big.jsx-322537325 .icon.jsx-322537325{min-width:15px;height:15px;}.big.jsx-322537325 svg{height:15px;}.extra.jsx-322537325 .icon.jsx-322537325,.extraIcon.jsx-322537325{min-width:17px;height:17px;}.extra.jsx-322537325 svg,.extraIcon.jsx-322537325 svg{height:17px;}.green.jsx-322537325{padding:0 15px;color:#FFFFFF;background-color:#36D57D;}.green.jsx-322537325 .icon.jsx-322537325 svg{width:13px;height:13px;fill:#FFFFFF;}.forcePadding.jsx-322537325{padding:0 15px;}}</style><style id="__jsx-3863678361">.ActionBarSearch.jsx-3863678361{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:start;-webkit-justify-content:flex-start;-ms-flex-pack:start;justify-content:flex-start;}</style><style id="__jsx-3666761727">.SubmitAnArticleButton.jsx-3666761727{margin-left:5px;}
.mobileButton.jsx-3666761727{display:block !important;}
.mobileButton.jsx-3666761727 svg{fill:#36D57D;width:35px;height:35px;}
.SubmitAnArticleButton.jsx-3666761727 .desktopButton{display:none !important;}
@media (min-width:800px) and (min-height:650px){.mobileButton.jsx-3666761727{display:none !important;}.SubmitAnArticleButton.jsx-3666761727 .desktopButton{display:-webkit-box !important;display:-webkit-flex !important;display:-ms-flexbox !important;display:flex !important;}}</style><style id="__jsx-3196442269">.ActionBarAuth.jsx-3196442269{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:end;-webkit-justify-content:flex-end;-ms-flex-pack:end;justify-content:flex-end;}
.wrapper.jsx-3196442269{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;cursor:pointer;}
.name.jsx-3196442269{margin-right:9px;font-size:13px;font-weight:bold;color:#3D4251;text-decoration:none;}
.name.jsx-3196442269:hover{color:#33AACC;}
.logout.jsx-3196442269{font-size:15px;padding:10px;color:#3D4251;display:inline-block;min-width:100px;}
.logout.jsx-3196442269:hover{background-color:#F0F4F5;border-bottom:solid 1px #E3E7E8;}
.menuList.jsx-3196442269 a.jsx-3196442269{display:block;}</style><style id="__jsx-702933904">.ActionBar.jsx-702933904{height:50px;margin-top:50px;padding:0 5px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;background-color:#FFFFFF;border-bottom:1px solid #E3E7E8;}
.authBlock.jsx-702933904{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-fles-direction:row;-ms-fles-direction:row;fles-direction:row;}
.Page.content .ActionBar{margin-bottom:10px;}
@media (min-width:800px) and (min-height:650px){.ActionBar.jsx-702933904{width:calc(100% - 220px);height:50px;margin-top:0;margin-bottom:0;padding:0 25px;position:fixed;z-index:300;}}</style><style id="__jsx-3889859319">.Title.jsx-3889859319{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}
.Title.jsx-3889859319 .icon.jsx-3889859319{-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;min-width:18px;height:18px;}
.icon.jsx-3889859319 svg{-webkit-flex:1 1 0;-ms-flex:1 1 0;flex:1 1 0;height:18px;-webkit-align-self:center;-ms-flex-item-align:center;align-self:center;fill:#33AACC;}
.Title.jsx-3889859319 .h1.jsx-3889859319,.Title.jsx-3889859319 h1.jsx-3889859319{-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;margin:auto 0 auto 9px;font-size:22px;text-transform:capitalize;}
.Title.jsx-3889859319 .status.jsx-3889859319{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-self:center;-ms-flex-item-align:center;align-self:center;padding:10px;}</style><style id="__jsx-1374485364">.TitleBar.jsx-1374485364{height:50px;padding:0 5px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;line-height:50px;background-color:#FFFFFF;border-bottom:1px solid #E3E7E8;margin-bottom:65px;}
.filter.jsx-1374485364{-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;height:48px;}
.action.jsx-1374485364{-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;line-height:normal;}
.title.jsx-1374485364{height:65px;line-height:65px;-webkit-flex:0 0 100%;-ms-flex:0 0 100%;flex:0 0 100%;-webkit-order:1;-ms-flex-order:1;order:1;text-align:center;}
h1.jsx-1374485364{margin:0 0;}
.Page.content .TitleBar{display:none;}
@media (min-width:800px) and (min-height:650px){.TitleBar.jsx-1374485364{height:50px;padding:0 25px;display:-webkit-box !important;display:-webkit-flex !important;display:-ms-flexbox !important;display:flex !important;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-flex-wrap:nowrap;-ms-flex-wrap:nowrap;flex-wrap:nowrap;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;margin-bottom:29px;margin-top:50px;background-color:#FFFFFF;border-bottom:1px solid #E3E7E8;}.filter.jsx-1374485364{-webkit-flex:0 0 33%;-ms-flex:0 0 33%;flex:0 0 33%;line-height:normal;}.action.jsx-1374485364{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:end;-webkit-justify-content:flex-end;-ms-flex-pack:end;justify-content:flex-end;line-height:normal;-webkit-flex:0 0 33%;-ms-flex:0 0 33%;flex:0 0 33%;}.action.jsx-1374485364 a{line-height:0;}.title.jsx-1374485364{-webkit-order:0;-ms-flex-order:0;order:0;-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;text-align:center;}h1.jsx-1374485364{margin:0 0;}}</style><style id="__jsx-3293774837">.CommentCounter.jsx-3293774837{width:54px;height:54px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;border-radius:4px;border:1px solid #E6EAEB;background-color:#F0F4F5;cursor:pointer;}
.CommentCounter.jsx-3293774837 .icon.jsx-3293774837{font-size:13px;line-height:0;color:#33AACC;}
.CommentCounter.jsx-3293774837 .icon.jsx-3293774837 svg{width:16px;height:16px;fill:#33AACC;}
.CommentCounter.jsx-3293774837 .count.jsx-3293774837{font-size:13px;font-weight:bold;-webkit-letter-spacing:0.2px;-moz-letter-spacing:0.2px;-ms-letter-spacing:0.2px;letter-spacing:0.2px;color:#686F75;}
.CommentCounter.jsx-3293774837:hover{background-color:#FFFFFF;}</style><style id="__jsx-4192737526">.Upvote.jsx-4192737526{position:relative;width:54px;height:54px;overflow:hidden;border-radius:4px;border:1px solid #E6EAEB;background-color:#F0F4F5;cursor:pointer;}
.Upvote.news.jsx-4192737526{width:45px;height:35px;border:none;background-color:transparent;}
.Upvote.comment.jsx-4192737526{width:45px;height:25px;border:none;background-color:transparent;}
.Upvote.jsx-4192737526>div.jsx-4192737526{position:absolute;top:0;-webkit-transition:all 0.15s ease-in-out;transition:all 0.15s ease-in-out;}
.Upvote.upvoted.jsx-4192737526>div.jsx-4192737526{top:-54px;}
.Upvote.upvoted.news.jsx-4192737526>div.jsx-4192737526{top:-35px;}
.Upvote.upvoted.comment.jsx-4192737526>div.jsx-4192737526{top:-25px;}
.Upvote.jsx-4192737526>div.jsx-4192737526>div.jsx-4192737526{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;width:54px;height:54px;}
.Upvote.news.jsx-4192737526>div.jsx-4192737526>div.jsx-4192737526{width:45px;height:35px;}
.Upvote.comment.jsx-4192737526>div.jsx-4192737526>div.jsx-4192737526{width:45px;height:25px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;}
.Upvote.jsx-4192737526 .icon.jsx-4192737526{font-size:13px;line-height:0;color:#33AACC;}
.Upvote.comment.jsx-4192737526 .icon.jsx-4192737526{padding-right:5px;}
.Upvote.comment.jsx-4192737526 .count.jsx-4192737526{padding-bottom:1px;}
.Upvote.jsx-4192737526 .icon.jsx-4192737526 svg{width:12px;height:12px;fill:#33AACC;}
.Upvote.jsx-4192737526 .count.jsx-4192737526{font-size:13px;font-weight:bold;-webkit-letter-spacing:0.2px;-moz-letter-spacing:0.2px;-ms-letter-spacing:0.2px;letter-spacing:0.2px;color:#686F75;}
.Upvote.jsx-4192737526:hover{background-color:#FFFFFF;}
.Upvote.news.jsx-4192737526:hover,.Upvote.comment.jsx-4192737526:hover{background-color:#EBF4F7;}
.Upvote.news.jsx-4192737526:hover .count.jsx-4192737526,.Upvote.comment.jsx-4192737526:hover .count.jsx-4192737526{color:#33AACC;}
.Upvote.jsx-4192737526 .voted.jsx-4192737526{background-color:#33AACC;border-color:#33AACC;}
.Upvote.news.jsx-4192737526 .voted.jsx-4192737526,.Upvote.comment.jsx-4192737526 .voted.jsx-4192737526{background-color:#FFFFFF;border:none;}
.Upvote.jsx-4192737526 .voted.jsx-4192737526 .icon.jsx-4192737526 svg{fill:#195B73;}
.Upvote.news.jsx-4192737526 .voted.jsx-4192737526 .icon.jsx-4192737526 svg,.Upvote.comment.jsx-4192737526 .voted.jsx-4192737526 .icon.jsx-4192737526 svg{fill:#36D57D;}
.Upvote.jsx-4192737526 .voted.jsx-4192737526 .count.jsx-4192737526{color:#FFFFFF;}
.Upvote.news.jsx-4192737526 .voted.jsx-4192737526 .count.jsx-4192737526,.Upvote.comment.jsx-4192737526 .voted.jsx-4192737526 .count.jsx-4192737526{color:#36D57D;}
@media (min-width:800px) and (min-height:650px){.Upvote.news.jsx-4192737526{height:45px;}.Upvote.comment.jsx-4192737526{height:25px;}.Upvote.upvoted.news.jsx-4192737526>div.jsx-4192737526{top:-45px;}.Upvote.upvoted.comment.jsx-4192737526>div.jsx-4192737526{top:-25px;}.Upvote.news.jsx-4192737526>div.jsx-4192737526>div.jsx-4192737526{height:45px;}.Upvote.comment.jsx-4192737526>div.jsx-4192737526>div.jsx-4192737526{height:25px;}}</style><style id="__jsx-1531915454">.Social.jsx-1531915454{-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;}
.icons.jsx-1531915454{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}
.icon.jsx-1531915454{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;width:28px;height:28px;border:1px solid #E3E7E8;background-color:#FFFFFF;border-radius:50%;}
.icon.jsx-1531915454:hover{background-color:#F0F4F5;}
.centerIcon.jsx-1531915454{margin:0 10px;}
.icon.jsx-1531915454 svg{fill:#686F75;-webkit-align-self:center;-ms-flex-item-align:center;align-self:center;-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;}
@media (min-width:800px) and (min-height:650px){.Social.jsx-1531915454{margin-top:18px;}.vertical.jsx-1531915454{margin-top:10px;}.vertical.jsx-1531915454 .icons.jsx-1531915454{-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}.vertical.jsx-1531915454 .centerIcon.jsx-1531915454{margin:10px 0;}}</style><style id="__jsx-3208234818">.Avatar.jsx-3208234818{display:inline-block;background-size:cover;background-color:#E6EAEB;background-repeat:no-repeat;}</style><style id="__jsx-566588255">.Author.jsx-566588255 a.jsx-566588255{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;cursor:pointer;}
.info.jsx-566588255{margin-left:9px;white-space:nowrap;}
.mirrored.jsx-566588255 .info.jsx-566588255{margin:0 9px 0 0;-webkit-order:-1;-ms-flex-order:-1;order:-1;}
.name.jsx-566588255{font-size:13px;font-weight:bold;-webkit-letter-spacing:0.2px;-moz-letter-spacing:0.2px;-ms-letter-spacing:0.2px;letter-spacing:0.2px;color:#3D4251;text-decoration:none;}
.name.jsx-566588255:hover{color:#33AACC;}
.date.jsx-566588255{font-size:11px;-webkit-letter-spacing:0.2px;-moz-letter-spacing:0.2px;-ms-letter-spacing:0.2px;letter-spacing:0.2px;color:#686F75;}</style><style id="__jsx-1764811326">.Tag.jsx-1764811326{display:inline-block;border-radius:4px;background-color:#F0F4F5;border:solid 1px #E6EAEB;-webkit-letter-spacing:0.2px;-moz-letter-spacing:0.2px;-ms-letter-spacing:0.2px;letter-spacing:0.2px;color:#686F75;cursor:default;}
.title.jsx-1764811326{line-height:20px;padding:0 8px;font-size:11px;text-transform:uppercase;}
.Tag.mustRead.jsx-1764811326{background-color:#AD86CE;border-color:#AD86CE;color:#FFFFFF;font-weight:bold;}
.Tag.jsx-1764811326:hover{background-color:#FFFFFF;}
.Tag.mustRead.jsx-1764811326:hover{background-color:#CEABEC;border-color:#CEABEC;}</style><style id="__jsx-1022557955">.more.jsx-1022557955{font-size:11px;cursor:default;color:#686F75;}
.more.jsx-1022557955:hover{text-decoration:underline;}</style><style id="__jsx-422934526">.tooltipInner .Tag{margin:4px;}
.rc-tooltip{position:absolute;z-index:200;display:block;visibility:visible;line-height:1.5;font-size:12px;border-radius:4px;}
.rc-tooltip-hidden{display:none;}
.rc-tooltip-inner{padding:12px;color:#333333;text-align:left;text-decoration:none;background-color:#ffffff;border-radius:4px;min-height:34px;border:1px solid #e3e7e8;}
.rc-tooltip-arrow,.rc-tooltip-arrow-inner{position:absolute;width:0;height:0;border-color:transparent;border-style:solid;}
.rc-tooltip-placement-top .rc-tooltip-arrow,.rc-tooltip-placement-topLeft .rc-tooltip-arrow,.rc-tooltip-placement-topRight .rc-tooltip-arrow{bottom:-5px;margin-left:-6px;border-width:6px 6px 0;border-top-color:#e3e7e8;}
.rc-tooltip-placement-top .rc-tooltip-arrow-inner,.rc-tooltip-placement-topLeft .rc-tooltip-arrow-inner,.rc-tooltip-placement-topRight .rc-tooltip-arrow-inner{bottom:1px;margin-left:-6px;border-width:6px 6px 0;border-top-color:#ffffff;}
.rc-tooltip-placement-top .rc-tooltip-arrow{left:50%;}
.rc-tooltip-placement-topLeft .rc-tooltip-arrow{left:15%;}
.rc-tooltip-placement-topRight .rc-tooltip-arrow{right:15%;}
.rc-tooltip-placement-right .rc-tooltip-arrow,.rc-tooltip-placement-rightTop .rc-tooltip-arrow,.rc-tooltip-placement-rightBottom .rc-tooltip-arrow{left:-5px;margin-top:-6px;border-width:6px 6px 6px 0;border-right-color:#e3e7e8;}
.rc-tooltip-placement-right .rc-tooltip-arrow-inner,.rc-tooltip-placement-rightTop .rc-tooltip-arrow-inner,.rc-tooltip-placement-rightBottom .rc-tooltip-arrow-inner{left:1px;margin-top:-6px;border-width:6px 6px 6px 0;border-right-color:#ffffff;}
.rc-tooltip-placement-right .rc-tooltip-arrow{top:50%;}
.rc-tooltip-placement-rightTop .rc-tooltip-arrow{top:15%;margin-top:0;}
.rc-tooltip-placement-rightBottom .rc-tooltip-arrow{bottom:15%;}
.rc-tooltip-placement-left .rc-tooltip-arrow,.rc-tooltip-placement-leftTop .rc-tooltip-arrow,.rc-tooltip-placement-leftBottom .rc-tooltip-arrow{right:-5px;margin-top:-6px;border-width:6px 0 6px 6px;border-left-color:#e3e7e8;}
.rc-tooltip-placement-left .rc-tooltip-arrow-inner,.rc-tooltip-placement-leftTop .rc-tooltip-arrow-inner,.rc-tooltip-placement-leftBottom .rc-tooltip-arrow-inner{right:1px;margin-top:-6px;border-width:6px 0 6px 6px;border-left-color:#ffffff;}
.rc-tooltip-placement-left .rc-tooltip-arrow{top:50%;}
.rc-tooltip-placement-leftTop .rc-tooltip-arrow{top:15%;margin-top:0;}
.rc-tooltip-placement-leftBottom .rc-tooltip-arrow{bottom:15%;}
.rc-tooltip-placement-bottom .rc-tooltip-arrow,.rc-tooltip-placement-bottomLeft .rc-tooltip-arrow,.rc-tooltip-placement-bottomRight .rc-tooltip-arrow{top:-5px;margin-left:-6px;border-width:0 6px 6px;border-bottom-color:#e3e7e8;}
.rc-tooltip-placement-bottom .rc-tooltip-arrow-inner,.rc-tooltip-placement-bottomLeft .rc-tooltip-arrow-inner,.rc-tooltip-placement-bottomRight .rc-tooltip-arrow-inner{top:1px;margin-left:-6px;border-width:0 6px 6px;border-bottom-color:#ffffff;}
.rc-tooltip-placement-bottom .rc-tooltip-arrow{left:50%;}
.rc-tooltip-placement-bottomLeft .rc-tooltip-arrow{left:15%;}
.rc-tooltip-placement-bottomRight .rc-tooltip-arrow{right:15%;}
.rc-tooltip.rc-tooltip-zoom-enter,.rc-tooltip.rc-tooltip-zoom-leave{display:block;}
.rc-tooltip-zoom-enter,.rc-tooltip-zoom-appear{opacity:0;-webkit-animation-duration:0.3s;-webkit-animation-duration:0.3s;animation-duration:0.3s;-webkit-animation-fill-mode:both;-webkit-animation-fill-mode:both;animation-fill-mode:both;-webkit-animation-timing-function:cubic-bezier(0.18,0.89,0.32,1.28);-webkit-animation-timing-function:cubic-bezier(0.18,0.89,0.32,1.28);animation-timing-function:cubic-bezier(0.18,0.89,0.32,1.28);-webkit-animation-play-state:paused;-webkit-animation-play-state:paused;animation-play-state:paused;}
.rc-tooltip-zoom-leave{-webkit-animation-duration:0.3s;-webkit-animation-duration:0.3s;animation-duration:0.3s;-webkit-animation-fill-mode:both;-webkit-animation-fill-mode:both;animation-fill-mode:both;-webkit-animation-timing-function:cubic-bezier(0.6,-0.3,0.74,0.05);-webkit-animation-timing-function:cubic-bezier(0.6,-0.3,0.74,0.05);animation-timing-function:cubic-bezier(0.6,-0.3,0.74,0.05);-webkit-animation-play-state:paused;-webkit-animation-play-state:paused;animation-play-state:paused;}
.rc-tooltip-zoom-enter.rc-tooltip-zoom-enter-active,.rc-tooltip-zoom-appear.rc-tooltip-zoom-appear-active{-webkit-animation-name:rcToolTipZoomIn;-webkit-animation-name:rcToolTipZoomIn;animation-name:rcToolTipZoomIn;-webkit-animation-play-state:running;-webkit-animation-play-state:running;animation-play-state:running;}
.rc-tooltip-zoom-leave.rc-tooltip-zoom-leave-active{-webkit-animation-name:rcToolTipZoomOut;-webkit-animation-name:rcToolTipZoomOut;animation-name:rcToolTipZoomOut;-webkit-animation-play-state:running;-webkit-animation-play-state:running;animation-play-state:running;}
@-webkit-keyframes rcToolTipZoomIn{0%{opacity:0;-webkit-transform-origin:50% 50%;-webkit-transform-origin:50% 50%;-ms-transform-origin:50% 50%;transform-origin:50% 50%;-webkit-transform:scale(0,0);-webkit-transform:scale(0,0);-ms-transform:scale(0,0);transform:scale(0,0);}100%{opacity:1;-webkit-transform-origin:50% 50%;-webkit-transform-origin:50% 50%;-ms-transform-origin:50% 50%;transform-origin:50% 50%;-webkit-transform:scale(1,1);-webkit-transform:scale(1,1);-ms-transform:scale(1,1);transform:scale(1,1);}}
@-webkit-keyframes rcToolTipZoomIn{0%{opacity:0;-webkit-transform-origin:50% 50%;-webkit-transform-origin:50% 50%;-ms-transform-origin:50% 50%;transform-origin:50% 50%;-webkit-transform:scale(0,0);-webkit-transform:scale(0,0);-ms-transform:scale(0,0);transform:scale(0,0);}100%{opacity:1;-webkit-transform-origin:50% 50%;-webkit-transform-origin:50% 50%;-ms-transform-origin:50% 50%;transform-origin:50% 50%;-webkit-transform:scale(1,1);-webkit-transform:scale(1,1);-ms-transform:scale(1,1);transform:scale(1,1);}}
@keyframes rcToolTipZoomIn{0%{opacity:0;-webkit-transform-origin:50% 50%;-webkit-transform-origin:50% 50%;-ms-transform-origin:50% 50%;transform-origin:50% 50%;-webkit-transform:scale(0,0);-webkit-transform:scale(0,0);-ms-transform:scale(0,0);transform:scale(0,0);}100%{opacity:1;-webkit-transform-origin:50% 50%;-webkit-transform-origin:50% 50%;-ms-transform-origin:50% 50%;transform-origin:50% 50%;-webkit-transform:scale(1,1);-webkit-transform:scale(1,1);-ms-transform:scale(1,1);transform:scale(1,1);}}
@-webkit-keyframes rcToolTipZoomOut{0%{opacity:1;-webkit-transform-origin:50% 50%;-webkit-transform-origin:50% 50%;-ms-transform-origin:50% 50%;transform-origin:50% 50%;-webkit-transform:scale(1,1);-webkit-transform:scale(1,1);-ms-transform:scale(1,1);transform:scale(1,1);}100%{opacity:0;-webkit-transform-origin:50% 50%;-webkit-transform-origin:50% 50%;-ms-transform-origin:50% 50%;transform-origin:50% 50%;-webkit-transform:scale(0,0);-webkit-transform:scale(0,0);-ms-transform:scale(0,0);transform:scale(0,0);}}
@-webkit-keyframes rcToolTipZoomOut{0%{opacity:1;-webkit-transform-origin:50% 50%;-webkit-transform-origin:50% 50%;-ms-transform-origin:50% 50%;transform-origin:50% 50%;-webkit-transform:scale(1,1);-webkit-transform:scale(1,1);-ms-transform:scale(1,1);transform:scale(1,1);}100%{opacity:0;-webkit-transform-origin:50% 50%;-webkit-transform-origin:50% 50%;-ms-transform-origin:50% 50%;transform-origin:50% 50%;-webkit-transform:scale(0,0);-webkit-transform:scale(0,0);-ms-transform:scale(0,0);transform:scale(0,0);}}
@keyframes rcToolTipZoomOut{0%{opacity:1;-webkit-transform-origin:50% 50%;-webkit-transform-origin:50% 50%;-ms-transform-origin:50% 50%;transform-origin:50% 50%;-webkit-transform:scale(1,1);-webkit-transform:scale(1,1);-ms-transform:scale(1,1);transform:scale(1,1);}100%{opacity:0;-webkit-transform-origin:50% 50%;-webkit-transform-origin:50% 50%;-ms-transform-origin:50% 50%;transform-origin:50% 50%;-webkit-transform:scale(0,0);-webkit-transform:scale(0,0);-ms-transform:scale(0,0);transform:scale(0,0);}}</style><style id="__jsx-2792531181">.TagLine.jsx-2792531181{display:inline-block;white-space:nowrap;}
.TagLine.jsx-2792531181>.Tag{margin-right:10px;}
.more.jsx-2792531181{font-size:11px;}</style><style id="__jsx-561262778">.markdown{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-box-pack:start;-webkit-justify-content:flex-start;-ms-flex-pack:start;justify-content:flex-start;-webkit-align-items:flex-start;-webkit-box-align:flex-start;-ms-flex-align:flex-start;align-items:flex-start;font-family:'Lora',serif;font-size:16px;padding:1.5em;}
.markdown [data-datacamp-exercise]{overflow:hidden;}
.markdown>div{width:100%;}
.markdown div{outline:none;}
.markdown hr{border:0;border-bottom:1px solid #E6EAEB;margin:3em 0;}
.markdown div[data-type="mathjax"]{margin:1.5em 0;}
.markdown p{font-family:'Lora',serif;font-size:1em;line-height:1.8em;color:#3D4251;}
.markdown .powered-by-datacamp+p{margin-top:1.5em !important;}
.markdown p+p,.markdown p+img,.markdown p+div,.markdown p+table,.markdown p+ol,.markdown p+ul,.markdown p+nav,.markdown div+p,.markdown p+iframe,.markdown iframe+p,.markdown pre+img,.markdown pre+p{margin-top:1.5em !important;}
.markdown h2{font-family:'Lato',sans-serif;font-size:1.5em;font-weight:700;color:#3D4251;line-height:1.3em;margin:1.5em 0 0.5em;}
.markdown h3{font-family:'Lato',sans-serif;font-size:1.1em;font-weight:700;color:#3D4251;line-height:1.2em;margin:1.5em 0 0.5em;}
.markdown h4{font-family:'Lato',sans-serif;font-size:1em;font-weight:700;color:#3D4251;line-height:1.2em;margin:1.5em 0 0.5em;}
.markdown .videoWrapper{position:relative;padding-bottom:47.25%;padding-top:25px;height:0;margin-bottom:1.5em;}
.markdown .videoWrapper iframe{position:absolute;top:0;left:0;width:100%;height:100%;}
.markdown p code,.markdown li code{display:inline-block;padding:0 5px;border-radius:4px;font-family:'Roboto Mono',monospace;font-size:0.9em;line-height:1.6em;color:#3D4251;background-color:#E6EAEB;}
.markdown a code{color:#33AACC;}
.markdown pre{padding:1em 1.5em;font-family:'Roboto Mono',monospace;font-size:0.9em;background-color:#002B36 !important;border-radius:4px;overflow-x:auto;-webkit-overflow-scrolling:touch;}
.markdown pre code{padding:0;font-size:0.9em;line-height:2em;background-color:#002B36;overflow-x:visible;-webkit-overflow-scrolling:touch;}
.markdown img{display:block;-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;margin:auto;max-width:100%;height:auto !important;}
.markdown img+p{margin-top:1.5em !important;}
.markdown nav+p,.markdown nav+div{margin-top:1.5em !important;}
.markdown iframe{width:100%;}
.markdown ul,.markdown ol{font-family:'Lora',serif;color:#3D4251;padding:0 0 0 1em;}
.markdown ul+p,.markdown ol+p,.markdown ul+div,.markdown ol+div,.markdown ul+pre,.markdown ol+pre{margin-top:1.5em !important;}
.markdown div.datacamp-exercise ul,.markdown div.datacamp-exercise ol{background-color:initial;margin:initial;padding:initial;width:initial;list-style-position:initial;line-height:initial;}
.markdown ul.oneliner,.markdown ol.oneliner{padding:0;list-style-position:inside;line-height:1.5em;}
.markdown li{line-height:1.8em;}
.markdown li+li{margin-top:1em;}
.markdown div.datacamp-exercise li{padding-left:initial;background-color:initial;font-size:initial;font-weight:initial;line-height:initial;}
.markdown li p{margin:0;font-size:1em;line-height:1.8em;}
.markdown ul.oneliner li,.markdown ol.oneliner li{padding-left:0;white-space:nowrap;text-overflow:ellipsis;overflow:hidden;}
.markdown ul ul{margin:0;list-style:circle;}
.markdown ol ol{margin:0;}
.markdown ol ul,.markdown ul ol{margin:0;}
.markdown a{font-weight:400;text-decoration:none;color:#33AACC;}
.markdown a:hover{text-decoration:underline;}
.markdown div.datacamp-exercise a{font-weight:initial;text-decoration:initial;}
.markdown div.datacamp-exercise a:hover{text-decoration:initial;}
.markdown div.datacamp-exercise li+li{margin-top:unset;}
.markdown blockquote{margin:1.5em 0;font-family:'Lato',sans-serif;color:#3D4251;font-weight:300;font-size:1.5em;font-style:italic;line-height:2em;}
.markdown blockquote::before{display:block;margin-bottom:15px;width:35px;height:35px;font-family:'Lora',serif;font-size:36px;font-weight:bold;font-style:normal;line-height:60px;text-align:center;color:#33AACC;content:'“';border:1px solid #E3E7E8;border-radius:50%;}
.markdown table{width:100% !important;border:1px solid #E3E7E8;border-radius:4px;overflow:hidden;border-collapse:separate;border-spacing:0;}
.markdown table th,.markdown table td{padding:0.75em;}
.markdown table tr th,.markdown table tr td{border:1px solid #E3E7E8;vertical-align:middle;}
.markdown table thead tr th{font-family:'Lato',sans-serif;background-color:#F0F4F5;}
.markdown table tr:nth-child(even){background-color:#F0F4F5;}
.markdown table+p{margin-top:1.5em !important;}
.markdown table+img{margin-top:1.5em !important;}
.markdown table+div{margin-top:1.5em !important;}
.markdown .dcl-content--tab-body{margin-top:0 !important;}
@media (min-width:800px) and (min-height:650px){.markdown{font-size:20px;padding:0;}.markdown h2,.markdown h3,.markdown h4{margin:1.5em 0 0.5em;}.markdown p{margin:0;}.markdown li p{font-size:inherit;line-height:inherit;}.markdown ul+p,.markdown ol+p,.markdown ul+div,.markdown ol+div,.markdown ul+pre,.markdown ol+pre{margin-top:1.5em !important;}.markdown blockquote{position:relative;margin:50px 55px;}.markdown blockquote::before{position:absolute;left:-55px;}}
.output_wrapper{overflow-x:auto;-webkit-overflow-scrolling:touch;}</style><style id="__jsx-2410884478">.RecommendedCard.jsx-2410884478{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;background-color:#FFFFFF;border-radius:4px;border:solid 1px #e3e7e8;overflow:hidden;cursor:pointer;-webkit-transition:all 0.15s ease-in-out;transition:all 0.15s ease-in-out;}
.RecommendedCard.jsx-2410884478:hover{box-shadow: 0 18px 21px 0 rgba(22, 63, 82, 0.15);transform: translate(0,-5px);transition: all 0.2s ease-in-out;}
h2.jsx-2410884478{height:52px;overflow:hidden;font-size:20px;}
.image.jsx-2410884478{background-size:cover;background-position:center;height:144px;}
.info.jsx-2410884478{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;padding:20px;}
.space.jsx-2410884478{-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;}
.authorWrapper.jsx-2410884478{margin:16px 0;}
@media (min-width:800px) and (min-height:650px){.info.noImage.jsx-2410884478{-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;}h2.jsx-2410884478{margin-bottom:0px;}.topCard.jsx-2410884478 .image.jsx-2410884478{height:170px;}}</style><style id="__jsx-3259579870">.RecommendedArticles.jsx-3259579870{margin:0 10px 30px;}
.articleWrapper.jsx-3259579870{margin-bottom:20px;}
.title.jsx-3259579870{text-transform:uppercase;font-size:13px;font-weight:bold;-webkit-letter-spacing:1px;-moz-letter-spacing:1px;-ms-letter-spacing:1px;letter-spacing:1px;text-align:left;color:#686F75;margin-bottom:10px;}
.articleWrapper.jsx-3259579870 .description{display:none !important;}
@media (min-width:800px) and (min-height:650px){.articleWrapper.jsx-3259579870 .description{display:inline-block;}.RecommendedArticles.jsx-3259579870{max-width:1120px;margin:0 auto;padding-bottom:30px;}.articleLayout.jsx-3259579870{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-align-items:stretch;-webkit-box-align:stretch;-ms-flex-align:stretch;align-items:stretch;}.articleWrapper.jsx-3259579870{margin:0;-webkit-flex-basis:346px;-ms-flex-preferred-size:346px;flex-basis:346px;}.articleWrapper.jsx-3259579870:nth-child(2){margin:0 41px;}.articleWrapper.jsx-3259579870>div{height:100%;}}</style><style id="__jsx-3269835606">.SidebarSocial.jsx-3269835606{-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;font-size:11px;font-weight:bold;}
.rss.jsx-3269835606{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;line-height:50px;}
.rss.jsx-3269835606 svg{padding-right:7px;fill:#FFC844;}
.rss.jsx-3269835606 a.jsx-3269835606{text-decoration:none;color:#FFFFFF;}
.rss.jsx-3269835606 a.jsx-3269835606:hover{text-decoration:none;color:#FFC844;}
.icons.jsx-3269835606{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}
.icon.jsx-3269835606{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;margin:0 7px;width:30px;height:30px;background-color:#195B73;border-radius:50%;}
.icon.jsx-3269835606 svg{fill:#7ECCE2;-webkit-align-self:center;-ms-flex-item-align:center;align-self:center;-webkit-flex:1 1 0;-ms-flex:1 1 0;flex:1 1 0;}
.icon.jsx-3269835606:hover svg{fill:#FFFFFF;}
.menu.jsx-3269835606{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;line-height:44px;}
.menuItem.jsx-3269835606{-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;padding:5px;text-decoration:none;color:#195B73;}
.menuItem--active.jsx-3269835606,a.jsx-3269835606:hover{color:#F0F4F5;}
@media (min-width:800px) and (min-height:650px){.SidebarSocial.jsx-3269835606{width:220px;position:fixed;bottom:0;left:0;}}</style><style id="__jsx-3994298077">.BottomBar.jsx-3994298077{position:fixed;bottom:0;width:100vw;padding:15px;z-index:300;background-color:#FFFFFF;box-shadow:0 -2px 26px 0 rgba(168,168,168,0.5);}
.BottomBar.editor.jsx-3994298077{padding-top:5px;}
.barView.jsx-3994298077{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:start;-webkit-justify-content:flex-start;-ms-flex-pack:start;justify-content:flex-start;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}
.editor.jsx-3994298077 .barView.jsx-3994298077{display:none;}
.blueBar.jsx-3994298077{-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;height:50px;margin-left:15px;padding:0 15px;color:#33AACC;line-height:50px;border-radius:4px;background-color:#ebf4f7;}
.editorView.jsx-3994298077{-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;}
.editorView.jsx-3994298077 .avatar{display:none;}
.bar.jsx-3994298077 .editorView.jsx-3994298077{display:none;}
.hideBar.jsx-3994298077{display:none;}
@media (min-width:800px) and (min-height:650px){.BottomBar.jsx-3994298077{width:calc(100% - 220px);margin-left:220px;}.editorView.jsx-3994298077 .avatar{display:block;}}</style><style id="__jsx-1902599493">.Layout.jsx-1902599493{-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-box-pack:start;-webkit-justify-content:flex-start;-ms-flex-pack:start;justify-content:flex-start;-webkit-align-items:stretch;-webkit-box-align:stretch;-ms-flex-align:stretch;align-items:stretch;}
.Layout--openMenu.jsx-1902599493{min-height:100vh;}
.Main.jsx-1902599493{min-height:100vh;-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;background-color:#F0F4F5;}
.Layout--banner.jsx-1902599493 .Main.jsx-1902599493{margin-top:55px;min-height:calc(100vh - 55px);}
.Layout.bar.jsx-1902599493:not(.Layout--openMenu) .SidebarSocial{margin-bottom:90px;}
.Layout.editor.jsx-1902599493:not(.Layout--openMenu) .SidebarSocial{margin-bottom:300px;}
@media (min-width:800px) and (min-height:650px){.Main.jsx-1902599493{margin-left:220px;}.Layout--banner.jsx-1902599493 .Main.jsx-1902599493{margin-top:80px;min-height:calc(100vh - 80px);}.Layout.bar.jsx-1902599493:not(.Layout--openMenu) .SidebarSocial,.Layout.editor.jsx-1902599493:not(.Layout--openMenu) .SidebarSocial{margin-bottom:0;}.Layout.bar.jsx-1902599493 .Main > div:last-child{margin-bottom:90px;}.Layout.editor.jsx-1902599493 .Main > div:last-child{margin-bottom:300px;}}</style><style id="__jsx-1448759959">.Tutorial.jsx-1448759959{margin:0 0px 30px;padding:20px 0 0;background-color:#FFFFFF;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}
.preface.jsx-1448759959{margin:0 20px;}
.author.jsx-1448759959{margin-bottom:10px;}
h1.jsx-1448759959{margin-top:20px;}
.illustration.jsx-1448759959{margin-bottom:30px;}
.illustration.jsx-1448759959 img.jsx-1448759959{max-width:100%;}
.Tutorial.jsx-1448759959 .social__top .voteAndSocial,.social__bottom.jsx-1448759959 .voteAndSocial.jsx-1448759959{padding:40px 20px 20px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;-webkit-align-items:flex-end;-webkit-box-align:flex-end;-ms-flex-align:flex-end;align-items:flex-end;}
.Tutorial.jsx-1448759959 .voteAndSocial.jsx-1448759959>div.jsx-1448759959{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:start;-webkit-justify-content:flex-start;-ms-flex-pack:start;justify-content:flex-start;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}
.Tutorial.jsx-1448759959 .voteAndSocial.jsx-1448759959>div.jsx-1448759959 .CommentCounter{margin-left:10px;}
@media (min-width:800px) and (min-height:650px){.Tutorial.jsx-1448759959{margin:0 auto 30px;padding:30px 100px 100px;max-width:1120px;border-radius:4px;border:1px solid #E3E7E8;}.preface.jsx-1448759959{margin:0;}.Tutorial.jsx-1448759959 .social__top{position:absolute;margin-top:220px;}.Tutorial.jsx-1448759959 .social__top .voteAndSocial{position:absolute;left:-100px;top:0;width:100px;height:auto;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-box-pack:start;-webkit-justify-content:flex-start;-ms-flex-pack:start;justify-content:flex-start;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}.Tutorial.jsx-1448759959 .voteAndSocial.jsx-1448759959>div.jsx-1448759959{-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}.Tutorial.jsx-1448759959 .voteAndSocial > div .CommentCounter{margin-left:0;margin-bottom:10px;}}</style><style id="__jsx-2361248863">*{box-sizing:border-box;}
html,body{min-height:100vh;margin:0;padding:0;background-image: linear-gradient(207deg, #2388B0, #33AACC); background-size: 100vw 100vh; background-attachment: fixed; background-repeat: no-repeat;}
body.ReactModal__Body--open{overflow:hidden;}
.ReactModal__Content{width:100%;}
img{margin:auto;}
.mobileOnlyShow{display:block !important;}
.mobileOnlyHide{display:none !important;}
.mobileOnly{display:block !important;}
.desktopOnly{display:none !important;}
@media (min-width:800px) and (min-height:650px){body{background-image: linear-gradient(207deg, #2388B0, #33AACC); background-size: 220px 100vh; background-attachment: fixed; background-repeat: no-repeat;}.ReactModal__Content{width:auto;}.mobileOnlyShow{display:block !important;}.mobileOnlyHide{display:block !important;}.mobileOnly{display:none !important;}.desktopOnly{display:block !important;}}</style><style id="__jsx-1302975859">body,input,button,select,textarea{font-family:'Lato',sans-serif;color:#686F75;font-size:15px;}
h1,.h1,h2,h3,h4,h5{font-family:'Lato',sans-serif;}
.pageTitle{font-family:'Lato',sans-serif;font-size:32px;font-weight:bold;line-height:1.3em;margin-bottom:0.5em;}
.pageDescription{font-family:'Lora',serif;font-size:20.8px;line-height:1.5em;margin-bottom:1.4em;color:#3D4251;}
h1,.h1{font-size:29px;color:#3D4251;font-weight:bold;}
h2{font-size:20px;-webkit-letter-spacing:0.3px;-moz-letter-spacing:0.3px;-ms-letter-spacing:0.3px;letter-spacing:0.3px;line-height:1.33;font-weight:bold;margin:18px 0px;color:#3D4251;}
h2.blue{color:#33AACC;}
a{color:#33AACC;text-decoration:none;}
.blocText{font-size:15px;-webkit-letter-spacing:0.2px;-moz-letter-spacing:0.2px;-ms-letter-spacing:0.2px;letter-spacing:0.2px;line-height:1.47;color:#686F75;}
label{display:block;width:100%;margin-bottom:8px;font-size:13px;}
label span{float:right;font-weight:300;}
input,textarea{padding:15px;font-weight:300;color:#3D4251;background-color:#F0F4F5;border:1px solid transparent;border-radius:4px;outline-style:none;}
input:disabled,textarea:disabled{color:#686F75;background-color:#E6EAEB;}
input.error,textarea.error{border:1px solid #FE5C5C;}
input:focus,textarea:focus{border:1px solid #33AACC;-webkit-transition:border 150ms ease-out;transition:border 150ms ease-out;}
input::-webkit-input-placeholder,textarea::-webkit-input-placeholder{color:#33AACC;-webkit-transition:color 150ms ease-out;transition:color 150ms ease-out;}
input::-moz-placeholder,textarea::-moz-placeholder{color:#33AACC;-webkit-transition:color 150ms ease-out;transition:color 150ms ease-out;}
input:-ms-input-placeholder,textarea:-ms-input-placeholder{color:#33AACC;-webkit-transition:color 150ms ease-out;transition:color 150ms ease-out;}
input::placeholder,textarea::placeholder{color:#33AACC;-webkit-transition:color 150ms ease-out;transition:color 150ms ease-out;}
input:focus::-webkit-input-placeholder,textarea:focus::-webkit-input-placeholder{color:transparent;}
input:focus::-moz-placeholder,textarea:focus::-moz-placeholder{color:transparent;}
input:focus:-ms-input-placeholder,textarea:focus:-ms-input-placeholder{color:transparent;}
input:focus::placeholder,textarea:focus::placeholder{color:transparent;}
input.small,textarea.small{margin-bottom:19px;padding:8px 10px;font-size:13px;}
textarea.small{min-height:55px;}
@media (min-width:800px) and (min-height:650px){h1,.h1{font-size:36px;}h2{font-size:32px;}.pageTitle{font-size:40px;}.pageDescription{font-size:26px;}}</style><script async="" src="./Convolutional Neural Networks in Python (article) - DataCamp_files/datacamp-light-latest.min.js"></script><script async="" src="./Convolutional Neural Networks in Python (article) - DataCamp_files/highlight.min.js"></script><script async="" src="./Convolutional Neural Networks in Python (article) - DataCamp_files/MathJax.js"></script><style type="text/css" data-styled-jsx=""></style><style type="text/css">div.datacamp-exercise {  margin: 0;  border: 1px solid #d5eaef;  background: none;  position: relative;  min-height: 300px;  color: black;  box-shadow: none;}div[data-datacamp-exercise] {  margin: 0;  border: 1px solid #d5eaef;  background: #fff url(https://cdn.datacamp.com/spinner.gif) no-repeat center center !important;  background-size: auto 80px !important;  position: relative;  min-height: 300px;  color: transparent;  box-shadow: none;}div[data-datacamp-exercise] > code,div[data-datacamp-exercise] > div,div[data-datacamp-exercise] > p {  display: none;}div.powered-by-datacamp {  margin: 5px 0;  display: block;}div.powered-by-datacamp a {@import "https://fonts.googleapis.com/css?family=Open+Sans";  font-family: "Open Sans", sans-serif;  text-decoration: none;  border: 0;  color: #3ac;  font-size: 20px;}div.powered-by-datacamp .logo {  vertical-align: sub;  display: inline-block;  background: url("https://cdn.datacamp.com/dcl/assets/images/logo_blue.svg") no-repeat center center;  background-size: contain;  height: 27px;  width: 23px;  margin-left: 4px;}</style><link type="text/css" rel="stylesheet" href="./Convolutional Neural Networks in Python (article) - DataCamp_files/style-8c2f2e17fe.css"><link type="text/css" rel="stylesheet" href="./Convolutional Neural Networks in Python (article) - DataCamp_files/font-awesome.min.css"><style id="ace_editor.css">.ace_editor {position: relative;overflow: hidden;font: 12px/normal 'Monaco', 'Menlo', 'Ubuntu Mono', 'Consolas', 'source-code-pro', monospace;direction: ltr;text-align: left;}.ace_scroller {position: absolute;overflow: hidden;top: 0;bottom: 0;background-color: inherit;-ms-user-select: none;-moz-user-select: none;-webkit-user-select: none;user-select: none;cursor: text;}.ace_content {position: absolute;-moz-box-sizing: border-box;-webkit-box-sizing: border-box;box-sizing: border-box;min-width: 100%;}.ace_dragging .ace_scroller:before{position: absolute;top: 0;left: 0;right: 0;bottom: 0;content: '';background: rgba(250, 250, 250, 0.01);z-index: 1000;}.ace_dragging.ace_dark .ace_scroller:before{background: rgba(0, 0, 0, 0.01);}.ace_selecting, .ace_selecting * {cursor: text !important;}.ace_gutter {position: absolute;overflow : hidden;width: auto;top: 0;bottom: 0;left: 0;cursor: default;z-index: 4;-ms-user-select: none;-moz-user-select: none;-webkit-user-select: none;user-select: none;}.ace_gutter-active-line {position: absolute;left: 0;right: 0;}.ace_scroller.ace_scroll-left {box-shadow: 17px 0 16px -16px rgba(0, 0, 0, 0.4) inset;}.ace_gutter-cell {padding-left: 19px;padding-right: 6px;background-repeat: no-repeat;}.ace_gutter-cell.ace_error {background-image: url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAMAAAAoLQ9TAAABOFBMVEX/////////QRswFAb/Ui4wFAYwFAYwFAaWGAfDRymzOSH/PxswFAb/SiUwFAYwFAbUPRvjQiDllog5HhHdRybsTi3/Tyv9Tir+Syj/UC3////XurebMBIwFAb/RSHbPx/gUzfdwL3kzMivKBAwFAbbvbnhPx66NhowFAYwFAaZJg8wFAaxKBDZurf/RB6mMxb/SCMwFAYwFAbxQB3+RB4wFAb/Qhy4Oh+4QifbNRcwFAYwFAYwFAb/QRzdNhgwFAYwFAbav7v/Uy7oaE68MBK5LxLewr/r2NXewLswFAaxJw4wFAbkPRy2PyYwFAaxKhLm1tMwFAazPiQwFAaUGAb/QBrfOx3bvrv/VC/maE4wFAbRPBq6MRO8Qynew8Dp2tjfwb0wFAbx6eju5+by6uns4uH9/f36+vr/GkHjAAAAYnRSTlMAGt+64rnWu/bo8eAA4InH3+DwoN7j4eLi4xP99Nfg4+b+/u9B/eDs1MD1mO7+4PHg2MXa347g7vDizMLN4eG+Pv7i5evs/v79yu7S3/DV7/498Yv24eH+4ufQ3Ozu/v7+y13sRqwAAADLSURBVHjaZc/XDsFgGIBhtDrshlitmk2IrbHFqL2pvXf/+78DPokj7+Fz9qpU/9UXJIlhmPaTaQ6QPaz0mm+5gwkgovcV6GZzd5JtCQwgsxoHOvJO15kleRLAnMgHFIESUEPmawB9ngmelTtipwwfASilxOLyiV5UVUyVAfbG0cCPHig+GBkzAENHS0AstVF6bacZIOzgLmxsHbt2OecNgJC83JERmePUYq8ARGkJx6XtFsdddBQgZE2nPR6CICZhawjA4Fb/chv+399kfR+MMMDGOQAAAABJRU5ErkJggg==");background-repeat: no-repeat;background-position: 2px center;}.ace_gutter-cell.ace_warning {background-image: url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAMAAAAoLQ9TAAAAmVBMVEX///8AAAD///8AAAAAAABPSzb/5sAAAAB/blH/73z/ulkAAAAAAAD85pkAAAAAAAACAgP/vGz/rkDerGbGrV7/pkQICAf////e0IsAAAD/oED/qTvhrnUAAAD/yHD/njcAAADuv2r/nz//oTj/p064oGf/zHAAAAA9Nir/tFIAAAD/tlTiuWf/tkIAAACynXEAAAAAAAAtIRW7zBpBAAAAM3RSTlMAABR1m7RXO8Ln31Z36zT+neXe5OzooRDfn+TZ4p3h2hTf4t3k3ucyrN1K5+Xaks52Sfs9CXgrAAAAjklEQVR42o3PbQ+CIBQFYEwboPhSYgoYunIqqLn6/z8uYdH8Vmdnu9vz4WwXgN/xTPRD2+sgOcZjsge/whXZgUaYYvT8QnuJaUrjrHUQreGczuEafQCO/SJTufTbroWsPgsllVhq3wJEk2jUSzX3CUEDJC84707djRc5MTAQxoLgupWRwW6UB5fS++NV8AbOZgnsC7BpEAAAAABJRU5ErkJggg==");background-position: 2px center;}.ace_gutter-cell.ace_info {background-image: url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAAAAAA6mKC9AAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAAJ0Uk5TAAB2k804AAAAPklEQVQY02NgIB68QuO3tiLznjAwpKTgNyDbMegwisCHZUETUZV0ZqOquBpXj2rtnpSJT1AEnnRmL2OgGgAAIKkRQap2htgAAAAASUVORK5CYII=");background-position: 2px center;}.ace_dark .ace_gutter-cell.ace_info {background-image: url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQBAMAAADt3eJSAAAAJFBMVEUAAAChoaGAgIAqKiq+vr6tra1ZWVmUlJSbm5s8PDxubm56enrdgzg3AAAAAXRSTlMAQObYZgAAAClJREFUeNpjYMAPdsMYHegyJZFQBlsUlMFVCWUYKkAZMxZAGdxlDMQBAG+TBP4B6RyJAAAAAElFTkSuQmCC");}.ace_scrollbar {position: absolute;right: 0;bottom: 0;z-index: 6;}.ace_scrollbar-inner {position: absolute;cursor: text;left: 0;top: 0;}.ace_scrollbar-v{overflow-x: hidden;overflow-y: scroll;top: 0;}.ace_scrollbar-h {overflow-x: scroll;overflow-y: hidden;left: 0;}.ace_print-margin {position: absolute;height: 100%;}.ace_text-input {position: absolute;z-index: 0;width: 0.5em;height: 1em;opacity: 0;background: transparent;-moz-appearance: none;appearance: none;border: none;resize: none;outline: none;overflow: hidden;font: inherit;padding: 0 1px;margin: 0 -1px;text-indent: -1em;-ms-user-select: text;-moz-user-select: text;-webkit-user-select: text;user-select: text;white-space: pre!important;}.ace_text-input.ace_composition {background: inherit;color: inherit;z-index: 1000;opacity: 1;text-indent: 0;}.ace_layer {z-index: 1;position: absolute;overflow: hidden;word-wrap: normal;white-space: pre;height: 100%;width: 100%;-moz-box-sizing: border-box;-webkit-box-sizing: border-box;box-sizing: border-box;pointer-events: none;}.ace_gutter-layer {position: relative;width: auto;text-align: right;pointer-events: auto;}.ace_text-layer {font: inherit !important;}.ace_cjk {display: inline-block;text-align: center;}.ace_cursor-layer {z-index: 4;}.ace_cursor {z-index: 4;position: absolute;-moz-box-sizing: border-box;-webkit-box-sizing: border-box;box-sizing: border-box;border-left: 2px solid;transform: translatez(0);}.ace_slim-cursors .ace_cursor {border-left-width: 1px;}.ace_overwrite-cursors .ace_cursor {border-left-width: 0;border-bottom: 1px solid;}.ace_hidden-cursors .ace_cursor {opacity: 0.2;}.ace_smooth-blinking .ace_cursor {-webkit-transition: opacity 0.18s;transition: opacity 0.18s;}.ace_editor.ace_multiselect .ace_cursor {border-left-width: 1px;}.ace_marker-layer .ace_step, .ace_marker-layer .ace_stack {position: absolute;z-index: 3;}.ace_marker-layer .ace_selection {position: absolute;z-index: 5;}.ace_marker-layer .ace_bracket {position: absolute;z-index: 6;}.ace_marker-layer .ace_active-line {position: absolute;z-index: 2;}.ace_marker-layer .ace_selected-word {position: absolute;z-index: 4;-moz-box-sizing: border-box;-webkit-box-sizing: border-box;box-sizing: border-box;}.ace_line .ace_fold {-moz-box-sizing: border-box;-webkit-box-sizing: border-box;box-sizing: border-box;display: inline-block;height: 11px;margin-top: -2px;vertical-align: middle;background-image:url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABEAAAAJCAYAAADU6McMAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAJpJREFUeNpi/P//PwOlgAXGYGRklAVSokD8GmjwY1wasKljQpYACtpCFeADcHVQfQyMQAwzwAZI3wJKvCLkfKBaMSClBlR7BOQikCFGQEErIH0VqkabiGCAqwUadAzZJRxQr/0gwiXIal8zQQPnNVTgJ1TdawL0T5gBIP1MUJNhBv2HKoQHHjqNrA4WO4zY0glyNKLT2KIfIMAAQsdgGiXvgnYAAAAASUVORK5CYII="),url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAA3CAYAAADNNiA5AAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAACJJREFUeNpi+P//fxgTAwPDBxDxD078RSX+YeEyDFMCIMAAI3INmXiwf2YAAAAASUVORK5CYII=");background-repeat: no-repeat, repeat-x;background-position: center center, top left;color: transparent;border: 1px solid black;border-radius: 2px;cursor: pointer;pointer-events: auto;}.ace_dark .ace_fold {}.ace_fold:hover{background-image:url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABEAAAAJCAYAAADU6McMAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAJpJREFUeNpi/P//PwOlgAXGYGRklAVSokD8GmjwY1wasKljQpYACtpCFeADcHVQfQyMQAwzwAZI3wJKvCLkfKBaMSClBlR7BOQikCFGQEErIH0VqkabiGCAqwUadAzZJRxQr/0gwiXIal8zQQPnNVTgJ1TdawL0T5gBIP1MUJNhBv2HKoQHHjqNrA4WO4zY0glyNKLT2KIfIMAAQsdgGiXvgnYAAAAASUVORK5CYII="),url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAA3CAYAAADNNiA5AAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAACBJREFUeNpi+P//fz4TAwPDZxDxD5X4i5fLMEwJgAADAEPVDbjNw87ZAAAAAElFTkSuQmCC");}.ace_tooltip {background-color: #FFF;background-image: -webkit-linear-gradient(top, transparent, rgba(0, 0, 0, 0.1));background-image: linear-gradient(to bottom, transparent, rgba(0, 0, 0, 0.1));border: 1px solid gray;border-radius: 1px;box-shadow: 0 1px 2px rgba(0, 0, 0, 0.3);color: black;max-width: 100%;padding: 3px 4px;position: fixed;z-index: 999999;-moz-box-sizing: border-box;-webkit-box-sizing: border-box;box-sizing: border-box;cursor: default;white-space: pre;word-wrap: break-word;line-height: normal;font-style: normal;font-weight: normal;letter-spacing: normal;pointer-events: none;}.ace_folding-enabled > .ace_gutter-cell {padding-right: 13px;}.ace_fold-widget {-moz-box-sizing: border-box;-webkit-box-sizing: border-box;box-sizing: border-box;margin: 0 -12px 0 1px;display: none;width: 11px;vertical-align: top;background-image: url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAUAAAAFCAYAAACNbyblAAAANElEQVR42mWKsQ0AMAzC8ixLlrzQjzmBiEjp0A6WwBCSPgKAXoLkqSot7nN3yMwR7pZ32NzpKkVoDBUxKAAAAABJRU5ErkJggg==");background-repeat: no-repeat;background-position: center;border-radius: 3px;border: 1px solid transparent;cursor: pointer;}.ace_folding-enabled .ace_fold-widget {display: inline-block;   }.ace_fold-widget.ace_end {background-image: url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAUAAAAFCAYAAACNbyblAAAANElEQVR42m3HwQkAMAhD0YzsRchFKI7sAikeWkrxwScEB0nh5e7KTPWimZki4tYfVbX+MNl4pyZXejUO1QAAAABJRU5ErkJggg==");}.ace_fold-widget.ace_closed {background-image: url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAMAAAAGCAYAAAAG5SQMAAAAOUlEQVR42jXKwQkAMAgDwKwqKD4EwQ26sSOkVWjgIIHAzPiCgaqiqnJHZnKICBERHN194O5b9vbLuAVRL+l0YWnZAAAAAElFTkSuQmCCXA==");}.ace_fold-widget:hover {border: 1px solid rgba(0, 0, 0, 0.3);background-color: rgba(255, 255, 255, 0.2);box-shadow: 0 1px 1px rgba(255, 255, 255, 0.7);}.ace_fold-widget:active {border: 1px solid rgba(0, 0, 0, 0.4);background-color: rgba(0, 0, 0, 0.05);box-shadow: 0 1px 1px rgba(255, 255, 255, 0.8);}.ace_dark .ace_fold-widget {background-image: url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAUAAAAFCAYAAACNbyblAAAAHklEQVQIW2P4//8/AzoGEQ7oGCaLLAhWiSwB146BAQCSTPYocqT0AAAAAElFTkSuQmCC");}.ace_dark .ace_fold-widget.ace_end {background-image: url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAUAAAAFCAYAAACNbyblAAAAH0lEQVQIW2P4//8/AxQ7wNjIAjDMgC4AxjCVKBirIAAF0kz2rlhxpAAAAABJRU5ErkJggg==");}.ace_dark .ace_fold-widget.ace_closed {background-image: url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAMAAAAFCAYAAACAcVaiAAAAHElEQVQIW2P4//+/AxAzgDADlOOAznHAKgPWAwARji8UIDTfQQAAAABJRU5ErkJggg==");}.ace_dark .ace_fold-widget:hover {box-shadow: 0 1px 1px rgba(255, 255, 255, 0.2);background-color: rgba(255, 255, 255, 0.1);}.ace_dark .ace_fold-widget:active {box-shadow: 0 1px 1px rgba(255, 255, 255, 0.2);}.ace_fold-widget.ace_invalid {background-color: #FFB4B4;border-color: #DE5555;}.ace_fade-fold-widgets .ace_fold-widget {-webkit-transition: opacity 0.4s ease 0.05s;transition: opacity 0.4s ease 0.05s;opacity: 0;}.ace_fade-fold-widgets:hover .ace_fold-widget {-webkit-transition: opacity 0.05s ease 0.05s;transition: opacity 0.05s ease 0.05s;opacity:1;}.ace_underline {text-decoration: underline;}.ace_bold {font-weight: bold;}.ace_nobold .ace_bold {font-weight: normal;}.ace_italic {font-style: italic;}.ace_error-marker {background-color: rgba(255, 0, 0,0.2);position: absolute;z-index: 9;}.ace_highlight-marker {background-color: rgba(255, 255, 0,0.2);position: absolute;z-index: 8;}.ace_br1 {border-top-left-radius    : 3px;}.ace_br2 {border-top-right-radius   : 3px;}.ace_br3 {border-top-left-radius    : 3px; border-top-right-radius:    3px;}.ace_br4 {border-bottom-right-radius: 3px;}.ace_br5 {border-top-left-radius    : 3px; border-bottom-right-radius: 3px;}.ace_br6 {border-top-right-radius   : 3px; border-bottom-right-radius: 3px;}.ace_br7 {border-top-left-radius    : 3px; border-top-right-radius:    3px; border-bottom-right-radius: 3px;}.ace_br8 {border-bottom-left-radius : 3px;}.ace_br9 {border-top-left-radius    : 3px; border-bottom-left-radius:  3px;}.ace_br10{border-top-right-radius   : 3px; border-bottom-left-radius:  3px;}.ace_br11{border-top-left-radius    : 3px; border-top-right-radius:    3px; border-bottom-left-radius:  3px;}.ace_br12{border-bottom-right-radius: 3px; border-bottom-left-radius:  3px;}.ace_br13{border-top-left-radius    : 3px; border-bottom-right-radius: 3px; border-bottom-left-radius:  3px;}.ace_br14{border-top-right-radius   : 3px; border-bottom-right-radius: 3px; border-bottom-left-radius:  3px;}.ace_br15{border-top-left-radius    : 3px; border-top-right-radius:    3px; border-bottom-right-radius: 3px; border-bottom-left-radius: 3px;}
/*# sourceURL=ace/css/ace_editor.css */</style><style id="ace-tm">.ace-tm .ace_gutter {background: #f0f0f0;color: #333;}.ace-tm .ace_print-margin {width: 1px;background: #e8e8e8;}.ace-tm .ace_fold {background-color: #6B72E6;}.ace-tm {background-color: #FFFFFF;color: black;}.ace-tm .ace_cursor {color: black;}.ace-tm .ace_invisible {color: rgb(191, 191, 191);}.ace-tm .ace_storage,.ace-tm .ace_keyword {color: blue;}.ace-tm .ace_constant {color: rgb(197, 6, 11);}.ace-tm .ace_constant.ace_buildin {color: rgb(88, 72, 246);}.ace-tm .ace_constant.ace_language {color: rgb(88, 92, 246);}.ace-tm .ace_constant.ace_library {color: rgb(6, 150, 14);}.ace-tm .ace_invalid {background-color: rgba(255, 0, 0, 0.1);color: red;}.ace-tm .ace_support.ace_function {color: rgb(60, 76, 114);}.ace-tm .ace_support.ace_constant {color: rgb(6, 150, 14);}.ace-tm .ace_support.ace_type,.ace-tm .ace_support.ace_class {color: rgb(109, 121, 222);}.ace-tm .ace_keyword.ace_operator {color: rgb(104, 118, 135);}.ace-tm .ace_string {color: rgb(3, 106, 7);}.ace-tm .ace_comment {color: rgb(76, 136, 107);}.ace-tm .ace_comment.ace_doc {color: rgb(0, 102, 255);}.ace-tm .ace_comment.ace_doc.ace_tag {color: rgb(128, 159, 191);}.ace-tm .ace_constant.ace_numeric {color: rgb(0, 0, 205);}.ace-tm .ace_variable {color: rgb(49, 132, 149);}.ace-tm .ace_xml-pe {color: rgb(104, 104, 91);}.ace-tm .ace_entity.ace_name.ace_function {color: #0000A2;}.ace-tm .ace_heading {color: rgb(12, 7, 255);}.ace-tm .ace_list {color:rgb(185, 6, 144);}.ace-tm .ace_meta.ace_tag {color:rgb(0, 22, 142);}.ace-tm .ace_string.ace_regex {color: rgb(255, 0, 0)}.ace-tm .ace_marker-layer .ace_selection {background: rgb(181, 213, 255);}.ace-tm.ace_multiselect .ace_selection.ace_start {box-shadow: 0 0 3px 0px white;}.ace-tm .ace_marker-layer .ace_step {background: rgb(252, 255, 0);}.ace-tm .ace_marker-layer .ace_stack {background: rgb(164, 229, 101);}.ace-tm .ace_marker-layer .ace_bracket {margin: -1px 0 0 -1px;border: 1px solid rgb(192, 192, 192);}.ace-tm .ace_marker-layer .ace_active-line {background: rgba(0, 0, 0, 0.07);}.ace-tm .ace_gutter-active-line {background-color : #dcdcdc;}.ace-tm .ace_marker-layer .ace_selected-word {background: rgb(250, 250, 255);border: 1px solid rgb(200, 200, 250);}.ace-tm .ace_indent-guide {background: url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAACCAYAAACZgbYnAAAAE0lEQVQImWP4////f4bLly//BwAmVgd1/w11/gAAAABJRU5ErkJggg==") right repeat-y;}
/*# sourceURL=ace/css/ace-tm */</style><style>    .error_widget_wrapper {        background: inherit;        color: inherit;        border:none    }    .error_widget {        border-top: solid 2px;        border-bottom: solid 2px;        margin: 5px 0;        padding: 10px 40px;        white-space: pre-wrap;    }    .error_widget.ace_error, .error_widget_arrow.ace_error{        border-color: #ff5a5a    }    .error_widget.ace_warning, .error_widget_arrow.ace_warning{        border-color: #F1D817    }    .error_widget.ace_info, .error_widget_arrow.ace_info{        border-color: #5a5a5a    }    .error_widget.ace_ok, .error_widget_arrow.ace_ok{        border-color: #5aaa5a    }    .error_widget_arrow {        position: absolute;        border: solid 5px;        border-top-color: transparent!important;        border-right-color: transparent!important;        border-left-color: transparent!important;        top: -5px;    }</style><style>.ace_snippet-marker {    -moz-box-sizing: border-box;    box-sizing: border-box;    background: rgba(194, 193, 208, 0.09);    border: 1px dotted rgba(211, 208, 235, 0.62);    position: absolute;}</style><style>.ace_editor.ace_autocomplete .ace_marker-layer .ace_active-line {    background-color: #CAD6FA;    z-index: 1;}.ace_editor.ace_autocomplete .ace_line-hover {    border: 1px solid #abbffe;    margin-top: -1px;    background: rgba(233,233,253,0.4);}.ace_editor.ace_autocomplete .ace_line-hover {    position: absolute;    z-index: 2;}.ace_editor.ace_autocomplete .ace_scroller {   background: none;   border: none;   box-shadow: none;}.ace_rightAlignedText {    color: gray;    display: inline-block;    position: absolute;    right: 4px;    text-align: right;    z-index: -1;}.ace_editor.ace_autocomplete .ace_completion-highlight{    color: #000;    text-shadow: 0 0 0.01em;}.ace_editor.ace_autocomplete {    width: 280px;    z-index: 200000;    background: #fbfbfb;    color: #444;    border: 1px lightgray solid;    position: fixed;    box-shadow: 2px 3px 5px rgba(0,0,0,.2);    line-height: 1.4;}</style><style type="text/css">.MathJax_Hover_Frame {border-radius: .25em; -webkit-border-radius: .25em; -moz-border-radius: .25em; -khtml-border-radius: .25em; box-shadow: 0px 0px 15px #83A; -webkit-box-shadow: 0px 0px 15px #83A; -moz-box-shadow: 0px 0px 15px #83A; -khtml-box-shadow: 0px 0px 15px #83A; border: 1px solid #A6D ! important; display: inline-block; position: absolute}
.MathJax_Menu_Button .MathJax_Hover_Arrow {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 4px; -webkit-border-radius: 4px; -moz-border-radius: 4px; -khtml-border-radius: 4px; font-family: 'Courier New',Courier; font-size: 9px; color: #F0F0F0}
.MathJax_Menu_Button .MathJax_Hover_Arrow span {display: block; background-color: #AAA; border: 1px solid; border-radius: 3px; line-height: 0; padding: 4px}
.MathJax_Hover_Arrow:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_Hover_Arrow:hover span {background-color: #CCC!important}
</style><style type="text/css">#MathJax_About {position: fixed; left: 50%; width: auto; text-align: center; border: 3px outset; padding: 1em 2em; background-color: #DDDDDD; color: black; cursor: default; font-family: message-box; font-size: 120%; font-style: normal; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 15px; -webkit-border-radius: 15px; -moz-border-radius: 15px; -khtml-border-radius: 15px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_About.MathJax_MousePost {outline: none}
.MathJax_Menu {position: absolute; background-color: white; color: black; width: auto; padding: 5px 0px; border: 1px solid #CCCCCC; margin: 0; cursor: default; font: menu; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 5px; -webkit-border-radius: 5px; -moz-border-radius: 5px; -khtml-border-radius: 5px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
.MathJax_MenuItem {padding: 1px 2em; background: transparent}
.MathJax_MenuArrow {position: absolute; right: .5em; padding-top: .25em; color: #666666; font-size: .75em}
.MathJax_MenuActive .MathJax_MenuArrow {color: white}
.MathJax_MenuArrow.RTL {left: .5em; right: auto}
.MathJax_MenuCheck {position: absolute; left: .7em}
.MathJax_MenuCheck.RTL {right: .7em; left: auto}
.MathJax_MenuRadioCheck {position: absolute; left: .7em}
.MathJax_MenuRadioCheck.RTL {right: .7em; left: auto}
.MathJax_MenuLabel {padding: 1px 2em 3px 1.33em; font-style: italic}
.MathJax_MenuRule {border-top: 1px solid #DDDDDD; margin: 4px 3px}
.MathJax_MenuDisabled {color: GrayText}
.MathJax_MenuActive {background-color: #606872; color: white}
.MathJax_MenuDisabled:focus, .MathJax_MenuLabel:focus {background-color: #E8E8E8}
.MathJax_ContextMenu:focus {outline: none}
.MathJax_ContextMenu .MathJax_MenuItem:focus {outline: none}
#MathJax_AboutClose {top: .2em; right: .2em}
.MathJax_Menu .MathJax_MenuClose {top: -10px; left: -10px}
.MathJax_MenuClose {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; font-family: 'Courier New',Courier; font-size: 24px; color: #F0F0F0}
.MathJax_MenuClose span {display: block; background-color: #AAA; border: 1.5px solid; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; line-height: 0; padding: 8px 0 6px}
.MathJax_MenuClose:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_MenuClose:hover span {background-color: #CCC!important}
.MathJax_MenuClose:hover:focus {outline: none}
</style><style type="text/css">.MathJax_Preview .MJXf-math {color: inherit!important}
</style><style type="text/css">.MJX_Assistive_MathML {position: absolute!important; top: 0; left: 0; clip: rect(1px, 1px, 1px, 1px); padding: 1px 0 0 0!important; border: 0!important; height: 1px!important; width: 1px!important; overflow: hidden!important; display: block!important; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none}
.MJX_Assistive_MathML.MJX_Assistive_MathML_Block {width: 100%!important}
</style><style type="text/css">#MathJax_Zoom {position: absolute; background-color: #F0F0F0; overflow: auto; display: block; z-index: 301; padding: .5em; border: 1px solid black; margin: 0; font-weight: normal; font-style: normal; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; -webkit-box-sizing: content-box; -moz-box-sizing: content-box; box-sizing: content-box; box-shadow: 5px 5px 15px #AAAAAA; -webkit-box-shadow: 5px 5px 15px #AAAAAA; -moz-box-shadow: 5px 5px 15px #AAAAAA; -khtml-box-shadow: 5px 5px 15px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_ZoomOverlay {position: absolute; left: 0; top: 0; z-index: 300; display: inline-block; width: 100%; height: 100%; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
#MathJax_ZoomFrame {position: relative; display: inline-block; height: 0; width: 0}
#MathJax_ZoomEventTrap {position: absolute; left: 0; top: 0; z-index: 302; display: inline-block; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
</style><script async="" src="./Convolutional Neural Networks in Python (article) - DataCamp_files/r.min.js"></script><style type="text/css">.MathJax_Preview {color: #888}
#MathJax_Message {position: fixed; left: 1em; bottom: 1.5em; background-color: #E6E6E6; border: 1px solid #959595; margin: 0px; padding: 2px 8px; z-index: 102; color: black; font-size: 80%; width: auto; white-space: nowrap}
#MathJax_MSIE_Frame {position: absolute; top: 0; left: 0; width: 0px; z-index: 101; border: 0px; margin: 0px; padding: 0px}
.MathJax_Error {color: #CC0000; font-style: italic}
</style><style type="text/css">.MJXp-script {font-size: .8em}
.MJXp-right {-webkit-transform-origin: right; -moz-transform-origin: right; -ms-transform-origin: right; -o-transform-origin: right; transform-origin: right}
.MJXp-bold {font-weight: bold}
.MJXp-italic {font-style: italic}
.MJXp-scr {font-family: MathJax_Script,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-frak {font-family: MathJax_Fraktur,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-sf {font-family: MathJax_SansSerif,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-cal {font-family: MathJax_Caligraphic,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-mono {font-family: MathJax_Typewriter,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-largeop {font-size: 150%}
.MJXp-largeop.MJXp-int {vertical-align: -.2em}
.MJXp-math {display: inline-block; line-height: 1.2; text-indent: 0; font-family: 'Times New Roman',Times,STIXGeneral,serif; white-space: nowrap; border-collapse: collapse}
.MJXp-display {display: block; text-align: center; margin: 1em 0}
.MJXp-math span {display: inline-block}
.MJXp-box {display: block!important; text-align: center}
.MJXp-box:after {content: " "}
.MJXp-rule {display: block!important; margin-top: .1em}
.MJXp-char {display: block!important}
.MJXp-mo {margin: 0 .15em}
.MJXp-mfrac {margin: 0 .125em; vertical-align: .25em}
.MJXp-denom {display: inline-table!important; width: 100%}
.MJXp-denom > * {display: table-row!important}
.MJXp-surd {vertical-align: top}
.MJXp-surd > * {display: block!important}
.MJXp-script-box > *  {display: table!important; height: 50%}
.MJXp-script-box > * > * {display: table-cell!important; vertical-align: top}
.MJXp-script-box > *:last-child > * {vertical-align: bottom}
.MJXp-script-box > * > * > * {display: block!important}
.MJXp-mphantom {visibility: hidden}
.MJXp-munderover {display: inline-table!important}
.MJXp-over {display: inline-block!important; text-align: center}
.MJXp-over > * {display: block!important}
.MJXp-munderover > * {display: table-row!important}
.MJXp-mtable {vertical-align: .25em; margin: 0 .125em}
.MJXp-mtable > * {display: inline-table!important; vertical-align: middle}
.MJXp-mtr {display: table-row!important}
.MJXp-mtd {display: table-cell!important; text-align: center; padding: .5em 0 0 .5em}
.MJXp-mtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-mlabeledtr {display: table-row!important}
.MJXp-mlabeledtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mlabeledtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
.MJXp-scale0 {-webkit-transform: scaleX(.0); -moz-transform: scaleX(.0); -ms-transform: scaleX(.0); -o-transform: scaleX(.0); transform: scaleX(.0)}
.MJXp-scale1 {-webkit-transform: scaleX(.1); -moz-transform: scaleX(.1); -ms-transform: scaleX(.1); -o-transform: scaleX(.1); transform: scaleX(.1)}
.MJXp-scale2 {-webkit-transform: scaleX(.2); -moz-transform: scaleX(.2); -ms-transform: scaleX(.2); -o-transform: scaleX(.2); transform: scaleX(.2)}
.MJXp-scale3 {-webkit-transform: scaleX(.3); -moz-transform: scaleX(.3); -ms-transform: scaleX(.3); -o-transform: scaleX(.3); transform: scaleX(.3)}
.MJXp-scale4 {-webkit-transform: scaleX(.4); -moz-transform: scaleX(.4); -ms-transform: scaleX(.4); -o-transform: scaleX(.4); transform: scaleX(.4)}
.MJXp-scale5 {-webkit-transform: scaleX(.5); -moz-transform: scaleX(.5); -ms-transform: scaleX(.5); -o-transform: scaleX(.5); transform: scaleX(.5)}
.MJXp-scale6 {-webkit-transform: scaleX(.6); -moz-transform: scaleX(.6); -ms-transform: scaleX(.6); -o-transform: scaleX(.6); transform: scaleX(.6)}
.MJXp-scale7 {-webkit-transform: scaleX(.7); -moz-transform: scaleX(.7); -ms-transform: scaleX(.7); -o-transform: scaleX(.7); transform: scaleX(.7)}
.MJXp-scale8 {-webkit-transform: scaleX(.8); -moz-transform: scaleX(.8); -ms-transform: scaleX(.8); -o-transform: scaleX(.8); transform: scaleX(.8)}
.MJXp-scale9 {-webkit-transform: scaleX(.9); -moz-transform: scaleX(.9); -ms-transform: scaleX(.9); -o-transform: scaleX(.9); transform: scaleX(.9)}
.MathJax_PHTML .noError {vertical-align: ; font-size: 90%; text-align: left; color: black; padding: 1px 3px; border: 1px solid}
</style></head><body><div id="MathJax_Message" style="display: none;"></div><div id="__next"><div data-reactroot=""><div class="Page content"><div class="jsx-1902599493 Layout bar"><div class="jsx-2803075824 SidebarMenu"><div class="jsx-2090414051 Logo"><a href="https://www.datacamp.com/" class="jsx-2090414051 Logo__image"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1367.47 306.77"><path d="M201.49 130.16c2.64-10.87 2.31-21.09-3.62-35.38 0 0 9.55 3.71 8.56-3.65S194.91 76 187 71.11c-3.48-2.17-12.89-6.79-25.52-9.6l2.36-5.32-.66-.32c-19.59-9.54-42.24-.89-42.47-.8l-.7.27 2.24 5.92a78 78 0 0 0-19 7.09C50 96.68 77 152 93.5 165.17s8.89 40 0 64.31H165c1-4.55.13 2.24 3.46-15.91s16.18-11.41 26.3-12 8.52-7.66 8.4-15.56c4.94-2.22 4.94-4.57 1.64-7.41 4.28-4 3.62-4 1.32-7.83s-.66-5.68-.66-5.68 6.92-1.35 7.9-5c.32-7.89-14.5-19.09-11.87-29.93zm-14.78-2.28l-10.59-3.6c-.56 1.45-6 14.9-13 17.27l-6.68-8.84c-3.21 2.51-10.54 4.72-14.07 3.69v-.32h-.19l.2 24.36c-14.05 1.45-30.84-7.06-38.88-18.77l-8.78 6.67c-10-12.07-11.51-26.62-11.62-35h11.77c0-9.27 3.62-21.34 8.72-28l9.23 6.52c.75-.93 7.72-9.27 17.05-12.28h.14l-6.67-17.64c14.09-4.06 24.44-4 35.7.19a3.87 3.87 0 0 1 1 .48l.18.13-1.99 5.26c.53.23 8 3.59 11.09 6.74l2.49-3.44a42.47 42.47 0 0 1 19 25.34L187 98v-.1a55.32 55.32 0 0 1-.28 29.98z"></path><path d="M141.69 95.69a11.77 11.77 0 1 0 11.76 11.77 11.78 11.78 0 0 0-11.76-11.77zM486.07 147.93a85.48 85.48 0 0 1-5.79 31.92 71.67 71.67 0 0 1-41.54 41.32 89 89 0 0 1-32.79 5.83h-60.24V68.9h60.23a88.33 88.33 0 0 1 32.79 5.85A74 74 0 0 1 464 91a72.76 72.76 0 0 1 16.29 25 85.49 85.49 0 0 1 5.78 31.93zm-30.17 0a73.61 73.61 0 0 0-3.44-23.34 48.4 48.4 0 0 0-9.95-17.49 43.45 43.45 0 0 0-15.74-11 54 54 0 0 0-20.82-3.83h-30.72v111.3h30.72a54 54 0 0 0 20.82-3.83 43.39 43.39 0 0 0 15.74-11 48.37 48.37 0 0 0 9.95-17.49 73.6 73.6 0 0 0 3.44-23.32zM505.36 130.44q19.35-17.71 46.57-17.71a45.54 45.54 0 0 1 17.6 3.22 37.21 37.21 0 0 1 13.12 9 38.4 38.4 0 0 1 8.14 13.72 52.72 52.72 0 0 1 2.79 17.49V227h-12.25a12.38 12.38 0 0 1-5.9-1.15q-2.08-1.15-3.28-4.65l-2.4-8.09a97.29 97.29 0 0 1-8.31 6.72 48.91 48.91 0 0 1-8.42 4.86 45.32 45.32 0 0 1-9.35 3 53.93 53.93 0 0 1-11 1 43.08 43.08 0 0 1-13.12-1.91 28.78 28.78 0 0 1-10.38-5.74 25.73 25.73 0 0 1-6.78-9.51 33.72 33.72 0 0 1-2.4-13.23 26.32 26.32 0 0 1 1.42-8.47 24.76 24.76 0 0 1 4.65-8 38.63 38.63 0 0 1 8.36-7.21 54.43 54.43 0 0 1 12.63-5.9 109.08 109.08 0 0 1 17.44-4.1 174.35 174.35 0 0 1 22.74-1.91v-6.56q0-11.26-4.81-16.67t-13.88-5.41a33 33 0 0 0-10.88 1.53 44.91 44.91 0 0 0-7.6 3.44q-3.28 1.91-6 3.44a11.78 11.78 0 0 1-6 1.53 7.79 7.79 0 0 1-4.81-1.48 12.33 12.33 0 0 1-3.17-3.44zm61.87 48.64a149.08 149.08 0 0 0-19.68 2 52.42 52.42 0 0 0-12.79 3.77 16.8 16.8 0 0 0-6.89 5.36 11.63 11.63 0 0 0-2.08 6.67q0 7.11 4.21 10.17t11 3.06a32 32 0 0 0 14.37-3 42.69 42.69 0 0 0 11.86-9.11zM657.79 228.72q-14.65 0-22.46-8.25t-7.82-22.79V135H616a5.26 5.26 0 0 1-3.72-1.42 5.53 5.53 0 0 1-1.53-4.26v-10.68l18-3 5.68-30.61a6 6 0 0 1 2.08-3.39 6.18 6.18 0 0 1 3.94-1.2h14v35.36h30V135h-30v60.78q0 5.25 2.57 8.2a8.85 8.85 0 0 0 7 3 12.7 12.7 0 0 0 4.21-.6 23 23 0 0 0 3-1.26q1.26-.66 2.24-1.26a3.75 3.75 0 0 1 2-.6 3.1 3.1 0 0 1 2 .6 9.23 9.23 0 0 1 1.64 1.8l8.09 13.12a40.87 40.87 0 0 1-13.55 7.43 50.47 50.47 0 0 1-15.86 2.51zM702.11 130.44q19.35-17.71 46.57-17.71a45.54 45.54 0 0 1 17.6 3.22 37.19 37.19 0 0 1 13.12 9 38.37 38.37 0 0 1 8.14 13.72 52.72 52.72 0 0 1 2.79 17.49V227h-12.25a12.37 12.37 0 0 1-5.9-1.15q-2.08-1.15-3.28-4.65l-2.4-8.09a97.21 97.21 0 0 1-8.31 6.72 49 49 0 0 1-8.42 4.86 45.33 45.33 0 0 1-9.35 3 53.92 53.92 0 0 1-11 1 43.08 43.08 0 0 1-13.12-1.91 28.78 28.78 0 0 1-10.38-5.74 25.74 25.74 0 0 1-6.78-9.51 33.72 33.72 0 0 1-2.4-13.23 26.31 26.31 0 0 1 1.42-8.47 24.76 24.76 0 0 1 4.65-8 38.66 38.66 0 0 1 8.36-7.21 54.45 54.45 0 0 1 12.63-5.9 109.07 109.07 0 0 1 17.44-4.1 174.32 174.32 0 0 1 22.76-1.93v-6.56q0-11.26-4.81-16.67t-13.88-5.41a33 33 0 0 0-10.88 1.53 44.89 44.89 0 0 0-7.6 3.44q-3.28 1.91-6 3.44a11.79 11.79 0 0 1-6 1.53 7.79 7.79 0 0 1-4.81-1.48 12.33 12.33 0 0 1-3.17-3.44zM764 179.09a149.06 149.06 0 0 0-19.68 2 52.43 52.43 0 0 0-12.79 3.77 16.81 16.81 0 0 0-6.89 5.36 11.63 11.63 0 0 0-2.08 6.67q0 7.11 4.21 10.17t11 3.06a32 32 0 0 0 14.37-3A42.68 42.68 0 0 0 764 198zM929.42 189.69a5.87 5.87 0 0 1 4.26 1.86l11.59 12.57a63.64 63.64 0 0 1-23.67 18.26q-14 6.34-33.72 6.34-17.6 0-31.65-6a69.71 69.71 0 0 1-24-16.73A73.19 73.19 0 0 1 817 180.4a96 96 0 0 1-5.3-32.47 90.36 90.36 0 0 1 5.68-32.63 75 75 0 0 1 16-25.52A72.5 72.5 0 0 1 858 73.11a81.77 81.77 0 0 1 31.7-6q17.27 0 30.66 5.68a73.08 73.08 0 0 1 22.83 14.91l-9.84 13.66a9 9 0 0 1-2.24 2.29 6.35 6.35 0 0 1-3.77 1 7.2 7.2 0 0 1-3.39-.93q-1.75-.93-3.83-2.29t-4.81-3a39.67 39.67 0 0 0-6.34-3 51.92 51.92 0 0 0-8.36-2.29 57.87 57.87 0 0 0-11-.93A48.74 48.74 0 0 0 870.23 96a42.16 42.16 0 0 0-15.14 10.93 50.38 50.38 0 0 0-9.84 17.49 73.27 73.27 0 0 0-3.5 23.56 69.25 69.25 0 0 0 3.77 23.72 52.12 52.12 0 0 0 10.22 17.49 43.61 43.61 0 0 0 15.2 10.81 47 47 0 0 0 18.8 3.77 81.89 81.89 0 0 0 10.88-.66 46.17 46.17 0 0 0 9-2.08 39.7 39.7 0 0 0 7.76-3.66 48.48 48.48 0 0 0 7.27-5.52 10.31 10.31 0 0 1 2.29-1.58 5.56 5.56 0 0 1 2.48-.58zM961.6 130.44q19.35-17.71 46.57-17.71a45.54 45.54 0 0 1 17.6 3.22 37.19 37.19 0 0 1 13.12 9 38.37 38.37 0 0 1 8.14 13.72 52.72 52.72 0 0 1 2.79 17.49V227h-12.24a12.37 12.37 0 0 1-5.9-1.15q-2.08-1.15-3.28-4.65l-2.4-8.09a97.21 97.21 0 0 1-8.31 6.72 49 49 0 0 1-8.42 4.86 45.33 45.33 0 0 1-9.35 3 53.92 53.92 0 0 1-11 1 43.08 43.08 0 0 1-13.12-1.91 28.78 28.78 0 0 1-10.38-5.74 25.74 25.74 0 0 1-6.78-9.51 33.73 33.73 0 0 1-2.4-13.23 26.31 26.31 0 0 1 1.42-8.47 24.76 24.76 0 0 1 4.65-8 38.66 38.66 0 0 1 8.36-7.21 54.45 54.45 0 0 1 12.63-5.9 109.07 109.07 0 0 1 17.44-4.1 174.32 174.32 0 0 1 22.74-1.91v-6.56q0-11.26-4.81-16.67t-13.88-5.41a33 33 0 0 0-10.88 1.53 44.89 44.89 0 0 0-7.6 3.44q-3.28 1.91-6 3.44a11.79 11.79 0 0 1-6 1.53 7.79 7.79 0 0 1-4.81-1.48 12.33 12.33 0 0 1-3.17-3.44zm61.87 48.64a149.06 149.06 0 0 0-19.68 2 52.43 52.43 0 0 0-12.79 3.8 16.81 16.81 0 0 0-6.89 5.36 11.63 11.63 0 0 0-2.08 6.67q0 7.11 4.21 10.17t11 3.06a32 32 0 0 0 14.37-3 42.68 42.68 0 0 0 11.86-9.13zM1078.18 227V114.81h16.51a6.63 6.63 0 0 1 6.89 4.92l1.75 8.31a63.82 63.82 0 0 1 6.18-6 39.66 39.66 0 0 1 6.89-4.7 37.29 37.29 0 0 1 7.87-3.12 35.05 35.05 0 0 1 9.24-1.15q10.6 0 17.43 5.74a34.56 34.56 0 0 1 10.22 15.25 34.23 34.23 0 0 1 6.56-9.57 35.9 35.9 0 0 1 8.63-6.5 39.77 39.77 0 0 1 10-3.72 48.07 48.07 0 0 1 10.66-1.2 44.82 44.82 0 0 1 16.51 2.84 31.69 31.69 0 0 1 12.13 8.31 36.63 36.63 0 0 1 7.49 13.34 58.1 58.1 0 0 1 2.57 18V227h-27v-71.41q0-10.71-4.7-16.12t-13.77-5.41a20.57 20.57 0 0 0-7.71 1.42 18.37 18.37 0 0 0-6.23 4.1 18.73 18.73 0 0 0-4.21 6.72 26.13 26.13 0 0 0-1.53 9.29V227h-27.11v-71.41q0-11.26-4.54-16.4t-13.28-5.14a21.83 21.83 0 0 0-11 2.9 36.66 36.66 0 0 0-9.46 7.92V227zM1289.85 130.12a58.51 58.51 0 0 1 15.63-12.57q8.74-4.81 20.55-4.81a36.79 36.79 0 0 1 16.78 3.83 37.68 37.68 0 0 1 13.12 11.09 53.26 53.26 0 0 1 8.53 17.93 90.21 90.21 0 0 1 3 24.43 76.84 76.84 0 0 1-3.39 23.28 57 57 0 0 1-9.67 18.58 44.72 44.72 0 0 1-15.19 12.3 44.22 44.22 0 0 1-19.95 4.43 40.23 40.23 0 0 1-16.07-2.9 39.23 39.23 0 0 1-11.92-8v45.91h-27V114.81h16.51a6.63 6.63 0 0 1 6.89 4.92zm1.42 67.77a26.57 26.57 0 0 0 10 7.87 29.76 29.76 0 0 0 11.75 2.3 25.79 25.79 0 0 0 11-2.3 21.63 21.63 0 0 0 8.36-7 34.62 34.62 0 0 0 5.3-11.86 67.79 67.79 0 0 0 1.86-16.89 75 75 0 0 0-1.58-16.67 32.22 32.22 0 0 0-4.54-11.09 17.92 17.92 0 0 0-7.16-6.23 22.34 22.34 0 0 0-9.57-2 27.28 27.28 0 0 0-14.32 3.55 43.46 43.46 0 0 0-11.15 10z"></path><path d="M144.06 306.77a9.83 9.83 0 0 1-4.72-1.21L23.79 242a9.82 9.82 0 0 1-5-7.56L.06 57.52a9.77 9.77 0 0 1 6.5-10.29L139.37.55a9.88 9.88 0 0 1 6.43 0L281.5 47.2a9.86 9.86 0 0 1 6.5 10.47L266.47 234.6a9.85 9.85 0 0 1-4.91 7.35l-112.68 63.56a9.84 9.84 0 0 1-4.82 1.26zm-110-77l110 60.49 107.22-60.48L271.89 60.5 142.64 16 16.15 60.5z"></path></svg></a></div><div class="jsx-2803075824 icon mobileOnly"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 80 70"><path d="M6 1a6 6 0 1 0 0 12h68a6 6 0 0 0 0-12H6zm0 28a6 6 0 1 0 0 12h68a6 6 0 0 0 0-12H6zm0 28a6 6 0 1 0 0 12h68a6 6 0 0 0 0-12H6z"></path></svg></div></div><div class="jsx-2919104997 Menu mobileOnlyHide"><div class="jsx-2919104997 section"><h5 class="jsx-2919104997">community</h5><nav class="jsx-2919104997"><div><a target="_self" class="jsx-2919104997 item" href="https://www.datacamp.com/community"><div class="jsx-2919104997 image"><svg height="14" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 23 23"><path id="a" d="M2 4.5h20a1.5 1.5 0 0 1 0 3H2a1.5 1.5 0 0 1 0-3zm0 6h14a1.5 1.5 0 0 1 0 3H2a1.5 1.5 0 0 1 0-3zm0 6h20a1.5 1.5 0 0 1 0 3H2a1.5 1.5 0 0 1 0-3z"></path></svg></div><div class="jsx-2919104997 text">News</div><div class="jsx-2919104997 statusIcon"><svg height="20" xmlns="http://www.w3.org/2000/svg" width="40" viewBox="0 0 40 20"><g fill="none" fill-rule="evenodd"><rect width="40" height="20" fill="#FFC844" rx="4"></rect><text fill="#3D4251" font-family="Lato-Bold, Lato" font-size="11" font-weight="bold" letter-spacing=".5"><tspan x="5" y="14">BETA</tspan></text></g></svg></div></a></div><div><a target="_self" class="jsx-2919104997 item active" href="https://www.datacamp.com/community/tutorials"><div class="jsx-2919104997 image"><svg height="14" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 24.22"><path d="M16.23 24.22a2 2 0 0 1-.73-.14L7 20.79a2 2 0 0 1-1.29-1.88v-4a1.5 1.5 0 0 1 3 0v3.36l7.54 2.92 7.54-2.92v-3.45a1.5 1.5 0 0 1 3 0v4.09a2 2 0 0 1-1.29 1.88L17 24.08a2 2 0 0 1-.77.14zm-.35-2.94zm.7 0z"></path><path d="M16.23 13.35a2 2 0 0 1-.62-.1C9.17 11.16 2.36 9 1.61 8.76a2 2 0 0 1-.25-3.87l14-4.78a2 2 0 0 1 1.3 0l14 4.78a2 2 0 0 1 0 3.81l-13.8 4.55a2 2 0 0 1-.63.1zm-.31-3zM5.21 6.74c3.49 1.11 9.07 2.92 11 3.56l10.68-3.53L16 3.05z"></path></svg></div><div class="jsx-2919104997 text">Tutorials</div></a></div><div><a target="_self" class="jsx-2919104997 item" href="https://www.datacamp.com/community/data-science-cheatsheets"><div class="jsx-2919104997 image"><svg height="14" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 26"><path d="M18.5 26h-13A5.51 5.51 0 0 1 0 20.5v-15A5.51 5.51 0 0 1 5.5 0h13A5.51 5.51 0 0 1 24 5.5v15a5.51 5.51 0 0 1-5.5 5.5zM5.5 3A2.5 2.5 0 0 0 3 5.5v15A2.5 2.5 0 0 0 5.5 23h13a2.5 2.5 0 0 0 2.5-2.5v-15A2.5 2.5 0 0 0 18.5 3z"></path><path d="M16 11H8a1.5 1.5 0 0 1 0-3h8a1.5 1.5 0 0 1 0 3zM16 18H8a1.5 1.5 0 0 1 0-3h8a1.5 1.5 0 0 1 0 3z"></path></svg></div><div class="jsx-2919104997 text">Cheat Sheets</div></a></div><div><a target="_self" class="jsx-2919104997 item" href="https://www.datacamp.com/community/open-courses"><div class="jsx-2919104997 image"><svg height="14" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 34 26"><path d="M28.5 26h-23A5.51 5.51 0 0 1 0 20.5v-15A5.51 5.51 0 0 1 5.5 0h23A5.51 5.51 0 0 1 34 5.5v15a5.51 5.51 0 0 1-5.5 5.5zM5.5 3A2.5 2.5 0 0 0 3 5.5v15A2.5 2.5 0 0 0 5.5 23h23a2.5 2.5 0 0 0 2.5-2.5v-15A2.5 2.5 0 0 0 28.5 3z"></path><path d="M13.5 26a1.5 1.5 0 0 1-1.5-1.5v-22a1.5 1.5 0 0 1 3 0v22a1.5 1.5 0 0 1-1.5 1.5zM27 11h-8a1.5 1.5 0 0 1 0-3h8a1.5 1.5 0 0 1 0 3zM27 18h-8a1.5 1.5 0 0 1 0-3h8a1.5 1.5 0 0 1 0 3z"></path></svg></div><div class="jsx-2919104997 text">Open Courses</div></a></div><div><a target="_self" class="jsx-2919104997 item" href="https://www.datacamp.com/community/podcast"><div class="jsx-2919104997 image"><svg height="14" xmlns="http://www.w3.org/2000/svg" width="18" viewBox="0 0 18 18"><path d="M9.415 11.077h-.369a2.777 2.777 0 0 1-2.769-2.77V2.77A2.777 2.777 0 0 1 9.047 0h.368a2.777 2.777 0 0 1 2.77 2.77v5.538a2.777 2.777 0 0 1-2.77 2.769zm5.008-7.615c.573 0 1.039.464 1.039 1.038v3.462c0 3.08-2.25 5.64-5.193 6.136v1.825h2.077a1.038 1.038 0 1 1 0 2.077h-6.23a1.038 1.038 0 1 1 0-2.077h2.076v-1.825C5.25 13.602 3 11.042 3 7.962V4.5a1.038 1.038 0 1 1 2.077 0v3.462a4.158 4.158 0 0 0 4.154 4.153 4.158 4.158 0 0 0 4.154-4.153V4.5c0-.574.465-1.038 1.038-1.038z"></path></svg></div><div class="jsx-2919104997 text">Podcast - DataFramed</div></a></div><div><a target="_self" class="jsx-2919104997 item" href="https://www.datacamp.com/community/chat"><div class="jsx-2919104997 image"><svg height="14" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 18 16"><g transform="translate(0 -1)"><path id="path-1" d="M12.595 13.364c.01-.111.02-.197.028-.251.058-.405.372-.702.74-.702h1.257c1.035-.002 1.875-.934 1.88-2.082V4.764c-.001-1.155-.842-2.092-1.878-2.094H3.38c-1.034.002-1.873.931-1.88 2.076v5.565c.001 1.156.842 2.092 1.878 2.094h6.626c.292 0 .557.189.68.484.408.977 1.07 1.576 1.94 1.85a6.004 6.004 0 0 1-.03-1.375h.001zm1.51 1.119c.048.314.136.521.235.606.566.487.258 1.497-.458 1.497-1.87 0-3.423-.785-4.33-2.51H3.376C1.513 14.07.004 12.39 0 10.311V4.74C.014 2.673 1.52 1.004 3.378 1h11.245c1.864.004 3.373 1.686 3.377 3.763v5.57c-.01 2.07-1.518 3.744-3.378 3.748h-.551c.004.138.016.273.035.402h-.001zm-8.423-5.81a1.115 1.115 0 1 0 0-2.229 1.115 1.115 0 0 0 0 2.229zm3.268 0a1.115 1.115 0 1 0 0-2.229 1.115 1.115 0 0 0 0 2.229zm3.318 0a1.114 1.114 0 1 0 0-2.229 1.114 1.114 0 0 0 0 2.229z"></path></g></svg></div><div class="jsx-2919104997 text">Chat</div><div class="jsx-2919104997 statusIcon"><svg height="20" xmlns="http://www.w3.org/2000/svg" width="40" viewBox="0 0 40 17"><g fill="none" fill-rule="evenodd"><rect width="40" height="17" fill="#36D57D" rx="4"></rect><text fill="#FFF" font-family="Lato-Bold, Lato" font-size="12" font-weight="bold" letter-spacing=".4"><tspan x="5" y="13">NEW</tspan></text></g></svg></div></a></div></nav></div><div class="jsx-2919104997 section"><h5 class="jsx-2919104997">datacamp</h5><nav class="jsx-2919104997"><div><a target="_self" class="jsx-2919104997 item" href="https://www.datacamp.com/community/blog"><div class="jsx-2919104997 image"><svg height="14" id="Réteg_1" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 17 18"><path id="path-1_1_" d="M12.3 9.8s-.1.1 0 .4c.1.2.2.2-.1.5.2.2.2.3-.1.5 0 .5.1.9-.5 1-.6 0-1.4-.4-1.7.8-.2 1.1-.2.7-.2 1H5.3c.6-1.5 1-3.2 0-4-1.1-1-2.7-4.4.6-6.2.4-.2.8-.3 1.2-.4L6.9 3s1.4-.5 2.7.1v.2c.8.2 1.4.5 1.6.6.5.3 1.2.8 1.2 1.3.1.5-.5.2-.5.2.4.9.4 1.5.2 2.2-.2.7.8 1.4.7 1.9-.1.3-.5.3-.5.3m4.2-7L8.6 0h-.4L.4 2.8c-.3.1-.4.3-.4.6l1.1 10.4c0 .2.1.4.3.4l6.8 3.7c.2.1.4.1.6 0l6.6-3.7c.2-.1.3-.3.3-.4L17 3.4c-.1-.3-.2-.5-.5-.6M8.3 7c-.4 0-.7-.4-.7-.8s.3-.7.7-.7c.4 0 .7.3.7.7 0 .4-.3.8-.7.8zm2.9-1.4l.2-.1c-.3-1-1.2-1.5-1.2-1.5l-.2.2c-.1-.2-.6-.4-.7-.5l.1-.3h-.1c-.6-.3-1.3-.3-2.1 0l.4 1.1c-.6.2-1.1.7-1.1.7l-.6-.4c-.3.5-.5 1.2-.5 1.8h-.8c0 .5.1 1.4.7 2.2l.6-.4c.5.7 1.6 1.3 2.4 1.2V8.1c.3 0 .7-.1.9-.3l.4.6c.4-.1.8-1 .8-1.1l.7.2c.2-.6.2-1.3.1-1.9z"></path></svg></div><div class="jsx-2919104997 text">Official Blog</div></a></div><div><a target="_self" class="jsx-2919104997 item" href="https://www.datacamp.com/community/tech"><div class="jsx-2919104997 image"><svg height="14" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 21.75 29.76"><path d="M15.56 22.57a1.5 1.5 0 0 1-1.5-1.5 7.66 7.66 0 0 1 2.47-5.29 7.38 7.38 0 0 0 2.21-5.31A7.48 7.48 0 0 0 11.28 3h-.82a7.47 7.47 0 0 0-5.2 12.83 7.63 7.63 0 0 1 2.42 5.23 1.5 1.5 0 0 1-3 0 4.65 4.65 0 0 0-1.45-3A10.47 10.47 0 0 1 10.47 0h.82a10.47 10.47 0 0 1 7.28 18 4.68 4.68 0 0 0-1.5 3.08 1.5 1.5 0 0 1-1.51 1.49zM16.5 24.26a5.5 5.5 0 0 1-11 0"></path><path d="M10.89 22.56a1.5 1.5 0 0 1-1.5-1.5v-8.84a1.5 1.5 0 0 1 3 0v8.84a1.5 1.5 0 0 1-1.5 1.5z"></path></svg></div><div class="jsx-2919104997 text">Tech Thoughts</div></a></div></nav></div></div><main class="jsx-1902599493 Main"><div class="jsx-702933904 ActionBar"><div><div class="jsx-3863678361 ActionBarSearch"><button style="font-weight:normal" class="jsx-322537325 Button extra noPadding"><div class="jsx-322537325 icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20.03 23"><path d="M10.39 19.29A9.65 9.65 0 1 1 20 9.65a9.66 9.66 0 0 1-9.61 9.64zm0-17.06a7.42 7.42 0 1 0 7.42 7.42 7.43 7.43 0 0 0-7.42-7.42z"></path><path d="M1.11 23a1.11 1.11 0 0 1-.89-1.78l4.1-5.47a1.11 1.11 0 1 1 1.78 1.34L2 22.56a1.11 1.11 0 0 1-.89.44z"></path></svg></div><div class="jsx-322537325 desktopOnly">Search</div></button></div></div><div class="jsx-702933904 authBlock"><div></div><div class="jsx-3196442269 ActionBarAuth"><div class="jsx-3196442269"><button class="jsx-322537325 Button border minWidth"><div class="jsx-322537325 ">Log in</div></button><button class="jsx-322537325 Button primary"><div class="jsx-322537325 ">Create Account</div></button></div><div class="jsx-3666761727 SubmitAnArticleButton"><button class="jsx-322537325 Button desktopButton green noPadding"><div class="jsx-322537325 icon"><svg id="Layer_1" xmlns="http://www.w3.org/2000/svg" viewBox="-90 92 18 18"><path id="a" d="M-80.4 100.4V97c0-.3-.3-.6-.6-.6s-.6.3-.6.6v3.4H-85c-.3 0-.6.3-.6.6s.3.6.6.6h3.4v3.4c0 .3.3.6.6.6s.6-.3.6-.6v-3.4h3.4c.3 0 .6-.3.6-.6s-.3-.6-.6-.6h-3.4zM-81 92c5 0 9 4 9 9s-4 9-9 9-9-4-9-9 4-9 9-9z"></path></svg></div><div class="jsx-322537325 desktopOnly">Share an Article</div></button><div class="jsx-3666761727 mobileButton"><svg xmlns="http://www.w3.org/2000/svg" width="40" height="40" viewBox="0 0 40 40"><path d="M20.86 19.15v-4.822c0-.47-.385-.851-.86-.851s-.86.38-.86.85v4.822h-4.878c-.475 0-.86.381-.86.851s.385.85.86.85h4.877v4.822c0 .47.386.851.861.851s.86-.38.86-.85V20.85h4.878c.475 0 .86-.381.86-.851s-.385-.85-.86-.85h-4.877zM20 0c11.045 0 20 8.953 20 20 0 11.045-8.955 20-20 20C8.953 40 0 31.045 0 20 0 8.953 8.953 0 20 0z"></path></svg></div></div></div></div></div><div class="jsx-1374485364 TitleBar"><div class="jsx-1374485364 filter"><button class="jsx-322537325 Button iconButton noPadding"><div class="jsx-322537325 icon"><svg id="Réteg_1" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 7 12"><path id="path-1_1_" d="M5.9 0c.4 0 .9.3 1 .7s.1.9-.2 1.2L2.7 6l4 4.1c.3.5.3 1.1-.1 1.6s-1.1.4-1.5.1l-4.8-5c-.4-.4-.4-1.2 0-1.6L5.1.3c.2-.2.5-.3.8-.3z"></path></svg></div><div class="jsx-322537325 desktopOnly">Back to Tutorials</div></button></div><div class="jsx-1374485364 title"><div class="jsx-3889859319 Title"><div class="jsx-3889859319 icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 24.22"><path d="M16.23 24.22a2 2 0 0 1-.73-.14L7 20.79a2 2 0 0 1-1.29-1.88v-4a1.5 1.5 0 0 1 3 0v3.36l7.54 2.92 7.54-2.92v-3.45a1.5 1.5 0 0 1 3 0v4.09a2 2 0 0 1-1.29 1.88L17 24.08a2 2 0 0 1-.77.14zm-.35-2.94zm.7 0z"></path><path d="M16.23 13.35a2 2 0 0 1-.62-.1C9.17 11.16 2.36 9 1.61 8.76a2 2 0 0 1-.25-3.87l14-4.78a2 2 0 0 1 1.3 0l14 4.78a2 2 0 0 1 0 3.81l-13.8 4.55a2 2 0 0 1-.63.1zm-.31-3zM5.21 6.74c3.49 1.11 9.07 2.92 11 3.56l10.68-3.53L16 3.05z"></path></svg></div><div class="jsx-3889859319 h1">Tutorials</div></div></div><div class="jsx-1374485364 action"><button class="jsx-322537325 Button iconButton noPadding"><div class="jsx-322537325 icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20.06 20.39"><path d="M.53 13.94l-.04.04L0 20.39l6.08-.83.04-.03-5.59-5.59zM8.37 17.27L18.9 6.74a4 4 0 0 0 0-5.59 4 4 0 0 0-5.59 0L2.78 11.69z"></path></svg></div><div class="jsx-322537325 desktopOnly">Write a Tutorial. Earn $250</div></button></div></div><div class="jsx-1448759959 Tutorial withRecommend"><div><div><div style="padding-bottom: 0px;"></div><div class="jsx-undefined social__top desktopOnly" style="transform: translateZ(0px); position: fixed; top: 0px; left: 321px; width: 853px;"><div class="jsx-undefined voteAndSocial"><div class="jsx-undefined"><a href="https://www.datacamp.com/community/tutorials/convolutional-neural-networks-python#comments" class="jsx-3293774837 CommentCounter"><span class="jsx-3293774837 icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 18 18"><path d="M12.595 13.364c.01-.111.02-.197.028-.251.058-.405.372-.702.74-.702h1.257c1.035-.002 1.875-.934 1.88-2.082V4.764c-.001-1.155-.842-2.092-1.878-2.094H3.38c-1.034.002-1.873.931-1.88 2.076v5.565c.001 1.156.842 2.092 1.878 2.094h6.626c.292 0 .557.189.68.484.408.977 1.07 1.576 1.94 1.85a6.004 6.004 0 0 1-.03-1.375zm1.51 1.119c.048.314.136.521.235.606.566.487.258 1.497-.458 1.497-1.87 0-3.423-.785-4.33-2.51H3.376C1.513 14.07.004 12.39 0 10.311V4.74C.014 2.673 1.52 1.004 3.378 1h11.245c1.864.004 3.373 1.686 3.377 3.763v5.57c-.01 2.07-1.518 3.744-3.378 3.748h-.551c.004.138.016.273.035.402zm-8.423-5.81a1.114 1.114 0 1 0 0-2.229 1.114 1.114 0 0 0 0 2.229zm3.268 0a1.114 1.114 0 1 0 0-2.229 1.114 1.114 0 0 0 0 2.229zm3.318 0a1.114 1.114 0 1 0 0-2.229 1.114 1.114 0 0 0 0 2.229z"></path></svg></span><span class="jsx-3293774837 count">4</span></a><div class="jsx-4192737526 Upvote"><div class="jsx-4192737526"><div class="jsx-4192737526 normal"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path d="M1 10L6 0l5 10z"></path></svg></span><span class="jsx-4192737526 count">54</span></div><div class="jsx-4192737526 voted"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path d="M1 10L6 0l5 10z"></path></svg></span><span class="jsx-4192737526 count">54</span></div></div></div></div><div class="jsx-1531915454 Social vertical"><div class="jsx-1531915454 icons"><a href="https://www.facebook.com/sharer.php?u=https://www.datacamp.com/community/tutorials/convolutional-neural-networks-python" target="_blank" rel="noopener noreferrer" class="jsx-1531915454 icon"><svg height="12" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 11.73 22.58"><path d="M7.61 22.58v-10.3h3.46l.52-4h-4V5.7c0-1.16.32-2 2-2h2.13V.16A28.47 28.47 0 0 0 8.63 0C5.56 0 3.47 1.87 3.47 5.31v3H0v4h3.47v10.3h4.14z"></path></svg></a><a href="https://twitter.com/intent/tweet?url=https://www.datacamp.com/community/tutorials/convolutional-neural-networks-python" target="_blank" rel="noopener noreferrer" class="jsx-1531915454 icon centerIcon"><svg height="10" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20.42 16.67"><path d="M10 5.18c0-.28-.06-.53-.07-.78a4 4 0 0 1 .73-2.57A4.08 4.08 0 0 1 13.93 0 4 4 0 0 1 17 1.15a.43.43 0 0 0 .46.12 8.68 8.68 0 0 0 2.2-.84l.2-.1a4.36 4.36 0 0 1-1.75 2.28A9 9 0 0 0 20.42 2l-.21.3a3.83 3.83 0 0 1-.23.3A8.45 8.45 0 0 1 18.5 4a.28.28 0 0 0-.13.27A12 12 0 0 1 17 10.18a11.8 11.8 0 0 1-3.37 4.11 11.17 11.17 0 0 1-4.39 2.06 12.53 12.53 0 0 1-4.44.22 11.87 11.87 0 0 1-4.74-1.73L0 14.79a8.6 8.6 0 0 0 6.16-1.74 4.28 4.28 0 0 1-3.91-2.91h.95a6.18 6.18 0 0 0 .89-.12A4.2 4.2 0 0 1 .8 5.88a4 4 0 0 0 1.81.49 4.23 4.23 0 0 1-1.78-3A4.07 4.07 0 0 1 1.38.79 12.06 12.06 0 0 0 10 5.18z" id="iOjKBC.tif"></path></svg></a><a href="https://www.linkedin.com/cws/share?url=https://www.datacamp.com/community/tutorials/convolutional-neural-networks-python" target="_blank" rel="noopener noreferrer" class="jsx-1531915454 icon"><svg height="10" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16.99 17"><path d="M3.85 17H.34V5.67h3.51zM2.07 4.18a2.09 2.09 0 1 1 2.08-2.09 2.08 2.08 0 0 1-2.08 2.09zM17 17h-3.5v-5.95c0-1.63-.62-2.54-1.91-2.54s-2.14.95-2.14 2.54V17H6.09V5.67h3.36v1.52a4 4 0 0 1 3.42-1.87c2.4 0 4.12 1.47 4.12 4.5V17z"></path></svg></a></div></div></div></div></div><div class="jsx-1448759959 preface"><div class="jsx-1448759959 author"><div class="jsx-566588255 Author"><a href="https://www.datacamp.com/profile/adityasharma101993" target="_blank" class="jsx-566588255"><div style="background-image:url(https://res.cloudinary.com/dyd911kmh/image/fetch/t_avatar_thumbnail/https://assets.datacamp.com/users/avatars/000/701/074/square/AAIA_wDGAAAAAQAAAAAAAAqsAAAAJDczODgzN2VkLTZhZDUtNDYzOC04M2ZlLTEyMTI2OTU0YjUyNQ.jpg?1512487068);border-radius:20px;min-width:40px;min-height:40px" class="jsx-3208234818 Avatar"></div><div class="jsx-566588255 info"><div class="jsx-566588255 name">Aditya Sharma</div><div class="jsx-566588255 date"><span>December 5th, 2017</span></div></div></a></div></div><div class="jsx-1448759959 tags"><div class="jsx-2792531181 TagLine"><div class="jsx-1764811326 Tag"><span class="jsx-1764811326 title">python</span></div><a class="jsx-1022557955 more">+<!-- -->4</a></div></div><h1 class="jsx-1448759959 pageTitle">Convolutional Neural Networks in Python with Keras</h1><div class="jsx-1448759959 description pageDescription">In this tutorial, you’ll learn how to implement Convolutional Neural Networks (CNNs) in Python with Keras, and how to overcome overfitting with dropout.</div></div><div class="markdown"><div><p>You might have already heard of image or facial recognition or self-driving cars. These are real-life implementations of Convolutional Neural Networks (CNNs). In this blog post, you will learn and understand how to implement these deep, feed-forward artificial neural networks in Keras and also learn how to overcome overfitting with the regularization technique called "dropout".</p>
<p>More specifically, you'll tackle the following topics in today's tutorial:</p>
<ul>
    <li> You will be introduced to <a href="https://www.datacamp.com/community/tutorials/convolutional-neural-networks-python#cnn">convolutional neural networks</a>;</li>
    <li> Then, you'll first try to <a href="https://www.datacamp.com/community/tutorials/convolutional-neural-networks-python#understand_data">understand the data</a>. You'll use Python and its libraries to load, <a href="https://www.datacamp.com/community/tutorials/convolutional-neural-networks-python#explore">explore and analyze your data</a>,</li>
    <li> After that, you'll <a href="https://www.datacamp.com/community/tutorials/convolutional-neural-networks-python#preprocess">preprocess</a> your data: you'll learn how to resize, rescale, convert your labels into one-hot encoding vectors and split up your data in training and validation sets;</li>
    <li> With all of this done, you can <a href="https://www.datacamp.com/community/tutorials/convolutional-neural-networks-python#network">construct the neural network model</a>: you'll learn how to model the data and form the network. Next, you'll compile, train and evaluate the model, visualizing the accuracy and loss plots;</li>
    <li> Then, you will learn about the concept of overfitting and how you can overcome it by <a href="https://www.datacamp.com/community/tutorials/convolutional-neural-networks-python#dropout">adding a dropout layer</a>;</li>
    <li> With this information, you can revisit your original model and re-train the model. You'll also <a href="https://www.datacamp.com/community/tutorials/convolutional-neural-networks-python#dropout_evaluate">re-evaluate your new model</a> and compare the results of both the models;</li>
    <li> Next, you'll make <a href="https://www.datacamp.com/community/tutorials/convolutional-neural-networks-python#predictions">predictions on the test data</a>, convert the probabilities into class labels and plot few test samples that your model correctly classified and incorrectly classified;</li>
    <li> Finally, you will visualize the <a href="https://www.datacamp.com/community/tutorials/convolutional-neural-networks-python#classification">classification report</a> which will give you more in-depth intuition about which class was (in)correctly classified by your model.</li>
</ul>

<p>Would you like to take a course on Keras and deep learning in Python? Consider taking DataCamp's <a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" target="_blank">Deep Learning in Python</a> course!</p>
<p>Also, don't miss our <a href="https://www.datacamp.com/community/blog/keras-cheat-sheet" target="_blank">Keras cheat sheet</a>, which shows you the six steps that you need to go through to build neural networks in Python with code examples!</p>
<p><a id="cnn"></a></p>
<h2 id="convolutional-neural-network-introduction">Convolutional Neural Network: Introduction</h2>
<p>By now, you might already know about machine learning and deep learning, a computer science branch that studies the design of algorithms that can learn. Deep learning is a subfield of machine learning that is inspired by artificial neural networks, which in turn are inspired by biological neural networks. </p>
<p>A specific kind of such a deep neural network is the convolutional network, which is commonly referred to as CNN or ConvNet. It's a deep, feed-forward artificial neural network. <strong>Remember</strong> that feed-forward neural networks are also called multi-layer perceptrons(MLPs), which are the quintessential deep learning models. The models are called "feed-forward" because information fl�ows right through the model. There are no feedback connections in which outputs of the model are fed back into itself.</p>
<p>CNNs specifically are inspired by the biological visual cortex. The cortex has small regions of cells that are sensitive to the specific areas of the visual field. This idea was expanded by a captivating experiment done by Hubel and Wiesel in 1962 (if you want to know more, here's a <a href="https://www.youtube.com/watch?v=Cw5PKV9Rj3o">video</a>). In this experiment, the researchers showed that some individual neurons in the brain activated or fired only in the presence of edges of a particular orientation like vertical or horizontal edges. For example, some neurons fired when exposed to vertical sides and some when shown a horizontal edge. Hubel and Wiesel found that all of these neurons were well ordered in a columnar fashion and that together they were able to produce visual perception. This idea of specialized components inside of a system having specific tasks is one that machines use as well and one that you can also find back in CNNs.</p>
<p>Convolutional neural networks have been one of the most influential innovations in the field of computer vision. They have performed a lot better than traditional computer vision and have produced state-of-the-art results. These neural networks have proven to be successful in many different real-life case studies and applications, like:</p>
<ul>
    <li>Image classification, object detection, segmentation, face recognition;</li>
    <li>Self driving cars that leverage CNN based vision systems; </li>
    <li>Classification of crystal structure using a convolutional neural network;</li>
    <li>And many more, of course!</li>
</ul>

<p>To understand this success, you'll have to go back to 2012, the year in which Alex Krizhevsky used convolutional neural networks to win that year's ImageNet Competition, reducing the classification error from 26% to 15%. </p>
<p><strong>Note</strong> that ImageNet Large Scale Visual Recognition Challenge (ILSVRC) began in the year 2010 is an annual competition where research teams assess their algorithms on the given data set and compete to achieve higher accuracy on several visual recognition tasks.</p>
<p>This was the time when neural networks <a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" target="_blank">regained</a> prominence after quite some time. This is often called the "third wave of neural networks". The other two waves were in the 1940s until the 1960s and in the 1970s to 1980s. </p>
<p>Alright, you know that you'll be working with feed-forward networks that are inspired by the biological visual cortex, but what does that actually mean?</p>
<p>Take a look at the picture below:</p>
<p></p><div style="text-align:center;"><img src="./Convolutional Neural Networks in Python (article) - DataCamp_files/Typical_cnn_kecdep.png" alt="convolutional neural networks python"></div><br><p></p>
<p></p><div style="text-align:center;"><small>Figure: Convolutional Neural Network from <a href="https://commons.wikimedia.org/wiki/File:Typical_cnn.png">Wikimedia</a></small></div><br><p></p>
<p>The image shows you that you feed an image as an input to the network, which goes through multiple convolutions, subsampling, a fully connected layer and finally outputs something.</p>
<p>But what are all these concepts? </p>
<ol>
    <li> The convolution layer computes the output of neurons that are connected to local regions or receptive fields in the input, each computing a dot product between their weights and a small receptive field to which they are connected to in the input volume. Each computation leads to extraction of a feature map from the input image. In other words, imagine you have an image represented as a 5x5 matrix of values, and you take a 3x3 matrix and slide that 3x3 window or kernel around the image. At each position of that matrix, you multiply the values of your 3x3 window by the values in the image that are currently being covered by the window. As a result, you'll get a single number that represents all the values in that window of the images. You use this layer to filtering: as the window moves over the image, you check for patterns in that section of the image. This works because of filters, which are multiplied by the values outputted by the convolution.</li>
    <li> The objective of subsampling is to get an input representation by reducing its dimensions, which helps in reducing overfitting. One of the techniques of subsampling is max pooling. With this technique, you select the highest pixel value from a region depending on its size. In other words, max pooling takes the largest value from the window of the image currently covered by the kernel. For example, you can have a max-pooling layer of size 2 x 2 will select the maximum pixel intensity value from 2 x 2 region. You're right to think that the pooling layer then works a lot like the convolution layer! You also take a kernel or a window and move it over the image; The only difference is the function that is applied to the kernel and the image window isn't linear. 
<div style="text-align:center;"><img src="./Convolutional Neural Networks in Python (article) - DataCamp_files/max-pooling_tkk5n2.png" alt="convolutional neural network in python"></div>
<div style="text-align:center;"><small>Figure: Max-Pooling from <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">Wikipedia</a></small></div><br>
    </li><li> The objective of the fully connected layer is to flatten the high-level features that are learned by convolutional layers and combining all the features. It passes the flattened output to the output layer where you use a softmax classifier or a sigmoid to predict the input class label.</li>
</ol>    

<p>For more information, you can go <a href="http://cs231n.github.io/convolutional-networks/">here</a>.</p>
<p><a id="understand_data"></a></p>
<h2 id="the-fashion-mnist-data-set">The Fashion-MNIST Data Set</h2>
<p>Before you go ahead and load in the data, it's good to take a look at what you'll exactly be working with! The <a href="https://arxiv.org/abs/1708.07747" target="_blank">Fashion-MNIST</a> dataset is a dataset of Zalando's article images, with 28x28 grayscale images of 70,000 fashion products from 10 categories, and 7,000 images per category. The training set has 60,000 images, and the test set has 10,000 images. You can double check this later when you have loaded in your data! ;)</p>
<p>Fashion-MNIST is similar to the MNIST dataset that you might already know, which you use to classify handwritten digits. That means that the image dimensions, training and test splits are similar to the MNIST dataset. <strong>Tip</strong>: if you want to learn how to implement an Multi-Layer Perceptron (MLP) for classification tasks with this latter dataset, go to <a href="https://www.datacamp.com/community/tutorials/deep-learning-python">this tutorial</a>.</p>
<p>You can find the Fashion-MNIST dataset <a href="https://github.com/zalandoresearch/fashion-mnist" target="_blank">here</a>, but you can also load it with the help of specific TensorFlow and Keras modules. You'll see how this works in the next section!</p>
<h2 id="load-the-data">Load the Data</h2>
<p>Keras comes with a library called <code>datasets</code>, which you can use to load datasets out of the box: you download the data from the server and speeds up the process since you no longer have to download the data to your computer. The train and test images along with the labels are loaded and stored in variables <code>train_X</code>, <code>train_Y</code>, <code>test_X</code>, <code>test_Y</code>, respectively. </p>
<pre><code class="lang-python hljs"><span class="hljs-keyword">from</span> keras.datasets <span class="hljs-keyword">import</span> fashion_mnist
(train_X,train_Y), (test_X,test_Y) = fashion_mnist.load_data()
</code></pre>
<pre><code>Using TensorFlow backend.
</code></pre><p>Great! That was pretty simple, wasn't it?</p>
<p>You have probably done this a million times by now, but it's always an essential step to get started. Now you're completely set to start analyzing, processing and modeling your data!</p>
<p><a id="explore"></a></p>
<h2 id="analyze-the-data">Analyze the Data</h2>
<p>Let's now analyze how images in the dataset look like. Even though you know the dimension of the images by now, it's still worth the effort to analyze it programmatically: you might have to rescale the image pixels and resize the images.</p>
<pre><code class="lang-python hljs"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">from</span> keras.utils <span class="hljs-keyword">import</span> to_categorical
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
%matplotlib inline

print(<span class="hljs-string">'Training data shape : '</span>, train_X.shape, train_Y.shape)

print(<span class="hljs-string">'Testing data shape : '</span>, test_X.shape, test_Y.shape)
</code></pre>
<pre><code>('Training data shape : ', (60000, 28, 28), (60000,))
('Testing data shape : ', (10000, 28, 28), (10000,))
</code></pre><p>From the above output, you can see that the training data has a shape of 60000 x 28 x 28 since there are 60,000 training samples each of 28 x 28 dimension. Similarly, the test data has a shape of 10000 x 28 x 28 since there are 10,000 testing samples.</p>
<pre><code class="lang-python hljs"><span class="hljs-comment"># Find the unique numbers from the train labels</span>
classes = np.unique(train_Y)
nClasses = len(classes)
print(<span class="hljs-string">'Total number of outputs : '</span>, nClasses)
print(<span class="hljs-string">'Output classes : '</span>, classes)
</code></pre>
<pre><code>('Total number of outputs : ', 10)
('Output classes : ', array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8))
</code></pre><p>There's also a total of ten output classes that range from 0 to 9.</p>
<p>Also, don't forget to take a look at what the images in your dataset:</p>
<pre><code class="lang-python hljs">plt.figure(figsize=[<span class="hljs-number">5</span>,<span class="hljs-number">5</span>])

<span class="hljs-comment"># Display the first image in training data</span>
plt.subplot(<span class="hljs-number">121</span>)
plt.imshow(train_X[<span class="hljs-number">0</span>,:,:], cmap=<span class="hljs-string">'gray'</span>)
plt.title(<span class="hljs-string">"Ground Truth : {}"</span>.format(train_Y[<span class="hljs-number">0</span>]))

<span class="hljs-comment"># Display the first image in testing data</span>
plt.subplot(<span class="hljs-number">122</span>)
plt.imshow(test_X[<span class="hljs-number">0</span>,:,:], cmap=<span class="hljs-string">'gray'</span>)
plt.title(<span class="hljs-string">"Ground Truth : {}"</span>.format(test_Y[<span class="hljs-number">0</span>]))
</code></pre>
<pre><code>Text(0.5,1,u'Ground Truth : 9')
</code></pre><p><img src="./Convolutional Neural Networks in Python (article) - DataCamp_files/output_19_1_udnwlg.png"></p>
<p>The output of above two plots looks like an ankle boot, and this class is assigned a class label of 9. Similarly, other fashion products will have different labels, but similar products will have same labels. This means that all the 7,000 ankle boot images will have a class label of 9.</p>
<p><a id="preprocess"></a></p>
<h2 id="data-preprocessing">Data Preprocessing</h2>
<p>As you could see in the above plot, the images are grayscale images have pixel values that range from 0 to 255. Also, these images have a dimension of 28 x 28. As a result, you'll need to preprocess the data before you feed it into the model.
<br></p>
<ul>
    <li>As a first step, convert each 28 x 28 image of the train and test set into a matrix of size 28 x 28 x 1 which is fed into the network.</li>
</ul>    


<pre><code class="lang-python hljs">train_X = train_X.reshape(<span class="hljs-number">-1</span>, <span class="hljs-number">28</span>,<span class="hljs-number">28</span>, <span class="hljs-number">1</span>)
test_X = test_X.reshape(<span class="hljs-number">-1</span>, <span class="hljs-number">28</span>,<span class="hljs-number">28</span>, <span class="hljs-number">1</span>)
train_X.shape, test_X.shape
</code></pre>
<pre><code>((60000, 28, 28, 1), (10000, 28, 28, 1))
</code></pre><ul> 
 <li> The data right now is in an int8 format, so before you feed it into the network you need to convert its type to float32, and you also have to rescale the pixel values in range 0 - 1 inclusive. So let's do that!</li>
</ul> 


<pre><code class="lang-python hljs">train_X = train_X.astype(<span class="hljs-string">'float32'</span>)
test_X = test_X.astype(<span class="hljs-string">'float32'</span>)
train_X = train_X / <span class="hljs-number">255.</span>
test_X = test_X / <span class="hljs-number">255.</span>
</code></pre>
<ul>
<li>Now you need to convert the class labels into a one-hot encoding vector.</li>
</ul>

<p>In one-hot encoding, you convert the categorical data into a vector of numbers. The reason why you convert the categorical data in one hot encoding is that machine learning algorithms cannot work with categorical data directly. You generate one boolean column for each category or class. Only one of these columns could take on the value 1 for each sample. Hence, the term one-hot encoding.</p>
<p>For your problem statement, the one hot encoding will be a row vector, and for each image, it will have a dimension of 1 x 10. The important thing to note here is that the vector consists of all zeros except for the class that it represents, and for that, it is 1. For example, the ankle boot image that you plotted above has a label of 9, so for all the ankle boot images, the one hot encoding vector would be <code>[0 0 0 0 0 0 0 0 1 0]</code>.
</p>
<p>So let's convert the training and testing labels into one-hot encoding vectors:</p>
<pre><code class="lang-python hljs"><span class="hljs-comment"># Change the labels from categorical to one-hot encoding</span>
train_Y_one_hot = to_categorical(train_Y)
test_Y_one_hot = to_categorical(test_Y)

<span class="hljs-comment"># Display the change for category label using one-hot encoding</span>
print(<span class="hljs-string">'Original label:'</span>, train_Y[<span class="hljs-number">0</span>])
print(<span class="hljs-string">'After conversion to one-hot:'</span>, train_Y_one_hot[<span class="hljs-number">0</span>])
</code></pre>
<pre><code>('Original label:', 9)
('After conversion to one-hot:', array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.]))
</code></pre><p>That's pretty clear, right? <strong>Note</strong> that you can also print the <code>train_Y_one_hot</code>, which will display a matrix of size 60000 x 10 in which each row depicts one-hot encoding of an image.</p>
<ul>
    <li> This last step is a crucial one. In machine learning or any data specific task, you should partition the data correctly. For the model to generalize well, you split the training data into two parts, one designed for training and another one for validation. In this case, you will train the model on 80\% of the training data and validate it on 20\% of the remaining training data. This will also help to reduce overfitting since you will be validating the model on the data it would not have seen in training phase, which will help in boosting the test performance.</li>
    </ul>


<pre><code class="lang-python hljs"><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split
train_X,valid_X,train_label,valid_label = train_test_split(train_X, train_Y_one_hot, test_size=<span class="hljs-number">0.2</span>, random_state=<span class="hljs-number">13</span>)
</code></pre>
<p>For one last time let's check the shape of training and validation set.</p>
<pre><code class="lang-python hljs">train_X.shape,valid_X.shape,train_label.shape,valid_label.shape
</code></pre>
<pre><code>((48000, 28, 28, 1), (12000, 28, 28, 1), (48000, 10), (12000, 10))
</code></pre><p><a id="network"></a></p>
<h2 id="the-network">The Network</h2>
<p>The images are of size 28 x 28. You convert the image matrix to an array, rescale it between 0 and 1, reshape it so that it's of size 28 x 28 x 1, and feed this as an input to the network. </p>
<p>You'll use three convolutional layers: </p>
<ul>
<li>The first layer will have 32-3 x 3 filters,</li>
<li>The second layer will have 64-3 x 3 filters and</li>
<li>The third layer will have 128-3 x 3 filters.</li>
</ul>

<p>In addition, there are three max-pooling layers each of size 2 x 2.</p>
<p></p><div style="text-align:center;"><img src="./Convolutional Neural Networks in Python (article) - DataCamp_files/fashion-mnist-architecture_htbpsz.png"></div><br><p></p>
<p></p><div style="text-align:center;">Figure: Architecture of the Model</div><br><p></p>
<h2 id="model-the-data">Model the Data</h2>
<p>First, let's import all the necessary modules required to train the model.</p>
<pre><code class="lang-python hljs"><span class="hljs-keyword">import</span> keras
<span class="hljs-keyword">from</span> keras.models <span class="hljs-keyword">import</span> Sequential,Input,Model
<span class="hljs-keyword">from</span> keras.layers <span class="hljs-keyword">import</span> Dense, Dropout, Flatten
<span class="hljs-keyword">from</span> keras.layers <span class="hljs-keyword">import</span> Conv2D, MaxPooling2D
<span class="hljs-keyword">from</span> keras.layers.normalization <span class="hljs-keyword">import</span> BatchNormalization
<span class="hljs-keyword">from</span> keras.layers.advanced_activations <span class="hljs-keyword">import</span> LeakyReLU
</code></pre>
<p>You will use a batch size of 64 using a higher batch size of 128 or 256 is also preferable it all depends on the memory. It contributes massively to determining the learning parameters and affects the prediction accuracy. You will train the network for 20 epochs.</p>
<pre><code class="lang-python hljs">batch_size = <span class="hljs-number">64</span>
epochs = <span class="hljs-number">20</span>
num_classes = <span class="hljs-number">10</span>
</code></pre>
<h2 id="neural-network-architecture">Neural Network Architecture</h2>
<p>In Keras, you can just stack up layers by adding the desired layer one by one. That's exactly what you'll do here: you'll first add a first convolutional layer with <code>Conv2D()</code>. Note that you use this function because you're working with images! Next, you add the Leaky ReLU activation function which helps the network learn non-linear decision boundaries. Since you have ten different classes, you'll need a non-linear decision boundary that could separate these ten classes which are not linearly separable. </p>
<p>More specifically, you add Leaky ReLUs because they attempt to fix the problem of dying Rectified Linear Units (ReLUs). The ReLU activation function is used a lot in neural network architectures and more specifically in convolutional networks, where it has proven to be more effective than the widely used logistic sigmoid function. As of 2017, this activation function is the most popular one for deep neural networks. The ReLU function allows the activation to be thresholded at zero. However, during the training, ReLU units can "die". This can happen when a large gradient flows through a ReLU neuron: it can cause the weights to update in such a way that the neuron will never activate on any data point again. If this happens, then the gradient flowing through the unit will forever be zero from that point on. Leaky ReLUs attempt to solve this: the function will not be zero but will instead have a small negative slope. </p>
<p>Next, you'll add the max-pooling layer with <code>MaxPooling2D()</code> and so on. The last layer is a Dense layer that has a softmax activation function with 10 units, which is needed for this multi-class classification problem.</p>
<pre><code class="lang-python hljs">fashion_model = Sequential()
fashion_model.add(Conv2D(<span class="hljs-number">32</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>),activation=<span class="hljs-string">'linear'</span>,input_shape=(<span class="hljs-number">28</span>,<span class="hljs-number">28</span>,<span class="hljs-number">1</span>),padding=<span class="hljs-string">'same'</span>))
fashion_model.add(LeakyReLU(alpha=<span class="hljs-number">0.1</span>))
fashion_model.add(MaxPooling2D((<span class="hljs-number">2</span>, <span class="hljs-number">2</span>),padding=<span class="hljs-string">'same'</span>))
fashion_model.add(Conv2D(<span class="hljs-number">64</span>, (<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), activation=<span class="hljs-string">'linear'</span>,padding=<span class="hljs-string">'same'</span>))
fashion_model.add(LeakyReLU(alpha=<span class="hljs-number">0.1</span>))
fashion_model.add(MaxPooling2D(pool_size=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>),padding=<span class="hljs-string">'same'</span>))
fashion_model.add(Conv2D(<span class="hljs-number">128</span>, (<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), activation=<span class="hljs-string">'linear'</span>,padding=<span class="hljs-string">'same'</span>))
fashion_model.add(LeakyReLU(alpha=<span class="hljs-number">0.1</span>))                  
fashion_model.add(MaxPooling2D(pool_size=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>),padding=<span class="hljs-string">'same'</span>))
fashion_model.add(Flatten())
fashion_model.add(Dense(<span class="hljs-number">128</span>, activation=<span class="hljs-string">'linear'</span>))
fashion_model.add(LeakyReLU(alpha=<span class="hljs-number">0.1</span>))                  
fashion_model.add(Dense(num_classes, activation=<span class="hljs-string">'softmax'</span>))
</code></pre>
<h2 id="compile-the-model">Compile the Model</h2>
<p>After the model is created, you compile it using the Adam optimizer, one of the most popular optimization algorithms. You can read more about this optimizer <a href="https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/" target="_blank">here</a>. Additionally, you specify the loss type which is categorical cross entropy which is used for multi-class classification, you can also use binary cross-entropy as the loss function. Lastly, you specify the metrics as accuracy which you want to analyze while the model is training.</p>
<pre><code class="lang-python hljs">fashion_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=[<span class="hljs-string">'accuracy'</span>])
</code></pre>
<p>Let's visualize the layers that you created in the above step by using the summary function. This will show some parameters (weights and biases) in each layer and also the total parameters in your model.</p>
<pre><code class="lang-python hljs">fashion_model.summary()
</code></pre>
<pre><code>_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_51 (Conv2D)           (None, 28, 28, 32)        320       
_________________________________________________________________
leaky_re_lu_57 (LeakyReLU)   (None, 28, 28, 32)        0         
_________________________________________________________________
max_pooling2d_49 (MaxPooling (None, 14, 14, 32)        0         
_________________________________________________________________
conv2d_52 (Conv2D)           (None, 14, 14, 64)        18496     
_________________________________________________________________
leaky_re_lu_58 (LeakyReLU)   (None, 14, 14, 64)        0         
_________________________________________________________________
max_pooling2d_50 (MaxPooling (None, 7, 7, 64)          0         
_________________________________________________________________
conv2d_53 (Conv2D)           (None, 7, 7, 128)         73856     
_________________________________________________________________
leaky_re_lu_59 (LeakyReLU)   (None, 7, 7, 128)         0         
_________________________________________________________________
max_pooling2d_51 (MaxPooling (None, 4, 4, 128)         0         
_________________________________________________________________
flatten_17 (Flatten)         (None, 2048)              0         
_________________________________________________________________
dense_33 (Dense)             (None, 128)               262272    
_________________________________________________________________
leaky_re_lu_60 (LeakyReLU)   (None, 128)               0         
_________________________________________________________________
dense_34 (Dense)             (None, 10)                1290      
=================================================================
Total params: 356,234
Trainable params: 356,234
Non-trainable params: 0
_________________________________________________________________
</code></pre><h2 id="train-the-model">Train the Model</h2>
<p>It's finally time to train the model with Keras' <code>fit()</code> function! The model trains for 20 epochs. The <code>fit()</code> function will return a <code>history</code> object; By storying the result of this function in <code>fashion_train</code>, you can use it later to plot the accuracy and loss function plots between training and validation which will help you to analyze your model's performance visually.</p>
<pre><code class="lang-python hljs">fashion_train = fashion_model.fit(train_X, train_label, batch_size=batch_size,epochs=epochs,verbose=<span class="hljs-number">1</span>,validation_data=(valid_X, valid_label))
</code></pre>
<pre><code>Train on 48000 samples, validate on 12000 samples
Epoch 1/20
48000/48000 [==============================] - 60s 1ms/step - loss: 0.4661 - acc: 0.8311 - val_loss: 0.3320 - val_acc: 0.8809
Epoch 2/20
48000/48000 [==============================] - 60s 1ms/step - loss: 0.2874 - acc: 0.8951 - val_loss: 0.2781 - val_acc: 0.8963
Epoch 3/20
48000/48000 [==============================] - 60s 1ms/step - loss: 0.2420 - acc: 0.9111 - val_loss: 0.2501 - val_acc: 0.9077
Epoch 4/20
48000/48000 [==============================] - 59s 1ms/step - loss: 0.2088 - acc: 0.9226 - val_loss: 0.2369 - val_acc: 0.9147
Epoch 5/20
48000/48000 [==============================] - 59s 1ms/step - loss: 0.1838 - acc: 0.9324 - val_loss: 0.2602 - val_acc: 0.9070
Epoch 6/20
48000/48000 [==============================] - 59s 1ms/step - loss: 0.1605 - acc: 0.9396 - val_loss: 0.2264 - val_acc: 0.9193
Epoch 7/20
48000/48000 [==============================] - 59s 1ms/step - loss: 0.1356 - acc: 0.9488 - val_loss: 0.2566 - val_acc: 0.9180
Epoch 8/20
48000/48000 [==============================] - 59s 1ms/step - loss: 0.1186 - acc: 0.9553 - val_loss: 0.2556 - val_acc: 0.9149
Epoch 9/20
48000/48000 [==============================] - 59s 1ms/step - loss: 0.0985 - acc: 0.9634 - val_loss: 0.2681 - val_acc: 0.9204
Epoch 10/20
48000/48000 [==============================] - 59s 1ms/step - loss: 0.0873 - acc: 0.9670 - val_loss: 0.2712 - val_acc: 0.9221
Epoch 11/20
48000/48000 [==============================] - 59s 1ms/step - loss: 0.0739 - acc: 0.9721 - val_loss: 0.2757 - val_acc: 0.9202
Epoch 12/20
48000/48000 [==============================] - 60s 1ms/step - loss: 0.0628 - acc: 0.9767 - val_loss: 0.3126 - val_acc: 0.9132
Epoch 13/20
48000/48000 [==============================] - 61s 1ms/step - loss: 0.0569 - acc: 0.9789 - val_loss: 0.3556 - val_acc: 0.9081
Epoch 14/20
48000/48000 [==============================] - 60s 1ms/step - loss: 0.0452 - acc: 0.9833 - val_loss: 0.3441 - val_acc: 0.9189
Epoch 15/20
48000/48000 [==============================] - 60s 1ms/step - loss: 0.0421 - acc: 0.9847 - val_loss: 0.3400 - val_acc: 0.9165
Epoch 16/20
48000/48000 [==============================] - 60s 1ms/step - loss: 0.0379 - acc: 0.9861 - val_loss: 0.3876 - val_acc: 0.9195
Epoch 17/20
48000/48000 [==============================] - 60s 1ms/step - loss: 0.0405 - acc: 0.9855 - val_loss: 0.4112 - val_acc: 0.9164
Epoch 18/20
48000/48000 [==============================] - 60s 1ms/step - loss: 0.0285 - acc: 0.9897 - val_loss: 0.4150 - val_acc: 0.9181
Epoch 19/20
48000/48000 [==============================] - 61s 1ms/step - loss: 0.0322 - acc: 0.9877 - val_loss: 0.4584 - val_acc: 0.9196
Epoch 20/20
48000/48000 [==============================] - 61s 1ms/step - loss: 0.0262 - acc: 0.9906 - val_loss: 0.4396 - val_acc: 0.9205
</code></pre><p>Finally! You trained the model on fashion-MNIST for 20 epochs, and by observing the training accuracy and loss, you can say that the model did a good job since after 20 epochs the training accuracy is 99% and the training loss is quite low.</p>
<p>However, it looks like the model is overfitting, as the validation loss is 0.4396 and the validation accuracy is 92%. Overfitting gives an intuition that the network has memorized the training data very well but is not guaranteed to work on unseen data, and that is why there is a difference in the training and validation accuracy. </p>
<p>You probably need to handle this. In next sections, you'll learn how you can make your model perform much better by adding a Dropout layer into the network and keeping all the other layers unchanged. </p>
<p>But first, let's evaluate the performance of your model on the test set before you come on to a conclusion.</p>
<h2 id="model-evaluation-on-the-test-set">Model Evaluation on the Test Set</h2>
<pre><code class="lang-python hljs">test_eval = fashion_model.evaluate(test_X, test_Y_one_hot, verbose=<span class="hljs-number">0</span>)
</code></pre>
<pre><code class="lang-python hljs">print(<span class="hljs-string">'Test loss:'</span>, test_eval[<span class="hljs-number">0</span>])
print(<span class="hljs-string">'Test accuracy:'</span>, test_eval[<span class="hljs-number">1</span>])
</code></pre>
<pre><code>('Test loss:', 0.46366268818555401)
('Test accuracy:', 0.91839999999999999)
</code></pre><p>The test accuracy looks impressive. It turns out that your classifier does better than the benchmark that was reported <a href="http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/" target="_blank">here</a>, which is an SVM classifier with mean accuracy of 0.897. Also, the model does well compared to some of the deep learning models mentioned on the <a href="https://github.com/zalandoresearch/fashion-mnist" target="_blank">GitHub</a> profile of the creators of fashion-MNIST dataset.</p>
<p>However, you saw that the model looked like it was overfitting. Are these results really all that good? </p>
<p>Let's put your model evaluation into perspective and plot the accuracy and loss plots between training and validation data:</p>
<pre><code class="lang-python hljs">accuracy = fashion_train.history[<span class="hljs-string">'acc'</span>]
val_accuracy = fashion_train.history[<span class="hljs-string">'val_acc'</span>]
loss = fashion_train.history[<span class="hljs-string">'loss'</span>]
val_loss = fashion_train.history[<span class="hljs-string">'val_loss'</span>]
epochs = range(len(accuracy))
plt.plot(epochs, accuracy, <span class="hljs-string">'bo'</span>, label=<span class="hljs-string">'Training accuracy'</span>)
plt.plot(epochs, val_accuracy, <span class="hljs-string">'b'</span>, label=<span class="hljs-string">'Validation accuracy'</span>)
plt.title(<span class="hljs-string">'Training and validation accuracy'</span>)
plt.legend()
plt.figure()
plt.plot(epochs, loss, <span class="hljs-string">'bo'</span>, label=<span class="hljs-string">'Training loss'</span>)
plt.plot(epochs, val_loss, <span class="hljs-string">'b'</span>, label=<span class="hljs-string">'Validation loss'</span>)
plt.title(<span class="hljs-string">'Training and validation loss'</span>)
plt.legend()
plt.show()
</code></pre>
<p><img src="./Convolutional Neural Networks in Python (article) - DataCamp_files/output_56_0_st6ods.png"></p>
<p><img src="./Convolutional Neural Networks in Python (article) - DataCamp_files/output_56_1_ie0rbw.png"></p>
<p>From the above two plots, you can see that the validation accuracy almost became stagnant after 4-5 epochs and rarely increased at certain epochs. In the beginning, the validation accuracy was linearly increasing with loss, but then it did not increase much.</p>
<p>The validation loss shows that this is the sign of overfitting, similar to validation accuracy it linearly decreased but after 4-5 epochs, it started to increase. This means that the model tried to memorize the data and succeeded.</p>
<p>With this in mind, it's time to introduce some dropout into our model and see if it helps in reducing overfitting.</p>
<p><a id="dropout"></a></p>
<h2 id="adding-dropout-into-the-network">Adding Dropout into the Network</h2>
<p>You can add a dropout layer to overcome the problem of overfitting to some extent. Dropout randomly turns off a fraction of neurons during the training process, reducing the dependency on the training set by some amount. How many fractions of neurons you want to turn off is decided by a hyperparameter, which can be tuned accordingly. This way, turning off some neurons will not allow the network to memorize the training data since not all the neurons will be active at the same time and the inactive neurons will not be able to learn anything.</p>
<p>So let's create, compile and train the network again but this time with dropout. And run it for 20 epochs with a batch size of 64.</p>
<pre><code class="lang-python hljs">batch_size = <span class="hljs-number">64</span>
epochs = <span class="hljs-number">20</span>
num_classes = <span class="hljs-number">10</span>
</code></pre>
<pre><code class="lang-python hljs">fashion_model = Sequential()
fashion_model.add(Conv2D(<span class="hljs-number">32</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>),activation=<span class="hljs-string">'linear'</span>,padding=<span class="hljs-string">'same'</span>,input_shape=(<span class="hljs-number">28</span>,<span class="hljs-number">28</span>,<span class="hljs-number">1</span>)))
fashion_model.add(LeakyReLU(alpha=<span class="hljs-number">0.1</span>))
fashion_model.add(MaxPooling2D((<span class="hljs-number">2</span>, <span class="hljs-number">2</span>),padding=<span class="hljs-string">'same'</span>))
fashion_model.add(Dropout(<span class="hljs-number">0.25</span>))
fashion_model.add(Conv2D(<span class="hljs-number">64</span>, (<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), activation=<span class="hljs-string">'linear'</span>,padding=<span class="hljs-string">'same'</span>))
fashion_model.add(LeakyReLU(alpha=<span class="hljs-number">0.1</span>))
fashion_model.add(MaxPooling2D(pool_size=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>),padding=<span class="hljs-string">'same'</span>))
fashion_model.add(Dropout(<span class="hljs-number">0.25</span>))
fashion_model.add(Conv2D(<span class="hljs-number">128</span>, (<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), activation=<span class="hljs-string">'linear'</span>,padding=<span class="hljs-string">'same'</span>))
fashion_model.add(LeakyReLU(alpha=<span class="hljs-number">0.1</span>))                  
fashion_model.add(MaxPooling2D(pool_size=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>),padding=<span class="hljs-string">'same'</span>))
fashion_model.add(Dropout(<span class="hljs-number">0.4</span>))
fashion_model.add(Flatten())
fashion_model.add(Dense(<span class="hljs-number">128</span>, activation=<span class="hljs-string">'linear'</span>))
fashion_model.add(LeakyReLU(alpha=<span class="hljs-number">0.1</span>))           
fashion_model.add(Dropout(<span class="hljs-number">0.3</span>))
fashion_model.add(Dense(num_classes, activation=<span class="hljs-string">'softmax'</span>))
</code></pre>
<pre><code class="lang-python hljs">fashion_model.summary()
</code></pre>
<pre><code>_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_54 (Conv2D)           (None, 28, 28, 32)        320       
_________________________________________________________________
leaky_re_lu_61 (LeakyReLU)   (None, 28, 28, 32)        0         
_________________________________________________________________
max_pooling2d_52 (MaxPooling (None, 14, 14, 32)        0         
_________________________________________________________________
dropout_29 (Dropout)         (None, 14, 14, 32)        0         
_________________________________________________________________
conv2d_55 (Conv2D)           (None, 14, 14, 64)        18496     
_________________________________________________________________
leaky_re_lu_62 (LeakyReLU)   (None, 14, 14, 64)        0         
_________________________________________________________________
max_pooling2d_53 (MaxPooling (None, 7, 7, 64)          0         
_________________________________________________________________
dropout_30 (Dropout)         (None, 7, 7, 64)          0         
_________________________________________________________________
conv2d_56 (Conv2D)           (None, 7, 7, 128)         73856     
_________________________________________________________________
leaky_re_lu_63 (LeakyReLU)   (None, 7, 7, 128)         0         
_________________________________________________________________
max_pooling2d_54 (MaxPooling (None, 4, 4, 128)         0         
_________________________________________________________________
dropout_31 (Dropout)         (None, 4, 4, 128)         0         
_________________________________________________________________
flatten_18 (Flatten)         (None, 2048)              0         
_________________________________________________________________
dense_35 (Dense)             (None, 128)               262272    
_________________________________________________________________
leaky_re_lu_64 (LeakyReLU)   (None, 128)               0         
_________________________________________________________________
dropout_32 (Dropout)         (None, 128)               0         
_________________________________________________________________
dense_36 (Dense)             (None, 10)                1290      
=================================================================
Total params: 356,234
Trainable params: 356,234
Non-trainable params: 0
_________________________________________________________________
</code></pre><pre><code class="lang-python hljs">fashion_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=[<span class="hljs-string">'accuracy'</span>])
</code></pre>
<pre><code class="lang-python hljs">fashion_train_dropout = fashion_model.fit(train_X, train_label, batch_size=batch_size,epochs=epochs,verbose=<span class="hljs-number">1</span>,validation_data=(valid_X, valid_label))
</code></pre>
<pre><code>Train on 48000 samples, validate on 12000 samples
Epoch 1/20
48000/48000 [==============================] - 66s 1ms/step - loss: 0.5954 - acc: 0.7789 - val_loss: 0.3788 - val_acc: 0.8586
Epoch 2/20
48000/48000 [==============================] - 64s 1ms/step - loss: 0.3797 - acc: 0.8591 - val_loss: 0.3150 - val_acc: 0.8832
Epoch 3/20
48000/48000 [==============================] - 64s 1ms/step - loss: 0.3302 - acc: 0.8787 - val_loss: 0.2836 - val_acc: 0.8961
Epoch 4/20
48000/48000 [==============================] - 64s 1ms/step - loss: 0.3034 - acc: 0.8868 - val_loss: 0.2663 - val_acc: 0.9002
Epoch 5/20
48000/48000 [==============================] - 64s 1ms/step - loss: 0.2843 - acc: 0.8936 - val_loss: 0.2481 - val_acc: 0.9083
Epoch 6/20
48000/48000 [==============================] - 64s 1ms/step - loss: 0.2699 - acc: 0.9002 - val_loss: 0.2469 - val_acc: 0.9032
Epoch 7/20
48000/48000 [==============================] - 65s 1ms/step - loss: 0.2561 - acc: 0.9049 - val_loss: 0.2422 - val_acc: 0.9095
Epoch 8/20
48000/48000 [==============================] - 65s 1ms/step - loss: 0.2503 - acc: 0.9068 - val_loss: 0.2429 - val_acc: 0.9098
Epoch 9/20
48000/48000 [==============================] - 65s 1ms/step - loss: 0.2437 - acc: 0.9096 - val_loss: 0.2230 - val_acc: 0.9173
Epoch 10/20
48000/48000 [==============================] - 65s 1ms/step - loss: 0.2307 - acc: 0.9126 - val_loss: 0.2170 - val_acc: 0.9187
Epoch 11/20
48000/48000 [==============================] - 65s 1ms/step - loss: 0.2307 - acc: 0.9135 - val_loss: 0.2265 - val_acc: 0.9193
Epoch 12/20
48000/48000 [==============================] - 65s 1ms/step - loss: 0.2229 - acc: 0.9160 - val_loss: 0.2136 - val_acc: 0.9229
Epoch 13/20
48000/48000 [==============================] - 65s 1ms/step - loss: 0.2202 - acc: 0.9162 - val_loss: 0.2173 - val_acc: 0.9187
Epoch 14/20
48000/48000 [==============================] - 64s 1ms/step - loss: 0.2161 - acc: 0.9188 - val_loss: 0.2142 - val_acc: 0.9211
Epoch 15/20
48000/48000 [==============================] - 65s 1ms/step - loss: 0.2119 - acc: 0.9196 - val_loss: 0.2133 - val_acc: 0.9233
Epoch 16/20
48000/48000 [==============================] - 65s 1ms/step - loss: 0.2073 - acc: 0.9222 - val_loss: 0.2159 - val_acc: 0.9213
Epoch 17/20
48000/48000 [==============================] - 65s 1ms/step - loss: 0.2050 - acc: 0.9231 - val_loss: 0.2123 - val_acc: 0.9233
Epoch 18/20
48000/48000 [==============================] - 64s 1ms/step - loss: 0.2016 - acc: 0.9238 - val_loss: 0.2191 - val_acc: 0.9235
Epoch 19/20
48000/48000 [==============================] - 65s 1ms/step - loss: 0.2001 - acc: 0.9244 - val_loss: 0.2110 - val_acc: 0.9258
Epoch 20/20
48000/48000 [==============================] - 64s 1ms/step - loss: 0.1972 - acc: 0.9255 - val_loss: 0.2092 - val_acc: 0.9269
</code></pre><p>Let's save the model so that you can directly load it and not have to train it again for 20 epochs. This way, you can load the model later on if you need it and modify the architecture; Alternatively, you can start the training process on this saved model. It is always a good idea to save the model -and even the model's weights!- because it saves you time. Note that you can also save the model after every epoch so that, if some issue occurs that stops the training at an epoch, you will not have to start the training from the beginning.</p>
<pre><code class="lang-python hljs">fashion_model.save(<span class="hljs-string">"fashion_model_dropout.h5py"</span>)
</code></pre>
<p><a id="dropout_evaluate"></a></p>
<h2 id="model-evaluation-on-the-test-set">Model Evaluation on the Test Set</h2>
<p>Finally, let's also evaluate your new model and see how it performs!</p>
<pre><code class="lang-python hljs">test_eval = fashion_model.evaluate(test_X, test_Y_one_hot, verbose=<span class="hljs-number">1</span>)
</code></pre>
<pre><code>10000/10000 [==============================] - 5s 461us/step
</code></pre><pre><code class="lang-python hljs">print(<span class="hljs-string">'Test loss:'</span>, test_eval[<span class="hljs-number">0</span>])
print(<span class="hljs-string">'Test accuracy:'</span>, test_eval[<span class="hljs-number">1</span>])
</code></pre>
<pre><code>('Test loss:', 0.21460009642243386)
('Test accuracy:', 0.92300000000000004)
</code></pre><p>Wow! Looks like adding Dropout in our model worked, even though the test accuracy did not improve significantly but the test loss decreased compared to the previous results.<br>
<br>
Now, let's plot the accuracy and loss plots between training and validation data for the one last time.</p>
<pre><code class="lang-python hljs">accuracy = fashion_train_dropout.history[<span class="hljs-string">'acc'</span>]
val_accuracy = fashion_train_dropout.history[<span class="hljs-string">'val_acc'</span>]
loss = fashion_train_dropout.history[<span class="hljs-string">'loss'</span>]
val_loss = fashion_train_dropout.history[<span class="hljs-string">'val_loss'</span>]
epochs = range(len(accuracy))
plt.plot(epochs, accuracy, <span class="hljs-string">'bo'</span>, label=<span class="hljs-string">'Training accuracy'</span>)
plt.plot(epochs, val_accuracy, <span class="hljs-string">'b'</span>, label=<span class="hljs-string">'Validation accuracy'</span>)
plt.title(<span class="hljs-string">'Training and validation accuracy'</span>)
plt.legend()
plt.figure()
plt.plot(epochs, loss, <span class="hljs-string">'bo'</span>, label=<span class="hljs-string">'Training loss'</span>)
plt.plot(epochs, val_loss, <span class="hljs-string">'b'</span>, label=<span class="hljs-string">'Validation loss'</span>)
plt.title(<span class="hljs-string">'Training and validation loss'</span>)
plt.legend()
plt.show()
</code></pre>
<p><img src="./Convolutional Neural Networks in Python (article) - DataCamp_files/output_71_0_dq7xtu.png"></p>
<p><img src="./Convolutional Neural Networks in Python (article) - DataCamp_files/output_71_1_rr3sym.png"></p>
<p>Finally, you can see that the validation loss and validation accuracy both are in sync with the training loss and training accuracy. Even though the validation loss and accuracy line are not linear, but it shows that your model is not overfitting: the validation loss is decreasing and not increasing, and there is not much gap between training and validation accuracy.</p>
<p>Therefore, you can say that your model's generalization capability became much better since the loss on both test set and validation set was only slightly more compared to the training loss.</p>
<p><a id="predictions"></a></p>
<h2 id="predict-labels">Predict Labels</h2>
<pre><code class="lang-python hljs">predicted_classes = fashion_model.predict(test_X)
</code></pre>
<p>Since the predictions you get are floating point values, it will not be feasible to compare the predicted labels with true test labels. So, you will round off the output which will convert the float values into an integer. Further, you will use <code>np.argmax()</code> to select the index number which has a higher value in a row. </p>
<p>For example, let's assume a prediction for one test image to be <code>0 1 0 0 0 0 0 0 0 0</code>, the output for this should be a class label <code>1</code>.</p>
<pre><code class="lang-python hljs">predicted_classes = np.argmax(np.round(predicted_classes),axis=<span class="hljs-number">1</span>)
</code></pre>
<pre><code class="lang-python hljs">predicted_classes.shape, test_Y.shape
</code></pre>
<pre><code>((10000,), (10000,))
</code></pre><pre><code class="lang-python hljs">correct = np.where(predicted_classes==test_Y)[<span class="hljs-number">0</span>]
<span class="hljs-keyword">print</span> <span class="hljs-string">"Found %d correct labels"</span> % len(correct)
<span class="hljs-keyword">for</span> i, correct <span class="hljs-keyword">in</span> enumerate(correct[:<span class="hljs-number">9</span>]):
    plt.subplot(<span class="hljs-number">3</span>,<span class="hljs-number">3</span>,i+<span class="hljs-number">1</span>)
    plt.imshow(test_X[correct].reshape(<span class="hljs-number">28</span>,<span class="hljs-number">28</span>), cmap=<span class="hljs-string">'gray'</span>, interpolation=<span class="hljs-string">'none'</span>)
    plt.title(<span class="hljs-string">"Predicted {}, Class {}"</span>.format(predicted_classes[correct], test_Y[correct]))
    plt.tight_layout()
</code></pre>
<pre><code>Found 9188 correct labels
</code></pre><p><img src="./Convolutional Neural Networks in Python (article) - DataCamp_files/output_78_1_djnisy.png"></p>
<pre><code class="lang-python hljs">incorrect = np.where(predicted_classes!=test_Y)[<span class="hljs-number">0</span>]
<span class="hljs-keyword">print</span> <span class="hljs-string">"Found %d incorrect labels"</span> % len(incorrect)
<span class="hljs-keyword">for</span> i, incorrect <span class="hljs-keyword">in</span> enumerate(incorrect[:<span class="hljs-number">9</span>]):
    plt.subplot(<span class="hljs-number">3</span>,<span class="hljs-number">3</span>,i+<span class="hljs-number">1</span>)
    plt.imshow(test_X[incorrect].reshape(<span class="hljs-number">28</span>,<span class="hljs-number">28</span>), cmap=<span class="hljs-string">'gray'</span>, interpolation=<span class="hljs-string">'none'</span>)
    plt.title(<span class="hljs-string">"Predicted {}, Class {}"</span>.format(predicted_classes[incorrect], test_Y[incorrect]))
    plt.tight_layout()
</code></pre>
<pre><code>Found 812 incorrect labels
</code></pre><p><img src="./Convolutional Neural Networks in Python (article) - DataCamp_files/output_79_1_mu5esp.png"></p>
<p>By looking at a few images, you cannot be sure as to why your model is not able to classify the above images correctly, but it seems like a variety of the similar patterns present on multiple classes affect the performance of the classifier although CNN is a robust architecture. For example, images 5 and 6 both belong to different classes but look kind of similar maybe a jacket or perhaps a long sleeve shirt.</p>
<p><a id="classification"></a></p>
<h2 id="classification-report">Classification Report</h2>
<p>Classification report will help us in identifying the misclassified classes in more detail. You will be able to observe for which class the model performed bad out of the given ten classes.</p>
<pre><code class="lang-python hljs"><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> classification_report
target_names = [<span class="hljs-string">"Class {}"</span>.format(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(num_classes)]
print(classification_report(test_Y, predicted_classes, target_names=target_names))
</code></pre>
<pre><code>             precision    recall  f1-score   support

    Class 0       0.77      0.90      0.83      1000
    Class 1       0.99      0.98      0.99      1000
    Class 2       0.88      0.88      0.88      1000
    Class 3       0.94      0.92      0.93      1000
    Class 4       0.88      0.87      0.88      1000
    Class 5       0.99      0.98      0.98      1000
    Class 6       0.82      0.72      0.77      1000
    Class 7       0.94      0.99      0.97      1000
    Class 8       0.99      0.98      0.99      1000
    Class 9       0.98      0.96      0.97      1000

avg / total       0.92      0.92      0.92     10000
</code></pre><p>You can see that the classifier is underperforming for class 6 regarding both precision and recall. For class 0 and class 2, the classifier is lacking precision. Also, for class 4, the classifier is slightly lacking both precision and recall.</p>
<h2 id="go-further-">Go Further!</h2>
<p>This tutorial was good start to convolutional neural networks in Python with Keras. If you were able to follow along easily or even with little more efforts, well done! Try doing some experiments maybe with same model architecture but using different types of public datasets available. </p>
<p>There is still a lot to cover, so why not take DataCamp's <a href="https://www.datacamp.com/courses/deep-learning-in-python">Deep Learning in Python</a> course? In the meantime, also make sure to check out the <a href="https://keras.io/"> Keras documentation</a>, if you haven't done so already. You will find more examples and information on all functions, arguments, more layers, etc. It will undoubtedly be an indispensable resource when you're learning how to work with neural networks in Python! </p>
<p>If you rather feel like reading a book that explains the fundamentals of deep learning (with Keras) together with how it's used in practice, you should definitely read François Chollet's <a href="https://www.manning.com/books/deep-learning-with-python">Deep Learning in Python</a> book.</p>
</div><link href="./Convolutional Neural Networks in Python (article) - DataCamp_files/solarized-dark.min.css" rel="stylesheet"><link href="./Convolutional Neural Networks in Python (article) - DataCamp_files/css" rel="stylesheet"><link href="./Convolutional Neural Networks in Python (article) - DataCamp_files/css(1)" rel="stylesheet"></div><div class="jsx-1448759959 social__bottom mobileOnly"><div class="jsx-1448759959 voteAndSocial"><div class="jsx-1448759959"><div class="jsx-4192737526 Upvote"><div class="jsx-4192737526"><div class="jsx-4192737526 normal"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path d="M1 10L6 0l5 10z"></path></svg></span><span class="jsx-4192737526 count">54</span></div><div class="jsx-4192737526 voted"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path d="M1 10L6 0l5 10z"></path></svg></span><span class="jsx-4192737526 count">54</span></div></div></div><a href="https://www.datacamp.com/community/tutorials/convolutional-neural-networks-python#comments" class="jsx-3293774837 CommentCounter"><span class="jsx-3293774837 icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 18 18"><path d="M12.595 13.364c.01-.111.02-.197.028-.251.058-.405.372-.702.74-.702h1.257c1.035-.002 1.875-.934 1.88-2.082V4.764c-.001-1.155-.842-2.092-1.878-2.094H3.38c-1.034.002-1.873.931-1.88 2.076v5.565c.001 1.156.842 2.092 1.878 2.094h6.626c.292 0 .557.189.68.484.408.977 1.07 1.576 1.94 1.85a6.004 6.004 0 0 1-.03-1.375zm1.51 1.119c.048.314.136.521.235.606.566.487.258 1.497-.458 1.497-1.87 0-3.423-.785-4.33-2.51H3.376C1.513 14.07.004 12.39 0 10.311V4.74C.014 2.673 1.52 1.004 3.378 1h11.245c1.864.004 3.373 1.686 3.377 3.763v5.57c-.01 2.07-1.518 3.744-3.378 3.748h-.551c.004.138.016.273.035.402zm-8.423-5.81a1.114 1.114 0 1 0 0-2.229 1.114 1.114 0 0 0 0 2.229zm3.268 0a1.114 1.114 0 1 0 0-2.229 1.114 1.114 0 0 0 0 2.229zm3.318 0a1.114 1.114 0 1 0 0-2.229 1.114 1.114 0 0 0 0 2.229z"></path></svg></span><span class="jsx-3293774837 count">4</span></a></div><div class="jsx-1531915454 Social"><div class="jsx-1531915454 icons"><a href="https://www.facebook.com/sharer.php?u=https://www.datacamp.com/community/tutorials/convolutional-neural-networks-python" target="_blank" rel="noopener noreferrer" class="jsx-1531915454 icon"><svg height="12" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 11.73 22.58"><path d="M7.61 22.58v-10.3h3.46l.52-4h-4V5.7c0-1.16.32-2 2-2h2.13V.16A28.47 28.47 0 0 0 8.63 0C5.56 0 3.47 1.87 3.47 5.31v3H0v4h3.47v10.3h4.14z"></path></svg></a><a href="https://twitter.com/intent/tweet?url=https://www.datacamp.com/community/tutorials/convolutional-neural-networks-python" target="_blank" rel="noopener noreferrer" class="jsx-1531915454 icon centerIcon"><svg height="10" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20.42 16.67"><path d="M10 5.18c0-.28-.06-.53-.07-.78a4 4 0 0 1 .73-2.57A4.08 4.08 0 0 1 13.93 0 4 4 0 0 1 17 1.15a.43.43 0 0 0 .46.12 8.68 8.68 0 0 0 2.2-.84l.2-.1a4.36 4.36 0 0 1-1.75 2.28A9 9 0 0 0 20.42 2l-.21.3a3.83 3.83 0 0 1-.23.3A8.45 8.45 0 0 1 18.5 4a.28.28 0 0 0-.13.27A12 12 0 0 1 17 10.18a11.8 11.8 0 0 1-3.37 4.11 11.17 11.17 0 0 1-4.39 2.06 12.53 12.53 0 0 1-4.44.22 11.87 11.87 0 0 1-4.74-1.73L0 14.79a8.6 8.6 0 0 0 6.16-1.74 4.28 4.28 0 0 1-3.91-2.91h.95a6.18 6.18 0 0 0 .89-.12A4.2 4.2 0 0 1 .8 5.88a4 4 0 0 0 1.81.49 4.23 4.23 0 0 1-1.78-3A4.07 4.07 0 0 1 1.38.79 12.06 12.06 0 0 0 10 5.18z" id="iOjKBC.tif"></path></svg></a><a href="https://www.linkedin.com/cws/share?url=https://www.datacamp.com/community/tutorials/convolutional-neural-networks-python" target="_blank" rel="noopener noreferrer" class="jsx-1531915454 icon"><svg height="10" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16.99 17"><path d="M3.85 17H.34V5.67h3.51zM2.07 4.18a2.09 2.09 0 1 1 2.08-2.09 2.08 2.08 0 0 1-2.08 2.09zM17 17h-3.5v-5.95c0-1.63-.62-2.54-1.91-2.54s-2.14.95-2.14 2.54V17H6.09V5.67h3.36v1.52a4 4 0 0 1 3.42-1.87c2.4 0 4.12 1.47 4.12 4.5V17z"></path></svg></a></div></div></div></div></div></div><div class="jsx-3259579870 RecommendedArticles"><div class="jsx-3259579870 title">Related posts</div><div class="jsx-3259579870 articleLayout"><div class="jsx-3259579870 articleWrapper"><div class="jsx-2410884478 RecommendedCard"><div class="jsx-2410884478 info noImage"><div class="jsx-2410884478 infoHead"><div class="jsx-2792531181 TagLine"><div class="jsx-1764811326 Tag mustRead"><span class="jsx-1764811326 title">must read</span></div><div class="jsx-1764811326 Tag"><span class="jsx-1764811326 title">python</span></div><a class="jsx-1022557955 more">+<!-- -->1</a></div><h2 class="jsx-2410884478"><a href="https://www.datacamp.com/community/tutorials/machine-learning-python">Python Machine Learning: Scikit-Learn Tutorial</a></h2></div><div class="jsx-2410884478 space"></div><div class="jsx-2410884478 authorWrapper"><div class="jsx-566588255 Author"><a href="https://www.datacamp.com/profile/karlijn" target="_blank" class="jsx-566588255"><div style="background-image:url(https://res.cloudinary.com/dyd911kmh/image/fetch/t_avatar_thumbnail/https://assets.datacamp.com/users/avatars/000/494/311/square/Screenshot_2017-04-26_16.02.58.png?1493215479);border-radius:20px;min-width:40px;min-height:40px" class="jsx-3208234818 Avatar"></div><div class="jsx-566588255 info"><div class="jsx-566588255 name">Karlijn Willems</div><div class="jsx-566588255 date"><span>January 3rd, 2017</span></div></div></a></div></div></div></div></div><div class="jsx-3259579870 articleWrapper"><div class="jsx-2410884478 RecommendedCard"><div style="background-image:url(https://res.cloudinary.com/dyd911kmh/image/fetch/t_all_tutorial_thumbnail/http://datacamp-community.s3.amazonaws.com/cc0d8057-2e88-4de5-b14e-d3c72dbc6c0d)" class="jsx-2410884478 image"></div><div class="jsx-2410884478 info"><div class="jsx-2410884478 infoHead"><div class="jsx-2792531181 TagLine"><div class="jsx-1764811326 Tag mustRead"><span class="jsx-1764811326 title">must read</span></div><div class="jsx-1764811326 Tag"><span class="jsx-1764811326 title">python</span></div><a class="jsx-1022557955 more">+<!-- -->4</a></div><h2 class="jsx-2410884478"><a href="https://www.datacamp.com/community/tutorials/deep-learning-python">Keras Tutorial: Deep Learning in Python</a></h2></div><div class="jsx-2410884478 space"></div><div class="jsx-2410884478 authorWrapper"><div class="jsx-566588255 Author"><a href="https://www.datacamp.com/profile/karlijn" target="_blank" class="jsx-566588255"><div style="background-image:url(https://res.cloudinary.com/dyd911kmh/image/fetch/t_avatar_thumbnail/https://assets.datacamp.com/users/avatars/000/494/311/square/Screenshot_2017-04-26_16.02.58.png?1493215479);border-radius:20px;min-width:40px;min-height:40px" class="jsx-3208234818 Avatar"></div><div class="jsx-566588255 info"><div class="jsx-566588255 name">Karlijn Willems</div><div class="jsx-566588255 date"><span>May 2nd, 2017</span></div></div></a></div></div></div></div></div><div class="jsx-3259579870 articleWrapper"><div class="jsx-2410884478 RecommendedCard"><div class="jsx-2410884478 info noImage"><div class="jsx-2410884478 infoHead"><div class="jsx-2792531181 TagLine"><div class="jsx-1764811326 Tag mustRead"><span class="jsx-1764811326 title">must read</span></div><div class="jsx-1764811326 Tag"><span class="jsx-1764811326 title">r programming</span></div><a class="jsx-1022557955 more">+<!-- -->4</a></div><h2 class="jsx-2410884478"><a href="https://www.datacamp.com/community/tutorials/keras-r-deep-learning">keras: Deep Learning in R</a></h2></div><div class="jsx-2410884478 space"></div><div class="jsx-2410884478 authorWrapper"><div class="jsx-566588255 Author"><a href="https://www.datacamp.com/profile/karlijn" target="_blank" class="jsx-566588255"><div style="background-image:url(https://res.cloudinary.com/dyd911kmh/image/fetch/t_avatar_thumbnail/https://assets.datacamp.com/users/avatars/000/494/311/square/Screenshot_2017-04-26_16.02.58.png?1493215479);border-radius:20px;min-width:40px;min-height:40px" class="jsx-3208234818 Avatar"></div><div class="jsx-566588255 info"><div class="jsx-566588255 name">Karlijn Willems</div><div class="jsx-566588255 date"><span>June 28th, 2017</span></div></div></a></div></div></div></div></div></div></div><div id="comments" class="jsx-3070642063 Comments"><div class="jsx-3070642063 title">Comments</div><div class="jsx-3070642063 wrapper"><div class="jsx-2482332697 CommentLevel top"><div class="jsx-487597203 Comment"><div id="comment-279" class="jsx-487597203 anchor"></div><div class="jsx-487597203"><a href="https://www.datacamp.com/profile/GaryRevell" target="_blank" class="jsx-487597203"><div class="jsx-3208234818 Avatar" style="background-image: url(&quot;https://res.cloudinary.com/dyd911kmh/image/fetch/t_avatar_thumbnail/https://cdn.datacamp.com/community/assets/placeholder_avatar-7f673b5d40e159404a56b5931250cc73.png&quot;); border-radius: 20px; min-width: 40px; min-height: 40px;"></div></a></div><div class="jsx-487597203 right"><div class="jsx-487597203 top"><div class="jsx-487597203"><a href="https://www.datacamp.com/profile/GaryRevell" target="_blank" class="jsx-487597203 username">Gary Revell</a></div><div class="jsx-487597203 more"></div></div><span class="date mobileOnly">05/03/2018 02:52 PM</span><div class="jsx-487597203 message"><p>Nice article and I'm following it avidly, however.... when I do my first set of 20 epoch it's taking on average 210 secs per epoch. Do I really need to do 20 epochs as per the article?</p>
<p>Any ideas on how to speed it up? I'm running in a Jupyter Notebook on Windows 10.</p>
<p>Thanks</p></div><div class="jsx-487597203 bottom"><div class="jsx-487597203 left"><div class="jsx-4192737526 Upvote comment"><div class="jsx-4192737526"><div class="jsx-4192737526 normal"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path d="M1 10L6 0l5 10z"></path></svg></span><span class="jsx-4192737526 count">1</span></div><div class="jsx-4192737526 voted"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path id="a" d="M9.769.435a1.255 1.255 0 0 1 1.81-.094 1.35 1.35 0 0 1 .09 1.865l-6.457 7.36a1.257 1.257 0 0 1-1.934-.04l-2.98-3.68a1.348 1.348 0 0 1 .162-1.86 1.255 1.255 0 0 1 1.805.168L4.3 6.667 9.77.435z"></path></svg></span><span class="jsx-4192737526 count">1</span></div></div></div><a class="jsx-487597203 replyIcon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="9" viewBox="0 0 12 9"><path d="M.234 3.663L5.032.065a.375.375 0 0 1 .585.293v1.895c5.23 0 6.221 3.633 6.383 5.57a.375.375 0 0 1-.654.27C9.028 5.388 5.617 6.008 5.617 6.008v1.895a.375.375 0 0 1-.585.293L.234 4.598a.584.584 0 0 1 0-.935z"></path></svg> <span class="jsx-487597203 replyText">Reply</span></a><span class="jsx-487597203 divider desktopOnly"></span><a href="https://www.datacamp.com/community/tutorials/convolutional-neural-networks-python#comment-279" class="jsx-487597203"><span class="date desktopOnly">05/03/2018 02:52 PM</span></a></div><div class="jsx-487597203 spam"><svg title="Flag as spam" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 10 12"><path d="M9.708.265A.441.441 0 0 0 9.304 0H.441A.441.441 0 0 0 0 .441v11.118a.441.441 0 1 0 .882 0V6.532h8.422a.441.441 0 0 0 .322-.735L7.274 3.27 9.626.742a.441.441 0 0 0 .082-.477z"></path></svg></div></div></div></div><div class="jsx-2482332697 CommentLevel"><div class="jsx-487597203 Comment"><div id="comment-568" class="jsx-487597203 anchor"></div><div class="jsx-487597203"><a href="https://www.datacamp.com/profile/adityasharma101993" target="_blank" class="jsx-487597203"><div class="jsx-3208234818 Avatar" style="background-image: url(&quot;https://res.cloudinary.com/dyd911kmh/image/fetch/t_avatar_thumbnail/https://assets.datacamp.com/users/avatars/000/701/074/square/AAIA_wDGAAAAAQAAAAAAAAqsAAAAJDczODgzN2VkLTZhZDUtNDYzOC04M2ZlLTEyMTI2OTU0YjUyNQ.jpg?1512487068&quot;); border-radius: 20px; min-width: 40px; min-height: 40px;"></div></a></div><div class="jsx-487597203 right"><div class="jsx-487597203 top"><div class="jsx-487597203"><a href="https://www.datacamp.com/profile/adityasharma101993" target="_blank" class="jsx-487597203 username">Aditya Sharma</a></div><div class="jsx-487597203 more"></div></div><span class="date mobileOnly">06/04/2018 10:17 AM</span><div class="jsx-487597203 message"><p>Hey Gary,</p>
<p>Well, how much time it takes to run 1 epoch depends on your system configurations, I suppose you are running it on a CPU RAM of may be 8gb or 16gb?</p>
<p>Using a GPU will definitely help speeding up the training process, but if you don't have the only option left is training on the system you currently have.</p>
<p>Also, it is &nbsp;not mandate and neither anyone can give you a perfect answer that how many epochs one should run, that totally depends on whether the training and validation loss is still decreasing if yes then running more epochs is a must.&nbsp;</p>
<p>Epochs is a hyper-parameter which should be decided by you, may be you come up with an architecture that does well in 5 or 10 epochs or may be takes longer.</p>
<p><br></p>
<p>I hope this answers your query!</p></div><div class="jsx-487597203 bottom"><div class="jsx-487597203 left"><div class="jsx-4192737526 Upvote comment"><div class="jsx-4192737526"><div class="jsx-4192737526 normal"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path d="M1 10L6 0l5 10z"></path></svg></span><span class="jsx-4192737526 count">1</span></div><div class="jsx-4192737526 voted"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path id="a" d="M9.769.435a1.255 1.255 0 0 1 1.81-.094 1.35 1.35 0 0 1 .09 1.865l-6.457 7.36a1.257 1.257 0 0 1-1.934-.04l-2.98-3.68a1.348 1.348 0 0 1 .162-1.86 1.255 1.255 0 0 1 1.805.168L4.3 6.667 9.77.435z"></path></svg></span><span class="jsx-4192737526 count">1</span></div></div></div><a class="jsx-487597203 replyIcon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="9" viewBox="0 0 12 9"><path d="M.234 3.663L5.032.065a.375.375 0 0 1 .585.293v1.895c5.23 0 6.221 3.633 6.383 5.57a.375.375 0 0 1-.654.27C9.028 5.388 5.617 6.008 5.617 6.008v1.895a.375.375 0 0 1-.585.293L.234 4.598a.584.584 0 0 1 0-.935z"></path></svg> <span class="jsx-487597203 replyText">Reply</span></a><span class="jsx-487597203 divider desktopOnly"></span><a href="https://www.datacamp.com/community/tutorials/convolutional-neural-networks-python#comment-568" class="jsx-487597203"><span class="date desktopOnly">06/04/2018 10:17 AM</span></a></div><div class="jsx-487597203 spam"><svg title="Flag as spam" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 10 12"><path d="M9.708.265A.441.441 0 0 0 9.304 0H.441A.441.441 0 0 0 0 .441v11.118a.441.441 0 1 0 .882 0V6.532h8.422a.441.441 0 0 0 .322-.735L7.274 3.27 9.626.742a.441.441 0 0 0 .082-.477z"></path></svg></div></div></div></div></div></div><div class="jsx-2482332697 CommentLevel top"><div class="jsx-487597203 Comment"><div id="comment-670" class="jsx-487597203 anchor"></div><div class="jsx-487597203"><a href="https://www.datacamp.com/profile/shrikantpandey2" target="_blank" class="jsx-487597203"><div class="jsx-3208234818 Avatar" style="background-image: url(&quot;https://res.cloudinary.com/dyd911kmh/image/fetch/t_avatar_thumbnail/https://graph.facebook.com/1635633539830904/picture?width=150&amp;height=150&quot;); border-radius: 20px; min-width: 40px; min-height: 40px;"></div></a></div><div class="jsx-487597203 right"><div class="jsx-487597203 top"><div class="jsx-487597203"><a href="https://www.datacamp.com/profile/shrikantpandey2" target="_blank" class="jsx-487597203 username">shrikantpandey2</a></div><div class="jsx-487597203 more"></div></div><span class="date mobileOnly">19/04/2018 04:50 PM</span><div class="jsx-487597203 message"><p>Hello @ Aditya Sharma</p>
<p>I am following every instruction as you explained in this tutorial , but when use Dropout method my model become more worst compare to first model.</p>
<p>1. First Model gives &nbsp;the almost same results &nbsp;to me as you explained&nbsp;</p>
<p>2. But when i use dropout method this model become more worst comp are &nbsp;to first model</p>
<p>Tell me what is the reason behind the worst model</p>
<p>By the way i am run this program on cpu with 8GB ddr4 memory</p>
<p><br></p></div><div class="jsx-487597203 bottom"><div class="jsx-487597203 left"><div class="jsx-4192737526 Upvote comment"><div class="jsx-4192737526"><div class="jsx-4192737526 normal"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path d="M1 10L6 0l5 10z"></path></svg></span><span class="jsx-4192737526 count">1</span></div><div class="jsx-4192737526 voted"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path id="a" d="M9.769.435a1.255 1.255 0 0 1 1.81-.094 1.35 1.35 0 0 1 .09 1.865l-6.457 7.36a1.257 1.257 0 0 1-1.934-.04l-2.98-3.68a1.348 1.348 0 0 1 .162-1.86 1.255 1.255 0 0 1 1.805.168L4.3 6.667 9.77.435z"></path></svg></span><span class="jsx-4192737526 count">1</span></div></div></div><a class="jsx-487597203 replyIcon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="9" viewBox="0 0 12 9"><path d="M.234 3.663L5.032.065a.375.375 0 0 1 .585.293v1.895c5.23 0 6.221 3.633 6.383 5.57a.375.375 0 0 1-.654.27C9.028 5.388 5.617 6.008 5.617 6.008v1.895a.375.375 0 0 1-.585.293L.234 4.598a.584.584 0 0 1 0-.935z"></path></svg> <span class="jsx-487597203 replyText">Reply</span></a><span class="jsx-487597203 divider desktopOnly"></span><a href="https://www.datacamp.com/community/tutorials/convolutional-neural-networks-python#comment-670" class="jsx-487597203"><span class="date desktopOnly">19/04/2018 04:50 PM</span></a></div><div class="jsx-487597203 spam"><svg title="Flag as spam" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 10 12"><path d="M9.708.265A.441.441 0 0 0 9.304 0H.441A.441.441 0 0 0 0 .441v11.118a.441.441 0 1 0 .882 0V6.532h8.422a.441.441 0 0 0 .322-.735L7.274 3.27 9.626.742a.441.441 0 0 0 .082-.477z"></path></svg></div></div></div></div></div><div class="jsx-2482332697 CommentLevel top"><div class="jsx-487597203 Comment"><div id="comment-748" class="jsx-487597203 anchor"></div><div class="jsx-487597203"><a href="https://www.datacamp.com/profile/amruthasrighakolapu" target="_blank" class="jsx-487597203"><div class="jsx-3208234818 Avatar" style="background-image: url(&quot;https://res.cloudinary.com/dyd911kmh/image/fetch/t_avatar_thumbnail/https://cdn.datacamp.com/community/assets/placeholder_avatar-7f673b5d40e159404a56b5931250cc73.png&quot;); border-radius: 20px; min-width: 40px; min-height: 40px;"></div></a></div><div class="jsx-487597203 right"><div class="jsx-487597203 top"><div class="jsx-487597203"><a href="https://www.datacamp.com/profile/amruthasrighakolapu" target="_blank" class="jsx-487597203 username">Amrutha Srighakolapu</a></div><div class="jsx-487597203 more"></div></div><span class="date mobileOnly">27/04/2018 01:07 PM</span><div class="jsx-487597203 message"><p>Hello,a very good article on cnn.</p>
<p>&nbsp;I dont have labels in my test data.So while evaluting on the test data, what do I have to give as the target?</p></div><div class="jsx-487597203 bottom"><div class="jsx-487597203 left"><div class="jsx-4192737526 Upvote comment"><div class="jsx-4192737526"><div class="jsx-4192737526 normal"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path d="M1 10L6 0l5 10z"></path></svg></span><span class="jsx-4192737526 count">1</span></div><div class="jsx-4192737526 voted"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path id="a" d="M9.769.435a1.255 1.255 0 0 1 1.81-.094 1.35 1.35 0 0 1 .09 1.865l-6.457 7.36a1.257 1.257 0 0 1-1.934-.04l-2.98-3.68a1.348 1.348 0 0 1 .162-1.86 1.255 1.255 0 0 1 1.805.168L4.3 6.667 9.77.435z"></path></svg></span><span class="jsx-4192737526 count">1</span></div></div></div><a class="jsx-487597203 replyIcon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="9" viewBox="0 0 12 9"><path d="M.234 3.663L5.032.065a.375.375 0 0 1 .585.293v1.895c5.23 0 6.221 3.633 6.383 5.57a.375.375 0 0 1-.654.27C9.028 5.388 5.617 6.008 5.617 6.008v1.895a.375.375 0 0 1-.585.293L.234 4.598a.584.584 0 0 1 0-.935z"></path></svg> <span class="jsx-487597203 replyText">Reply</span></a><span class="jsx-487597203 divider desktopOnly"></span><a href="https://www.datacamp.com/community/tutorials/convolutional-neural-networks-python#comment-748" class="jsx-487597203"><span class="date desktopOnly">27/04/2018 01:07 PM</span></a></div><div class="jsx-487597203 spam"><svg title="Flag as spam" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 10 12"><path d="M9.708.265A.441.441 0 0 0 9.304 0H.441A.441.441 0 0 0 0 .441v11.118a.441.441 0 1 0 .882 0V6.532h8.422a.441.441 0 0 0 .322-.735L7.274 3.27 9.626.742a.441.441 0 0 0 .082-.477z"></path></svg></div></div></div></div></div></div></div></main><div class="jsx-3269835606 SidebarSocial"><div class="jsx-3269835606 rss"><a href="https://www.datacamp.com/community/rss.xml" class="jsx-3269835606"><svg height="13" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 18 18"><circle cx="3.08" cy="14.92" r="3.08"></circle><path d="M16.46 18a1.54 1.54 0 0 1-1.54-1.54c0-8.25-5.13-13.38-13.38-13.38A1.59 1.59 0 0 1 .46 1.15 1.72 1.72 0 0 1 1.54 0a16.45 16.45 0 0 1 12 4.51c3 2.95 4.51 7.08 4.51 12A1.54 1.54 0 0 1 16.46 18z"></path><path d="M10.63 18a1.54 1.54 0 0 1-1.54-1.54c0-5-2.54-7.54-7.54-7.54a1.54 1.54 0 0 1 0-3.08c6.75 0 10.63 3.87 10.63 10.62A1.54 1.54 0 0 1 10.63 18z"></path></svg>Subscribe to RSS</a></div><div class="jsx-3269835606 icons"><a href="https://www.facebook.com/pages/DataCamp/726282547396228" target="_blank" rel="noopener noreferrer" class="jsx-3269835606 icon"><svg height="16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 11.73 22.58"><path d="M7.61 22.58v-10.3h3.46l.52-4h-4V5.7c0-1.16.32-2 2-2h2.13V.16A28.47 28.47 0 0 0 8.63 0C5.56 0 3.47 1.87 3.47 5.31v3H0v4h3.47v10.3h4.14z"></path></svg></a><a href="https://twitter.com/datacamp" target="_blank" rel="noopener noreferrer" class="jsx-3269835606 icon"><svg height="13" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20.42 16.67"><path d="M10 5.18c0-.28-.06-.53-.07-.78a4 4 0 0 1 .73-2.57A4.08 4.08 0 0 1 13.93 0 4 4 0 0 1 17 1.15a.43.43 0 0 0 .46.12 8.68 8.68 0 0 0 2.2-.84l.2-.1a4.36 4.36 0 0 1-1.75 2.28A9 9 0 0 0 20.42 2l-.21.3a3.83 3.83 0 0 1-.23.3A8.45 8.45 0 0 1 18.5 4a.28.28 0 0 0-.13.27A12 12 0 0 1 17 10.18a11.8 11.8 0 0 1-3.37 4.11 11.17 11.17 0 0 1-4.39 2.06 12.53 12.53 0 0 1-4.44.22 11.87 11.87 0 0 1-4.74-1.73L0 14.79a8.6 8.6 0 0 0 6.16-1.74 4.28 4.28 0 0 1-3.91-2.91h.95a6.18 6.18 0 0 0 .89-.12A4.2 4.2 0 0 1 .8 5.88a4 4 0 0 0 1.81.49 4.23 4.23 0 0 1-1.78-3A4.07 4.07 0 0 1 1.38.79 12.06 12.06 0 0 0 10 5.18z" id="iOjKBC.tif"></path></svg></a><a href="https://www.linkedin.com/company/datamind-org" target="_blank" rel="noopener noreferrer" class="jsx-3269835606 icon"><svg height="12" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16.99 17"><path d="M3.85 17H.34V5.67h3.51zM2.07 4.18a2.09 2.09 0 1 1 2.08-2.09 2.08 2.08 0 0 1-2.08 2.09zM17 17h-3.5v-5.95c0-1.63-.62-2.54-1.91-2.54s-2.14.95-2.14 2.54V17H6.09V5.67h3.36v1.52a4 4 0 0 1 3.42-1.87c2.4 0 4.12 1.47 4.12 4.5V17z"></path></svg></a><a href="https://www.youtube.com/channel/UC79Gv3mYp6zKiSwYemEik9A" target="_blank" rel="noopener noreferrer" class="jsx-3269835606 icon"><svg height="12" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 25.19 17.73"><path d="M24.21 1.52C23.3.44 21.62 0 18.42 0H6.78C3.5 0 1.79.47.88 1.62S0 4.4 0 6.68V11c0 4.43 1 6.68 6.78 6.68h11.64c2.78 0 4.32-.39 5.32-1.34S25.2 13.76 25.2 11V6.68c-.01-2.41-.08-4.07-.99-5.16zm-8 7.94l-5.29 2.76a.81.81 0 0 1-1.19-.72V6a.81.81 0 0 1 1.19-.72L16.17 8a.81.81 0 0 1 0 1.44z"></path></svg></a></div><div class="jsx-3269835606 menu"><a href="https://www.datacamp.com/about" class="jsx-3269835606 menuItem">About</a><a href="https://www.datacamp.com/terms-of-use" class="jsx-3269835606 menuItem">Terms</a><a href="https://www.datacamp.com/privacy-policy" class="jsx-3269835606 menuItem">Privacy</a></div></div><div class="jsx-3994298077 BottomBar bar"><div class="jsx-3994298077 barView"><div style="background-image:url(https://res.cloudinary.com/dyd911kmh/image/fetch/t_avatar_thumbnail/https://cdn.datacamp.com/community/assets/placeholder_avatar-7f673b5d40e159404a56b5931250cc73.png);border-radius:20px;min-width:40px;min-height:40px" class="jsx-3208234818 Avatar"></div><div class="jsx-3994298077 blueBar">Want to leave a comment?</div></div></div></div><link href="./Convolutional Neural Networks in Python (article) - DataCamp_files/css(2)" rel="stylesheet"><div class="Analytics"><script>
      ;(function(p,l,o,w,i,n,g){if(!p[i]){p.GlobalSnowplowNamespace=p.GlobalSnowplowNamespace||[];
        p.GlobalSnowplowNamespace.push(i);p[i]=function(){(p[i].q=p[i].q||[]).push(arguments)
        };p[i].q=p[i].q||[];n=l.createElement(o);g=l.getElementsByTagName(o)[0];n.async=1;
        n.src=w;g.parentNode.insertBefore(n,g)}}(window,document,"script","//d36fqcuygdrd4y.cloudfront.net/BuKMCyKUvvyXZkMi44LjI.js","snowplow"));

      window.snowplow('newTracker', 'co', 'track.datacamp.com', {
        platform: 'web',
        post: true,
        discoverRootDomain: true,
        contexts: {
          webPage: true,
          performanceTiming: true
        }
      });
      window.snowplow('enableActivityTracking', 10, 10);
      window.snowplow('enableLinkClickTracking');
    </script><script data-cfasync="false">(function(W,i,s,e,P,o,p){W['WisePopsObject']=P;W[P]=W[P]||function(){
      (W[P].q=W[P].q||[]).push(arguments)},W[P].l=1*new Date();o=i.createElement(s),
      p=i.getElementsByTagName(s)[0];o.async=1;o.src=e;p.parentNode.insertBefore(o,p)
    })(window,document,'script','//loader.wisepops.com/get-loader.js?v=1&site=VswVJn7o4J','wisepops');</script></div></div></div></div><div id="__next-error"></div><script>
          __NEXT_DATA__ = {"props":{"isServer":true,"store":{},"initialState":{"adminContent":{"isFetching":false,"isFetched":false,"statusMessage":"","content":{},"form":{"isSaving":false,"isSucceeded":false,"statusMessage":"","isAdminFormModalOpen":false,"previewSlug":""},"delete":{"isDeleting":false,"isSucceeded":false,"statusMessage":"","isDeleteAdminContentModalOpen":false},"update":{"isApprovingArticle":false,"isSucceeded":false,"statusMessage":"","isApproveArticleModalOpen":false}},"adminList":{"isFetched":false,"isFetching":false,"statusMessage":""},"auth":{"isAuthModalOpen":false,"isLogin":false,"isAuthorized":false,"isSubscriber":false,"user":{},"loginTitle":"","signUpTitle":""},"clientConfig":{"isDevelopment":false,"absoluteUrl":"https://www.datacamp.com","isNewsActive":true,"ALGOLIA_APP_ID":"7H5IORUQLD","ALGOLIA_API_KEY":"ae6cc3c278ce31c9e334adc652020c2a","ALGOLIA_API_INDEX":"community_prod","DC_COMMUNITY_AUTHOR_APP_URL":"http://datacamp-community-author.us-east-1.elasticbeanstalk.com/","DC_LIGHT_URL":"https://cdn.datacamp.com/datacamp-light-latest.min.js","ANALYTICS_GOOGLE_TAG_MANAGER":"GTM-TGGWB2P","ANALYTICS_SNOWPLOW_ENDPOINT":"track.datacamp.com","COUNTDOWN_BANNER_TITLE":"Commit to learning data science in 2018 now and save $151 on DataCamp!","COUNTDOWN_BANNER_TEXT":"Offer ends in","COUNTDOWN_BANNER_START_DATE":"2018-01-02T10:00:00Z","COUNTDOWN_BANNER_END_DATE":"2018-01-10T04:59:59Z","COUNTDOWN_BANNER_LINK":"https://www.datacamp.com/promo/new-year","WISEPOPS":"VswVJn7o4J","CHAT_SUBSCRIBER_REDIRECT":"https://www.datacamp.com/slack/join","CHAT_NONSUBSCRIBER_LINK":"https://www.datacamp.com/subscribe?from_communitychat=true","CHAT_SUBSCRIBE_TEAM":"https://www.datacamp.com/groups/business"},"comment":{"isFetching":false,"isFetched":false,"statusMessage":"","comments":[],"commentsTotal":0,"form":{"isSaving":false,"isSucceeded":false,"statusMessage":"","id":"new","parentId":null,"commentText":""},"delete":{"isDeleting":false,"isSucceeded":false,"statusMessage":"","isDeleteCommentModalOpen":false},"isBottomBarOpen":true,"bottomBarView":"bar"},"content":{"content":{"id":8224,"externalId":null,"type":"Tutorial","status":"published","authorId":"adityasharma101993","title":"Convolutional Neural Networks in Python with Keras","slug":"convolutional-neural-networks-python","previewSlug":null,"description":"In this tutorial, you’ll learn how to implement Convolutional Neural Networks (CNNs) in Python with Keras, and how to overcome overfitting with dropout.","articles":[219,327,362],"courses":[],"redirectSlug":null,"contentHtml":"\u003cp\u003eYou might have already heard of image or facial recognition or self-driving cars. These are real-life implementations of Convolutional Neural Networks (CNNs). In this blog post, you will learn and understand how to implement these deep, feed-forward artificial neural networks in Keras and also learn how to overcome overfitting with the regularization technique called \u0026quot;dropout\u0026quot;.\u003c/p\u003e\r\n\u003cp\u003eMore specifically, you\u0026#39;ll tackle the following topics in today\u0026#39;s tutorial:\u003c/p\u003e\r\n\u003cul\u003e\r\n    \u003cli\u003e You will be introduced to \u003ca href='#cnn'\u003econvolutional neural networks\u003c/a\u003e;\u003c/li\u003e\r\n    \u003cli\u003e Then, you\u0026#39;ll first try to \u003ca href='#understand_data'\u003eunderstand the data\u003c/a\u003e. You\u0026#39;ll use Python and its libraries to load, \u003ca href='#explore'\u003eexplore and analyze your data\u003c/a\u003e,\u003c/li\u003e\r\n    \u003cli\u003e After that, you\u0026#39;ll \u003ca href='#preprocess'\u003epreprocess\u003c/a\u003e your data: you\u0026#39;ll learn how to resize, rescale, convert your labels into one-hot encoding vectors and split up your data in training and validation sets;\u003c/li\u003e\r\n    \u003cli\u003e With all of this done, you can \u003ca href='#network'\u003econstruct the neural network model\u003c/a\u003e: you\u0026#39;ll learn how to model the data and form the network. Next, you\u0026#39;ll compile, train and evaluate the model, visualizing the accuracy and loss plots;\u003c/li\u003e\r\n    \u003cli\u003e Then, you will learn about the concept of overfitting and how you can overcome it by \u003ca href='#dropout'\u003eadding a dropout layer\u003c/a\u003e;\u003c/li\u003e\r\n    \u003cli\u003e With this information, you can revisit your original model and re-train the model. You\u0026#39;ll also \u003ca href='#dropout_evaluate'\u003ere-evaluate your new model\u003c/a\u003e and compare the results of both the models;\u003c/li\u003e\r\n    \u003cli\u003e Next, you\u0026#39;ll make \u003ca href='#predictions'\u003epredictions on the test data\u003c/a\u003e, convert the probabilities into class labels and plot few test samples that your model correctly classified and incorrectly classified;\u003c/li\u003e\r\n    \u003cli\u003e Finally, you will visualize the \u003ca href='#classification'\u003eclassification report\u003c/a\u003e which will give you more in-depth intuition about which class was (in)correctly classified by your model.\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\r\n\u003cp\u003eWould you like to take a course on Keras and deep learning in Python? Consider taking DataCamp\u0026#39;s \u003ca href=\"  https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf\" target=\"_blank\"\u003eDeep Learning in Python\u003c/a\u003e course!\u003c/p\u003e\r\n\u003cp\u003eAlso, don't miss our \u003ca href=\"  https://www.datacamp.com/community/blog/keras-cheat-sheet\" target=\"_blank\"\u003eKeras cheat sheet\u003c/a\u003e, which shows you the six steps that you need to go through to build neural networks in Python with code examples!\u003c/p\u003e\r\n\u003cp\u003e\u003ca id='cnn'\u003e\u003c/a\u003e\u003c/p\u003e\r\n\u003ch2 id=\"convolutional-neural-network-introduction\"\u003eConvolutional Neural Network: Introduction\u003c/h2\u003e\r\n\u003cp\u003eBy now, you might already know about machine learning and deep learning, a computer science branch that studies the design of algorithms that can learn. Deep learning is a subfield of machine learning that is inspired by artificial neural networks, which in turn are inspired by biological neural networks. \u003c/p\u003e\r\n\u003cp\u003eA specific kind of such a deep neural network is the convolutional network, which is commonly referred to as CNN or ConvNet. It\u0026#39;s a deep, feed-forward artificial neural network. \u003cstrong\u003eRemember\u003c/strong\u003e that feed-forward neural networks are also called multi-layer perceptrons(MLPs), which are the quintessential deep learning models. The models are called \u0026quot;feed-forward\u0026quot; because information fl�ows right through the model. There are no feedback connections in which outputs of the model are fed back into itself.\u003c/p\u003e\r\n\u003cp\u003eCNNs specifically are inspired by the biological visual cortex. The cortex has small regions of cells that are sensitive to the specific areas of the visual field. This idea was expanded by a captivating experiment done by Hubel and Wiesel in 1962 (if you want to know more, here\u0026#39;s a \u003ca href=\"https://www.youtube.com/watch?v=Cw5PKV9Rj3o\"\u003evideo\u003c/a\u003e). In this experiment, the researchers showed that some individual neurons in the brain activated or fired only in the presence of edges of a particular orientation like vertical or horizontal edges. For example, some neurons fired when exposed to vertical sides and some when shown a horizontal edge. Hubel and Wiesel found that all of these neurons were well ordered in a columnar fashion and that together they were able to produce visual perception. This idea of specialized components inside of a system having specific tasks is one that machines use as well and one that you can also find back in CNNs.\u003c/p\u003e\r\n\u003cp\u003eConvolutional neural networks have been one of the most influential innovations in the field of computer vision. They have performed a lot better than traditional computer vision and have produced state-of-the-art results. These neural networks have proven to be successful in many different real-life case studies and applications, like:\u003c/p\u003e\r\n\u003cul\u003e\r\n    \u003cli\u003eImage classification, object detection, segmentation, face recognition;\u003c/li\u003e\r\n    \u003cli\u003eSelf driving cars that leverage CNN based vision systems; \u003c/li\u003e\r\n    \u003cli\u003eClassification of crystal structure using a convolutional neural network;\u003c/li\u003e\r\n    \u003cli\u003eAnd many more, of course!\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\r\n\u003cp\u003eTo understand this success, you\u0026#39;ll have to go back to 2012, the year in which Alex Krizhevsky used convolutional neural networks to win that year\u0026#39;s ImageNet Competition, reducing the classification error from 26% to 15%. \u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eNote\u003c/strong\u003e that ImageNet Large Scale Visual Recognition Challenge (ILSVRC) began in the year 2010 is an annual competition where research teams assess their algorithms on the given data set and compete to achieve higher accuracy on several visual recognition tasks.\u003c/p\u003e\r\n\u003cp\u003eThis was the time when neural networks \u003ca href=\"https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf\" target=\"_blank\"\u003eregained\u003c/a\u003e prominence after quite some time. This is often called the \u0026quot;third wave of neural networks\u0026quot;. The other two waves were in the 1940s until the 1960s and in the 1970s to 1980s. \u003c/p\u003e\r\n\u003cp\u003eAlright, you know that you\u0026#39;ll be working with feed-forward networks that are inspired by the biological visual cortex, but what does that actually mean?\u003c/p\u003e\r\n\u003cp\u003eTake a look at the picture below:\u003c/p\u003e\r\n\u003cp\u003e\u003cdiv style=\"text-align:center\"\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1512486717/Typical_cnn_kecdep.png\" alt=\"convolutional neural networks python\"\u003e\u003c/div\u003e\u003cbr\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cdiv style=\"text-align:center\"\u003e\u003csmall\u003eFigure: Convolutional Neural Network from \u003ca href=\"https://commons.wikimedia.org/wiki/File:Typical_cnn.png\"\u003eWikimedia\u003c/a\u003e\u003c/small\u003e\u003c/div\u003e\u003cbr\u003e\u003c/p\u003e\r\n\u003cp\u003eThe image shows you that you feed an image as an input to the network, which goes through multiple convolutions, subsampling, a fully connected layer and finally outputs something.\u003c/p\u003e\r\n\u003cp\u003eBut what are all these concepts? \u003c/p\u003e\r\n\u003col\u003e\r\n    \u003cli\u003e The convolution layer computes the output of neurons that are connected to local regions or receptive fields in the input, each computing a dot product between their weights and a small receptive field to which they are connected to in the input volume. Each computation leads to extraction of a feature map from the input image. In other words, imagine you have an image represented as a 5x5 matrix of values, and you take a 3x3 matrix and slide that 3x3 window or kernel around the image. At each position of that matrix, you multiply the values of your 3x3 window by the values in the image that are currently being covered by the window. As a result, you\u0026#39;ll get a single number that represents all the values in that window of the images. You use this layer to filtering: as the window moves over the image, you check for patterns in that section of the image. This works because of filters, which are multiplied by the values outputted by the convolution.\u003c/li\u003e\r\n    \u003cli\u003e The objective of subsampling is to get an input representation by reducing its dimensions, which helps in reducing overfitting. One of the techniques of subsampling is max pooling. With this technique, you select the highest pixel value from a region depending on its size. In other words, max pooling takes the largest value from the window of the image currently covered by the kernel. For example, you can have a max-pooling layer of size 2 x 2 will select the maximum pixel intensity value from 2 x 2 region. You\u0026#39;re right to think that the pooling layer then works a lot like the convolution layer! You also take a kernel or a window and move it over the image; The only difference is the function that is applied to the kernel and the image window isn\u0026#39;t linear. \r\n\u003cdiv style=\"text-align:center\"\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1512486717/max-pooling_tkk5n2.png\" alt=\"convolutional neural network in python\"\u003e\u003c/div\u003e\r\n\u003cdiv style=\"text-align:center\"\u003e\u003csmall\u003eFigure: Max-Pooling from \u003ca href=\"https://en.wikipedia.org/wiki/Convolutional_neural_network\"\u003eWikipedia\u003c/a\u003e\u003c/small\u003e\u003c/div\u003e\u003cbr\u003e\r\n    \u003cli\u003e The objective of the fully connected layer is to flatten the high-level features that are learned by convolutional layers and combining all the features. It passes the flattened output to the output layer where you use a softmax classifier or a sigmoid to predict the input class label.\u003c/li\u003e\r\n\u003c/ol\u003e    \r\n\r\n\u003cp\u003eFor more information, you can go \u003ca href=\"http://cs231n.github.io/convolutional-networks/\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\r\n\u003cp\u003e\u003ca id='understand_data'\u003e\u003c/a\u003e\u003c/p\u003e\r\n\u003ch2 id=\"the-fashion-mnist-data-set\"\u003eThe Fashion-MNIST Data Set\u003c/h2\u003e\r\n\u003cp\u003eBefore you go ahead and load in the data, it\u0026#39;s good to take a look at what you\u0026#39;ll exactly be working with! The \u003ca href=\"https://arxiv.org/abs/1708.07747\" target=\"_blank\"\u003eFashion-MNIST\u003c/a\u003e dataset is a dataset of Zalando\u0026#39;s article images, with 28x28 grayscale images of 70,000 fashion products from 10 categories, and 7,000 images per category. The training set has 60,000 images, and the test set has 10,000 images. You can double check this later when you have loaded in your data! ;)\u003c/p\u003e\r\n\u003cp\u003eFashion-MNIST is similar to the MNIST dataset that you might already know, which you use to classify handwritten digits. That means that the image dimensions, training and test splits are similar to the MNIST dataset. \u003cstrong\u003eTip\u003c/strong\u003e: if you want to learn how to implement an Multi-Layer Perceptron (MLP) for classification tasks with this latter dataset, go to \u003ca href=\"https://www.datacamp.com/community/tutorials/deep-learning-python\"\u003ethis tutorial\u003c/a\u003e.\u003c/p\u003e\r\n\u003cp\u003eYou can find the Fashion-MNIST dataset \u003ca href=\"https://github.com/zalandoresearch/fashion-mnist\" target=\"_blank\"\u003ehere\u003c/a\u003e, but you can also load it with the help of specific TensorFlow and Keras modules. You\u0026#39;ll see how this works in the next section!\u003c/p\u003e\r\n\u003ch2 id=\"load-the-data\"\u003eLoad the Data\u003c/h2\u003e\r\n\u003cp\u003eKeras comes with a library called \u003ccode\u003edatasets\u003c/code\u003e, which you can use to load datasets out of the box: you download the data from the server and speeds up the process since you no longer have to download the data to your computer. The train and test images along with the labels are loaded and stored in variables \u003ccode\u003etrain_X\u003c/code\u003e, \u003ccode\u003etrain_Y\u003c/code\u003e, \u003ccode\u003etest_X\u003c/code\u003e, \u003ccode\u003etest_Y\u003c/code\u003e, respectively. \u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003efrom keras.datasets import fashion_mnist\r\n(train_X,train_Y), (test_X,test_Y) = fashion_mnist.load_data()\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003eUsing TensorFlow backend.\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eGreat! That was pretty simple, wasn\u0026#39;t it?\u003c/p\u003e\r\n\u003cp\u003eYou have probably done this a million times by now, but it\u0026#39;s always an essential step to get started. Now you\u0026#39;re completely set to start analyzing, processing and modeling your data!\u003c/p\u003e\r\n\u003cp\u003e\u003ca id='explore'\u003e\u003c/a\u003e\u003c/p\u003e\r\n\u003ch2 id=\"analyze-the-data\"\u003eAnalyze the Data\u003c/h2\u003e\r\n\u003cp\u003eLet\u0026#39;s now analyze how images in the dataset look like. Even though you know the dimension of the images by now, it\u0026#39;s still worth the effort to analyze it programmatically: you might have to rescale the image pixels and resize the images.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003eimport numpy as np\r\nfrom keras.utils import to_categorical\r\nimport matplotlib.pyplot as plt\r\n%matplotlib inline\r\n\r\nprint(\u0026#39;Training data shape : \u0026#39;, train_X.shape, train_Y.shape)\r\n\r\nprint(\u0026#39;Testing data shape : \u0026#39;, test_X.shape, test_Y.shape)\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e(\u0026#39;Training data shape : \u0026#39;, (60000, 28, 28), (60000,))\r\n(\u0026#39;Testing data shape : \u0026#39;, (10000, 28, 28), (10000,))\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eFrom the above output, you can see that the training data has a shape of 60000 x 28 x 28 since there are 60,000 training samples each of 28 x 28 dimension. Similarly, the test data has a shape of 10000 x 28 x 28 since there are 10,000 testing samples.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# Find the unique numbers from the train labels\r\nclasses = np.unique(train_Y)\r\nnClasses = len(classes)\r\nprint(\u0026#39;Total number of outputs : \u0026#39;, nClasses)\r\nprint(\u0026#39;Output classes : \u0026#39;, classes)\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e(\u0026#39;Total number of outputs : \u0026#39;, 10)\r\n(\u0026#39;Output classes : \u0026#39;, array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8))\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eThere\u0026#39;s also a total of ten output classes that range from 0 to 9.\u003c/p\u003e\r\n\u003cp\u003eAlso, don\u0026#39;t forget to take a look at what the images in your dataset:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003eplt.figure(figsize=[5,5])\r\n\r\n# Display the first image in training data\r\nplt.subplot(121)\r\nplt.imshow(train_X[0,:,:], cmap=\u0026#39;gray\u0026#39;)\r\nplt.title(\u0026quot;Ground Truth : {}\u0026quot;.format(train_Y[0]))\r\n\r\n# Display the first image in testing data\r\nplt.subplot(122)\r\nplt.imshow(test_X[0,:,:], cmap=\u0026#39;gray\u0026#39;)\r\nplt.title(\u0026quot;Ground Truth : {}\u0026quot;.format(test_Y[0]))\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003eText(0.5,1,u\u0026#39;Ground Truth : 9\u0026#39;)\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1512485101/output_19_1_udnwlg.png\"/\u003e\u003c/p\u003e\r\n\u003cp\u003eThe output of above two plots looks like an ankle boot, and this class is assigned a class label of 9. Similarly, other fashion products will have different labels, but similar products will have same labels. This means that all the 7,000 ankle boot images will have a class label of 9.\u003c/p\u003e\r\n\u003cp\u003e\u003ca id='preprocess'\u003e\u003c/a\u003e\u003c/p\u003e\r\n\u003ch2 id=\"data-preprocessing\"\u003eData Preprocessing\u003c/h2\u003e\r\n\u003cp\u003eAs you could see in the above plot, the images are grayscale images have pixel values that range from 0 to 255. Also, these images have a dimension of 28 x 28. As a result, you\u0026#39;ll need to preprocess the data before you feed it into the model.\r\n\u003cbr\u003e\u003c/p\u003e\r\n\u003cul\u003e\r\n    \u003cli\u003eAs a first step, convert each 28 x 28 image of the train and test set into a matrix of size 28 x 28 x 1 which is fed into the network.\u003c/li\u003e\r\n\u003c/ul\u003e    \r\n\r\n\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003etrain_X = train_X.reshape(-1, 28,28, 1)\r\ntest_X = test_X.reshape(-1, 28,28, 1)\r\ntrain_X.shape, test_X.shape\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e((60000, 28, 28, 1), (10000, 28, 28, 1))\r\n\u003c/code\u003e\u003c/pre\u003e\u003cul\u003e \r\n \u003cli\u003e The data right now is in an int8 format, so before you feed it into the network you need to convert its type to float32, and you also have to rescale the pixel values in range 0 - 1 inclusive. So let\u0026#39;s do that!\u003c/li\u003e\r\n\u003c/ul\u003e \r\n\r\n\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003etrain_X = train_X.astype(\u0026#39;float32\u0026#39;)\r\ntest_X = test_X.astype(\u0026#39;float32\u0026#39;)\r\ntrain_X = train_X / 255.\r\ntest_X = test_X / 255.\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cul\u003e\r\n\u003cli\u003eNow you need to convert the class labels into a one-hot encoding vector.\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\r\n\u003cp\u003eIn one-hot encoding, you convert the categorical data into a vector of numbers. The reason why you convert the categorical data in one hot encoding is that machine learning algorithms cannot work with categorical data directly. You generate one boolean column for each category or class. Only one of these columns could take on the value 1 for each sample. Hence, the term one-hot encoding.\u003c/p\u003e\r\n\u003cp\u003eFor your problem statement, the one hot encoding will be a row vector, and for each image, it will have a dimension of 1 x 10. The important thing to note here is that the vector consists of all zeros except for the class that it represents, and for that, it is 1. For example, the ankle boot image that you plotted above has a label of 9, so for all the ankle boot images, the one hot encoding vector would be \u003ccode\u003e[0 0 0 0 0 0 0 0 1 0]\u003c/code\u003e.\r\n\u003c/ul\u003e\u003c/p\u003e\r\n\u003cp\u003eSo let\u0026#39;s convert the training and testing labels into one-hot encoding vectors:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# Change the labels from categorical to one-hot encoding\r\ntrain_Y_one_hot = to_categorical(train_Y)\r\ntest_Y_one_hot = to_categorical(test_Y)\r\n\r\n# Display the change for category label using one-hot encoding\r\nprint(\u0026#39;Original label:\u0026#39;, train_Y[0])\r\nprint(\u0026#39;After conversion to one-hot:\u0026#39;, train_Y_one_hot[0])\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e(\u0026#39;Original label:\u0026#39;, 9)\r\n(\u0026#39;After conversion to one-hot:\u0026#39;, array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.]))\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eThat\u0026#39;s pretty clear, right? \u003cstrong\u003eNote\u003c/strong\u003e that you can also print the \u003ccode\u003etrain_Y_one_hot\u003c/code\u003e, which will display a matrix of size 60000 x 10 in which each row depicts one-hot encoding of an image.\u003c/p\u003e\r\n\u003cul\u003e\r\n    \u003cli\u003e This last step is a crucial one. In machine learning or any data specific task, you should partition the data correctly. For the model to generalize well, you split the training data into two parts, one designed for training and another one for validation. In this case, you will train the model on 80\\% of the training data and validate it on 20\\% of the remaining training data. This will also help to reduce overfitting since you will be validating the model on the data it would not have seen in training phase, which will help in boosting the test performance.\u003c/li\u003e\r\n    \u003c/ul\u003e\r\n\r\n\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003efrom sklearn.model_selection import train_test_split\r\ntrain_X,valid_X,train_label,valid_label = train_test_split(train_X, train_Y_one_hot, test_size=0.2, random_state=13)\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eFor one last time let\u0026#39;s check the shape of training and validation set.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003etrain_X.shape,valid_X.shape,train_label.shape,valid_label.shape\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e((48000, 28, 28, 1), (12000, 28, 28, 1), (48000, 10), (12000, 10))\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003ca id='network'\u003e\u003c/a\u003e\u003c/p\u003e\r\n\u003ch2 id=\"the-network\"\u003eThe Network\u003c/h2\u003e\r\n\u003cp\u003eThe images are of size 28 x 28. You convert the image matrix to an array, rescale it between 0 and 1, reshape it so that it\u0026#39;s of size 28 x 28 x 1, and feed this as an input to the network. \u003c/p\u003e\r\n\u003cp\u003eYou\u0026#39;ll use three convolutional layers: \u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli\u003eThe first layer will have 32-3 x 3 filters,\u003c/li\u003e\r\n\u003cli\u003eThe second layer will have 64-3 x 3 filters and\u003c/li\u003e\r\n\u003cli\u003eThe third layer will have 128-3 x 3 filters.\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\r\n\u003cp\u003eIn addition, there are three max-pooling layers each of size 2 x 2.\u003c/p\u003e\r\n\u003cp\u003e\u003cdiv style=\"text-align:center\"\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1512486717/fashion-mnist-architecture_htbpsz.png\"\u003e\u003c/div\u003e\u003cbr\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cdiv style=\"text-align:center\"\u003eFigure: Architecture of the Model\u003c/div\u003e\u003cbr\u003e\u003c/p\u003e\r\n\u003ch2 id=\"model-the-data\"\u003eModel the Data\u003c/h2\u003e\r\n\u003cp\u003eFirst, let\u0026#39;s import all the necessary modules required to train the model.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003eimport keras\r\nfrom keras.models import Sequential,Input,Model\r\nfrom keras.layers import Dense, Dropout, Flatten\r\nfrom keras.layers import Conv2D, MaxPooling2D\r\nfrom keras.layers.normalization import BatchNormalization\r\nfrom keras.layers.advanced_activations import LeakyReLU\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eYou will use a batch size of 64 using a higher batch size of 128 or 256 is also preferable it all depends on the memory. It contributes massively to determining the learning parameters and affects the prediction accuracy. You will train the network for 20 epochs.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003ebatch_size = 64\r\nepochs = 20\r\nnum_classes = 10\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003ch2 id=\"neural-network-architecture\"\u003eNeural Network Architecture\u003c/h2\u003e\r\n\u003cp\u003eIn Keras, you can just stack up layers by adding the desired layer one by one. That\u0026#39;s exactly what you\u0026#39;ll do here: you\u0026#39;ll first add a first convolutional layer with \u003ccode\u003eConv2D()\u003c/code\u003e. Note that you use this function because you\u0026#39;re working with images! Next, you add the Leaky ReLU activation function which helps the network learn non-linear decision boundaries. Since you have ten different classes, you\u0026#39;ll need a non-linear decision boundary that could separate these ten classes which are not linearly separable. \u003c/p\u003e\r\n\u003cp\u003eMore specifically, you add Leaky ReLUs because they attempt to fix the problem of dying Rectified Linear Units (ReLUs). The ReLU activation function is used a lot in neural network architectures and more specifically in convolutional networks, where it has proven to be more effective than the widely used logistic sigmoid function. As of 2017, this activation function is the most popular one for deep neural networks. The ReLU function allows the activation to be thresholded at zero. However, during the training, ReLU units can \u0026quot;die\u0026quot;. This can happen when a large gradient flows through a ReLU neuron: it can cause the weights to update in such a way that the neuron will never activate on any data point again. If this happens, then the gradient flowing through the unit will forever be zero from that point on. Leaky ReLUs attempt to solve this: the function will not be zero but will instead have a small negative slope. \u003c/p\u003e\r\n\u003cp\u003eNext, you\u0026#39;ll add the max-pooling layer with \u003ccode\u003eMaxPooling2D()\u003c/code\u003e and so on. The last layer is a Dense layer that has a softmax activation function with 10 units, which is needed for this multi-class classification problem.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003efashion_model = Sequential()\r\nfashion_model.add(Conv2D(32, kernel_size=(3, 3),activation=\u0026#39;linear\u0026#39;,input_shape=(28,28,1),padding=\u0026#39;same\u0026#39;))\r\nfashion_model.add(LeakyReLU(alpha=0.1))\r\nfashion_model.add(MaxPooling2D((2, 2),padding=\u0026#39;same\u0026#39;))\r\nfashion_model.add(Conv2D(64, (3, 3), activation=\u0026#39;linear\u0026#39;,padding=\u0026#39;same\u0026#39;))\r\nfashion_model.add(LeakyReLU(alpha=0.1))\r\nfashion_model.add(MaxPooling2D(pool_size=(2, 2),padding=\u0026#39;same\u0026#39;))\r\nfashion_model.add(Conv2D(128, (3, 3), activation=\u0026#39;linear\u0026#39;,padding=\u0026#39;same\u0026#39;))\r\nfashion_model.add(LeakyReLU(alpha=0.1))                  \r\nfashion_model.add(MaxPooling2D(pool_size=(2, 2),padding=\u0026#39;same\u0026#39;))\r\nfashion_model.add(Flatten())\r\nfashion_model.add(Dense(128, activation=\u0026#39;linear\u0026#39;))\r\nfashion_model.add(LeakyReLU(alpha=0.1))                  \r\nfashion_model.add(Dense(num_classes, activation=\u0026#39;softmax\u0026#39;))\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003ch2 id=\"compile-the-model\"\u003eCompile the Model\u003c/h2\u003e\r\n\u003cp\u003eAfter the model is created, you compile it using the Adam optimizer, one of the most popular optimization algorithms. You can read more about this optimizer \u003ca href=\" https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/\" target=\"_blank\"\u003ehere\u003c/a\u003e. Additionally, you specify the loss type which is categorical cross entropy which is used for multi-class classification, you can also use binary cross-entropy as the loss function. Lastly, you specify the metrics as accuracy which you want to analyze while the model is training.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003efashion_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=[\u0026#39;accuracy\u0026#39;])\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eLet\u0026#39;s visualize the layers that you created in the above step by using the summary function. This will show some parameters (weights and biases) in each layer and also the total parameters in your model.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003efashion_model.summary()\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\nconv2d_51 (Conv2D)           (None, 28, 28, 32)        320       \r\n_________________________________________________________________\r\nleaky_re_lu_57 (LeakyReLU)   (None, 28, 28, 32)        0         \r\n_________________________________________________________________\r\nmax_pooling2d_49 (MaxPooling (None, 14, 14, 32)        0         \r\n_________________________________________________________________\r\nconv2d_52 (Conv2D)           (None, 14, 14, 64)        18496     \r\n_________________________________________________________________\r\nleaky_re_lu_58 (LeakyReLU)   (None, 14, 14, 64)        0         \r\n_________________________________________________________________\r\nmax_pooling2d_50 (MaxPooling (None, 7, 7, 64)          0         \r\n_________________________________________________________________\r\nconv2d_53 (Conv2D)           (None, 7, 7, 128)         73856     \r\n_________________________________________________________________\r\nleaky_re_lu_59 (LeakyReLU)   (None, 7, 7, 128)         0         \r\n_________________________________________________________________\r\nmax_pooling2d_51 (MaxPooling (None, 4, 4, 128)         0         \r\n_________________________________________________________________\r\nflatten_17 (Flatten)         (None, 2048)              0         \r\n_________________________________________________________________\r\ndense_33 (Dense)             (None, 128)               262272    \r\n_________________________________________________________________\r\nleaky_re_lu_60 (LeakyReLU)   (None, 128)               0         \r\n_________________________________________________________________\r\ndense_34 (Dense)             (None, 10)                1290      \r\n=================================================================\r\nTotal params: 356,234\r\nTrainable params: 356,234\r\nNon-trainable params: 0\r\n_________________________________________________________________\r\n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"train-the-model\"\u003eTrain the Model\u003c/h2\u003e\r\n\u003cp\u003eIt\u0026#39;s finally time to train the model with Keras\u0026#39; \u003ccode\u003efit()\u003c/code\u003e function! The model trains for 20 epochs. The \u003ccode\u003efit()\u003c/code\u003e function will return a \u003ccode\u003ehistory\u003c/code\u003e object; By storying the result of this function in \u003ccode\u003efashion_train\u003c/code\u003e, you can use it later to plot the accuracy and loss function plots between training and validation which will help you to analyze your model\u0026#39;s performance visually.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003efashion_train = fashion_model.fit(train_X, train_label, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X, valid_label))\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003eTrain on 48000 samples, validate on 12000 samples\r\nEpoch 1/20\r\n48000/48000 [==============================] - 60s 1ms/step - loss: 0.4661 - acc: 0.8311 - val_loss: 0.3320 - val_acc: 0.8809\r\nEpoch 2/20\r\n48000/48000 [==============================] - 60s 1ms/step - loss: 0.2874 - acc: 0.8951 - val_loss: 0.2781 - val_acc: 0.8963\r\nEpoch 3/20\r\n48000/48000 [==============================] - 60s 1ms/step - loss: 0.2420 - acc: 0.9111 - val_loss: 0.2501 - val_acc: 0.9077\r\nEpoch 4/20\r\n48000/48000 [==============================] - 59s 1ms/step - loss: 0.2088 - acc: 0.9226 - val_loss: 0.2369 - val_acc: 0.9147\r\nEpoch 5/20\r\n48000/48000 [==============================] - 59s 1ms/step - loss: 0.1838 - acc: 0.9324 - val_loss: 0.2602 - val_acc: 0.9070\r\nEpoch 6/20\r\n48000/48000 [==============================] - 59s 1ms/step - loss: 0.1605 - acc: 0.9396 - val_loss: 0.2264 - val_acc: 0.9193\r\nEpoch 7/20\r\n48000/48000 [==============================] - 59s 1ms/step - loss: 0.1356 - acc: 0.9488 - val_loss: 0.2566 - val_acc: 0.9180\r\nEpoch 8/20\r\n48000/48000 [==============================] - 59s 1ms/step - loss: 0.1186 - acc: 0.9553 - val_loss: 0.2556 - val_acc: 0.9149\r\nEpoch 9/20\r\n48000/48000 [==============================] - 59s 1ms/step - loss: 0.0985 - acc: 0.9634 - val_loss: 0.2681 - val_acc: 0.9204\r\nEpoch 10/20\r\n48000/48000 [==============================] - 59s 1ms/step - loss: 0.0873 - acc: 0.9670 - val_loss: 0.2712 - val_acc: 0.9221\r\nEpoch 11/20\r\n48000/48000 [==============================] - 59s 1ms/step - loss: 0.0739 - acc: 0.9721 - val_loss: 0.2757 - val_acc: 0.9202\r\nEpoch 12/20\r\n48000/48000 [==============================] - 60s 1ms/step - loss: 0.0628 - acc: 0.9767 - val_loss: 0.3126 - val_acc: 0.9132\r\nEpoch 13/20\r\n48000/48000 [==============================] - 61s 1ms/step - loss: 0.0569 - acc: 0.9789 - val_loss: 0.3556 - val_acc: 0.9081\r\nEpoch 14/20\r\n48000/48000 [==============================] - 60s 1ms/step - loss: 0.0452 - acc: 0.9833 - val_loss: 0.3441 - val_acc: 0.9189\r\nEpoch 15/20\r\n48000/48000 [==============================] - 60s 1ms/step - loss: 0.0421 - acc: 0.9847 - val_loss: 0.3400 - val_acc: 0.9165\r\nEpoch 16/20\r\n48000/48000 [==============================] - 60s 1ms/step - loss: 0.0379 - acc: 0.9861 - val_loss: 0.3876 - val_acc: 0.9195\r\nEpoch 17/20\r\n48000/48000 [==============================] - 60s 1ms/step - loss: 0.0405 - acc: 0.9855 - val_loss: 0.4112 - val_acc: 0.9164\r\nEpoch 18/20\r\n48000/48000 [==============================] - 60s 1ms/step - loss: 0.0285 - acc: 0.9897 - val_loss: 0.4150 - val_acc: 0.9181\r\nEpoch 19/20\r\n48000/48000 [==============================] - 61s 1ms/step - loss: 0.0322 - acc: 0.9877 - val_loss: 0.4584 - val_acc: 0.9196\r\nEpoch 20/20\r\n48000/48000 [==============================] - 61s 1ms/step - loss: 0.0262 - acc: 0.9906 - val_loss: 0.4396 - val_acc: 0.9205\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eFinally! You trained the model on fashion-MNIST for 20 epochs, and by observing the training accuracy and loss, you can say that the model did a good job since after 20 epochs the training accuracy is 99% and the training loss is quite low.\u003c/p\u003e\r\n\u003cp\u003eHowever, it looks like the model is overfitting, as the validation loss is 0.4396 and the validation accuracy is 92%. Overfitting gives an intuition that the network has memorized the training data very well but is not guaranteed to work on unseen data, and that is why there is a difference in the training and validation accuracy. \u003c/p\u003e\r\n\u003cp\u003eYou probably need to handle this. In next sections, you\u0026#39;ll learn how you can make your model perform much better by adding a Dropout layer into the network and keeping all the other layers unchanged. \u003c/p\u003e\r\n\u003cp\u003eBut first, let\u0026#39;s evaluate the performance of your model on the test set before you come on to a conclusion.\u003c/p\u003e\r\n\u003ch2 id=\"model-evaluation-on-the-test-set\"\u003eModel Evaluation on the Test Set\u003c/h2\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003etest_eval = fashion_model.evaluate(test_X, test_Y_one_hot, verbose=0)\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003eprint(\u0026#39;Test loss:\u0026#39;, test_eval[0])\r\nprint(\u0026#39;Test accuracy:\u0026#39;, test_eval[1])\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e(\u0026#39;Test loss:\u0026#39;, 0.46366268818555401)\r\n(\u0026#39;Test accuracy:\u0026#39;, 0.91839999999999999)\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eThe test accuracy looks impressive. It turns out that your classifier does better than the benchmark that was reported \u003ca href=\"http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/\" target=\"_blank\"\u003ehere\u003c/a\u003e, which is an SVM classifier with mean accuracy of 0.897. Also, the model does well compared to some of the deep learning models mentioned on the \u003ca href=\"https://github.com/zalandoresearch/fashion-mnist\" target=\"_blank\"\u003eGitHub\u003c/a\u003e profile of the creators of fashion-MNIST dataset.\u003c/p\u003e\r\n\u003cp\u003eHowever, you saw that the model looked like it was overfitting. Are these results really all that good? \u003c/p\u003e\r\n\u003cp\u003eLet\u0026#39;s put your model evaluation into perspective and plot the accuracy and loss plots between training and validation data:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003eaccuracy = fashion_train.history[\u0026#39;acc\u0026#39;]\r\nval_accuracy = fashion_train.history[\u0026#39;val_acc\u0026#39;]\r\nloss = fashion_train.history[\u0026#39;loss\u0026#39;]\r\nval_loss = fashion_train.history[\u0026#39;val_loss\u0026#39;]\r\nepochs = range(len(accuracy))\r\nplt.plot(epochs, accuracy, \u0026#39;bo\u0026#39;, label=\u0026#39;Training accuracy\u0026#39;)\r\nplt.plot(epochs, val_accuracy, \u0026#39;b\u0026#39;, label=\u0026#39;Validation accuracy\u0026#39;)\r\nplt.title(\u0026#39;Training and validation accuracy\u0026#39;)\r\nplt.legend()\r\nplt.figure()\r\nplt.plot(epochs, loss, \u0026#39;bo\u0026#39;, label=\u0026#39;Training loss\u0026#39;)\r\nplt.plot(epochs, val_loss, \u0026#39;b\u0026#39;, label=\u0026#39;Validation loss\u0026#39;)\r\nplt.title(\u0026#39;Training and validation loss\u0026#39;)\r\nplt.legend()\r\nplt.show()\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1512485101/output_56_0_st6ods.png\"/\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1512485101/output_56_1_ie0rbw.png\"/\u003e\u003c/p\u003e\r\n\u003cp\u003eFrom the above two plots, you can see that the validation accuracy almost became stagnant after 4-5 epochs and rarely increased at certain epochs. In the beginning, the validation accuracy was linearly increasing with loss, but then it did not increase much.\u003c/p\u003e\r\n\u003cp\u003eThe validation loss shows that this is the sign of overfitting, similar to validation accuracy it linearly decreased but after 4-5 epochs, it started to increase. This means that the model tried to memorize the data and succeeded.\u003c/p\u003e\r\n\u003cp\u003eWith this in mind, it\u0026#39;s time to introduce some dropout into our model and see if it helps in reducing overfitting.\u003c/p\u003e\r\n\u003cp\u003e\u003ca id='dropout'\u003e\u003c/a\u003e\u003c/p\u003e\r\n\u003ch2 id=\"adding-dropout-into-the-network\"\u003eAdding Dropout into the Network\u003c/h2\u003e\r\n\u003cp\u003eYou can add a dropout layer to overcome the problem of overfitting to some extent. Dropout randomly turns off a fraction of neurons during the training process, reducing the dependency on the training set by some amount. How many fractions of neurons you want to turn off is decided by a hyperparameter, which can be tuned accordingly. This way, turning off some neurons will not allow the network to memorize the training data since not all the neurons will be active at the same time and the inactive neurons will not be able to learn anything.\u003c/p\u003e\r\n\u003cp\u003eSo let\u0026#39;s create, compile and train the network again but this time with dropout. And run it for 20 epochs with a batch size of 64.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003ebatch_size = 64\r\nepochs = 20\r\nnum_classes = 10\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003efashion_model = Sequential()\r\nfashion_model.add(Conv2D(32, kernel_size=(3, 3),activation=\u0026#39;linear\u0026#39;,padding=\u0026#39;same\u0026#39;,input_shape=(28,28,1)))\r\nfashion_model.add(LeakyReLU(alpha=0.1))\r\nfashion_model.add(MaxPooling2D((2, 2),padding=\u0026#39;same\u0026#39;))\r\nfashion_model.add(Dropout(0.25))\r\nfashion_model.add(Conv2D(64, (3, 3), activation=\u0026#39;linear\u0026#39;,padding=\u0026#39;same\u0026#39;))\r\nfashion_model.add(LeakyReLU(alpha=0.1))\r\nfashion_model.add(MaxPooling2D(pool_size=(2, 2),padding=\u0026#39;same\u0026#39;))\r\nfashion_model.add(Dropout(0.25))\r\nfashion_model.add(Conv2D(128, (3, 3), activation=\u0026#39;linear\u0026#39;,padding=\u0026#39;same\u0026#39;))\r\nfashion_model.add(LeakyReLU(alpha=0.1))                  \r\nfashion_model.add(MaxPooling2D(pool_size=(2, 2),padding=\u0026#39;same\u0026#39;))\r\nfashion_model.add(Dropout(0.4))\r\nfashion_model.add(Flatten())\r\nfashion_model.add(Dense(128, activation=\u0026#39;linear\u0026#39;))\r\nfashion_model.add(LeakyReLU(alpha=0.1))           \r\nfashion_model.add(Dropout(0.3))\r\nfashion_model.add(Dense(num_classes, activation=\u0026#39;softmax\u0026#39;))\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003efashion_model.summary()\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\nconv2d_54 (Conv2D)           (None, 28, 28, 32)        320       \r\n_________________________________________________________________\r\nleaky_re_lu_61 (LeakyReLU)   (None, 28, 28, 32)        0         \r\n_________________________________________________________________\r\nmax_pooling2d_52 (MaxPooling (None, 14, 14, 32)        0         \r\n_________________________________________________________________\r\ndropout_29 (Dropout)         (None, 14, 14, 32)        0         \r\n_________________________________________________________________\r\nconv2d_55 (Conv2D)           (None, 14, 14, 64)        18496     \r\n_________________________________________________________________\r\nleaky_re_lu_62 (LeakyReLU)   (None, 14, 14, 64)        0         \r\n_________________________________________________________________\r\nmax_pooling2d_53 (MaxPooling (None, 7, 7, 64)          0         \r\n_________________________________________________________________\r\ndropout_30 (Dropout)         (None, 7, 7, 64)          0         \r\n_________________________________________________________________\r\nconv2d_56 (Conv2D)           (None, 7, 7, 128)         73856     \r\n_________________________________________________________________\r\nleaky_re_lu_63 (LeakyReLU)   (None, 7, 7, 128)         0         \r\n_________________________________________________________________\r\nmax_pooling2d_54 (MaxPooling (None, 4, 4, 128)         0         \r\n_________________________________________________________________\r\ndropout_31 (Dropout)         (None, 4, 4, 128)         0         \r\n_________________________________________________________________\r\nflatten_18 (Flatten)         (None, 2048)              0         \r\n_________________________________________________________________\r\ndense_35 (Dense)             (None, 128)               262272    \r\n_________________________________________________________________\r\nleaky_re_lu_64 (LeakyReLU)   (None, 128)               0         \r\n_________________________________________________________________\r\ndropout_32 (Dropout)         (None, 128)               0         \r\n_________________________________________________________________\r\ndense_36 (Dense)             (None, 10)                1290      \r\n=================================================================\r\nTotal params: 356,234\r\nTrainable params: 356,234\r\nNon-trainable params: 0\r\n_________________________________________________________________\r\n\u003c/code\u003e\u003c/pre\u003e\u003cpre\u003e\u003ccode class=\"lang-python\"\u003efashion_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=[\u0026#39;accuracy\u0026#39;])\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003efashion_train_dropout = fashion_model.fit(train_X, train_label, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X, valid_label))\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003eTrain on 48000 samples, validate on 12000 samples\r\nEpoch 1/20\r\n48000/48000 [==============================] - 66s 1ms/step - loss: 0.5954 - acc: 0.7789 - val_loss: 0.3788 - val_acc: 0.8586\r\nEpoch 2/20\r\n48000/48000 [==============================] - 64s 1ms/step - loss: 0.3797 - acc: 0.8591 - val_loss: 0.3150 - val_acc: 0.8832\r\nEpoch 3/20\r\n48000/48000 [==============================] - 64s 1ms/step - loss: 0.3302 - acc: 0.8787 - val_loss: 0.2836 - val_acc: 0.8961\r\nEpoch 4/20\r\n48000/48000 [==============================] - 64s 1ms/step - loss: 0.3034 - acc: 0.8868 - val_loss: 0.2663 - val_acc: 0.9002\r\nEpoch 5/20\r\n48000/48000 [==============================] - 64s 1ms/step - loss: 0.2843 - acc: 0.8936 - val_loss: 0.2481 - val_acc: 0.9083\r\nEpoch 6/20\r\n48000/48000 [==============================] - 64s 1ms/step - loss: 0.2699 - acc: 0.9002 - val_loss: 0.2469 - val_acc: 0.9032\r\nEpoch 7/20\r\n48000/48000 [==============================] - 65s 1ms/step - loss: 0.2561 - acc: 0.9049 - val_loss: 0.2422 - val_acc: 0.9095\r\nEpoch 8/20\r\n48000/48000 [==============================] - 65s 1ms/step - loss: 0.2503 - acc: 0.9068 - val_loss: 0.2429 - val_acc: 0.9098\r\nEpoch 9/20\r\n48000/48000 [==============================] - 65s 1ms/step - loss: 0.2437 - acc: 0.9096 - val_loss: 0.2230 - val_acc: 0.9173\r\nEpoch 10/20\r\n48000/48000 [==============================] - 65s 1ms/step - loss: 0.2307 - acc: 0.9126 - val_loss: 0.2170 - val_acc: 0.9187\r\nEpoch 11/20\r\n48000/48000 [==============================] - 65s 1ms/step - loss: 0.2307 - acc: 0.9135 - val_loss: 0.2265 - val_acc: 0.9193\r\nEpoch 12/20\r\n48000/48000 [==============================] - 65s 1ms/step - loss: 0.2229 - acc: 0.9160 - val_loss: 0.2136 - val_acc: 0.9229\r\nEpoch 13/20\r\n48000/48000 [==============================] - 65s 1ms/step - loss: 0.2202 - acc: 0.9162 - val_loss: 0.2173 - val_acc: 0.9187\r\nEpoch 14/20\r\n48000/48000 [==============================] - 64s 1ms/step - loss: 0.2161 - acc: 0.9188 - val_loss: 0.2142 - val_acc: 0.9211\r\nEpoch 15/20\r\n48000/48000 [==============================] - 65s 1ms/step - loss: 0.2119 - acc: 0.9196 - val_loss: 0.2133 - val_acc: 0.9233\r\nEpoch 16/20\r\n48000/48000 [==============================] - 65s 1ms/step - loss: 0.2073 - acc: 0.9222 - val_loss: 0.2159 - val_acc: 0.9213\r\nEpoch 17/20\r\n48000/48000 [==============================] - 65s 1ms/step - loss: 0.2050 - acc: 0.9231 - val_loss: 0.2123 - val_acc: 0.9233\r\nEpoch 18/20\r\n48000/48000 [==============================] - 64s 1ms/step - loss: 0.2016 - acc: 0.9238 - val_loss: 0.2191 - val_acc: 0.9235\r\nEpoch 19/20\r\n48000/48000 [==============================] - 65s 1ms/step - loss: 0.2001 - acc: 0.9244 - val_loss: 0.2110 - val_acc: 0.9258\r\nEpoch 20/20\r\n48000/48000 [==============================] - 64s 1ms/step - loss: 0.1972 - acc: 0.9255 - val_loss: 0.2092 - val_acc: 0.9269\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eLet\u0026#39;s save the model so that you can directly load it and not have to train it again for 20 epochs. This way, you can load the model later on if you need it and modify the architecture; Alternatively, you can start the training process on this saved model. It is always a good idea to save the model -and even the model\u0026#39;s weights!- because it saves you time. Note that you can also save the model after every epoch so that, if some issue occurs that stops the training at an epoch, you will not have to start the training from the beginning.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003efashion_model.save(\u0026quot;fashion_model_dropout.h5py\u0026quot;)\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003e\u003ca id='dropout_evaluate'\u003e\u003c/a\u003e\u003c/p\u003e\r\n\u003ch2 id=\"model-evaluation-on-the-test-set\"\u003eModel Evaluation on the Test Set\u003c/h2\u003e\r\n\u003cp\u003eFinally, let\u0026#39;s also evaluate your new model and see how it performs!\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003etest_eval = fashion_model.evaluate(test_X, test_Y_one_hot, verbose=1)\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e10000/10000 [==============================] - 5s 461us/step\r\n\u003c/code\u003e\u003c/pre\u003e\u003cpre\u003e\u003ccode class=\"lang-python\"\u003eprint(\u0026#39;Test loss:\u0026#39;, test_eval[0])\r\nprint(\u0026#39;Test accuracy:\u0026#39;, test_eval[1])\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e(\u0026#39;Test loss:\u0026#39;, 0.21460009642243386)\r\n(\u0026#39;Test accuracy:\u0026#39;, 0.92300000000000004)\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eWow! Looks like adding Dropout in our model worked, even though the test accuracy did not improve significantly but the test loss decreased compared to the previous results.\u003cbr\u003e\r\n\u003cbr\u003e\r\nNow, let\u0026#39;s plot the accuracy and loss plots between training and validation data for the one last time.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003eaccuracy = fashion_train_dropout.history[\u0026#39;acc\u0026#39;]\r\nval_accuracy = fashion_train_dropout.history[\u0026#39;val_acc\u0026#39;]\r\nloss = fashion_train_dropout.history[\u0026#39;loss\u0026#39;]\r\nval_loss = fashion_train_dropout.history[\u0026#39;val_loss\u0026#39;]\r\nepochs = range(len(accuracy))\r\nplt.plot(epochs, accuracy, \u0026#39;bo\u0026#39;, label=\u0026#39;Training accuracy\u0026#39;)\r\nplt.plot(epochs, val_accuracy, \u0026#39;b\u0026#39;, label=\u0026#39;Validation accuracy\u0026#39;)\r\nplt.title(\u0026#39;Training and validation accuracy\u0026#39;)\r\nplt.legend()\r\nplt.figure()\r\nplt.plot(epochs, loss, \u0026#39;bo\u0026#39;, label=\u0026#39;Training loss\u0026#39;)\r\nplt.plot(epochs, val_loss, \u0026#39;b\u0026#39;, label=\u0026#39;Validation loss\u0026#39;)\r\nplt.title(\u0026#39;Training and validation loss\u0026#39;)\r\nplt.legend()\r\nplt.show()\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1512485101/output_71_0_dq7xtu.png\"/\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1512485101/output_71_1_rr3sym.png\"/\u003e\u003c/p\u003e\r\n\u003cp\u003eFinally, you can see that the validation loss and validation accuracy both are in sync with the training loss and training accuracy. Even though the validation loss and accuracy line are not linear, but it shows that your model is not overfitting: the validation loss is decreasing and not increasing, and there is not much gap between training and validation accuracy.\u003c/p\u003e\r\n\u003cp\u003eTherefore, you can say that your model\u0026#39;s generalization capability became much better since the loss on both test set and validation set was only slightly more compared to the training loss.\u003c/p\u003e\r\n\u003cp\u003e\u003ca id='predictions'\u003e\u003c/a\u003e\u003c/p\u003e\r\n\u003ch2 id=\"predict-labels\"\u003ePredict Labels\u003c/h2\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003epredicted_classes = fashion_model.predict(test_X)\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eSince the predictions you get are floating point values, it will not be feasible to compare the predicted labels with true test labels. So, you will round off the output which will convert the float values into an integer. Further, you will use \u003ccode\u003enp.argmax()\u003c/code\u003e to select the index number which has a higher value in a row. \u003c/p\u003e\r\n\u003cp\u003eFor example, let\u0026#39;s assume a prediction for one test image to be \u003ccode\u003e0 1 0 0 0 0 0 0 0 0\u003c/code\u003e, the output for this should be a class label \u003ccode\u003e1\u003c/code\u003e.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003epredicted_classes = np.argmax(np.round(predicted_classes),axis=1)\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003epredicted_classes.shape, test_Y.shape\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e((10000,), (10000,))\r\n\u003c/code\u003e\u003c/pre\u003e\u003cpre\u003e\u003ccode class=\"lang-python\"\u003ecorrect = np.where(predicted_classes==test_Y)[0]\r\nprint \u0026quot;Found %d correct labels\u0026quot; % len(correct)\r\nfor i, correct in enumerate(correct[:9]):\r\n    plt.subplot(3,3,i+1)\r\n    plt.imshow(test_X[correct].reshape(28,28), cmap=\u0026#39;gray\u0026#39;, interpolation=\u0026#39;none\u0026#39;)\r\n    plt.title(\u0026quot;Predicted {}, Class {}\u0026quot;.format(predicted_classes[correct], test_Y[correct]))\r\n    plt.tight_layout()\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003eFound 9188 correct labels\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1512485101/output_78_1_djnisy.png\"/\u003e\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003eincorrect = np.where(predicted_classes!=test_Y)[0]\r\nprint \u0026quot;Found %d incorrect labels\u0026quot; % len(incorrect)\r\nfor i, incorrect in enumerate(incorrect[:9]):\r\n    plt.subplot(3,3,i+1)\r\n    plt.imshow(test_X[incorrect].reshape(28,28), cmap=\u0026#39;gray\u0026#39;, interpolation=\u0026#39;none\u0026#39;)\r\n    plt.title(\u0026quot;Predicted {}, Class {}\u0026quot;.format(predicted_classes[incorrect], test_Y[incorrect]))\r\n    plt.tight_layout()\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003eFound 812 incorrect labels\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1512485101/output_79_1_mu5esp.png\"/\u003e\u003c/p\u003e\r\n\u003cp\u003eBy looking at a few images, you cannot be sure as to why your model is not able to classify the above images correctly, but it seems like a variety of the similar patterns present on multiple classes affect the performance of the classifier although CNN is a robust architecture. For example, images 5 and 6 both belong to different classes but look kind of similar maybe a jacket or perhaps a long sleeve shirt.\u003c/p\u003e\r\n\u003cp\u003e\u003ca id='classification'\u003e\u003c/a\u003e\u003c/p\u003e\r\n\u003ch2 id=\"classification-report\"\u003eClassification Report\u003c/h2\u003e\r\n\u003cp\u003eClassification report will help us in identifying the misclassified classes in more detail. You will be able to observe for which class the model performed bad out of the given ten classes.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003efrom sklearn.metrics import classification_report\r\ntarget_names = [\u0026quot;Class {}\u0026quot;.format(i) for i in range(num_classes)]\r\nprint(classification_report(test_Y, predicted_classes, target_names=target_names))\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e             precision    recall  f1-score   support\r\n\r\n    Class 0       0.77      0.90      0.83      1000\r\n    Class 1       0.99      0.98      0.99      1000\r\n    Class 2       0.88      0.88      0.88      1000\r\n    Class 3       0.94      0.92      0.93      1000\r\n    Class 4       0.88      0.87      0.88      1000\r\n    Class 5       0.99      0.98      0.98      1000\r\n    Class 6       0.82      0.72      0.77      1000\r\n    Class 7       0.94      0.99      0.97      1000\r\n    Class 8       0.99      0.98      0.99      1000\r\n    Class 9       0.98      0.96      0.97      1000\r\n\r\navg / total       0.92      0.92      0.92     10000\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eYou can see that the classifier is underperforming for class 6 regarding both precision and recall. For class 0 and class 2, the classifier is lacking precision. Also, for class 4, the classifier is slightly lacking both precision and recall.\u003c/p\u003e\r\n\u003ch2 id=\"go-further-\"\u003eGo Further!\u003c/h2\u003e\r\n\u003cp\u003eThis tutorial was good start to convolutional neural networks in Python with Keras. If you were able to follow along easily or even with little more efforts, well done! Try doing some experiments maybe with same model architecture but using different types of public datasets available. \u003c/p\u003e\r\n\u003cp\u003eThere is still a lot to cover, so why not take DataCamp\u0026#39;s \u003ca href=\"https://www.datacamp.com/courses/deep-learning-in-python\"\u003eDeep Learning in Python\u003c/a\u003e course? In the meantime, also make sure to check out the \u003ca href=\" https://keras.io/\"\u003e Keras documentation\u003c/a\u003e, if you haven\u0026#39;t done so already. You will find more examples and information on all functions, arguments, more layers, etc. It will undoubtedly be an indispensable resource when you\u0026#39;re learning how to work with neural networks in Python! \u003c/p\u003e\r\n\u003cp\u003eIf you rather feel like reading a book that explains the fundamentals of deep learning (with Keras) together with how it\u0026#39;s used in practice, you should definitely read François Chollet\u0026#39;s \u003ca href=\"https://www.manning.com/books/deep-learning-with-python\"\u003eDeep Learning in Python\u003c/a\u003e book.\u003c/p\u003e\r\n","contentUrl":"https://www.datacamp.com/community/tutorials/convolutional-neural-networks-python","userContentUrl":null,"illustrationUrl":"http://datacamp-community.s3.amazonaws.com/2f48e07c-3c50-4bd7-bbba-1dc6edfd5e90","seoTitle":"Convolutional Neural Networks in Python","seoMetaDescription":"In this tutorial, you’ll learn how to implement Convolutional Neural Networks (CNNs) in Python with Keras, and how to overcome overfitting with dropout.","seoKeyword":"convolutional neural network python","mustRead":false,"programmingLanguage":null,"submissionDate":"2017-12-05T14:50:08.378Z","publishDate":"2017-12-05T14:50:24.171Z","episode":null,"isLatest":null,"externalUrl":null,"transcriptUrl":null,"guests":[],"links":null,"isSpam":false,"xp":0,"flaggingUsers":[],"isDisabled":false,"connectedInternalContentId":null,"createdAt":"2017-12-05T14:50:08.358Z","updatedAt":"2018-02-22T08:28:27.486Z","upvoting":{"voteCount":54,"voted":false},"tags":["python","machine learning","keras","deep learning","neural networks"],"author":{"id":701074,"slug":"adityasharma101993","avatarUrlSquare":"https://assets.datacamp.com/users/avatars/000/701/074/square/AAIA_wDGAAAAAQAAAAAAAAqsAAAAJDczODgzN2VkLTZhZDUtNDYzOC04M2ZlLTEyMTI2OTU0YjUyNQ.jpg?1512487068","fullName":"Aditya Sharma","nameFromEmail":"adityasharma101993","isAdmin":false},"recommendedArticles":[{"id":219,"externalId":null,"type":"Tutorial","status":"published","authorId":"karlijn","title":"Python Machine Learning: Scikit-Learn Tutorial","slug":"machine-learning-python","previewSlug":null,"description":"An easy-to-follow scikit-learn tutorial that will help you to get started with the Python machine learning.\r\n","articles":[327,330,392],"courses":[],"redirectSlug":null,"contentHtml":"\u003cscript src=\"data:application/x-javascript;base64,/*
 DataCamp Light
 Version 1.1.0
 */
!function(){"use strict";function e(){function e(e){return null!==location.hostname.match(e)}function t(e){for(var t=0;t<i.length;t++)i[t].getElementsByTagName("a")[0].href=e}function a(){for(;i[0];)i[0].parentNode.removeChild(i[0])}var i=document.getElementsByClassName("powered-by-datacamp");e("r-bloggers.com")?t("https://www.datacamp.com?tap_a=5644-dce66f&tap_s=10907-287229"):e("datacamp.com")&&a()}function t(e){e.className+=" datacamp-exercise";if("height"in e.dataset&&"auto"!==e.dataset.height){var t=Math.round(e.dataset.height);if(isNaN(t))console.log("Invalid height attribute.");else if(t>=p){e.style.height=t+"px";var a="height:"+t+"px;";e.setAttribute("style",a)}else console.log("The height attribute should be >= "+p+".")}"encoded"in e.dataset&&(e.innerHTML='<div class="encoded">'+e.innerHTML.trim()+"</div>"),e.innerHTML+='<!--[if lt IE 10]><p class="browsehappy">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</p><![endif]--><div ng-controller="NormalExerciseController"><div class="dcl-exercise-area" resize-layout=""><div class="dcl-left-pane" ng-class="{\'dcl-mini\': useMiniLayout}"><ul class="dcl-content--tab"><li><a href="" ng-click="activateLeftTab(\'usercode\')" ng-class="{\'dcl-active\': isActiveLeftTab(\'usercode\')}">script.{{backendConfig.extension}}</a></li><li ng-show="solutionTabShown"><a class="dcl-animation--flash" href="" ng-click="activateLeftTab(\'solution\')" ng-class="{\'dcl-active\': isActiveLeftTab(\'solution\')}">solution.{{backendConfig.extension}}</a></li><li><a href="" ng-show="useMiniLayout" ng-click="activateLeftTab(\'console\')" ng-class="{\'dcl-active\': isActiveLeftTab(\'console\')}">{{backendConfig.console}}</a></li><li><a href="" ng-show="useMiniLayout && plotTabShown" ng-click="activateLeftTab(\'plots\')" ng-class="{\'dcl-active\': isActiveLeftTab(\'plots\')}">Plots</a></li></ul><div class="dcl-content--tab-body"><div code-editor="" control="editor" ng-show="isActiveLeftTab(\'usercode\') || isActiveLeftTab(\'solution\')" ng-model="userCode"></div><div ng-show="isActiveLeftTab(\'console\')" class="dcl-console-target dcl-console-mini-target"></div><div ng-show="isActiveLeftTab(\'plots\')" class="dcl-plots-mini-target"></div><div growl="" ng-show="!isActiveLeftTab(\'plots\')" inline="true" limit-messages="1" sct-feedback="" class="sct-feedback-container"></div></div></div><div ng-show="!useMiniLayout" class="dcl-right-pane clearfix"><a class="dcl-github-link dcl-no-link-style" href="https://github.com/datacamp/datacamp-light" uib-tooltip="View DataCamp Light on Github" tooltip-placement="left" target="_blank"><div class="dcl-github-logo"></div></a><ul class="dcl-content--tab"><li><a href="" ng-click="activateRightTab(\'console\')" ng-class="{\'dcl-active\': isActiveRightTab(\'console\')}">{{backendConfig.console}}</a></li><li><a ng-show="plotTabShown" href="" ng-click="activateRightTab(\'plots\')" ng-class="{\'dcl-active\': isActiveRightTab(\'plots\')}">Plots</a></li></ul><div class="dcl-content--tab-body"><div ng-show="isActiveRightTab(\'console\')" control="console" class="dcl-console-target dcl-console-full-target"><console class="dcl-console"></console></div><div ng-show="isActiveRightTab(\'plots\')" class="dcl-plots-full-target"><plots-container class="dcl-plots-container"></plots-container></div></div></div></div><action-panel exercise="exercise"></action-panel></div>';var i='<div class="powered-by-datacamp"><a href="https://www.datacamp.com">Powered by DataCamp<div class="logo"></div></a></div>',o=document.createElement("div");o.innerHTML=i;var c=o.firstChild;e.parentNode.insertBefore(c,e.nextSibling)}function a(e){var t=document.createElement("script");t.type="text/javascript",t.src=e,t.charset="utf-8",l("body",t)}function i(e){var t=document.createElement("link");t.type="text/css",t.rel="stylesheet",t.href=e,l("head",t)}function o(){var a=document.querySelectorAll("[data-datacamp-exercise]");0===a.length&&console.log("No DataCamp Light exercises found. Make sure the exercise has the 'data-datacamp-exercise' attribute.");for(var i=0;i<a.length;i++)!function(e){var i=a[e];(" "+i.className+" ").indexOf(" datacamp-exercise ")>-1||t(i)}(i);e()}function c(){o(),a(g+"script-41eb27f7cc.js")}function n(){o(),window.bootstrapDCLightExercises()}function s(){d();for(var e=[g+"style-b5d7fbe3f1.css","https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css"],t=0;t<e.length;t++)i(e[t])}function l(e,t){document.getElementsByTagName(e)[0].appendChild(t)}function d(){var e=document.createElement("style");e.type="text/css",l("head",e);var t='div.datacamp-exercise {  margin: 0;  border: 1px solid #d5eaef;  background: none;  position: relative;  min-height: 300px;  color: black;  box-shadow: none;}div[data-datacamp-exercise] {  margin: 0;  border: 1px solid #d5eaef;  background: #fff url(https://cdn.datacamp.com/spinner.gif) no-repeat center center !important;  background-size: auto 80px !important;  position: relative;  min-height: 300px;  color: transparent;  box-shadow: none;}div[data-datacamp-exercise] > code,div[data-datacamp-exercise] > div,div[data-datacamp-exercise] > p {  display: none;}div.powered-by-datacamp {  margin: 5px 0;  display: block;}div.powered-by-datacamp a {@import "https://fonts.googleapis.com/css?family=Open+Sans";  font-family: "Open Sans", sans-serif;  text-decoration: none;  border: 0;  color: #3ac;  font-size: 20px;}div.powered-by-datacamp .logo {  vertical-align: sub;  display: inline-block;  background: url("https://cdn.datacamp.com/dcl/assets/images/logo_blue.svg") no-repeat center center;  background-size: contain;  height: 27px;  width: 23px;  margin-left: 4px;}';e.styleSheet?e.styleSheet.cssText=t:e.innerHTML=t}function r(){return"function"==typeof window.initAddedDCLightExercises}var p=300,g="https://cdn.datacamp.com/dcl/";r()?console.log("Warning: tried to load DataCamp Light multiple times."):(window.initAddedDCLightExercises=n,s(),"complete"==document.readyState||"loaded"==document.readyState?c():document.addEventListener("DOMContentLoaded",c))}();\"\u003e\u003c/script\u003e\r\n\u003cdiv class=\"section level2\" id=\"machine-learning-with-python\"\u003e\r\n\u003ch2\u003eMachine Learning with Python\u003c/h2\u003e\r\n\r\n\u003cp\u003eMachine learning is a branch in computer science that studies the design of algorithms that can learn.\u003c/p\u003e\r\n\r\n\u003cp\u003eTypical tasks are concept learning, function learning or \u0026ldquo;predictive modeling\u0026rdquo;, clustering and finding predictive patterns. These tasks are learned through available data that were observed through experiences or instructions, for example.\u003c/p\u003e\r\n\r\n\u003cp\u003eThe hope that comes with this discipline is that including the experience into its tasks will eventually improve the learning. But this improvement needs to happen in such a way that the learning itself becomes automatic so that humans like ourselves don\u0026rsquo;t need to interfere anymore is the ultimate goal.\u003c/p\u003e\r\n\r\n\u003cp\u003eToday\u0026rsquo;s scikit-learn tutorial will introduce you to the basics of Python machine learning: \r\n\u003cnav\u003e\r\n\u003cul\u003e \r\n\u003cli\u003e You'll learn how to use Python and its libraries to \u003ca href=\"#explore\"\u003eexplore your data\u003c/a\u003e with the help of \u003ccode\u003ematplotlib\u003c/code\u003e and Principal Component Analysis (PCA),\u003c/li\u003e\r\n\u003cli\u003e And you'll \u003ca href=\"#preprocess\"\u003epreprocess your data\u003c/a\u003e with normalization and you'll split your data into training and test sets. \u003c/li\u003e\r\n\u003cli\u003e Next, you'll work with the well-known \u003ca href=\"#kmeans\"\u003eKMeans algorithm\u003c/a\u003e to construct an unsupervised model, fit this model to your data, predict values, and validate the model that you have built.\u003c/li\u003e\r\n\u003cli\u003e As an extra, you'll also see how you can also use \u003ca href=\"#svm\"\u003eSupport Vector Machines (SVM)\u003c/a\u003e to construct another model to classify your data.\u003c/li\u003e\r\n\u003c/ul\u003e\u003c/nav\u003e\u003c/p\u003e\r\n \u003cbr\u003e\r\n\u003cdiv id=\"scoped-content\"\u003e\r\n\u003cstyle type=\"text/css\"\u003e:target:before { content:\"\"; display:block; height:150px; margin:-150px 0 0; } h3 {font-weight:normal; margin-top:.5em} h4 { font-weight:lighter }\r\n\u003c/style\u003e\r\n\r\n\r\n\u003cp\u003eIf you\u0026rsquo;re more interested in an R tutorial, take a look at our \u003ca href=\"https://www.datacamp.com/community/tutorials/machine-learning-in-r/\"\u003eMachine Learning with R for Beginners tutorial\u003c/a\u003e.\u003c/p\u003e\r\n\r\n\u003cp\u003eAlternatively, check out DataCamp's \u003ca href=\"https://www.datacamp.com/courses/supervised-learning-with-scikit-learn/\"\u003eSupervised Learning with scikit-learn\u003c/a\u003e and \u003ca href=\"https://www.datacamp.com/courses/unsupervised-learning-in-python/\"\u003eUnsupervised Learning in Python\u003c/a\u003e courses!\r\n\r\n\u003cdiv class=\"section level2\" id=\"loading-your-data-set\"\u003e\r\n\u003ch2\u003eLoading Your Data Set\u003c/h2\u003e\r\n\r\n\u003cp\u003eThe first step to about anything in data science is loading in your data. This is also the starting point of this scikit-learn tutorial.\u003c/p\u003e\r\n\r\n\u003cp\u003eThis discipline typically works with observed data. This data might be collected by yourself or you can browse through other sources to find data sets. But if you\u0026rsquo;re not a researcher or otherwise involved in experiments, you\u0026rsquo;ll probably do the latter.\u003c/p\u003e\r\n\r\n\u003cp\u003eIf you\u0026rsquo;re new to this and you want to start problems on your own, finding these data sets might prove to be a challenge. However, you can typically find good data sets at the \u003ca href=\"http://archive.ics.uci.edu/ml/datasets\"\u003eUCI Machine Learning Repository\u003c/a\u003e or on the \u003ca href=\"www.kaggle.com\"\u003eKaggle\u003c/a\u003e website. Also, check out \u003ca href=\"http://www.kdnuggets.com/datasets/index.html\"\u003ethis KD Nuggets list with resources\u003c/a\u003e.\u003c/p\u003e\r\n\r\n\u003cp\u003eFor now, you should warm up, not worry about finding any data by yourself and just load in the \u003ccode\u003edigits\u003c/code\u003e data set that comes with a Python library, called \u003ccode\u003escikit-learn\u003c/code\u003e.\u003c/p\u003e\r\n\r\n\u003cp\u003eFun fact: did you know the name originates from the fact that this library is a scientific toolbox built around SciPy? By the way, there is \u003ca href=\"https://scikits.appspot.com/scikits\"\u003emore than just one scikit\u003c/a\u003e out there. This scikit contains modules specifically for machine learning and data mining, which explains the second component of the library name. :)\u003c/p\u003e\r\n\r\n\u003cp\u003eTo load in the data, you import the module \u003ccode\u003edatasets\u003c/code\u003e from \u003ccode\u003esklearn\u003c/code\u003e. Then, you can use the \u003ccode\u003eload_digits()\u003c/code\u003e method from \u003ccode\u003edatasets\u003c/code\u003e to load in the data:\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise data-height=\"300\" data-encoded=\"true\"\u003e\r\neyJsYW5ndWFnZSI6InB5dGhvbiIsInNhbXBsZSI6IiMgSW1wb3J0IGBkYXRhc2V0c2AgZnJvbSBgc2tsZWFybmBcbmZyb20gc2tsZWFybiBpbXBvcnQgX19fX19fX19cblxuIyBMb2FkIGluIHRoZSBgZGlnaXRzYCBkYXRhXG5kaWdpdHMgPSBkYXRhc2V0cy5sb2FkX2RpZ2l0cygpXG5cbiMgUHJpbnQgdGhlIGBkaWdpdHNgIGRhdGEgXG5wcmludChfX19fX18pIiwic29sdXRpb24iOiIjIEltcG9ydCBgZGF0YXNldHNgIGZyb20gYHNrbGVhcm5gXG5mcm9tIHNrbGVhcm4gaW1wb3J0IGRhdGFzZXRzXG5cbiMgTG9hZCBpbiB0aGUgYGRpZ2l0c2AgZGF0YVxuZGlnaXRzID0gZGF0YXNldHMubG9hZF9kaWdpdHMoKVxuXG4jIFByaW50IHRoZSBgZGlnaXRzYCBkYXRhIFxucHJpbnQoZGlnaXRzKSIsInNjdCI6ImltcG9ydF9tc2c9XCJEaWQgeW91IGltcG9ydCBgZGF0YXNldHNgIGZyb20gYHNrbGVhcm5gP1wiXG5pbmNvcnJlY3RfaW1wb3J0X21zZz1cIkRvbid0IGZvcmdldCB0byBpbXBvcnQgdGhlIGBkYXRhc2V0c2AgbW9kdWxlIGZyb20gYHNrbGVhcm5gIVwiXG5ub3RfY2FsbGVkX21zZz1cIkRpZCB5b3UgdXNlIGBkYXRhc2V0cy5sb2FkX2RpZ2l0cygpYCB0byBsb2FkIGluIHRoZSBgZGlnaXRzYCBkYXRhP1wiXG5pbmNvcnJlY3RfbXNnPVwiVXNlIGBkYXRhc2V0cy5sb2FkX2RpZ2l0cygpYCB0byBsb2FkIGluIHRoZSBgZGlnaXRzYCBkYXRhIVwiXG5wcmVkZWZfbXNnPVwiRGlkIHlvdSBjYWxsIHRoZSBgcHJpbnQoKWAgZnVuY3Rpb24/XCJcbnRlc3RfaW1wb3J0KFwic2tsZWFybi5kYXRhc2V0c1wiLCBzYW1lX2FzID0gVHJ1ZSwgbm90X2ltcG9ydGVkX21zZyA9IGltcG9ydF9tc2csIGluY29ycmVjdF9hc19tc2cgPSBpbmNvcnJlY3RfaW1wb3J0X21zZylcbnRlc3RfZnVuY3Rpb24oXCJza2xlYXJuLmRhdGFzZXRzLmxvYWRfZGlnaXRzXCIsIG5vdF9jYWxsZWRfbXNnID0gbm90X2NhbGxlZF9tc2csIGluY29ycmVjdF9tc2cgPSBpbmNvcnJlY3RfbXNnKVxuIyBUZXN0IGBwcmludCgpYCBmdW5jdGlvblxudGVzdF9mdW5jdGlvbihcbiAgICBcInByaW50XCIsXG4gICAgbm90X2NhbGxlZF9tc2c9cHJlZGVmX21zZyxcbiAgICBpbmNvcnJlY3RfbXNnPXByZWRlZl9tc2csXG4gICAgZG9fZXZhbD1GYWxzZVxuKVxuc3VjY2Vzc19tc2c9XCJQZXJmZWN0ISBZb3UncmUgcmVhZHkgdG8gZ28hXCIifQ==\r\n\u003c/div\u003e\r\n\u003cbr\u003e\u003cbr\u003e\r\n\u003cp\u003eNote that the \u003ccode\u003edatasets\u003c/code\u003e module contains other methods to load and fetch popular reference datasets, and you can also count on this module in case you need artificial data generators. In addition, this data set is also available through the UCI Repository that was mentioned above: you can find the data \u003ca href=\"http://archive.ics.uci.edu/ml/machine-learning-databases/optdigits/\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\r\n\r\n\u003cp\u003eIf you would have decided to pull the data from the latter page, your data import would\u0026rsquo;ve looked like this:\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise data-height=\"300\" data-encoded=\"true\"\u003e\r\neyJsYW5ndWFnZSI6InB5dGhvbiIsInNhbXBsZSI6IiMgSW1wb3J0IHRoZSBgcGFuZGFzYCBsaWJyYXJ5IGFzIGBwZGBcbmltcG9ydCBfX19fX18gYXMgX19cblxuIyBMb2FkIGluIHRoZSBkYXRhIHdpdGggYHJlYWRfY3N2KClgXG5kaWdpdHMgPSBwZC5yZWFkX2NzdihcImh0dHA6Ly9hcmNoaXZlLmljcy51Y2kuZWR1L21sL21hY2hpbmUtbGVhcm5pbmctZGF0YWJhc2VzL29wdGRpZ2l0cy9vcHRkaWdpdHMudHJhXCIsIGhlYWRlcj1Ob25lKVxuXG4jIFByaW50IG91dCBgZGlnaXRzYFxucHJpbnQoX19fX19fKSIsInNvbHV0aW9uIjoiIyBJbXBvcnQgdGhlIGBwYW5kYXNgIGxpYnJhcnkgYXMgYHBkYFxuaW1wb3J0IHBhbmRhcyBhcyBwZFxuXG4jIExvYWQgaW4gdGhlIGRhdGEgd2l0aCBgcmVhZF9jc3YoKWBcbmRpZ2l0cyA9IHBkLnJlYWRfY3N2KFwiaHR0cDovL2FyY2hpdmUuaWNzLnVjaS5lZHUvbWwvbWFjaGluZS1sZWFybmluZy1kYXRhYmFzZXMvb3B0ZGlnaXRzL29wdGRpZ2l0cy50cmFcIiwgaGVhZGVyPU5vbmUpXG5cbiMgUHJpbnQgb3V0IGBkaWdpdHNgXG5wcmludChkaWdpdHMpIiwic2N0IjoiaW1wb3J0X21zZz1cIkRpZCB5b3UgYWRkIHNvbWUgY29kZSB0byBpbXBvcnQgYHBhbmRhc2AgYXMgYHBkYD9cIlxuaW5jb3JyZWN0X2ltcG9ydF9tc2c9XCJEb24ndCBmb3JnZXQgdG8gaW1wb3J0IHRoZSAncGFuZGFzJyBsaWJyYXJ5IGFzIGBwZGAhXCJcbmNzdl9tc2c9XCJEaWQgeW91IHVzZSB0aGUgYHJlYWRfY3N2KClgIG1ldGhvZCBmcm9tIHBhbmRhcyB0byBsb2FkIGluIHRoZSBkYXRhP1wiXG5jc3ZfaW5jb3JyZWN0X21zZz1cIlVzZSBgcmVhZF9jc3YoKWAgZnJvbSB0aGUgcGFuZGFzIGxpYnJhcnkgdG8gbG9hZCBpbiB0aGUgZGF0YSBcIlxucHJlZGVmX21zZz1cIkRpZCB5b3UgY2FsbCB0aGUgYHByaW50KClgIGZ1bmN0aW9uP1wiXG4jIFRlc3QgaW1wb3J0IGBwYW5kYXNgXG50ZXN0X2ltcG9ydChcInBhbmRhc1wiLCBzYW1lX2FzID0gVHJ1ZSwgbm90X2ltcG9ydGVkX21zZyA9IGltcG9ydF9tc2csIGluY29ycmVjdF9hc19tc2cgPSBpbmNvcnJlY3RfaW1wb3J0X21zZylcbiMgVGVzdCBgcmVhZF9jc3YoKWBcbnRlc3RfZnVuY3Rpb24oXCJwYW5kYXMucmVhZF9jc3ZcIiwgbm90X2NhbGxlZF9tc2cgPSBjc3ZfbXNnLCBpbmNvcnJlY3RfbXNnID0gY3N2X2luY29ycmVjdF9tc2cpXG4jIFRlc3QgYHByaW50KClgIGZ1bmN0aW9uXG50ZXN0X2Z1bmN0aW9uKFxuICAgIFwicHJpbnRcIixcbiAgICBub3RfY2FsbGVkX21zZz1wcmVkZWZfbXNnLFxuICAgIGluY29ycmVjdF9tc2c9cHJlZGVmX21zZyxcbiAgICBkb19ldmFsPUZhbHNlXG4pXG5zdWNjZXNzX21zZyhcIkF3ZXNvbWUgam9iIVwiKSJ9\r\n\u003c/div\u003e\r\n\u003cbr\u003e\u003cbr\u003e\r\n\u003cp\u003eNote that if you download the data like this, the data is already split up in a training and a test set, indicated by the extensions \u003ccode\u003e.tra\u003c/code\u003e and \u003ccode\u003e.tes\u003c/code\u003e. You\u0026rsquo;ll need to load in both files to elaborate your project. With the command above, you only load in the training set.\u003c/p\u003e\r\n\r\n\u003cp\u003e\u003cb\u003eTip:\u003c/b\u003e if you want to know more about importing data with the Python data manipulation library Pandas, consider taking DataCamp\u0026rsquo;s \u003ca href=\"https://www.datacamp.com/courses/importing-data-in-python-part-1/\"\u003eImporting Data in Python course\u003c/a\u003e.\u003c/p\u003e\r\n\u003c/div\u003e\r\n\u003cbr\u003e\r\n\u003cp\u003e\u003ca href=\"https://www.datacamp.com/courses/\" target=\"_blank\"\u003e\u003cimg alt=\"Learn Python for Data Science With DataCamp\" src=\"http://community.datacamp.com.s3.amazonaws.com/community/production/ckeditor_assets/pictures/293/content_blog_banner.png\" /\u003e\u003c/a\u003e\u003c/p\u003e\r\n\u003cbr\u003e\r\n\u003ch2 id=\"explore\"\u003eExplore Your Data\u003c/h2\u003e\r\n\r\n\u003cp\u003eWhen first starting out with a data set, it\u0026rsquo;s always a good idea to go through the data description and see what you can already learn. When it comes to \u003ccode\u003escikit-learn\u003c/code\u003e, you don\u0026rsquo;t immediately have this information readily available, but in the case where you import data from another source, there\u0026#39;s usually a data description present, which will already be a sufficient amount of information to gather some insights into your data.\u003c/p\u003e\r\n\r\n\u003cp\u003eHowever, these insights are not merely deep enough for the analysis that you are going to perform. You really need to have a good working knowledge about the data set.\u003c/p\u003e\r\n\r\n\u003cp\u003ePerforming an exploratory data analysis (EDA) on a data set like the one that this tutorial now has might seem difficult.\u003c/p\u003e\r\n\r\n\u003cp\u003eWhere do you start exploring these handwritten digits?\u003c/p\u003e\r\n\r\n\u003cdiv class=\"section level3\" id=\"gathering-basic-information-on-your-data\"\u003e\r\n\u003ch3\u003eGathering Basic Information on Your Data\u003c/h3\u003e\r\n\r\n\u003cp\u003eLet\u0026rsquo;s say that you haven\u0026rsquo;t checked any data description folder (or maybe you want to double-check the information that has been given to you).\u003c/p\u003e\r\n\r\n\u003cp\u003eThen you should start with gathering the basic information.\u003c/p\u003e\r\n\r\n\u003cp\u003eWhen you printed out the \u003ccode\u003edigits\u003c/code\u003e data after having loaded it with the help of the \u003ccode\u003escikit-learn\u003c/code\u003e \u003ccode\u003edatasets\u003c/code\u003e module, you will have noticed that there is already a lot of information available. You already have knowledge of things such as the target values and the description of your data. You can access the \u003ccode\u003edigits\u003c/code\u003e data through the attribute \u003ccode\u003edata\u003c/code\u003e. Similarly, you can also access the target values or labels through the \u003ccode\u003etarget\u003c/code\u003e attribute and the description through the \u003ccode\u003eDESCR\u003c/code\u003e attribute.\u003c/p\u003e\r\n\r\n\u003cp\u003eTo see which keys you have available to already get to know your data, you can just run \u003ccode\u003edigits.keys()\u003c/code\u003e.\u003c/p\u003e\r\n\r\n\u003cp\u003eTry this all out in the following DataCamp Light blocks:\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"300\"\u003eeyJsYW5ndWFnZSI6InB5dGhvbiIsInByZV9leGVyY2lzZV9jb2RlIjoiZnJvbSBza2xlYXJuIGltcG9ydCBkYXRhc2V0c1xuZGlnaXRzID0gZGF0YXNldHMubG9hZF9kaWdpdHMoKSIsInNhbXBsZSI6IiMgR2V0IHRoZSBrZXlzIG9mIHRoZSBgZGlnaXRzYCBkYXRhXG5wcmludChkaWdpdHMuX19fX19fKVxuXG4jIFByaW50IG91dCB0aGUgZGF0YVxucHJpbnQoZGlnaXRzLl9fX18pXG5cbiMgUHJpbnQgb3V0IHRoZSB0YXJnZXQgdmFsdWVzXG5wcmludChkaWdpdHMuX19fX19fKVxuXG4jIFByaW50IG91dCB0aGUgZGVzY3JpcHRpb24gb2YgdGhlIGBkaWdpdHNgIGRhdGFcbnByaW50KGRpZ2l0cy5ERVNDUikiLCJzb2x1dGlvbiI6IiMgR2V0IHRoZSBrZXlzIG9mIHRoZSBgZGlnaXRzYCBkYXRhXG5wcmludChkaWdpdHMua2V5cygpKVxuXG4jIFByaW50IG91dCB0aGUgZGF0YVxucHJpbnQoZGlnaXRzLmRhdGEpXG5cbiMgUHJpbnQgb3V0IHRoZSB0YXJnZXQgdmFsdWVzXG5wcmludChkaWdpdHMudGFyZ2V0KVxuXG4jIFByaW50IG91dCB0aGUgZGVzY3JpcHRpb24gb2YgdGhlIGBkaWdpdHNgIGRhdGFcbnByaW50KGRpZ2l0cy5ERVNDUikiLCJzY3QiOiIjIFRlc3QgYHByaW50YCBcbnRlc3RfZnVuY3Rpb24oXG4gICAgXCJwcmludFwiLFxuICAgIDEsXG4gICAgbm90X2NhbGxlZF9tc2c9XCJEaWQgeW91IHByaW50IG91dCB0aGUga2V5cyBvZiBgZGlnaXRzYD9cIixcbiAgICBpbmNvcnJlY3RfbXNnPVwiRG9uJ3QgZm9yZ2V0IHRvIHByaW50IG91dCB0aGUga2V5cyBvZiBgZGlnaXRzYCFcIixcbiAgICBkb19ldmFsPUZhbHNlXG4pXG4jIFRlc3QgYHByaW50YFxudGVzdF9mdW5jdGlvbihcbiAgICBcInByaW50XCIsXG4gICAgMixcbiAgICBub3RfY2FsbGVkX21zZz1cIkRpZCB5b3UgcHJpbnQgb3V0IHRoZSBkYXRhP1wiLFxuICAgIGluY29ycmVjdF9tc2c9XCJEb24ndCBmb3JnZXQgdG8gcHJpbnQgb3V0IHRoZSBkYXRhIVwiLFxuICAgIGRvX2V2YWw9RmFsc2VcbilcbiMgVGVzdCBgcHJpbnRgXG50ZXN0X2Z1bmN0aW9uKFxuICAgIFwicHJpbnRcIixcbiAgICAzLFxuICAgIG5vdF9jYWxsZWRfbXNnPVwiRGlkIHlvdSBwcmludCBvdXQgdGhlIHRhcmdldCB2YWx1ZXMgb2YgdGhlIGRhdGE/XCIsXG4gICAgaW5jb3JyZWN0X21zZz1cIkRvbid0IGZvcmdldCB0byBwcmludCBvdXQgdGhlIHRhcmdldCB2YWx1ZXMgb2YgdGhlIGRhdGEhXCIsXG4gICAgZG9fZXZhbD1GYWxzZVxuKVxuIyBUZXN0IGBwcmludGAgXG50ZXN0X2Z1bmN0aW9uKFxuICAgIFwicHJpbnRcIixcbiAgICA0LFxuICAgIG5vdF9jYWxsZWRfbXNnPVwiRGlkIHlvdSBwcmludCBvdXQgdGhlIGRlc2NyaXB0aW9uIG9mIGBkaWdpdHNgP1wiLFxuICAgIGluY29ycmVjdF9tc2c9XCJEb24ndCBmb3JnZXQgdG8gcHJpbnQgb3V0IHRoZSBkZXNjcmlwdGlvbiBvZiBgZGlnaXRzYCFcIixcbiAgICBkb19ldmFsPUZhbHNlXG4pXG5zdWNjZXNzX21zZyhcIkF3ZXNvbWUhXCIpIn0=\u003c/div\u003e\r\n\u003cbr\u003e\u003cbr\u003e\r\n\u003cp\u003eThe next thing that you can (double)check is the type of your data.\u003c/p\u003e\r\n\r\n\u003cp\u003eIf you used \u003ccode\u003eread_csv()\u003c/code\u003e to import the data, you would have had a data frame that contains just the data. There wouldn\u0026rsquo;t be any description component, but you would be able to resort to, for example, \u003ccode\u003ehead()\u003c/code\u003e or \u003ccode\u003etail()\u003c/code\u003e to inspect your data. In these cases, it\u0026rsquo;s always wise to read up on the data description folder!\u003c/p\u003e\r\n\r\n\u003cp\u003eHowever, this tutorial assumes that you make use of the library\u0026#39;s data and the type of the \u003ccode\u003edigits\u003c/code\u003e variable is not that straightforward if you\u0026rsquo;re not familiar with the library. Look at the print out in the first code chunk. You\u0026rsquo;ll see that \u003ccode\u003edigits\u003c/code\u003e actually contains \u003ccode\u003enumpy\u003c/code\u003e arrays!\u003c/p\u003e\r\n\r\n\u003cp\u003eThis is already quite some important information. But how do you access these arays?\u003c/p\u003e\r\n\r\n\u003cp\u003eIt\u0026rsquo;s very easy, actually: you use attributes to access the relevant arrays.\u003c/p\u003e\r\n\r\n\u003cp\u003eRemember that you have already seen which attributes are available when you printed \u003ccode\u003edigits.keys()\u003c/code\u003e. For instance, you have the \u003ccode\u003edata\u003c/code\u003e attribute to isolate the data, \u003ccode\u003etarget\u003c/code\u003e to see the target values and the \u003ccode\u003eDESCR\u003c/code\u003e for the description, \u0026hellip;\u003c/p\u003e\r\n\r\n\u003cp\u003eBut what then?\u003c/p\u003e\r\n\r\n\u003cp\u003eThe first thing that you should know of an array is its shape. That is, the number of dimensions and items that is contained within an array. The array\u0026rsquo;s shape is a tuple of integers that specify the sizes of each dimension. In other words, if you have a 3d array like this \u003ccode\u003ey = np.zeros((2, 3, 4))\u003c/code\u003e, the shape of your array will be \u003ccode\u003e(2,3,4)\u003c/code\u003e.\u003c/p\u003e\r\n\r\n\u003cp\u003eNow let\u0026rsquo;s try to see what the shape is of these three arrays that you have distinguished (the \u003ccode\u003edata\u003c/code\u003e, \u003ccode\u003etarget\u003c/code\u003e and \u003ccode\u003eDESCR\u003c/code\u003e arrays).\u003c/p\u003e\r\n\r\n\u003cp\u003eUse first the \u003ccode\u003edata\u003c/code\u003e attribute to isolate the numpy array from the \u003ccode\u003edigits\u003c/code\u003e data and then use the \u003ccode\u003eshape\u003c/code\u003e attribute to find out more. You can do the same for the \u003ccode\u003etarget\u003c/code\u003e and \u003ccode\u003eDESCR\u003c/code\u003e. There\u0026rsquo;s also the \u003ccode\u003eimages\u003c/code\u003e attribute, which is basically the data in images. You\u0026rsquo;re also going to test this out.\u003c/p\u003e\r\n\r\n\u003cp\u003eCheck up on this statement by using the \u003ccode\u003eshape\u003c/code\u003e attribute on the array:\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"300\"\u003eeyJsYW5ndWFnZSI6InB5dGhvbiIsInByZV9leGVyY2lzZV9jb2RlIjoiZnJvbSBza2xlYXJuIGltcG9ydCBkYXRhc2V0c1xuaW1wb3J0IG51bXB5IGFzIG5wXG5kaWdpdHMgPSBkYXRhc2V0cy5sb2FkX2RpZ2l0cygpIiwic2FtcGxlIjoiIyBJc29sYXRlIHRoZSBgZGlnaXRzYCBkYXRhXG5kaWdpdHNfZGF0YSA9IGRpZ2l0cy5kYXRhXG5cbiMgSW5zcGVjdCB0aGUgc2hhcGVcbnByaW50KGRpZ2l0c19kYXRhLnNoYXBlKVxuXG4jIElzb2xhdGUgdGhlIHRhcmdldCB2YWx1ZXMgd2l0aCBgdGFyZ2V0YFxuZGlnaXRzX3RhcmdldCA9IGRpZ2l0cy5fX19fX19cblxuIyBJbnNwZWN0IHRoZSBzaGFwZVxucHJpbnQoZGlnaXRzX3RhcmdldC5fX19fXylcblxuIyBQcmludCB0aGUgbnVtYmVyIG9mIHVuaXF1ZSBsYWJlbHNcbm51bWJlcl9kaWdpdHMgPSBsZW4obnAudW5pcXVlKGRpZ2l0cy50YXJnZXQpKVxuXG4jIElzb2xhdGUgdGhlIGBpbWFnZXNgXG5kaWdpdHNfaW1hZ2VzID0gZGlnaXRzLmltYWdlc1xuXG4jIEluc3BlY3QgdGhlIHNoYXBlXG5wcmludChkaWdpdHNfaW1hZ2VzLnNoYXBlKSIsInNvbHV0aW9uIjoiIyBJc29sYXRlIHRoZSBgZGlnaXRzYCBkYXRhXG5kaWdpdHNfZGF0YSA9IGRpZ2l0cy5kYXRhXG5cbiMgSW5zcGVjdCB0aGUgc2hhcGVcbnByaW50KGRpZ2l0c19kYXRhLnNoYXBlKVxuXG4jIElzb2xhdGUgdGhlIHRhcmdldCB2YWx1ZXMgd2l0aCBgdGFyZ2V0YFxuZGlnaXRzX3RhcmdldCA9IGRpZ2l0cy50YXJnZXRcblxuIyBJbnNwZWN0IHRoZSBzaGFwZVxucHJpbnQoZGlnaXRzX3RhcmdldC5zaGFwZSlcblxuIyBQcmludCB0aGUgbnVtYmVyIG9mIHVuaXF1ZSBsYWJlbHNcbm51bWJlcl9kaWdpdHMgPSBsZW4obnAudW5pcXVlKGRpZ2l0cy50YXJnZXQpKVxuXG4jIElzb2xhdGUgdGhlIGBpbWFnZXNgXG5kaWdpdHNfaW1hZ2VzID0gZGlnaXRzLmltYWdlc1xuXG4jIEluc3BlY3QgdGhlIHNoYXBlXG5wcmludChkaWdpdHNfaW1hZ2VzLnNoYXBlKSIsInNjdCI6Im1zZ19kYXRhPVwiRGlkIHlvdSBhZGQgYHNoYXBlYCB0byBnZXQgdGhlIG51bWJlciBvZiBkaW1lbnNpb25zIGFuZCBpdGVtcyBvZiB0aGUgYGRpZ2l0c19kYXRhYCBhcnJheT9cIlxubXNnX3RhcmdldD1cIkRpZCB5b3UgYWRkIGBzaGFwZWAgdG8gZ2V0IHRoZSBudW1iZXIgb2YgZGltZW5zaW9ucyBhbmQgaXRlbXMgb2YgdGhlIGBkaWdpdHNfdGFyZ2V0YCBhcnJheT9cIlxubXNnX2ltYWdlPVwiRGlkIHlvdSBhZGQgYHNoYXBlYCB0byBnZXQgdGhlIG51bWJlciBvZiBkaW1lbnNpb25zIGFuZCBpdGVtcyBvZiB0aGUgYGRpZ2l0c19pbWFnZXNgIGFycmF5P1wiXG4jIFRlc3Qgb2JqZWN0IGBkaWdpdHNfZGF0YWBcbnRlc3Rfb2JqZWN0KFwiZGlnaXRzX2RhdGFcIiwgdW5kZWZpbmVkX21zZz1cIkRpZCB5b3UgZGVmaW5lIHRoZSBgZGlnaXRzX2RhdGFgIG9iamVjdD9cIiwgaW5jb3JyZWN0X21zZz1cIkRpZCB5b3UgdXNlIHRoZSBgZGF0YWAgYXR0cmlidXRlIHRvIGlzb2xhdGUgdGhlIGRhdGEgb2YgYGRpZ2l0c2A/XCIpXG4jIFRlc3Qgb2JqZWN0IGBkaWdpdHNfdGFyZ2V0YFxudGVzdF9vYmplY3QoXCJkaWdpdHNfdGFyZ2V0XCIsIHVuZGVmaW5lZF9tc2c9XCJEaWQgeW91IGRlZmluZSB0aGUgYGRpZ2l0c190YXJnZXRgIG9iamVjdD9cIiwgaW5jb3JyZWN0X21zZz1cIkRpZCB5b3UgdXNlIHRoZSBgdGFyZ2V0YCBhdHRyaWJ1dGUgdG8gaXNvbGF0ZSB0aGUgdGFyZ2V0IHZhbHVlcyBvZiB0aGUgYGRpZ2l0c2AgZGF0YT9cIilcbiMgVGVzdCBgc2hhcGVgIG9mIGBkaWdpdHNfZGF0YWBcbiN0ZXN0IGZ1bmN0aW9uIHByaW50XG50ZXN0X2Z1bmN0aW9uKFxuICAgIFwicHJpbnRcIixcbiAgICAxLFxuICAgIG5vdF9jYWxsZWRfbXNnPVwiRGlkIHlvdSBwcmludCBvdXQgdGhlIHNoYXBlIG9mIHRoZWRhdGE/XCIsXG4gICAgaW5jb3JyZWN0X21zZz1cIkRvbid0IGZvcmdldCB0byBwcmludCBvdXQgdGhlIHNoYXBlIG9mIHRoZSBkYXRhIVwiLFxuICAgIGRvX2V2YWw9RmFsc2VcbilcbnRlc3Rfb2JqZWN0X2FjY2Vzc2VkKFwiZGlnaXRzX2RhdGEuc2hhcGVcIiwgbm90X2FjY2Vzc2VkX21zZz1tc2dfZGF0YSlcbiMgVGVzdCBgcHJpbnRgXG50ZXN0X2Z1bmN0aW9uKFxuICAgIFwicHJpbnRcIixcbiAgICAyLFxuICAgIG5vdF9jYWxsZWRfbXNnPVwiRGlkIHlvdSBwcmludCBvdXQgdGhlIHNoYXBlIG9mIHRoZSB0YXJnZXQgdmFsdWVzIG9mIHRoZSBkYXRhP1wiLFxuICAgIGluY29ycmVjdF9tc2c9XCJEb24ndCBmb3JnZXQgdG8gcHJpbnQgb3V0IHRoZSBzaGFwZSBvZiB0aGUgdGFyZ2V0IHZhbHVlcyBvZiB0aGUgZGF0YSFcIixcbiAgICBkb19ldmFsPUZhbHNlXG4pXG4jIFRlc3QgYWNjZXNzIGBzaGFwZWAgb2YgYGRpZ2l0c190YXJnZXRgXG50ZXN0X29iamVjdF9hY2Nlc3NlZChcImRpZ2l0c190YXJnZXQuc2hhcGVcIiwgbm90X2FjY2Vzc2VkX21zZz1tc2dfdGFyZ2V0KVxuIyBUZXN0IG9iamVjdCBgbnVtYmVyX2RpZ2l0c2BcbnRlc3Rfb2JqZWN0KFwibnVtYmVyX2RpZ2l0c1wiLCB1bmRlZmluZWRfbXNnPVwiRGlkIHlvdSBkZWZpbmUgdGhlIGBudW1iZXJfZGlnaXRzYCBvYmplY3Q/XCIsIGluY29ycmVjdF9tc2c9XCJEaWQgeW91IHVzZSBgbnAudW5pcXVlKClgIHRvIGdpdmUgYmFjayB0aGUgdW5pcXVlIHRhcmdldCB2YWx1ZXM/IERvbid0IGZvcmdldCB0byBnaXZlIGJhY2sgdGhlIGxlbmd0aCBvZiB0aGlzIGFycmF5IHdpdGggYGxlbigpYCFcIilcbiMgVGVzdCBvYmplY3QgYGRpZ2l0c19pbWFnZXNgXG50ZXN0X29iamVjdChcImRpZ2l0c19pbWFnZXNcIiwgdW5kZWZpbmVkX21zZz1cIkRpZCB5b3UgZGVmaW5lIHRoZSBgZGlnaXRzX2ltYWdlc2Agb2JqZWN0P1wiLCBpbmNvcnJlY3RfbXNnPVwiRGlkIHlvdSB1c2UgdGhlIGBpbWFnZXNgIGF0dHJpYnV0ZSB0byBpc29sYXRlIHRoZSBpbWFnZXMgb2YgdGhlIGBkaWdpdHNgIGRhdGE/XCIpXG4jIFRlc3QgYHNoYXBlYCBvZiBgZGlnaXRzX2ltYWdlc2BcbnRlc3Rfb2JqZWN0X2FjY2Vzc2VkKFwiZGlnaXRzX2ltYWdlcy5zaGFwZVwiLCBub3RfYWNjZXNzZWRfbXNnPW1zZ19pbWFnZSlcbiMgVGVzdCBgcHJpbnRgIFxudGVzdF9mdW5jdGlvbihcbiAgICBcInByaW50XCIsXG4gICAgMyxcbiAgICBub3RfY2FsbGVkX21zZz1cIkRpZCB5b3UgcHJpbnQgb3V0IHRoZSBzaGFwZSBvZiB0aGUgaW1hZ2VzIG9mIGBkaWdpdHNgP1wiLFxuICAgIGluY29ycmVjdF9tc2c9XCJEb24ndCBmb3JnZXQgdG8gcHJpbnQgb3V0IHRoZSBzaGFwZSBvZiB0aGUgaW1hZ2VzIG9mIGBkaWdpdHNgIVwiLFxuICAgIGRvX2V2YWw9RmFsc2VcbilcbnN1Y2Nlc3NfbXNnKFwiV2VsbCBkb25lIVwiKSJ9\u003c/div\u003e\r\n\u003cbr\u003e\u003cbr\u003e\r\n\u003cp\u003eTo recap: by inspecting \u003ccode\u003edigits.data\u003c/code\u003e, you see that there are 1797 samples and that there are 64 features. Because you have 1797 samples, you also have 1797 target values.\u003c/p\u003e\r\n\r\n\u003cp\u003eBut all those target values contain 10 unique values, namely, from 0 to 9. In other words, all 1797 target values are made up of numbers that lie between 0 and 9. This means that the digits that your model will need to recognize are numbers from 0 to 9.\u003c/p\u003e\r\n\r\n\u003cp\u003eLastly, you see that the \u003ccode\u003eimages\u003c/code\u003e data contains three dimensions: there are 1797 instances that are 8 by 8 pixels big. You can visually check that the \u003ccode\u003eimages\u003c/code\u003e and the \u003ccode\u003edata\u003c/code\u003e are related by reshaping the \u003ccode\u003eimages\u003c/code\u003e array to two dimensions: \u003ccode\u003edigits.images.reshape((1797, 64))\u003c/code\u003e.\u003c/p\u003e\r\n\r\n\u003cp\u003eBut if you want to be completely sure, better to check with\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003eprint(np.all(digits.images.reshape((1797,64)) == digits.data))\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eWith the \u003ccode\u003enumpy\u003c/code\u003e method \u003ccode\u003eall()\u003c/code\u003e, you test whether all array elements along a given axis evaluate to \u003ccode\u003eTrue\u003c/code\u003e. In this case, you evaluate if it\u0026rsquo;s true that the reshaped \u003ccode\u003eimages\u003c/code\u003e array equals \u003ccode\u003edigits.data\u003c/code\u003e. You\u0026rsquo;ll see that the result will be \u003ccode\u003eTrue\u003c/code\u003e in this case.\u003c/p\u003e\r\n\u003c/div\u003e\r\n\r\n\u003cdiv class=\"section level3\" id=\"visualize-your-data-images-with-matplotlib\"\u003e\r\n\u003ch3\u003eVisualize Your Data Images With \u003ccode\u003ematplotlib\u003c/code\u003e\u003c/h3\u003e\r\n\r\n\u003cp\u003eThen, you can take your exploration up a notch by visualizing the images that you\u0026rsquo;ll be working with. You can use one of Python\u0026rsquo;s data visualization libraries, such as \u003ccode\u003e\u003ca href=\"http://matplotlib.org/\"\u003ematplotlib\u003c/a\u003e\u003c/code\u003e, for this purpose:\u003c/p\u003e\r\n\r\n\u003cpre\u003e\r\n\u003ccode\u003e# Import matplotlib\r\nimport matplotlib.pyplot as plt\r\n\r\n# Figure size (width, height) in inches\r\nfig = plt.figure(figsize=(6, 6))\r\n\r\n# Adjust the subplots \r\nfig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\r\n\r\n# For each of the 64 images\r\nfor i in range(64):\r\n    # Initialize the subplots: add a subplot in the grid of 8 by 8, at the i+1-th position\r\n    ax = fig.add_subplot(8, 8, i + 1, xticks=[], yticks=[])\r\n    # Display an image at the i-th position\r\n    ax.imshow(digits.images[i], cmap=plt.cm.binary, interpolation='nearest')\r\n    # label the image with the target value\r\n    ax.text(0, 7, str(digits.target[i]))\r\n\r\n# Show the plot\r\nplt.show()\u003c/code\u003e\u003c/pre\u003e\r\n\r\n\u003cp\u003eThe code chunk seems quite lengthy at first sight and this might be overwhelming. But, what happens in the code chunk above is actually pretty easy once you break it down into parts:\u003c/p\u003e\r\n\r\n\u003cul\u003e\r\n\t\u003cli\u003eYou import \u003ccode\u003ematplotlib.pyplot\u003c/code\u003e.\u003c/li\u003e\r\n\t\u003cli\u003eNext, you set up a figure with a figure size of \u003ccode\u003e6\u003c/code\u003e inches wide and \u003ccode\u003e6\u003c/code\u003e inches long. This is your blank canvas where all the subplots with the images will appear.\u003c/li\u003e\r\n\t\u003cli\u003eThen you go to the level of the subplots to adjust some parameters: you set the left side of the suplots of the figure to \u003ccode\u003e0\u003c/code\u003e, the right side of the suplots of the figure to \u003ccode\u003e1\u003c/code\u003e, the bottom to \u003ccode\u003e0\u003c/code\u003e and the top to \u003ccode\u003e1\u003c/code\u003e. The height of the blank space between the suplots is set at \u003ccode\u003e0.005\u003c/code\u003e and the width is set at \u003ccode\u003e0.05\u003c/code\u003e. These are merely layout adjustments.\u003c/li\u003e\r\n\t\u003cli\u003eAfter that, you start filling up the figure that you have made with the help of a for loop.\u003c/li\u003e\r\n\t\u003cli\u003eYou initialize the suplots one by one, adding one at each position in the grid that is \u003ccode\u003e8\u003c/code\u003e by \u003ccode\u003e8\u003c/code\u003e images big.\u003c/li\u003e\r\n\t\u003cli\u003eYou display each time one of the images at each position in the grid. As a color map, you take binary colors, which in this case will result in black, gray values and white colors. The interpolation method that you use is \u003ccode\u003e\u0026#39;nearest\u0026#39;\u003c/code\u003e, which means that your data is interpolated in such a way that it isn\u0026rsquo;t smooth. You can see the effect of the different interpolation methods \u003ca href=\"http://matplotlib.org/examples/images_contours_and_fields/interpolation_methods.html\"\u003ehere\u003c/a\u003e.\u003c/li\u003e\r\n\t\u003cli\u003eThe cherry on the pie is the addition of text to your subplots. The target labels are printed at coordinates (0,7) of each subplot, which in practice means that they will appear in the bottom-left of each of the subplots.\u003c/li\u003e\r\n\t\u003cli\u003eDon\u0026rsquo;t forget to show the plot with \u003ccode\u003eplt.show()\u003c/code\u003e!\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cbr\u003e\r\n\u003cp\u003eIn the end, you\u0026rsquo;ll get to see the following:\u003c/p\u003e\r\n\u003cbr\u003e\r\n\u003cp\u003e\u003cimg alt=\"Python machine learning visualization of images\" src=\"http://community.datacamp.com.s3.amazonaws.com/community/production/ckeditor_assets/pictures/266/content_plot1.png\" /\u003e\u003c/p\u003e\r\n\u003cbr\u003e\r\n\u003cp\u003eOn a more simple note, you can also visualize the target labels with an image, just like this:\u003c/p\u003e\r\n\r\n\u003cpre\u003e\r\n\u003ccode\u003e# Import matplotlib\r\nimport matplotlib.pyplot as plt \r\n\r\n# Join the images and target labels in a list\r\nimages_and_labels = list(zip(digits.images, digits.target))\r\n\r\n# for every element in the list\r\nfor index, (image, label) in enumerate(images_and_labels[:8]):\r\n    # initialize a subplot of 2X4 at the i+1-th position\r\n    plt.subplot(2, 4, index + 1)\r\n    # Don't plot any axes\r\n    plt.axis('off')\r\n    # Display images in all subplots \r\n    plt.imshow(image, cmap=plt.cm.gray_r,interpolation='nearest')\r\n    # Add a title to each subplot\r\n    plt.title('Training: ' + str(label))\r\n\r\n# Show the plot\r\nplt.show()\u003c/code\u003e\u003c/pre\u003e\r\n\r\n\u003cp\u003eWhich will render the following visualization:\u003c/p\u003e\r\n\u003cbr\u003e\r\n\u003cp\u003e\u003cimg alt=\"Python scikit-learn visualization of images\" src=\"http://community.datacamp.com.s3.amazonaws.com/community/production/ckeditor_assets/pictures/267/content_plot2.png\" /\u003e\u003c/p\u003e\r\n\u003cbr\u003e\r\n\u003cp\u003eNote that in this case, after you have imported \u003ccode\u003ematplotlib.pyplot\u003c/code\u003e, you zip the two \u003ccode\u003enumpy\u003c/code\u003e arrays together and save it into a variable called \u003ccode\u003eimages_and_labels\u003c/code\u003e. You\u0026rsquo;ll see now that this list contains suples of each time an instance of \u003ccode\u003edigits.images\u003c/code\u003e and a corresponding \u003ccode\u003edigits.target\u003c/code\u003e value.\u003c/p\u003e\r\n\r\n\u003cp\u003eThen, you say that for the first eight elements of \u003ccode\u003eimages_and_labels\u003c/code\u003e -note that the index starts at 0!-, you initialize subplots in a grid of 2 by 4 at each position. You turn of the plotting of the axes and you display images in all the subplots with a color map \u003ccode\u003eplt.cm.gray_r\u003c/code\u003e (which returns all grey colors) and the interpolation method used is \u003ccode\u003enearest\u003c/code\u003e. You give a title to each subplot, and you show it.\u003c/p\u003e\r\n\r\n\u003cp\u003eNot too hard, huh?\u003c/p\u003e\r\n\r\n\u003cp\u003eAnd now you know a very good idea of the data that you\u0026rsquo;ll be working with!\u003c/p\u003e\r\n\u003c/div\u003e\r\n\r\n\u003cdiv class=\"section level3\" id=\"visualizing-your-data-principal-component-analysis-pca\"\u003e\r\n\u003ch3\u003eVisualizing Your Data: Principal Component Analysis (PCA)\u003c/h3\u003e\r\n\r\n\u003cp\u003eBut is there no other way to visualize the data?\u003c/p\u003e\r\n\r\n\u003cp\u003eAs the \u003ccode\u003edigits\u003c/code\u003e data set contains 64 features, this might prove to be a challenging task. You can imagine that it\u0026rsquo;s very hard to understand the structure and keep the overview of the \u003ccode\u003edigits\u003c/code\u003e data. In such cases, it is said that you\u0026rsquo;re working with a high dimensional data set.\u003c/p\u003e\r\n\r\n\u003cp\u003eHigh dimensionality of data is a direct result of trying to describe the objects via a collection of features. Other examples of high dimensional data are, for example, financial data, climate data, neuroimaging, \u0026hellip;\u003c/p\u003e\r\n\r\n\u003cp\u003eBut, as you might have gathered already, this is not always easy. In some cases, high dimensionality can be problematic, as your algorithms will need to take into account too many features. In such cases, you speak of the curse of dimensionality. Because having a lot of dimensions can also mean that your data points are far away from virtually every other point, which makes the distances between the data points uninformative.\u003c/p\u003e\r\n\r\n\u003cp\u003eDont\u0026rsquo; worry, though, because the curse of dimensionality is not simply a matter of counting the number of features. There are also cases in which the effective dimensionality might be much smaller than the number of the features, such as in data sets where some features are irrelevant.\u003c/p\u003e\r\n\r\n\u003cp\u003eIn addition, you can also understand that data with only two or three dimensions is easier to grasp and can also be visualized easily.\u003c/p\u003e\r\n\r\n\u003cp\u003eThat all explains why you\u0026rsquo;re going to visualize the data with the help of one of the Dimensionality Reduction techniques, namely Principal Component Analysis (PCA). The idea in PCA is to find a linear combination of the two variables that contains most of the information. This new variable or \u0026ldquo;principal component\u0026rdquo; can replace the two original variables.\u003c/p\u003e\r\n\r\n\u003cp\u003eIn short, it\u0026rsquo;s a linear transformation method that yields the directions (principal components) that maximize the variance of the data. Remember that the variance indicates how far a set of data points lie apart. If you want to know more, go to \u003ca href=\"http://www.lauradhamilton.com/introduction-to-principal-component-analysis-pca\"\u003ethis page\u003c/a\u003e.\u003c/p\u003e\r\n\r\n\u003cp\u003eYou can easily apply PCA do your data with the help of \u003ccode\u003escikit-learn\u003c/code\u003e:\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"300\"\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\u003c/div\u003e\r\n\u003cbr\u003e\u003cbr\u003e\r\n\u003cp\u003e\u003cstrong\u003eTip\u003c/strong\u003e: you have used the \u003ccode\u003eRandomizedPCA()\u003c/code\u003e here because it performs better when there\u0026rsquo;s a high number of dimensions. Try replacing the randomized PCA model or estimator object with a regular PCA model and see what the difference is.\u003c/p\u003e\r\n\r\n\u003cp\u003eNote how you explicitly tell the model to only keep two components. This is to make sure that you have two-dimensional data to plot. Also, note that you don\u0026rsquo;t pass the target class with the labels to the PCA transformation because you want to investigate if the PCA reveals the distribution of the different labels and if you can clearly separate the instances from each other.\u003c/p\u003e\r\n\r\n\u003cp\u003eYou can now build a scatterplot to visualize the data:\u003c/p\u003e\r\n\r\n\u003cpre\u003e\r\n\u003ccode\u003ecolors = ['black', 'blue', 'purple', 'yellow', 'white', 'red', 'lime', 'cyan', 'orange', 'gray']\r\nfor i in range(len(colors)):\r\n    x = reduced_data_rpca[:, 0][digits.target == i]\r\n    y = reduced_data_rpca[:, 1][digits.target == i]\r\n    plt.scatter(x, y, c=colors[i])\r\nplt.legend(digits.target_names, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\r\nplt.xlabel('First Principal Component')\r\nplt.ylabel('Second Principal Component')\r\nplt.title(\"PCA Scatter Plot\")\r\nplt.show()\u003c/code\u003e\u003c/pre\u003e\r\n\r\n\u003cp\u003eWhich looks like this:\u003c/p\u003e\r\n\u003cbr\u003e\r\n\u003cp\u003e\u003cimg alt=\"Scikit-learn tutorial - Principal Component Analysis (PCA)\" src=\"http://community.datacamp.com.s3.amazonaws.com/community/production/ckeditor_assets/pictures/268/content_plot3.png\" /\u003e\u003c/p\u003e\r\n\u003cbr\u003e\r\n\u003cp\u003eAgain you use \u003ccode\u003ematplotlib\u003c/code\u003e to visualize the data. It\u0026rsquo;s good for a quick visualization of what you\u0026rsquo;re working with, but you might have to consider something a little bit more fancy if you\u0026rsquo;re working on making this part of your data science portfolio.\u003c/p\u003e\r\n\r\n\u003cp\u003eAlso note that the last call to show the plot (\u003ccode\u003eplt.show()\u003c/code\u003e) is not necessary if you\u0026rsquo;re working in Jupyter Notebook, as you\u0026rsquo;ll want to put the images inline. When in doubt, you can always check out our \u003ca href=\"https://www.datacamp.com/community/tutorials/tutorial-jupyter-notebook/\"\u003eDefinitive Guide to Jupyter Notebook\u003c/a\u003e.\u003c/p\u003e\r\n\r\n\u003cp\u003eWhat happens in the code chunk above is the following:\u003c/p\u003e\r\n\r\n\u003col style=\"list-style-type: decimal\"\u003e\r\n\t\u003cli\u003eYou put your colors together in a list. Note that you list ten colors, which is equal to the number of labels that you have. This way, you make sure that your data points can be colored in according to the labels. Then, you set up a range that goes from 0 to 10. Mind you that this range is not inclusive! Remember that this is the same for indices of a list, for example.\u003c/li\u003e\r\n\t\u003cli\u003eYou set up your \u003ccode\u003ex\u003c/code\u003e and \u003ccode\u003ey\u003c/code\u003e coordinates. You take the first or the second column of \u003ccode\u003ereduced_data_rpca\u003c/code\u003e, and you select only those data points for which the label equals the index that you\u0026rsquo;re considering. That means that in the first run, you\u0026rsquo;ll consider the data points with label \u003ccode\u003e0\u003c/code\u003e, then label \u003ccode\u003e1\u003c/code\u003e, \u0026hellip; and so on.\u003c/li\u003e\r\n\t\u003cli\u003eYou construct the scatter plot. Fill in the \u003ccode\u003ex\u003c/code\u003e and \u003ccode\u003ey\u003c/code\u003e coordinates and assign a color to the batch that you\u0026rsquo;re processing. The first run, you\u0026rsquo;ll give the color \u003ccode\u003eblack\u003c/code\u003e to all data points, the next run \u003ccode\u003eblue\u003c/code\u003e, \u0026hellip; and so on.\u003c/li\u003e\r\n\t\u003cli\u003eYou add a legend to your scatter plot. Use the \u003ccode\u003etarget_names\u003c/code\u003e key to get the right labels for your data points.\u003c/li\u003e\r\n\t\u003cli\u003eAdd labels to your \u003ccode\u003ex\u003c/code\u003e and \u003ccode\u003ey\u003c/code\u003e axes that are meaningful.\u003c/li\u003e\r\n\t\u003cli\u003eReveal the resulting plot.\u003c/li\u003e\r\n\u003c/ol\u003e\r\n\u003c/div\u003e\r\n\u003cbr\u003e\r\n\u003cdiv class=\"section level2\" id=\"where-to-go-now\"\u003e\r\n\u003ch2\u003eWhere To Go Now?\u003c/h2\u003e\r\n\r\n\u003cp\u003eNow that you have even more information about your data and you have a visualization ready, it does seem a bit like the data points sort of group together, but you also see there is quite some overlap.\u003c/p\u003e\r\n\r\n\u003cp\u003eThis might be interesting to investigate further.\u003c/p\u003e\r\n\r\n\u003cp\u003eDo you think that, in a case where you knew that there are 10 possible digits labels to assign to the data points, but you have no access to the labels, the observations would group or \u0026ldquo;cluster\u0026rdquo; together by some criterion in such a way that you could infer the labels?\u003c/p\u003e\r\n\r\n\u003cp\u003eNow this is a research question!\u003c/p\u003e\r\n\r\n\u003cp\u003eIn general, when you have acquired a good understanding of your data, you have to decide on the use cases that would be relevant to your data set. In other words, you think about what your data set might teach you or what you think you can learn from your data.\u003c/p\u003e\r\n\r\n\u003cp\u003eFrom there on, you can think about what kind of algorithms you would be able to apply to your data set in order to get the results that you think you can obtain.\u003c/p\u003e\r\n\r\n\u003cp\u003e\u003cb\u003eTip:\u003c/b\u003e the more familiar you are with your data, the easier it will be to assess the use cases for your specific data set. The same also holds for finding the appropriate machine algorithm.\u003c/p\u003e\r\n\r\n\u003cp\u003eHowever, when you\u0026rsquo;re first getting started with \u003ccode\u003escikit-learn\u003c/code\u003e, you\u0026rsquo;ll see that the amount of algorithms that the library contains is pretty vast and that you might still want additional help when you\u0026rsquo;re doing the assessment for your data set. That\u0026rsquo;s why \u003ca href=\"http://scikit-learn.org/stable/tutorial/machine_learning_map/\"\u003ethis \u003ccode\u003escikit-learn\u003c/code\u003e machine learning map\u003c/a\u003e will come in handy.\u003c/p\u003e\r\n\r\n\u003cp\u003eNote that this map does require you to have some knowledge about the algorithms that are included in the \u003ccode\u003escikit-learn\u003c/code\u003e library. This, by the way, also holds some truth for taking this next step in your project: if you have no idea what is possible, it will be very hard to decide on what your use case will be for the data.\u003c/p\u003e\r\n\r\n\u003cp\u003eAs your use case was one for clustering, you can follow the path on the map towards \u0026ldquo;KMeans\u0026rdquo;. You\u0026rsquo;ll see the use case that you have just thought about requires you to have more than 50 samples (\u0026ldquo;check!\u0026rdquo;), to have labeled data (\u0026ldquo;check!\u0026rdquo;), to know the number of categories that you want to predict (\u0026ldquo;check!\u0026rdquo;) and to have less than 10K samples (\u0026ldquo;check!\u0026rdquo;).\u003c/p\u003e\r\n\r\n\u003cp\u003eBut what exactly is the K-Means algorithm?\u003c/p\u003e\r\n\r\n\u003cp\u003eIt is one of the simplest and widely used unsupervised learning algorithms to solve clustering problems. The procedure follows a simple and easy way to classify a given data set through a certain number of clusters that you have set before you run the algorithm. This number of clusters is called \u003ccode\u003ek\u003c/code\u003e and you select this number at random.\u003c/p\u003e\r\n\r\n\u003cp\u003eThen, the k-means algorithm will find the nearest cluster center for each data point and assign the data point closest to that cluster.\u003c/p\u003e\r\n\r\n\u003cp\u003eOnce all data points have been assigned to clusters, the cluster centers will be recomputed. In other words, new cluster centers will emerge from the average of the values of the cluster data points. This process is repeated until most data points stick to the same cluster. The cluster membership should stabilize.\u003c/p\u003e\r\n\r\n\u003cp\u003eYou can already see that, because the k-means algorithm works the way it does, the initial set of cluster centers that you give up can have a big effect on the clusters that are eventually found. You can, of course, deal with this effect, as you will see further on.\u003c/p\u003e\r\n\r\n\u003cp\u003eHowever, before you can go into making a model for your data, you should definitely take a look into preparing your data for this purpose.\u003c/p\u003e\r\n\u003c/div\u003e\r\n\u003cbr\u003e\r\n\u003cp\u003e\u003ca href=\"https://www.datacamp.com/courses/\" target=\"_blank\"\u003e\u003cimg alt=\"Learn Python for Data Science With DataCamp\" src=\"http://community.datacamp.com.s3.amazonaws.com/community/production/ckeditor_assets/pictures/293/content_blog_banner.png\" /\u003e\u003c/a\u003e\u003c/p\u003e\r\n\u003cbr\u003e\r\n\u003ch2 id=\"preprocess\"\u003ePreprocessing Your Data\u003c/h2\u003e\r\n\r\n\u003cp\u003eAs you have read in the previous section, before modeling your data, you\u0026rsquo;ll do well by preparing it first. This preparation step is called \u0026ldquo;preprocessing\u0026rdquo;.\u003c/p\u003e\r\n\r\n\u003cdiv class=\"section level3\" id=\"data-normalization\"\u003e\r\n\u003ch3\u003eData Normalization\u003c/h3\u003e\r\n\r\n\u003cp\u003eThe first thing that we\u0026rsquo;re going to do is preprocessing the data. You can standardize the \u003ccode\u003edigits\u003c/code\u003e data by, for example, making use of the \u003ccode\u003escale()\u003c/code\u003e method:\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"300\"\u003eeyJsYW5ndWFnZSI6InB5dGhvbiIsInByZV9leGVyY2lzZV9jb2RlIjoiZnJvbSBza2xlYXJuIGltcG9ydCBkYXRhc2V0c1xuZGlnaXRzID0gZGF0YXNldHMubG9hZF9kaWdpdHMoKSIsInNhbXBsZSI6IiMgSW1wb3J0XG5mcm9tIHNrbGVhcm4ucHJlcHJvY2Vzc2luZyBpbXBvcnQgc2NhbGVcblxuIyBBcHBseSBgc2NhbGUoKWAgdG8gdGhlIGBkaWdpdHNgIGRhdGFcbmRhdGEgPSBfX19fXyhkaWdpdHMuZGF0YSkiLCJzb2x1dGlvbiI6IiMgSW1wb3J0XG5mcm9tIHNrbGVhcm4ucHJlcHJvY2Vzc2luZyBpbXBvcnQgc2NhbGVcblxuIyBBcHBseSBgc2NhbGUoKWAgdG8gdGhlIGBkaWdpdHNgIGRhdGFcbmRhdGEgPSBzY2FsZShkaWdpdHMuZGF0YSkiLCJzY3QiOiJ0ZXN0X2Z1bmN0aW9uKFxuICAgIFwic2tsZWFybi5wcmVwcm9jZXNzaW5nLnNjYWxlXCIsXG4gICAgbm90X2NhbGxlZF9tc2c9XCJEaWQgeW91IHN0YW5kYXJkaXplIHRoZSBgZGlnaXRzYCBkYXRhP1wiLFxuICAgIGluY29ycmVjdF9tc2c9XCJEb24ndCBmb3JnZXQgdG8gc3RhbmRhcmRpemUgdGhlIGBkaWdpdHNgIGRhdGEgd2l0aCBgc2NhbGUoKWAhXCIsXG4gICAgZG9fZXZhbD1GYWxzZVxuKVxuc3VjY2Vzc19tc2coXCJBd2Vzb21lIVwiKSJ9\u003c/div\u003e\r\n\u003cbr\u003e\u003cbr\u003e\r\n\u003cp\u003eBy scaling the data, you shift the distribution of each attribute to have a mean of zero and a standard deviation of one (unit variance).\u003c/p\u003e\r\n\u003c/div\u003e\r\n\r\n\u003cdiv class=\"section level3\" id=\"splitting-your-data-into-training-and-test-sets\"\u003e\r\n\u003ch3\u003eSplitting Your Data Into Training And Test Sets\u003c/h3\u003e\r\n\r\n\u003cp\u003eIn order to assess your model\u0026rsquo;s performance later, you will also need to divide the data set into two parts: a training set and a test set. The first is used to train the system, while the second is used to evaluate the learned or trained system.\u003c/p\u003e\r\n\r\n\u003cp\u003eIn practice, the division of your data set into a test and a training sets is disjoint: the most common splitting choice is to take 2/3 of your original data set as the training set, while the 1/3 that remains will compose the test set.\u003c/p\u003e\r\n\r\n\u003cp\u003eYou will try to do this also here. You see in the code chunk below that this \u0026lsquo;traditional\u0026rsquo; splitting choice is respected: in the arguments of the \u003ccode\u003etrain_test_split()\u003c/code\u003e method, you clearly see that the \u003ccode\u003etest_size\u003c/code\u003e is set to \u003ccode\u003e0.25\u003c/code\u003e.\u003c/p\u003e\r\n\r\n\u003cp\u003eYou\u0026rsquo;ll also note that the argument \u003ccode\u003erandom_state\u003c/code\u003e has the value \u003ccode\u003e42\u003c/code\u003e assigned to it. With this argument, you can guarantee that your split will always be the same. That is particularly handy if you want reproducible results.\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"300\"\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\u003c/div\u003e\r\n\u003cbr\u003e\u003cbr\u003e\r\n\u003cp\u003eAfter you have split up your data set into train and test sets, you can quickly inspect the numbers before you go and model the data:\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"300\"\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\u003c/div\u003e\r\n\u003cbr\u003e\u003cbr\u003e\r\n\u003cp\u003eYou\u0026rsquo;ll see that the training set \u003ccode\u003eX_train\u003c/code\u003e now contains 1347 samples, which is exactly 2/3d of the samples that the original data set contained, and 64 features, which hasn\u0026rsquo;t changed. The \u003ccode\u003ey_train\u003c/code\u003e training set also contains 2/3d of the labels of the original data set. This means that the test sets \u003ccode\u003eX_test\u003c/code\u003e and \u003ccode\u003ey_test\u003c/code\u003e contain 450 samples.\u003c/p\u003e\r\n\u003c/div\u003e\r\n\r\n\u003ch2 id=\"kmeans\"\u003eClustering The \u003ccode\u003edigits\u003c/code\u003e Data\u003c/h2\u003e\r\n\r\n\u003cp\u003eAfter all these preparation steps, you have made sure that all your known (training) data is stored. No actual model or learning was performed up until this moment.\u003c/p\u003e\r\n\r\n\u003cp\u003eNow, it\u0026rsquo;s finally time to find those clusters of your training set. Use \u003ccode\u003eKMeans()\u003c/code\u003e from the \u003ccode\u003ecluster\u003c/code\u003e module to set up your model. You\u0026rsquo;ll see that there are three arguments that are passed to this method: \u003ccode\u003einit\u003c/code\u003e, \u003ccode\u003en_clusters\u003c/code\u003e and the \u003ccode\u003erandom_state\u003c/code\u003e.\u003c/p\u003e\r\n\r\n\u003cp\u003eYou might still remember this last argument from before when you split the data into training and test sets. This argument basically guaranteed that you got reproducible results.\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"300\"\u003eeyJsYW5ndWFnZSI6InB5dGhvbiIsInByZV9leGVyY2lzZV9jb2RlIjoiZnJvbSBza2xlYXJuIGltcG9ydCBkYXRhc2V0c1xuZnJvbSBza2xlYXJuLmNyb3NzX3ZhbGlkYXRpb24gaW1wb3J0IHRyYWluX3Rlc3Rfc3BsaXRcbmZyb20gc2tsZWFybi5wcmVwcm9jZXNzaW5nIGltcG9ydCBzY2FsZVxuaW1wb3J0IG51bXB5IGFzIG5wXG5kaWdpdHMgPSBkYXRhc2V0cy5sb2FkX2RpZ2l0cygpXG5kYXRhID0gc2NhbGUoZGlnaXRzLmRhdGEpXG5YX3RyYWluLCBYX3Rlc3QsIHlfdHJhaW4sIHlfdGVzdCwgaW1hZ2VzX3RyYWluLCBpbWFnZXNfdGVzdCA9IHRyYWluX3Rlc3Rfc3BsaXQoZGF0YSwgZGlnaXRzLnRhcmdldCwgZGlnaXRzLmltYWdlcywgdGVzdF9zaXplPTAuMjUsIHJhbmRvbV9zdGF0ZT00MikiLCJzYW1wbGUiOiIjIEltcG9ydCB0aGUgYGNsdXN0ZXJgIG1vZHVsZVxuZnJvbSBza2xlYXJuIGltcG9ydCBfX19fX19fX1xuXG4jIENyZWF0ZSB0aGUgS01lYW5zIG1vZGVsXG5jbGYgPSBjbHVzdGVyLktNZWFucyhpbml0PSdrLW1lYW5zKysnLCBuX2NsdXN0ZXJzPTEwLCByYW5kb21fc3RhdGU9NDIpXG5cbiMgRml0IHRoZSB0cmFpbmluZyBkYXRhIGBYX3RyYWluYHRvIHRoZSBtb2RlbFxuY2xmLmZpdChfX19fX19fXykiLCJzb2x1dGlvbiI6IiMgSW1wb3J0IHRoZSBgY2x1c3RlcmAgbW9kdWxlXG5mcm9tIHNrbGVhcm4gaW1wb3J0IGNsdXN0ZXJcblxuIyBDcmVhdGUgdGhlIEtNZWFucyBtb2RlbFxuY2xmID0gY2x1c3Rlci5LTWVhbnMoaW5pdD0nay1tZWFucysrJywgbl9jbHVzdGVycz0xMCwgcmFuZG9tX3N0YXRlPTQyKVxuXG4jIEZpdCB0aGUgdHJhaW5pbmcgZGF0YSB0byB0aGUgbW9kZWxcbmNsZi5maXQoWF90cmFpbikiLCJzY3QiOiJpbXBvcnRfbXNnPVwiRGlkIHlvdSBpbXBvcnQgYGNsdXN0ZXJgIGZyb20gYHNrbGVhcm5gP1wiXG5wcmVkZWZfbXNnPVwiRG9uJ3QgZm9yZ2V0IHRvIGltcG9ydCBgY2x1c3RlciBmcm9tIGBza2xlYXJuYCFcIlxudGVzdF9pbXBvcnQoXCJza2xlYXJuLmNsdXN0ZXJcIiwgc2FtZV9hcyA9IFRydWUsIG5vdF9pbXBvcnRlZF9tc2cgPSBpbXBvcnRfbXNnLCBpbmNvcnJlY3RfYXNfbXNnID0gcHJlZGVmX21zZylcbnRlc3Rfb2JqZWN0KFwiY2xmXCIsIGRvX2V2YWw9RmFsc2UsIGluY29ycmVjdF9tc2c9XCJkaWQgY3JlYXRlIHRoZSBLTWVhbnMgbW9kZWwgY29ycmVjdGx5P1wiKVxudGVzdF9mdW5jdGlvbihcImNsZi5maXRcIiwgZG9fZXZhbD1GYWxzZSlcbnN1Y2Nlc3NfbXNnKFwiV29vaG9vIVwiKSJ9\u003c/div\u003e\r\n\u003cbr\u003e\u003cbr\u003e\r\n\u003cp\u003eThe \u003ccode\u003einit\u003c/code\u003e indicates the method for initialization and even though it defaults to \u003ccode\u003e\u0026lsquo;k-means++\u0026rsquo;\u003c/code\u003e, you see it explicitly coming back in the code. That means that you can leave it out if you want. Try it out in the DataCamp Light chunk above!\u003c/p\u003e\r\n\r\n\u003cp\u003eNext, you also see that the \u003ccode\u003en_clusters\u003c/code\u003e argument is set to \u003ccode\u003e10\u003c/code\u003e. This number not only indicates the number of clusters or groups you want your data to form, but also the number of centroids to generate. Remember that a cluster centroid is the middle of a cluster.\u003c/p\u003e\r\n\r\n\u003cp\u003eDo you also still remember how the previous section described this as one of the possible disadvantages of the K-Means algorithm?\u003c/p\u003e\r\n\r\n\u003cp\u003eThat is, that the initial set of cluster centers that you give up can have a big effect on the clusters that are eventually found?\u003c/p\u003e\r\n\r\n\u003cp\u003eUsually, you try to deal with this effect by trying several initial sets in multiple runs and by selecting the set of clusters with the minimum sum of the squared errors (SSE). In other words, you want to minimize the distance of each point in the cluster to the mean or centroid of that cluster.\u003c/p\u003e\r\n\r\n\u003cp\u003eBy adding the \u003ccode\u003en-init\u003c/code\u003e argument to \u003ccode\u003eKMeans()\u003c/code\u003e, you can determine how many different centroid configurations the algorithm will try.\u003c/p\u003e\r\n\r\n\u003cp\u003e\u003cstrong\u003eNote\u003c/strong\u003e again that you don\u0026rsquo;t want to insert the test labels when you fit the model to your data: these will be used to see if your model is good at predicting the actual classes of your instances!\u003c/p\u003e\r\n\r\n\u003cp\u003eYou can also visualize the images that make up the cluster centers as follows:\u003c/p\u003e\r\n\r\n\u003cpre\u003e\r\n\u003ccode\u003e# Import matplotlib\r\nimport matplotlib.pyplot as plt\r\n\r\n# Figure size in inches\r\nfig = plt.figure(figsize=(8, 3))\r\n\r\n# Add title\r\nfig.suptitle('Cluster Center Images', fontsize=14, fontweight='bold')\r\n\r\n# For all labels (0-9)\r\nfor i in range(10):\r\n    # Initialize subplots in a grid of 2X5, at i+1th position\r\n    ax = fig.add_subplot(2, 5, 1 + i)\r\n    # Display images\r\n    ax.imshow(clf.cluster_centers_[i].reshape((8, 8)), cmap=plt.cm.binary)\r\n    # Don't show the axes\r\n    plt.axis('off')\r\n\r\n# Show the plot\r\nplt.show()\u003c/code\u003e\u003c/pre\u003e\r\n\r\n\u003cbr\u003e\r\n\u003cp\u003e\u003cimg alt=\"KMeans cluster visualization with scikit-learn\" src=\"http://community.datacamp.com.s3.amazonaws.com/community/production/ckeditor_assets/pictures/270/content_plot4.png\" /\u003e\u003c/p\u003e\r\n\u003cbr\u003e\r\n\u003cp\u003eIf you want to see another example that visualizes the \u003cdigits\u003e data clusters and their centers, go \u003ca href=\"http://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_digits.html\"\u003ehere\u003c/a\u003e.\u003c/digits\u003e\u003c/p\u003e\r\n\r\n\u003cp\u003eThe next step is to predict the labels of the test set:\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"300\"\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\u003c/div\u003e\r\n\u003cbr\u003e\u003cbr\u003e\r\n\u003cp\u003eIn the code chunk above, you predict the values for the test set, which contains 450 samples. You store the result in \u003ccode\u003ey_pred\u003c/code\u003e. You also print out the first 100 instances of \u003ccode\u003ey_pred\u003c/code\u003e and \u003ccode\u003ey_test\u003c/code\u003e and you immediately see some results.\u003c/p\u003e\r\n\r\n\u003cp\u003eIn addition, you can study the shape of the cluster centers: you immediately see that there are 10 clusters with each 64 features.\u003c/p\u003e\r\n\r\n\u003cp\u003eBut this doesn\u0026rsquo;t tell you much because we set the number of clusters to 10 and you already knew that there were 64 features.\u003c/p\u003e\r\n\r\n\u003cp\u003eMaybe a visualization would be more helpful.\u003c/p\u003e\r\n\r\n\u003cp\u003eLet\u0026rsquo;s visualize the predicted labels:\u003c/p\u003e\r\n\r\n\u003cpre\u003e\r\n\u003ccode\u003e# Import `Isomap()`\r\nfrom sklearn.manifold import Isomap\r\n\r\n# Create an isomap and fit the `digits` data to it\r\nX_iso = Isomap(n_neighbors=10).fit_transform(X_train)\r\n\r\n# Compute cluster centers and predict cluster index for each sample\r\nclusters = clf.fit_predict(X_train)\r\n\r\n# Create a plot with subplots in a grid of 1X2\r\nfig, ax = plt.subplots(1, 2, figsize=(8, 4))\r\n\r\n# Adjust layout\r\nfig.suptitle('Predicted Versus Training Labels', fontsize=14, fontweight='bold')\r\nfig.subplots_adjust(top=0.85)\r\n\r\n# Add scatterplots to the subplots \r\nax[0].scatter(X_iso[:, 0], X_iso[:, 1], c=clusters)\r\nax[0].set_title('Predicted Training Labels')\r\nax[1].scatter(X_iso[:, 0], X_iso[:, 1], c=y_train)\r\nax[1].set_title('Actual Training Labels')\r\n\r\n# Show the plots\r\nplt.show()\u003c/code\u003e\u003c/pre\u003e\r\n\r\n\u003cp\u003eYou use \u003ccode\u003eIsomap()\u003c/code\u003e as a way to reduce the dimensions of your high-dimensional data set \u003ccode\u003edigits\u003c/code\u003e. The difference with the PCA method is that the Isomap is a non-linear reduction method.\u003c/p\u003e\r\n\u003cbr\u003e\r\n\u003cp\u003e\u003cimg alt=\"Isomap visualization\" src=\"http://community.datacamp.com.s3.amazonaws.com/community/production/ckeditor_assets/pictures/271/content_plot5.png\" /\u003e\u003c/p\u003e\r\n\u003cbr\u003e\r\n\u003cp\u003e\u003cstrong\u003eTip\u003c/strong\u003e: run the code from above again, but use the PCA reduction method instead of the Isomap to study the effect of reduction methods yourself.\u003c/p\u003e\r\n\r\n\u003cp\u003eYou will find the solution here:\u003c/p\u003e\r\n\r\n\u003cpre\u003e\r\n\u003ccode\u003e# Import `PCA()`\r\nfrom sklearn.decomposition import PCA\r\n\r\n# Model and fit the `digits` data to the PCA model\r\nX_pca = PCA(n_components=2).fit_transform(X_train)\r\n\r\n# Compute cluster centers and predict cluster index for each sample\r\nclusters = clf.fit_predict(X_train)\r\n\r\n# Create a plot with subplots in a grid of 1X2\r\nfig, ax = plt.subplots(1, 2, figsize=(8, 4))\r\n\r\n# Adjust layout\r\nfig.suptitle('Predicted Versus Training Labels', fontsize=14, fontweight='bold')\r\nfig.subplots_adjust(top=0.85)\r\n\r\n# Add scatterplots to the subplots \r\nax[0].scatter(X_pca[:, 0], X_pca[:, 1], c=clusters)\r\nax[0].set_title('Predicted Training Labels')\r\nax[1].scatter(X_pca[:, 0], X_pca[:, 1], c=y_train)\r\nax[1].set_title('Actual Training Labels')\r\n\r\n# Show the plots\r\nplt.show()\u003c/code\u003e\u003c/pre\u003e\r\n\u003cbr\u003e\r\n\u003cp\u003e\u003cimg alt=\"PCA visualization with matplotlib\" src=\"http://community.datacamp.com.s3.amazonaws.com/community/production/ckeditor_assets/pictures/272/content_plot6.png\" /\u003e\u003c/p\u003e\r\n\u003cbr\u003e\r\n\u003cp\u003eAt first sight, the visualization doesn\u0026rsquo;t seem to indicate that the model works well.\u003c/p\u003e\r\n\r\n\u003cp\u003eBut this needs some further investigation.\u003c/p\u003e\r\n\u003c/div\u003e\r\n\r\n\u003cdiv class=\"section level3\" id=\"evaluation-of-your-clustering-model\"\u003e\r\n\u003ch3\u003eEvaluation of Your Clustering Model\u003c/h3\u003e\r\n\r\n\u003cp\u003eAnd this need for further investigation brings you to the next essential step, which is the evaluation of your model\u0026rsquo;s performance. In other words, you want to analyze the degree of correctness of the model\u0026rsquo;s predictions.\u003c/p\u003e\r\n\r\n\u003cp\u003eLet\u0026rsquo;s print out a confusion matrix:\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"300\"\u003eeyJsYW5ndWFnZSI6InB5dGhvbiIsInByZV9leGVyY2lzZV9jb2RlIjoiZnJvbSBza2xlYXJuIGltcG9ydCBkYXRhc2V0c1xuZnJvbSBza2xlYXJuLmNyb3NzX3ZhbGlkYXRpb24gaW1wb3J0IHRyYWluX3Rlc3Rfc3BsaXRcbmZyb20gc2tsZWFybi5wcmVwcm9jZXNzaW5nIGltcG9ydCBzY2FsZVxuZnJvbSBza2xlYXJuIGltcG9ydCBjbHVzdGVyXG5kaWdpdHMgPSBkYXRhc2V0cy5sb2FkX2RpZ2l0cygpXG5kYXRhID0gc2NhbGUoZGlnaXRzLmRhdGEpXG5YX3RyYWluLCBYX3Rlc3QsIHlfdHJhaW4sIHlfdGVzdCwgaW1hZ2VzX3RyYWluLCBpbWFnZXNfdGVzdCA9IHRyYWluX3Rlc3Rfc3BsaXQoZGF0YSwgZGlnaXRzLnRhcmdldCwgZGlnaXRzLmltYWdlcywgdGVzdF9zaXplPTAuMjUsIHJhbmRvbV9zdGF0ZT00MilcbmNsZiA9IGNsdXN0ZXIuS01lYW5zKGluaXQ9J2stbWVhbnMrKycsIG5fY2x1c3RlcnM9MTAsIHJhbmRvbV9zdGF0ZT00MilcbmNsZi5maXQoWF90cmFpbilcbnlfcHJlZD1jbGYucHJlZGljdChYX3Rlc3QpIiwic2FtcGxlIjoiIyBJbXBvcnQgYG1ldHJpY3NgIGZyb20gYHNrbGVhcm5gXG5mcm9tIHNrbGVhcm4gaW1wb3J0IF9fX19fX19cblxuIyBQcmludCBvdXQgdGhlIGNvbmZ1c2lvbiBtYXRyaXggd2l0aCBgY29uZnVzaW9uX21hdHJpeCgpYFxucHJpbnQobWV0cmljcy5jb25mdXNpb25fbWF0cml4KHlfdGVzdCwgeV9wcmVkKSkiLCJzb2x1dGlvbiI6IiMgSW1wb3J0IGBtZXRyaWNzYCBmcm9tIGBza2xlYXJuYFxuZnJvbSBza2xlYXJuIGltcG9ydCBtZXRyaWNzXG5cbiMgUHJpbnQgb3V0IHRoZSBjb25mdXNpb24gbWF0cml4IHdpdGggYGNvbmZ1c2lvbl9tYXRyaXgoKWBcbnByaW50KG1ldHJpY3MuY29uZnVzaW9uX21hdHJpeCh5X3Rlc3QsIHlfcHJlZCkpIiwic2N0IjoidGVzdF9pbXBvcnQoXCJza2xlYXJuLm1ldHJpY3NcIiwgc2FtZV9hcyA9IFRydWUsIG5vdF9pbXBvcnRlZF9tc2cgPSBcIkRpZCB5b3UgaW1wb3J0IGBtZXRyaWNzYCBmcm9tIGBza2xlYXJuYD9cIiwgaW5jb3JyZWN0X2FzX21zZyA9IFwiRG9uJ3QgZm9yZ2V0IHRvIGltcG9ydCBgbWV0cmljc2AgZnJvbSBgc2tsZWFybmAhXCIpXG50ZXN0X2Z1bmN0aW9uKFxuICAgIFwicHJpbnRcIixcbiAgICBub3RfY2FsbGVkX21zZz1cIkRpZCB5b3UgcHJpbnQgb3V0IHRoZSBjb25mdXNpb24gbWF0cml4P1wiLFxuICAgIGluY29ycmVjdF9tc2c9XCJEb24ndCBmb3JnZXQgdG8gcHJpbnQgb3V0IHRoZSBjb25mdXNpb24gbWF0cml4IVwiLFxuICAgIGRvX2V2YWw9RmFsc2VcbilcbnN1Y2Nlc3NfbXNnPVwiV2VsbCBkb25lISBOb3csIHdoYXQgZG8gdGhlIHJlc3VsdHMgdGVsbCB5b3U/XCIifQ==\u003c/div\u003e\r\n\u003cbr\u003e\u003cbr\u003e\r\n\u003cp\u003eAt first sight, the results seem to confirm our first thoughts that you gathered from the visualizations. Only the digit \u003ccode\u003e5\u003c/code\u003e was classified correctly in 41 cases. Also, the digit \u003ccode\u003e8\u003c/code\u003e was classified correctly in 11 instances. But this is not really a success.\u003c/p\u003e\r\n\r\n\u003cp\u003eYou might need to know a bit more about the results than just the confusion matrix.\u003c/p\u003e\r\n\r\n\u003cp\u003eLet\u0026rsquo;s try to figure out something more about the quality of the clusters by applying different cluster quality metrics. That way, you can judge the goodness of fit of the cluster labels to the correct labels.\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"300\"\u003eeyJsYW5ndWFnZSI6InB5dGhvbiIsInByZV9leGVyY2lzZV9jb2RlIjoiZnJvbSBza2xlYXJuIGltcG9ydCBkYXRhc2V0c1xuZnJvbSBza2xlYXJuLmNyb3NzX3ZhbGlkYXRpb24gaW1wb3J0IHRyYWluX3Rlc3Rfc3BsaXRcbmZyb20gc2tsZWFybi5wcmVwcm9jZXNzaW5nIGltcG9ydCBzY2FsZVxuZnJvbSBza2xlYXJuIGltcG9ydCBjbHVzdGVyXG5mcm9tIHNrbGVhcm4ubWV0cmljcyBpbXBvcnQgaG9tb2dlbmVpdHlfc2NvcmUsIGNvbXBsZXRlbmVzc19zY29yZSwgdl9tZWFzdXJlX3Njb3JlLCBhZGp1c3RlZF9yYW5kX3Njb3JlLCBhZGp1c3RlZF9tdXR1YWxfaW5mb19zY29yZSwgc2lsaG91ZXR0ZV9zY29yZVxuZGlnaXRzID0gZGF0YXNldHMubG9hZF9kaWdpdHMoKVxuZGF0YSA9IHNjYWxlKGRpZ2l0cy5kYXRhKVxuWF90cmFpbiwgWF90ZXN0LCB5X3RyYWluLCB5X3Rlc3QsIGltYWdlc190cmFpbiwgaW1hZ2VzX3Rlc3QgPSB0cmFpbl90ZXN0X3NwbGl0KGRhdGEsIGRpZ2l0cy50YXJnZXQsIGRpZ2l0cy5pbWFnZXMsIHRlc3Rfc2l6ZT0wLjI1LCByYW5kb21fc3RhdGU9NDIpXG5jbGYgPSBjbHVzdGVyLktNZWFucyhpbml0PSdrLW1lYW5zKysnLCBuX2NsdXN0ZXJzPTEwLCByYW5kb21fc3RhdGU9NDIpXG5jbGYuZml0KFhfdHJhaW4pXG55X3ByZWQ9Y2xmLnByZWRpY3QoWF90ZXN0KSIsInNhbXBsZSI6ImZyb20gc2tsZWFybi5tZXRyaWNzIGltcG9ydCBob21vZ2VuZWl0eV9zY29yZSwgY29tcGxldGVuZXNzX3Njb3JlLCB2X21lYXN1cmVfc2NvcmUsIGFkanVzdGVkX3JhbmRfc2NvcmUsIGFkanVzdGVkX211dHVhbF9pbmZvX3Njb3JlLCBzaWxob3VldHRlX3Njb3JlXG5wcmludCgnJSA5cycgJSAnaW5lcnRpYSAgICBob21vICAgY29tcGwgIHYtbWVhcyAgICAgQVJJIEFNSSAgc2lsaG91ZXR0ZScpXG5wcmludCgnJWkgICAlLjNmICAgJS4zZiAgICUuM2YgICAlLjNmICAgJS4zZiAgICAlLjNmJ1xuICAgICAgICAgICUoY2xmLmluZXJ0aWFfLFxuICAgICAgaG9tb2dlbmVpdHlfc2NvcmUoeV90ZXN0LCB5X3ByZWQpLFxuICAgICAgY29tcGxldGVuZXNzX3Njb3JlKHlfdGVzdCwgeV9wcmVkKSxcbiAgICAgIHZfbWVhc3VyZV9zY29yZSh5X3Rlc3QsIHlfcHJlZCksXG4gICAgICBhZGp1c3RlZF9yYW5kX3Njb3JlKHlfdGVzdCwgeV9wcmVkKSxcbiAgICAgIGFkanVzdGVkX211dHVhbF9pbmZvX3Njb3JlKHlfdGVzdCwgeV9wcmVkKSxcbiAgICAgIHNpbGhvdWV0dGVfc2NvcmUoWF90ZXN0LCB5X3ByZWQsIG1ldHJpYz0nZXVjbGlkZWFuJykpKSJ9\u003c/div\u003e\r\n\u003cbr\u003e\u003cbr\u003e\r\n\u003cp\u003eYou\u0026rsquo;ll see that there are quite some metrics to consider:\u003c/p\u003e\r\n\r\n\u003cul\u003e\r\n\t\u003cli\u003eThe homogeneity score tells you to what extent all of the clusters contain only data points which are members of a single class.\u003c/li\u003e\r\n\t\u003cli\u003eThe completeness score measures the extent to which all of the data points that are members of a given class are also elements of the same cluster.\u003c/li\u003e\r\n\t\u003cli\u003eThe V-measure score is the harmonic mean between homogeneity and completeness.\u003c/li\u003e\r\n\t\u003cli\u003eThe adjusted Rand score measures the similarity between two clusterings and considers all pairs of samples and counting pairs that are assigned in the same or different clusters in the predicted and true clusterings.\u003c/li\u003e\r\n\t\u003cli\u003eThe Adjusted Mutual Info (AMI) score is used to compare clusters. It measures the similarity between the data points that are in the clusterings, accounting for chance groupings and takes a maximum value of 1 when clusterings are equivalent.\u003c/li\u003e\r\n\t\u003cli\u003eThe silhouette score measures how similar an object is to its own cluster compared to other clusters. The silhouette scores ranges from -1 to 1, where a higher value indicates that the object is better matched to its own cluster and worse mached to neighboring clusters. If many points have a high value, the clusteirng configuration is good.\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cbr\u003e\r\n\u003cp\u003eYou clearly see that these scores aren\u0026rsquo;t fantastic: for example, you see that the value for the silhouette score is close to 0, which indicates that the sample is on or very close to the decision boundary between two neighboring clusters. This could indicate that the samples could have been assigned to the wrong cluster.\u003c/p\u003e\r\n\r\n\u003cp\u003eAlso the ARI measure seems to indicate that not all data points in a given cluster are similar and the completeness score tells you that there are definitely data points that weren\u0026rsquo;t put in the right cluster.\u003c/p\u003e\r\n\r\n\u003cp\u003eClearly, you should consider another estimator to predict the labels for the \u003ccode\u003edigits\u003c/code\u003e data.\u003c/p\u003e\r\n\u003c/div\u003e\r\n\r\n\u003ch2 id=\"svm\"\u003eTrying Out Another Model: Support Vector Machines\u003c/h2\u003e\r\n\r\n\u003cp\u003eWhen you recapped all of the information that you gathered out of the data exploration, you saw that you could build a model to predict which group a digit belongs to without you knowing the labels. And indeed, you just used the training data and not the target values to build your KMeans model.\u003c/p\u003e\r\n\r\n\u003cp\u003eLet\u0026rsquo;s assume that you depart from the case where you use both the \u003ccode\u003edigits\u003c/code\u003e training data and the corresponding target values to build your model.\u003c/p\u003e\r\n\r\n\u003cp\u003eIf you follow the algorithm map, you\u0026rsquo;ll see that the first model that you meet is the linear SVC. Let\u0026rsquo;s apply this now to the \u003ccode\u003edigits\u003c/code\u003e data:\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"300\"\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\u003c/div\u003e\r\n\u003cbr\u003e\u003cbr\u003e\r\n\u003cp\u003eYou see here that you make use of \u003ccode\u003eX_train\u003c/code\u003e and \u003ccode\u003ey_train\u003c/code\u003e to fit the data to the SVC model. This is clearly different from clustering. Note also that in this example, you set the value of \u003ccode\u003egamma\u003c/code\u003e manually. It is possible to automatically find good values for the parameters by using tools such as grid search and cross validation.\u003c/p\u003e\r\n\r\n\u003cp\u003eEven though this is not the focus of this tutorial, you will see how you could have gone about this if you would have made use of grid search to adjust your parameters. You would have done something like the following:\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"300\"\u003eeyJsYW5ndWFnZSI6InB5dGhvbiIsInByZV9leGVyY2lzZV9jb2RlIjoiZnJvbSBza2xlYXJuIGltcG9ydCBzdm1cbmZyb20gc2tsZWFybiBpbXBvcnQgZGF0YXNldHNcbmZyb20gc2tsZWFybi5jcm9zc192YWxpZGF0aW9uIGltcG9ydCB0cmFpbl90ZXN0X3NwbGl0XG5kaWdpdHMgPSBkYXRhc2V0cy5sb2FkX2RpZ2l0cygpIiwic2FtcGxlIjoiIyBTcGxpdCB0aGUgYGRpZ2l0c2AgZGF0YSBpbnRvIHR3byBlcXVhbCBzZXRzXG5YX3RyYWluLCBYX3Rlc3QsIHlfdHJhaW4sIHlfdGVzdCA9IHRyYWluX3Rlc3Rfc3BsaXQoZGlnaXRzLmRhdGEsIGRpZ2l0cy50YXJnZXQsIHRlc3Rfc2l6ZT0wLjUsIHJhbmRvbV9zdGF0ZT0wKVxuXG4jIEltcG9ydCBHcmlkU2VhcmNoQ1ZcbmZyb20gc2tsZWFybi5ncmlkX3NlYXJjaCBpbXBvcnQgR3JpZFNlYXJjaENWXG5cbiMgU2V0IHRoZSBwYXJhbWV0ZXIgY2FuZGlkYXRlc1xucGFyYW1ldGVyX2NhbmRpZGF0ZXMgPSBbXG4gIHsnQyc6IFsxLCAxMCwgMTAwLCAxMDAwXSwgJ2tlcm5lbCc6IFsnbGluZWFyJ119LFxuICB7J0MnOiBbMSwgMTAsIDEwMCwgMTAwMF0sICdnYW1tYSc6IFswLjAwMSwgMC4wMDAxXSwgJ2tlcm5lbCc6IFsncmJmJ119LFxuXVxuXG4jIENyZWF0ZSBhIGNsYXNzaWZpZXIgd2l0aCB0aGUgcGFyYW1ldGVyIGNhbmRpZGF0ZXNcbmNsZiA9IEdyaWRTZWFyY2hDVihlc3RpbWF0b3I9c3ZtLlNWQygpLCBwYXJhbV9ncmlkPXBhcmFtZXRlcl9jYW5kaWRhdGVzLCBuX2pvYnM9LTEpXG5cbiMgVHJhaW4gdGhlIGNsYXNzaWZpZXIgb24gdHJhaW5pbmcgZGF0YVxuY2xmLmZpdChYX3RyYWluLCB5X3RyYWluKVxuXG4jIFByaW50IG91dCB0aGUgcmVzdWx0cyBcbnByaW50KCdCZXN0IHNjb3JlIGZvciB0cmFpbmluZyBkYXRhOicsIGNsZi5iZXN0X3Njb3JlXylcbnByaW50KCdCZXN0IGBDYDonLGNsZi5iZXN0X2VzdGltYXRvcl8uQylcbnByaW50KCdCZXN0IGtlcm5lbDonLGNsZi5iZXN0X2VzdGltYXRvcl8ua2VybmVsKVxucHJpbnQoJ0Jlc3QgYGdhbW1hYDonLGNsZi5iZXN0X2VzdGltYXRvcl8uZ2FtbWEpIn0=\u003c/div\u003e\r\n\u003cbr\u003e\u003cbr\u003e\r\n\u003cp\u003eNext, you use the classifier with the classifier and parameter candidates that you have just created to apply it to the second part of your data set. Next, you also train a new classifier using the best parameters found by the grid search. You score the result to see if the best parameters that were found in the grid search are actually working.\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"300\"\u003eeyJsYW5ndWFnZSI6InB5dGhvbiIsInByZV9leGVyY2lzZV9jb2RlIjoiZnJvbSBza2xlYXJuIGltcG9ydCBzdm1cbmZyb20gc2tsZWFybiBpbXBvcnQgZGF0YXNldHNcbmZyb20gc2tsZWFybi5jcm9zc192YWxpZGF0aW9uIGltcG9ydCB0cmFpbl90ZXN0X3NwbGl0XG5kaWdpdHMgPSBkYXRhc2V0cy5sb2FkX2RpZ2l0cygpXG5YX3RyYWluLCBYX3Rlc3QsIHlfdHJhaW4sIHlfdGVzdCA9IHRyYWluX3Rlc3Rfc3BsaXQoZGlnaXRzLmRhdGEsIGRpZ2l0cy50YXJnZXQsIHRlc3Rfc2l6ZT0wLjUsIHJhbmRvbV9zdGF0ZT0wKVxuZnJvbSBza2xlYXJuLmdyaWRfc2VhcmNoIGltcG9ydCBHcmlkU2VhcmNoQ1ZcbnBhcmFtZXRlcl9jYW5kaWRhdGVzID0gW1xuICB7J0MnOiBbMSwgMTAsIDEwMCwgMTAwMF0sICdrZXJuZWwnOiBbJ2xpbmVhciddfSxcbiAgeydDJzogWzEsIDEwLCAxMDAsIDEwMDBdLCAnZ2FtbWEnOiBbMC4wMDEsIDAuMDAwMV0sICdrZXJuZWwnOiBbJ3JiZiddfSxcbl1cbmNsZiA9IEdyaWRTZWFyY2hDVihlc3RpbWF0b3I9c3ZtLlNWQygpLCBwYXJhbV9ncmlkPXBhcmFtZXRlcl9jYW5kaWRhdGVzLCBuX2pvYnM9LTEpXG5jbGYuZml0KFhfdHJhaW4sIHlfdHJhaW4pIiwic2FtcGxlIjoiIyBBcHBseSB0aGUgY2xhc3NpZmllciB0byB0aGUgdGVzdCBkYXRhLCBhbmQgdmlldyB0aGUgYWNjdXJhY3kgc2NvcmVcbmNsZi5zY29yZShYX3Rlc3QsIHlfdGVzdCkgIFxuXG4jIFRyYWluIGFuZCBzY29yZSBhIG5ldyBjbGFzc2lmaWVyIHdpdGggdGhlIGdyaWQgc2VhcmNoIHBhcmFtZXRlcnNcbnN2bS5TVkMoQz0xMCwga2VybmVsPSdyYmYnLCBnYW1tYT0wLjAwMSkuZml0KFhfdHJhaW4sIHlfdHJhaW4pLnNjb3JlKFhfdGVzdCwgeV90ZXN0KSJ9\u003c/div\u003e\r\n\u003cbr\u003e\u003cbr\u003e\r\n\u003cp\u003eThe parameters indeed work well!\u003c/p\u003e\r\n\r\n\u003cp\u003eNow what does this new knowledge tell you about the SVC classifier that you had modeled before you had done the grid search?\u003c/p\u003e\r\n\r\n\u003cp\u003eLet\u0026rsquo;s back up to the model that you had made before.\u003c/p\u003e\r\n\r\n\u003cp\u003eYou see that in the SVM classifier, the penalty parameter \u003ccode\u003eC\u003c/code\u003e of the error term is specified at \u003ccode\u003e100.\u003c/code\u003e. Lastly, you see that the kernel has been explicitly specified as a \u003ccode\u003elinear\u003c/code\u003e one. The \u003ccode\u003ekernel\u003c/code\u003eargument specifies the kernel type that you\u0026rsquo;re going to use in the algorithm and by default, this is \u003ccode\u003erbf\u003c/code\u003e. In other cases, you can specify others such as \u003ccode\u003elinear\u003c/code\u003e, \u003ccode\u003epoly\u003c/code\u003e, \u0026hellip;\u003c/p\u003e\r\n\r\n\u003cp\u003eBut what is a kernel exactly?\u003c/p\u003e\r\n\r\n\u003cp\u003eA kernel is a similarity function, which is used to compute similarity between the training data points. When you provide a kernel to an algorithm, together with the training data and the labels, you will get a classifier, as is the case here. You will have trained a model that assigns new unseen objects into a particular category. For the SVM, you will typicall try to linearly divide your data points.\u003c/p\u003e\r\n\r\n\u003cp\u003eHowever, the grid search tells you that an \u003ccode\u003erbf\u003c/code\u003e kernel would\u0026rsquo;ve worked better. The penalty parameter and the gamma were specified correctly.\u003c/p\u003e\r\n\r\n\u003cp\u003e\u003cb\u003eTip: \u003c/b\u003etry out the classifier with an \u003ccode\u003erbf\u003c/code\u003e kernel.\u003c/p\u003e\r\n\r\n\u003cp\u003eFor now, let\u0026rsquo;s just say you just continue with a linear kernel and predict the values for the test set:\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"300\"\u003eeyJsYW5ndWFnZSI6InB5dGhvbiIsInByZV9leGVyY2lzZV9jb2RlIjoiZnJvbSBza2xlYXJuIGltcG9ydCBkYXRhc2V0c1xuZnJvbSBza2xlYXJuLnByZXByb2Nlc3NpbmcgaW1wb3J0IHNjYWxlXG5mcm9tIHNrbGVhcm4gaW1wb3J0IGNsdXN0ZXJcbmRpZ2l0cyA9IGRhdGFzZXRzLmxvYWRfZGlnaXRzKClcbmRhdGEgPSBzY2FsZShkaWdpdHMuZGF0YSlcbmZyb20gc2tsZWFybi5jcm9zc192YWxpZGF0aW9uIGltcG9ydCB0cmFpbl90ZXN0X3NwbGl0XG5YX3RyYWluLCBYX3Rlc3QsIHlfdHJhaW4sIHlfdGVzdCwgaW1hZ2VzX3RyYWluLCBpbWFnZXNfdGVzdCA9IHRyYWluX3Rlc3Rfc3BsaXQoZGlnaXRzLmRhdGEsIGRpZ2l0cy50YXJnZXQsIGRpZ2l0cy5pbWFnZXMsIHRlc3Rfc2l6ZT0wLjI1LCByYW5kb21fc3RhdGU9NDIpXG5mcm9tIHNrbGVhcm4gaW1wb3J0IHN2bVxuc3ZjX21vZGVsID0gc3ZtLlNWQyhnYW1tYT0wLjAwMSwgQz0xMDAuLCBrZXJuZWw9J2xpbmVhcicpXG5zdmNfbW9kZWwuZml0KFhfdHJhaW4sIHlfdHJhaW4pIiwic2FtcGxlIjoiIyBQcmVkaWN0IHRoZSBsYWJlbCBvZiBgWF90ZXN0YFxucHJpbnQoc3ZjX21vZGVsLnByZWRpY3QoX19fX19fKSlcblxuIyBQcmludCBgeV90ZXN0YCB0byBjaGVjayB0aGUgcmVzdWx0c1xucHJpbnQoX19fX19fKSIsInNvbHV0aW9uIjoiIyBQcmVkaWN0IHRoZSBsYWJlbCBvZiBgWF90ZXN0YFxucHJpbnQoc3ZjX21vZGVsLnByZWRpY3QoWF90ZXN0KSlcblxuIyBQcmludCBgeV90ZXN0YCB0byBjaGVjayB0aGUgcmVzdWx0c1xucHJpbnQoeV90ZXN0KSIsInNjdCI6InRlc3RfZnVuY3Rpb24oXG4gICAgXCJwcmludFwiLFxuICAgIDEsXG4gICAgbm90X2NhbGxlZF9tc2c9XCJEaWQgeW91IHByaW50IG91dCB0aGUgcHJlZGljdGVkIGxhYmVscyBvZiBgWF90ZXN0YD9cIixcbiAgICBpbmNvcnJlY3RfbXNnPVwiRG9uJ3QgZm9yZ2V0IHRvIHByaW50IG91dCB0aGUgcHJlZGljdGVkIGxhYmVscyBvZiBgWF90ZXN0YCFcIixcbiAgICBkb19ldmFsPUZhbHNlXG4pXG50ZXN0X2Z1bmN0aW9uKFxuICAgIFwicHJpbnRcIixcbiAgICAyLFxuICAgIG5vdF9jYWxsZWRfbXNnPVwiRGlkIHlvdSBwcmludCBvdXQgdGhlIHRydWUgbGFiZWxzIG9mIGB5X3Rlc3RgP1wiLFxuICAgIGluY29ycmVjdF9tc2c9XCJEb24ndCBmb3JnZXQgdG8gcmV2ZWFsaW5nIHRoZSB0cnVlIGxhYmVscyBieSBwcmludGluZyBvdXQgYHlfdGVzdGAhXCIsXG4gICAgZG9fZXZhbD1GYWxzZVxuKVxuc3VjY2Vzc19tc2coXCJXZWxsIGRvbmUhXCIpIn0=\u003c/div\u003e\r\n\u003cbr\u003e\u003cbr\u003e\r\n\u003cp\u003eYou can also visualize the images and their predicted labels:\u003c/p\u003e\r\n\r\n\u003cpre\u003e\r\n\u003ccode\u003e# Import matplotlib\r\nimport matplotlib.pyplot as plt\r\n\r\n# Assign the predicted values to `predicted`\r\npredicted = svc_model.predict(X_test)\r\n\r\n# Zip together the `images_test` and `predicted` values in `images_and_predictions`\r\nimages_and_predictions = list(zip(images_test, predicted))\r\n\r\n# For the first 4 elements in `images_and_predictions`\r\nfor index, (image, prediction) in enumerate(images_and_predictions[:4]):\r\n    # Initialize subplots in a grid of 1 by 4 at positions i+1\r\n    plt.subplot(1, 4, index + 1)\r\n    # Don't show axes\r\n    plt.axis('off')\r\n    # Display images in all subplots in the grid\r\n    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\r\n    # Add a title to the plot\r\n    plt.title('Predicted: ' + str(prediction))\r\n\r\n# Show the plot\r\nplt.show()\u003c/code\u003e\u003c/pre\u003e\r\n\r\n\u003cp\u003eThis plot is very similar to the plot that you made when you were exploring the data:\u003c/p\u003e\r\n\u003cbr\u003e\r\n\u003cp\u003e\u003cimg alt=\"Images and Predicted labels visualized with matplotlib\" src=\"http://community.datacamp.com.s3.amazonaws.com/community/production/ckeditor_assets/pictures/273/content_plot7.png\" /\u003e\u003c/p\u003e\r\n\u003cbr\u003e\r\n\u003cp\u003eOnly this time, you zip together the images and the predicted values and you only take the first 4 elements of \u003ccode\u003eimages_and_predictions\u003c/code\u003e.\u003c/p\u003e\r\n\r\n\u003cp\u003eBut now the biggest question: how does this model perform?\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"300\"\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\u003c/div\u003e\r\n\u003cbr\u003e\u003cbr\u003e\r\n\u003cp\u003eYou clearly see that this model performs a whole lot better than the clustering model that you used earlier.\u003c/p\u003e\r\n\r\n\u003cp\u003eYou can also see it when you visualize the predicted and the actual labels with the help of \u003ccode\u003eIsomap()\u003c/code\u003e:\u003c/p\u003e\r\n\r\n\u003cpre\u003e\r\n\u003ccode\u003e# Import `Isomap()`\r\nfrom sklearn.manifold import Isomap\r\n\r\n# Create an isomap and fit the `digits` data to it\r\nX_iso = Isomap(n_neighbors=10).fit_transform(X_train)\r\n\r\n# Compute cluster centers and predict cluster index for each sample\r\npredicted = svc_model.predict(X_train)\r\n\r\n# Create a plot with subplots in a grid of 1X2\r\nfig, ax = plt.subplots(1, 2, figsize=(8, 4))\r\n\r\n# Adjust the layout\r\nfig.subplots_adjust(top=0.85)\r\n\r\n# Add scatterplots to the subplots \r\nax[0].scatter(X_iso[:, 0], X_iso[:, 1], c=predicted)\r\nax[0].set_title('Predicted labels')\r\nax[1].scatter(X_iso[:, 0], X_iso[:, 1], c=y_train)\r\nax[1].set_title('Actual Labels')\r\n\r\n\r\n# Add title\r\nfig.suptitle('Predicted versus actual labels', fontsize=14, fontweight='bold')\r\n\r\n# Show the plot\r\nplt.show()\u003c/code\u003e\u003c/pre\u003e\r\n\r\n\u003cp\u003eThis will give you the following scatterplots:\u003c/p\u003e\r\n\u003cbr\u003e\r\n\u003cp\u003e\u003cimg alt=\"Isomap scatterplot visualization\" src=\"http://community.datacamp.com.s3.amazonaws.com/community/production/ckeditor_assets/pictures/274/content_plot8.png\" /\u003e\u003c/p\u003e\r\n\u003cbr\u003e\r\n\u003cp\u003eYou\u0026rsquo;ll see that this visualization confirms your classification report, which is very good news. :)\u003c/p\u003e\r\n\r\n\u003cdiv class=\"section level3\" id=\"whats-next\"\u003e\r\n\u003ch3\u003eWhat\u0026#39;s Next?\u003c/h3\u003e\r\n\r\n\u003cdiv class=\"section level4\" id=\"digit-recognition-in-natural-images\"\u003e\r\n\u003ch4\u003eDigit Recognition in Natural Images\u003c/h4\u003e\r\n\r\n\u003cp\u003eCongratulations, you have reached the end of this scikit-learn tutorial, which was meant to introduce you to Python machine learning! Now it\u0026#39;s your turn.\u003c/p\u003e\r\n\r\n\u003cp\u003eFirstly, make sure you get a hold of DataCamp's \u003ca href=\"https://www.datacamp.com/community/blog/scikit-learn-cheat-sheet/\" target=\"_blank\"\u003e\u003ccode\u003escikit-learn\u003c/code\u003e cheat sheet\u003c/a\u003e.\u003c/p\u003e\r\n\r\n\u003cp\u003eNext, start your own digit recognition project with different data. One dataset that you can already use is the MNIST data, which you can download \u003ca href=\"http://yann.lecun.com/exdb/mnist/\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\r\n\r\n\u003cp\u003eThe steps that you can take are very similar to the ones that you have gone through with this tutorial, but if you still feel that you can use some help, you should check out \u003ca href=\"http://johnloeber.com/docs/kmeans.html\"\u003ethis page\u003c/a\u003e, which works with the MNIST data and applies the KMeans algorithm.\u003c/p\u003e\r\n\r\n\u003cp\u003eWorking with the \u003ccode\u003edigits\u003c/code\u003e dataset was the first step in classifying characters with \u003ccode\u003escikit-learn\u003c/code\u003e. If you\u0026rsquo;re done with this, you might consider trying out an even more challenging problem, namely, classifying alphanumeric characters in natural images.\u003c/p\u003e\r\n\r\n\u003cp\u003eA well-known dataset that you can use for this problem is the Chars74K dataset, which contains more than 74,000 images of digits from 0 to 9 and the both lowercase and higher case letters of the English alphabet. You can download the dataset \u003ca href=\"http://www.ee.surrey.ac.uk/CVSSP/demos/chars74k/\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\r\n\u003c/div\u003e\r\n\r\n\u003cdiv class=\"section level4\" id=\"data-visualization-and-pandas\"\u003e\r\n\u003ch4\u003eData Visualization and \u003ccode\u003epandas\u003c/code\u003e\u003c/h4\u003e\r\n\r\n\u003cp\u003eWhether you\u0026#39;re going to start with the projects that have been mentioned above or not, this is definitely not the end of your journey of data science with Python. If you choose not to widen your view just yet, consider deepening your data visualization and data manipulation knowledge.\u003c/p\u003e\r\n\r\n\u003cp\u003eDon\u0026#39;t miss out on our \u003ca href=\"https://www.datacamp.com/courses/interactive-data-visualization-with-bokeh/\"\u003eInteractive Data Visualization with Bokeh course\u003c/a\u003e to make sure you can impress your peers with a stunning data science portfolio or our \u003ca href=\"https://www.datacamp.com/courses/pandas-foundations/\"\u003epandas Foundation course\u003c/a\u003e, to learn more about working with data frames in Python.\u003c/p\u003e\r\n\u003c/div\u003e\r\n\u003c/div\u003e\r\n\u003c/div\u003e\r\n\u003cscript\u003e","contentUrl":"https://www.datacamp.com/community/tutorials/machine-learning-python","userContentUrl":null,"illustrationUrl":null,"seoTitle":"Python Machine Learning: Scikit-Learn Tutorial","seoMetaDescription":"An easy-to-follow scikit-learn tutorial that will help you to get started with the Python machine learning.\r\n","seoKeyword":"scikit-learn tutorial","mustRead":true,"programmingLanguage":null,"submissionDate":"2016-12-22T15:35:58.000Z","publishDate":"2017-01-03T12:01:15.000Z","episode":null,"isLatest":null,"externalUrl":null,"transcriptUrl":null,"guests":[],"links":null,"isSpam":false,"xp":0,"flaggingUsers":[],"isDisabled":false,"connectedInternalContentId":null,"createdAt":"2017-09-08T15:37:09.806Z","updatedAt":"2018-03-02T08:50:54.519Z","upvoting":{"voteCount":58,"voted":false},"tags":["python","machine learning"],"author":{"id":494311,"slug":"karlijn","avatarUrlSquare":"https://assets.datacamp.com/users/avatars/000/494/311/square/Screenshot_2017-04-26_16.02.58.png?1493215479","fullName":"Karlijn Willems","nameFromEmail":"karlijn","isAdmin":false}},{"id":327,"externalId":null,"type":"Tutorial","status":"published","authorId":"karlijn","title":"Keras Tutorial: Deep Learning in Python","slug":"deep-learning-python","previewSlug":null,"description":"This Keras tutorial introduces you to deep learning in Python: learn to preprocess your data, model, evaluate and optimize neural networks. ","articles":[219,369,8224],"courses":[],"redirectSlug":null,"contentHtml":"\u003cmeta charset=\"utf-8\" /\u003e\u003cmeta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\" /\u003e\u003cmeta name=\"generator\" content=\"pandoc\" /\u003e\u003cscript src=\"keras_deep_learning_files/jquery-1.11.3/jquery.min.js\"\u003e\u003c/script\u003e\u003cmeta name=\"viewport\" content=\"width=device-width, initial-scale=1\" /\u003e\r\n\r\n\u003cscript src=\"https://cdn.datacamp.com/datacamp-light-latest.min.js\"\u003e\u003c/script\u003e\r\n\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1508150350/keras-watermark_vhhlzl.png\"/\u003e\r\n\u003cdiv class=\"section level2\" id=\"deep-learning\"\u003e\r\n\u003ch2\u003eDeep Learning\u003c/h2\u003e\r\n\r\n\u003cp\u003eBy now, you might already know machine learning, a branch in computer science that studies the design of algorithms that can learn. Today, you\u0026rsquo;re going to focus on deep learning, a subfield of machine learning that is a set of algorithms that is inspired by the structure and function of the brain. These algorithms are usually called Artificial Neural Networks (ANN). Deep learning is one of the hottest fields in data science with many case studies with marvelous results in robotics, image recognition and Artificial Intelligence (AI).\u003c/p\u003e\r\n\r\n\u003cp\u003eOne of the most powerful and easy-to-use Python libraries for developing and evaluating deep learning models is Keras; It wraps the efficient numerical computation libraries Theano and TensorFlow. The advantage of this is mainly that you can get started with neural networks in an easy and fun way.\u003c/p\u003e\r\n\r\n\u003cp\u003eToday\u0026rsquo;s Keras tutorial for beginners will introduce you to the basics of Python deep learning:\u003c/p\u003e\r\n\r\n\u003cnav\u003e\r\n\u003cul\u003e\r\n\t\u003cli\u003eYou\u0026rsquo;ll first learn what \u003ca href=\"#ann\"\u003eArtificial Neural Networks\u003c/a\u003e are\u003c/li\u003e\r\n\t\u003cli\u003eThen, the tutorial will show you step-by-step how to use Python and its libraries to \u003ca href=\"#Python\"\u003eunderstand, explore and visualize your data\u003c/a\u003e,\u003c/li\u003e\r\n\t\u003cli\u003eHow to \u003ca href=\"#preprocess\"\u003epreprocess\u003c/a\u003e your data: you\u0026rsquo;ll learn how to split up your data in train and test sets and how you can standardize your data,\u003c/li\u003e\r\n\t\u003cli\u003eHow to \u003ca href=\"#modeling\"\u003ebuild up multi-layer perceptrons for classification tasks\u003c/a\u003e,\u003c/li\u003e\r\n\t\u003cli\u003eHow to \u003ca href=\"#compfit\"\u003ecompile and fit\u003c/a\u003e the data to these models,\u003c/li\u003e\r\n\t\u003cli\u003eHow to use your model to \u003ca href=\"#predict\"\u003epredict target values\u003c/a\u003e, and\u003c/li\u003e\r\n\t\u003cli\u003eHow to \u003ca href=\"#validate\"\u003evalidate the models\u003c/a\u003e that you have built.\u003c/li\u003e\r\n\t\u003cli\u003eLastly, you\u0026rsquo;ll also see how you can build up \u003ca href=\"#finetune\"\u003ea model for regression tasks\u003c/a\u003e and you\u0026rsquo;ll learn how you can fine-tune the model that you\u0026rsquo;ve built.\r\n\t\u003cp\u003e\u0026nbsp;\u003c/p\u003e\r\n\t\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cdiv id=\"scoped-content\"\u003e\r\n\u003cstyle type=\"text/css\"\u003e:target:before { content:\"\"; display:block; height:150px; margin:-150px 0 0; } h3 {font-weight:normal; margin-top:.5em} h4 { font-weight:lighter }\r\n\u003c/style\u003e\r\n\u003cbr\u003e\r\n\r\n\u003cp\u003eWould you like to take a course on Keras and deep learning in Python? Consider taking DataCamp\u0026rsquo;s \u003ca href=\"https://www.datacamp.com/courses/deep-learning-in-python\"\u003eDeep Learning in Python\u003c/a\u003e course!\u003c/p\u003e\r\n\r\n\u003cp\u003eAlso, don\u0026rsquo;t miss our \u003ca href=\"https://www.datacamp.com/community/blog/keras-cheat-sheet\"\u003eKeras cheat sheet\u003c/a\u003e, which shows you the six steps that you need to go through to build neural networks in Python with code examples!\u003c/p\u003e\r\n\r\n\u003ch2 id=\"ann\"\u003eIntroducing Artificial Neural Networks\u003c/h2\u003e\r\n\r\n\u003cp\u003eBefore going deeper into Keras and how you can use it to get started with deep learning in Python, you should probably know a thing or two about neural networks. As you briefly read in the previous section, neural networks found their inspiration and biology, where the term \u0026ldquo;neural network\u0026rdquo; can also be used for neurons. The human brain is then an example of such a neural network, which is composed of a number of neurons.\u003c/p\u003e\r\n\r\n\u003cp\u003eAnd, as you all know, the brain is capable of performing quite complex computations and this is where the inspiration for Artificial Neural Networks comes from. The network a whole is a powerful modeling tool.\u003c/p\u003e\r\n\r\n\u003ch3\u003ePerceptrons\u003c/h3\u003e\r\n\r\n\u003cp\u003eThe most simple neural network is the \u0026ldquo;perceptron\u0026rdquo;, which, in its simplest form, consists of a single neuron. Much like biological neurons, which have dendrites and axons, the single artificial neuron is a simple tree structure which has input nodes and a single output node, which is connected to each input node. Here\u0026rsquo;s a visual comparison of the two:\u003c/p\u003e\r\n\r\n\u003cp\u003e\u003cimg src=\"https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Keras+Python+Tutorial/content_content_neuron.png\" /\u003e\u003c/p\u003e\r\n\r\n\u003cp\u003eAs you can see from the picture, there are six components to artificial neurons. From left to right, these are:\u003c/p\u003e\r\n\r\n\u003col style=\"list-style-type: decimal\"\u003e\r\n\t\u003cli\u003e\u003cstrong\u003eInput nodes\u003c/strong\u003e. As it so happens, each input node is associated with a numerical value, which can be any real number. Remember that real numbers make up the full spectrum of numbers: they can be positive or negative, whole or decimal numbers.\u003c/li\u003e\r\n\t\u003cli\u003e\u003cstrong\u003eConnections\u003c/strong\u003e. Similarly, each connection that departs from the input node has a weight associated with it and this can also be any real number.\u003c/li\u003e\r\n\t\u003cli\u003eNext, all the values of the input nodes and weights of the connections are brought together: they are used as inputs for a \u003cstrong\u003eweighted sum\u003c/strong\u003e: \u003cspan class=\"math inline\"\u003e\\(y = f(\\sum_{i=1}^{D} w_i*x_i)\\)\u003c/span\u003e, or, stated differently, \u003cspan class=\"math inline\"\u003e\\(y = f(w_1*x_1 + w_2*x_2 + ... w_D*x_D)\\)\u003c/span\u003e.\u003c/li\u003e\r\n\t\u003cli\u003eThis result will be the input for a \u003cstrong\u003etransfer or activation function\u003c/strong\u003e. In the simplest but trivial case, this transfer function would be an identity function, \u003cspan class=\"math inline\"\u003e\\(f(x)=x\\)\u003c/span\u003e or \u003cspan class=\"math inline\"\u003e\\(y=x\\)\u003c/span\u003e. In this case, \u003cspan class=\"math inline\"\u003e\\(x\\)\u003c/span\u003e is the weighted sum of the input nodes and the connections. However, just like a biological neuron only fires when a certain treshold is exceeded, the artificial neuron will also only fire when the sum of the inputs exceeds a treshold, let\u0026rsquo;s say for example 0. This is something that you can\u0026rsquo;t find back in an identity function! The most intuitive way that one can think of is by devising a system like the following:\r\n\r\n\t\u003cp\u003e\u003cspan class=\"math inline\"\u003e\\(f(x) = 0\\)\u003c/span\u003e if \u003cspan class=\"math inline\"\u003e\\(x\u0026lt;0\\)\u003c/span\u003e\u003cbr /\u003e\r\n\t\u003cspan class=\"math inline\"\u003e\\(f(x) = 0.5\\)\u003c/span\u003e if \u003cspan class=\"math inline\"\u003e\\(x=0\\)\u003c/span\u003e\u003cbr /\u003e\r\n\t\u003cspan class=\"math inline\"\u003e\\(f(x) = 1\\)\u003c/span\u003e if \u003cspan class=\"math inline\"\u003e\\(x\u0026gt;0\\)\u003c/span\u003e\u003c/p\u003e\u003c/li\u003e\r\n\r\n\t\u003cli style=\"list-style: none;\"\u003eOf course, you can already imagine that the output is not going to be a smooth line: it will be a discontinuous function. Because this can cause problems in the mathematical processing, a continuous variant, the sigmoid function, is often used. An example of a sigmoid function that you might already know is the logistic function. Using this function results in a much smoother result!\u003c/li\u003e\r\n\t\u003cli\u003eAs a result, you have the \u003cstrong\u003eoutput node\u003c/strong\u003e, which is associated with the function (such as the sigmoid function) of the weighted sum of the input nodes. Note that the sigmoid function is a mathematical function that results in an \u0026ldquo;S\u0026rdquo; shaped curve; You\u0026rsquo;ll read more about this later.\u003c/li\u003e\r\n\t\u003cli\u003eLastly, the perceptron may be an additional parameter, called a \u003cstrong\u003ebias\u003c/strong\u003e, which you can actually consider as the weight associated with an additional input node that is permanently set to 1. The bias value is important because it allows you to shift the activation function to the left or right, which can make a determine the success of your learning.\u003c/li\u003e\r\n\u003c/ol\u003e\r\n\u003cbr\u003e\r\n\u003cp\u003eNote that the logical consequence of this model is that perceptrons only work with numerical data. This implies that you should convert any nominal data into a numerical format.\u003c/p\u003e\r\n\r\n\u003cp\u003eNow that you know that perceptrons work with tresholds, the step to using them for classification purproses isn\u0026rsquo;t that far off: the perceptron can agree that any output above a certain treshold indicates that an instance belongs to one class, while an output below the treshold might result in the input being a member of the other class. The straight line where the output equals the treshold is then the boundary between the two classes.\u003c/p\u003e\r\n\r\n\u003cp\u003e\u003ca href=\"https://www.datacamp.com/courses/\" target=\"_blank\"\u003e\u003cimg alt=\"Learn Python for Data Science With DataCamp\" src=\"http://community.datacamp.com.s3.amazonaws.com/community/production/ckeditor_assets/pictures/293/content_blog_banner.png\" /\u003e\u003c/a\u003e\u003c/p\u003e\r\n\r\n\u003ch3\u003eMulti-Layer Perceptrons\u003c/h3\u003e\r\n\r\n\u003cp\u003eNetworks of perceptrons are multi-layer perceptrons, and this is what this tutorial will implement in Python with the help of Keras! Multi-layer perceptrons are also known as \u0026ldquo;feed-forward neural networks\u0026rdquo;. As you sort of guessed it by now, these are more complex networks than the perceptron, as they consist of multiple neurons that are organized in layers. The number of layers is usually limited to two or three, but theoretically, there is no limit!\u003c/p\u003e\r\n\r\n\u003cp\u003eThe layers act very much like the biological neurons that you have read about above: the outputs of one layer serve as the inputs for the next layer.\u003c/p\u003e\r\n\r\n\u003cp\u003eAmong the layers, you can distinguish an input layer, hidden layers and an output layer. Multi-layer perceptrons are often fully connected. This means that there\u0026rsquo;s a connection from each perceptron in a certain layer to each perceptron in the next layer. Even though the connectedness is no requirement, this is typically the case.\u003c/p\u003e\r\n\r\n\u003cp\u003eNote that while the perceptron could only represent linear separations between classes, the multi-layer perceptron overcomes that limitation and can also represent more complex decision boundaries.\u003c/p\u003e\r\n\r\n\u003ch2 id=\"Python\"\u003ePredicting Wine Types: Red or White?\u003c/h2\u003e\r\n\r\n\u003cp\u003eFor this tutorial, you\u0026rsquo;ll use the wine quality data set that you can find in the \u003ca href=\"\"\u003ewine quality data set\u003c/a\u003e from the UCI Machine Learning Repository. Ideally, you perform deep learning on bigger data sets but for the purpose of this tutorial, you will make use of a smaller one. This is mainly because the goal is to get you started with the library and to familiarize yourself with how neural networks work.\u003c/p\u003e\r\n\r\n\u003cp\u003eYou might already know this data set, as it\u0026rsquo;s one of the most popular data sets to get started on learning how to work out machine learning problems. In this case, it will serve for you to get started with deep learning in Python with Keras.\u003c/p\u003e\r\n\r\n\u003cp\u003eLet\u0026rsquo;s get started now!\u003c/p\u003e\r\n\r\n\u003ch3\u003eUnderstanding The Data\u003c/h3\u003e\r\n\r\n\u003cp\u003eHowever, before you start loading in the data, it might be a good idea to check how much you really know about wine (in relation with the dataset, of course). Most of you will know that there are, in general, two very popular types of wine: red and white.\u003c/p\u003e\r\n\r\n\u003cp\u003e(I\u0026rsquo;m sure that there are many others, but for simplicity and because of my limited knowledge of wines, I\u0026rsquo;ll keep it at this. I\u0026rsquo;m sorry if I\u0026rsquo;m disappointing the true connoisseurs among you :)).\u003c/p\u003e\r\n\r\n\u003cp\u003eKnowing this is already one thing but if you want to analyze this data, you will need to know just a little bit more.\u003c/p\u003e\r\n\r\n\u003cp\u003eFirst, check out the data description folder to see which variables have been included. This is usually the first step to understanding your data. Go to \u003ca href=\"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality.names\"\u003ethis page\u003c/a\u003e to check out the description or keep on reading to get to know your data a little bit better.\u003c/p\u003e\r\n\r\n\u003cp\u003eThe data consists of two datasets that are related to red and white variants of the Portuguese \u0026ldquo;Vinho Verde\u0026rdquo; wine. As stated in the description, you\u0026rsquo;ll only find physicochecmical and sensory variables included in this data set. The data description file just list the 12 variables that are included in the data, but for those who, like me, aren\u0026rsquo;t really chemistry experts either, here\u0026rsquo;s a short description of each variable:\u003c/p\u003e\r\n\r\n\u003col style=\"list-style-type: decimal\"\u003e\r\n\t\u003cli\u003e\u003cem\u003eFixed acidity\u003c/em\u003e: acids are major wine properties and contribute greatly to the wine\u0026rsquo;s taste. Usually, the total acidity is divided into two groups: the volatile acids and the nonvolatile or fixed acids. Among the fixed acids that you can find in wines are the following: tartaric, malic, citric, and succinic. This variable is expressed in g(\u003cspan class=\"math inline\"\u003e\\(tartaric acid\\)\u003c/span\u003e)/\u003cspan class=\"math inline\"\u003e\\(dm^3\\)\u003c/span\u003e in the data sets.\u003c/li\u003e\r\n\t\u003cli\u003e\u003cem\u003eVolatile acidity\u003c/em\u003e: the volatile acidity is basically the process of wine turning into vinegar. In the U.S, the legal limits of Volatile Acidity are 1.2 g/L for red table wine and 1.1 g/L for white table wine. In these data sets, the volatile acidity is expressed in g(\u003cspan class=\"math inline\"\u003e\\(acetic acid\\)\u003c/span\u003e)/\u003cspan class=\"math inline\"\u003e\\(dm^3\\)\u003c/span\u003e.\u003c/li\u003e\r\n\t\u003cli\u003e\u003cem\u003eCitric acid\u003c/em\u003e is one of the fixed acids that you\u0026rsquo;ll find in wines. It\u0026rsquo;s expressed in g/\u003cspan class=\"math inline\"\u003e\\(dm^3\\)\u003c/span\u003e in the two data sets.\u003c/li\u003e\r\n\t\u003cli\u003e\u003cem\u003eResidual sugar\u003c/em\u003e typically refers to the sugar remaining after fermentation stops, or is stopped. It\u0026rsquo;s expressed in g/\u003cspan class=\"math inline\"\u003e\\(dm^3\\)\u003c/span\u003e in the \u003ccode class=\"lang-python\"\u003ered\u003c/code\u003e and \u003ccode class=\"lang-python\"\u003ewhite\u003c/code\u003e data.\u003c/li\u003e\r\n\t\u003cli\u003e\u003cem\u003eChlorides\u003c/em\u003e can be a major contributor to saltiness in wine. Here, you\u0026rsquo;ll see that it\u0026rsquo;s expressed in g(\u003cspan class=\"math inline\"\u003e\\(sodium chloride\\)\u003c/span\u003e)/\u003cspan class=\"math inline\"\u003e\\(dm^3\\)\u003c/span\u003e.\u003c/li\u003e\r\n\t\u003cli\u003e\u003cem\u003eFree sulfur dioxide\u003c/em\u003e: the part of the sulphur dioxide that is added to a wine and that is lost into it is said to be bound, while the active part is said to be free. Winemaker will always try to get the highest proportion of free sulphur to bind. This variables is expressed in mg/\u003cspan class=\"math inline\"\u003e\\(dm^3\\)\u003c/span\u003e in the data.\u003c/li\u003e\r\n\t\u003cli\u003e\u003cem\u003eTotal sulfur dioxide\u003c/em\u003e is the sum of the bound and the free sulfur dioxide (SO2). Here, it\u0026rsquo;s expressed in mg/\u003cspan class=\"math inline\"\u003e\\(dm^3\\)\u003c/span\u003e. There are legal limits for sulfur levels in wines: in the EU, red wines can only have 160mg/L, while white and rose wines can have about 210mg/L. Sweet wines are allowed to have 400mg/L. For the US, the legal limits are set at 350mg/L and for Australia, this is 250mg/L.\u003c/li\u003e\r\n\t\u003cli\u003e\u003cem\u003eDensity\u003c/em\u003e is generally used as a measure of the conversion of sugar to alcohol. Here, it\u0026rsquo;s expressed in g/\u003cspan class=\"math inline\"\u003e\\(cm^3\\)\u003c/span\u003e.\u003c/li\u003e\r\n\t\u003cli\u003e\u003cem\u003epH\u003c/em\u003e or the potential of hydrogen is a numeric scale to specify the acidity or basicity the wine. As you might know, solutions with a pH less than 7 are acidic, while solutions with a pH greater than 7 are basic. With a pH of 7, pure water is neutral. Most wines have a pH between 2.9 and 3.9 and are therefore acidic.\u003c/li\u003e\r\n\t\u003cli\u003e\u003cem\u003eSulphates\u003c/em\u003e are to wine as gluten is to food. You might already know sulphites from the headaches that they can cause. They are a regular part of the winemaking around the world and are considered necessary. In this case, they are expressed in g(\u003cspan class=\"math inline\"\u003e\\(potassium sulphate\\)\u003c/span\u003e)/\u003cspan class=\"math inline\"\u003e\\(dm^3\\)\u003c/span\u003e.\u003c/li\u003e\r\n\t\u003cli\u003e\u003cem\u003eAlcohol\u003c/em\u003e: wine is an alcoholic beverage and as you know, the percentage of alcohol can vary from wine to wine. It shouldn\u0026rsquo;t surprised that this variable is inclued in the data sets, where it\u0026rsquo;s expressed in % vol.\u003c/li\u003e\r\n\t\u003cli\u003e\u003cem\u003eQuality\u003c/em\u003e: wine experts graded the wine quality between 0 (very bad) and 10 (very excellent). The eventual number is the median of at least three evaluations made by those same wine experts.\u003c/li\u003e\r\n\u003c/ol\u003e\r\n\u003cbr\u003e\r\n\u003cp\u003eThis all, of course, is some very basic information that you might need to know to get started. If you\u0026rsquo;re a true wine connoisseur, you probably know all of this and more!\u003c/p\u003e\r\n\r\n\u003cp\u003eNow, it\u0026rsquo;s time to get your data!\u003c/p\u003e\r\n\r\n\u003ch3\u003eLoading In The Data\u003c/h3\u003e\r\n\r\n\u003cp\u003eThis can be easily done with the Python data manipulation library Pandas. You follow the import convention and import the package under it\u0026rsquo;s alias, \u003ccode class=\"lang-python\"\u003epd\u003c/code\u003e.\u003c/p\u003e\r\n\r\n\u003cp\u003eNext, you make use of the \u003ccode class=\"lang-python\"\u003eread_csv()\u003c/code\u003e function to read in the CSV files in which the data is stored. Additionally, use the \u003ccode class=\"lang-python\"\u003esep\u003c/code\u003e argument to specify that the separator in this case is a semicolon and not a regular comma.\u003c/p\u003e\r\n\r\n\u003cp\u003eTry it out in the DataCamp Light chunk below:\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"300\"\u003eeyJsYW5ndWFnZSI6InB5dGhvbiIsInNhbXBsZSI6IiMgSW1wb3J0IHBhbmRhcyBcbmltcG9ydCBwYW5kYXMgYXMgcGRcblxuIyBSZWFkIGluIHdoaXRlIHdpbmUgZGF0YSBcbndoaXRlID0gX19fX19fX19fX18oXCJodHRwOi8vYXJjaGl2ZS5pY3MudWNpLmVkdS9tbC9tYWNoaW5lLWxlYXJuaW5nLWRhdGFiYXNlcy93aW5lLXF1YWxpdHkvd2luZXF1YWxpdHktd2hpdGUuY3N2XCIsIHNlcD0nOycpXG5cbiMgUmVhZCBpbiByZWQgd2luZSBkYXRhIFxucmVkID0gX19fX19fX19fX18oXCJodHRwOi8vYXJjaGl2ZS5pY3MudWNpLmVkdS9tbC9tYWNoaW5lLWxlYXJuaW5nLWRhdGFiYXNlcy93aW5lLXF1YWxpdHkvd2luZXF1YWxpdHktcmVkLmNzdlwiLCBzZXA9JzsnKSIsInNvbHV0aW9uIjoiIyBJbXBvcnQgcGFuZGFzIFxuaW1wb3J0IHBhbmRhcyBhcyBwZFxuXG4jIFJlYWQgaW4gd2hpdGUgd2luZSBkYXRhIFxud2hpdGUgPSBwZC5yZWFkX2NzdihcImh0dHA6Ly9hcmNoaXZlLmljcy51Y2kuZWR1L21sL21hY2hpbmUtbGVhcm5pbmctZGF0YWJhc2VzL3dpbmUtcXVhbGl0eS93aW5lcXVhbGl0eS13aGl0ZS5jc3ZcIiwgc2VwPSc7JylcblxuIyBSZWFkIGluIHJlZCB3aW5lIGRhdGEgXG5yZWQgPSBwZC5yZWFkX2NzdihcImh0dHA6Ly9hcmNoaXZlLmljcy51Y2kuZWR1L21sL21hY2hpbmUtbGVhcm5pbmctZGF0YWJhc2VzL3dpbmUtcXVhbGl0eS93aW5lcXVhbGl0eS1yZWQuY3N2XCIsIHNlcD0nOycpIiwic2N0IjoiRXgoKS50ZXN0X2ltcG9ydChcInBhbmRhc1wiKVxuRXgoKS50ZXN0X29iamVjdChcIndoaXRlXCIpXG5FeCgpLnRlc3Rfb2JqZWN0KFwicmVkXCIpXG5zdWNjZXNzX21zZz1cIlBlcmZlY3QhIFlvdSdyZSByZWFkeSB0byBnbyFcIiJ9\u003c/div\u003e\r\n\u003cbr\u003e\u003cbr\u003e\r\n\u003cp\u003eAwesome! That wasn\u0026rsquo;t a piece of cake, wasn\u0026rsquo;t it?\u003c/p\u003e\r\n\r\n\u003cp\u003eYou have probably done this a million times by now, but it\u0026rsquo;s always an essential step to get started. Now you\u0026rsquo;re completely set to start exploring, manipulating and modeling your data!\u003c/p\u003e\r\n\r\n\u003ch2\u003eData Exploration\u003c/h2\u003e\r\n\r\n\u003cp\u003eWith the data at hand, it\u0026rsquo;s easy for you to learn more about these wines! One of the first things that you\u0026rsquo;ll probably want to do is to start off with getting a quick view on both of your DataFrames:\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"300\"\u003eeyJsYW5ndWFnZSI6InB5dGhvbiIsInByZV9leGVyY2lzZV9jb2RlIjoiaW1wb3J0IHBhbmRhcyBhcyBwZFxuaW1wb3J0IG51bXB5IGFzIG5wXG5ucC5yYW5kb20uc2VlZCg3KVxud2hpdGUgPSBwZC5yZWFkX2NzdihcImh0dHA6Ly9hcmNoaXZlLmljcy51Y2kuZWR1L21sL21hY2hpbmUtbGVhcm5pbmctZGF0YWJhc2VzL3dpbmUtcXVhbGl0eS93aW5lcXVhbGl0eS13aGl0ZS5jc3ZcIiwgc2VwPSc7JylcbnJlZCA9IHBkLnJlYWRfY3N2KFwiaHR0cDovL2FyY2hpdmUuaWNzLnVjaS5lZHUvbWwvbWFjaGluZS1sZWFybmluZy1kYXRhYmFzZXMvd2luZS1xdWFsaXR5L3dpbmVxdWFsaXR5LXJlZC5jc3ZcIiwgc2VwPSc7JykiLCJzYW1wbGUiOiIjIFByaW50IGluZm8gb24gd2hpdGUgd2luZVxuX19fX18od2hpdGUuX19fXygpKVxuXG4jIFByaW50IGluZm8gb24gcmVkIHdpbmVcbl9fX19fKHJlZC5fX19fKCkpIiwic29sdXRpb24iOiIjIFByaW50IGluZm8gb24gd2hpdGUgd2luZVxucHJpbnQod2hpdGUuaW5mbygpKVxuXG4jIFByaW50IGluZm8gb24gcmVkIHdpbmVcbnByaW50KHJlZC5pbmZvKCkpIiwic2N0IjoiRXgoKS50ZXN0X2Z1bmN0aW9uKFwid2hpdGUuaW5mb1wiKVxuRXgoKS50ZXN0X2Z1bmN0aW9uKFwicHJpbnRcIiwgaW5kZXg9MSlcbkV4KCkudGVzdF9mdW5jdGlvbihcInJlZC5pbmZvXCIpXG5FeCgpLnRlc3RfZnVuY3Rpb24oXCJwcmludFwiLCBpbmRleD0yKVxuc3VjY2Vzc19tc2coXCJXZWxsIGRvbmUhXCIpIn0=\u003c/div\u003e\r\n\u003cbr\u003e\u003cbr\u003e\r\n\u003cp\u003eNow is the time to check whether your import was successful: double check whether the data contains all the variables that the data description file of the UCI Machine Learning Repository promised you. Besides the number of variables, also check the quality of the import: are the data types correct? Did all the rows come through? Are there any null values that you should take into account when you\u0026rsquo;re cleaning up the data?\u003c/p\u003e\r\n\r\n\u003cp\u003eYou might also want to check out your data with more than just \u003ccode class=\"lang-python\"\u003einfo()\u003c/code\u003e:\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"300\"\u003eeyJsYW5ndWFnZSI6InB5dGhvbiIsInByZV9leGVyY2lzZV9jb2RlIjoiaW1wb3J0IHBhbmRhcyBhcyBwZFxuaW1wb3J0IG51bXB5IGFzIG5wXG5ucC5yYW5kb20uc2VlZCg3KVxud2hpdGUgPSBwZC5yZWFkX2NzdihcImh0dHA6Ly9hcmNoaXZlLmljcy51Y2kuZWR1L21sL21hY2hpbmUtbGVhcm5pbmctZGF0YWJhc2VzL3dpbmUtcXVhbGl0eS93aW5lcXVhbGl0eS13aGl0ZS5jc3ZcIiwgc2VwPSc7JylcbnJlZCA9IHBkLnJlYWRfY3N2KFwiaHR0cDovL2FyY2hpdmUuaWNzLnVjaS5lZHUvbWwvbWFjaGluZS1sZWFybmluZy1kYXRhYmFzZXMvd2luZS1xdWFsaXR5L3dpbmVxdWFsaXR5LXJlZC5jc3ZcIiwgc2VwPSc7JykiLCJzYW1wbGUiOiIjIEZpcnN0IHJvd3Mgb2YgYHJlZGAgXG5yZWQuX19fXygpXG5cbiMgTGFzdCByb3dzIG9mIGB3aGl0ZWBcbndoaXRlLl9fX18oKVxuXG4jIFRha2UgYSBzYW1wbGUgb2YgNSByb3dzIG9mIGByZWRgXG5yZWQuX19fX19fKDUpXG5cbiMgRGVzY3JpYmUgYHdoaXRlYFxud2hpdGUuX19fX19fX18oKVxuXG4jIERvdWJsZSBjaGVjayBmb3IgbnVsbCB2YWx1ZXMgaW4gYHJlZGBcbnBkLmlzbnVsbChyZWQpIiwic29sdXRpb24iOiIjIEZpcnN0IHJvd3Mgb2YgYHJlZGAgXG5yZWQuaGVhZCgpXG5cbiMgTGFzdCByb3dzIG9mIGB3aGl0ZWBcbndoaXRlLnRhaWwoKVxuXG4jIFRha2UgYSBzYW1wbGUgb2YgNSByb3dzIG9mIGByZWRgXG5yZWQuc2FtcGxlKDUpXG5cbiMgRGVzY3JpYmUgYHdoaXRlYFxud2hpdGUuZGVzY3JpYmUoKVxuXG4jIERvdWJsZSBjaGVjayBmb3IgbnVsbCB2YWx1ZXMgaW4gYHJlZGBcbnBkLmlzbnVsbChyZWQpIiwic2N0IjoiI2NoZWNrIGhlYWQgXG5FeCgpLnRlc3RfZnVuY3Rpb24oXCJyZWQuaGVhZFwiKVxuIyBjaGVjayB0YWlsXG5FeCgpLnRlc3RfZnVuY3Rpb24oXCJ3aGl0ZS50YWlsXCIpXG4jIGNoZWNrIHNhbXBsZVxuRXgoKS50ZXN0X2Z1bmN0aW9uKFwicmVkLnNhbXBsZVwiKVxuIyBjaGVjayBkZXNjcmliZVxuRXgoKS50ZXN0X2Z1bmN0aW9uKFwid2hpdGUuZGVzY3JpYmVcIilcbiMgY2hlY2sgaXNudWxsIFxudGVzdF9mdW5jdGlvbihcInBhbmRhcy5pc251bGxcIilcbnN1Y2Nlc3NfbXNnKFwiR3JlYXQgam9iIVwiKSJ9\u003c/div\u003e\r\n\u003cbr\u003e\u003cbr\u003e\r\n\u003cp\u003eA brief recap of all these pandas functions: you see that \u003ccode class=\"lang-python\"\u003ehead()\u003c/code\u003e, \u003ccode class=\"lang-python\"\u003etail()\u003c/code\u003e and \u003ccode class=\"lang-python\"\u003esample()\u003c/code\u003e are awesome because they provide you with a quick way of inspecting your data without any hassle.\u003c/p\u003e\r\n\r\n\u003cp\u003eNext, \u003ccode class=\"lang-python\"\u003edescribe()\u003c/code\u003e offers some summary statistics about your data that can help you to assess your data quality. You see that some of the variables really have a lot of difference in their \u003ccode class=\"lang-python\"\u003emin\u003c/code\u003e and \u003ccode class=\"lang-python\"\u003emax\u003c/code\u003e values. This is something that you\u0026rsquo;ll deal with later, but at this point, it\u0026rsquo;s just very important to be aware of this.\u003c/p\u003e\r\n\r\n\u003cp\u003eLastly, you have double checked the presence of null values in \u003ccode class=\"lang-python\"\u003ered\u003c/code\u003e with the help of \u003ccode class=\"lang-python\"\u003eisnull()\u003c/code\u003e. This is a function that always can come in handy when you\u0026rsquo;re still in doubt after having read the results of \u003ccode class=\"lang-python\"\u003einfo()\u003c/code\u003e.\u003c/p\u003e\r\n\r\n\u003cp\u003e\u003cstrong\u003eTip\u003c/strong\u003e: also check out whether the wine data contains null values. You can do this by using the IPython shell of the DataCamp Light chunk which you see right above.\u003c/p\u003e\r\n\r\n\u003cp\u003eNow that you have already inspected your data to see if the import was successful and correct, it\u0026rsquo;s time to dig a little bit deeper.\u003c/p\u003e\r\n\r\n\u003ch3\u003eVisualizing The Data\u003c/h3\u003e\r\n\r\n\u003cp\u003eOne way to do this is by looking at the distribution of some of the dataset\u0026rsquo;s variables and make scatter plots to see possible correlations. Of course, you can take this all to a much higher level if you would use this data for your own project.\u003c/p\u003e\r\n\r\n\u003ch3\u003eAlcohol\u003c/h3\u003e\r\n\r\n\u003cp\u003eOne variable that you could find interesting at first sight is \u003ccode class=\"lang-python\"\u003ealcohol\u003c/code\u003e. It\u0026rsquo;s probably one of the first things that catches your attention when you\u0026rsquo;re inspecting a wine data set. You can visualize the distributions with any data visualization library, but in this case, the tutorial makes use of \u003ccode class=\"lang-python\"\u003ematplotlib\u003c/code\u003e to quickly plot the distributions:\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"500\"\u003eeyJsYW5ndWFnZSI6InB5dGhvbiIsInByZV9leGVyY2lzZV9jb2RlIjoiaW1wb3J0IHBhbmRhcyBhcyBwZFxuaW1wb3J0IG51bXB5IGFzIG5wXG5ucC5yYW5kb20uc2VlZCg3KVxud2hpdGUgPSBwZC5yZWFkX2NzdihcImh0dHA6Ly9hcmNoaXZlLmljcy51Y2kuZWR1L21sL21hY2hpbmUtbGVhcm5pbmctZGF0YWJhc2VzL3dpbmUtcXVhbGl0eS93aW5lcXVhbGl0eS13aGl0ZS5jc3ZcIiwgc2VwPSc7JylcbnJlZCA9IHBkLnJlYWRfY3N2KFwiaHR0cDovL2FyY2hpdmUuaWNzLnVjaS5lZHUvbWwvbWFjaGluZS1sZWFybmluZy1kYXRhYmFzZXMvd2luZS1xdWFsaXR5L3dpbmVxdWFsaXR5LXJlZC5jc3ZcIiwgc2VwPSc7JykiLCJzYW1wbGUiOiJpbXBvcnQgbWF0cGxvdGxpYi5weXBsb3QgYXMgcGx0XG5cbmZpZywgYXggPSBwbHQuc3VicGxvdHMoMSwgMilcblxuYXhbMF0uaGlzdChyZWQuYWxjb2hvbCwgMTAsIGZhY2Vjb2xvcj0ncmVkJywgYWxwaGE9MC41LCBsYWJlbD1cIlJlZCB3aW5lXCIpXG5heFsxXS5oaXN0KHdoaXRlLmFsY29ob2wsIDEwLCBmYWNlY29sb3I9J3doaXRlJywgZWM9XCJibGFja1wiLCBsdz0wLjUsIGFscGhhPTAuNSwgbGFiZWw9XCJXaGl0ZSB3aW5lXCIpXG5cbmZpZy5zdWJwbG90c19hZGp1c3QobGVmdD0wLCByaWdodD0xLCBib3R0b209MCwgdG9wPTAuNSwgaHNwYWNlPTAuMDUsIHdzcGFjZT0xKVxuYXhbMF0uc2V0X3lsaW0oWzAsIDEwMDBdKVxuYXhbMF0uc2V0X3hsYWJlbChcIkFsY29ob2wgaW4gJSBWb2xcIilcbmF4WzBdLnNldF95bGFiZWwoXCJGcmVxdWVuY3lcIilcbmF4WzFdLnNldF94bGFiZWwoXCJBbGNvaG9sIGluICUgVm9sXCIpXG5heFsxXS5zZXRfeWxhYmVsKFwiRnJlcXVlbmN5XCIpXG4jYXhbMF0ubGVnZW5kKGxvYz0nYmVzdCcpXG4jYXhbMV0ubGVnZW5kKGxvYz0nYmVzdCcpXG5maWcuc3VwdGl0bGUoXCJEaXN0cmlidXRpb24gb2YgQWxjb2hvbCBpbiAlIFZvbFwiKVxuXG5wbHQuc2hvdygpIn0=\u003c/div\u003e\r\n\u003cbr\u003e\u003cbr\u003e\r\n\u003cp\u003eAs you can see in the image below, you see that the alcohol levels between the red and white wine are mostly the same: they have around 9% of alcohol. Of course, there are also a considerable amount of observations that have 10% or 11% of alcohol percentage.\u003c/p\u003e\r\n\u003cbr\u003e\r\n\u003cp\u003e\u003cimg alt=\"distribution alcohol for neural network model\" src=\"http://community.datacamp.com.s3.amazonaws.com/community/production/ckeditor_assets/pictures/520/content_alcohol-distribution.png\" /\u003e\u003c/p\u003e\r\n\u003cbr\u003e\r\n\u003cp\u003eNote that you can double check this if you use the \u003ccode class=\"lang-python\"\u003ehistogram()\u003c/code\u003e function from the \u003ccode class=\"lang-python\"\u003enumpy\u003c/code\u003e package to compute the histogram of the \u003ccode class=\"lang-python\"\u003ewhite\u003c/code\u003e and \u003ccode class=\"lang-python\"\u003ered\u003c/code\u003e data, just like this\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"300\"\u003eeyJsYW5ndWFnZSI6InB5dGhvbiIsInByZV9leGVyY2lzZV9jb2RlIjoiaW1wb3J0IHBhbmRhcyBhcyBwZFxuaW1wb3J0IG51bXB5IGFzIG5wXG5ucC5yYW5kb20uc2VlZCg3KVxud2hpdGUgPSBwZC5yZWFkX2NzdihcImh0dHA6Ly9hcmNoaXZlLmljcy51Y2kuZWR1L21sL21hY2hpbmUtbGVhcm5pbmctZGF0YWJhc2VzL3dpbmUtcXVhbGl0eS93aW5lcXVhbGl0eS13aGl0ZS5jc3ZcIiwgc2VwPSc7JylcbnJlZCA9IHBkLnJlYWRfY3N2KFwiaHR0cDovL2FyY2hpdmUuaWNzLnVjaS5lZHUvbWwvbWFjaGluZS1sZWFybmluZy1kYXRhYmFzZXMvd2luZS1xdWFsaXR5L3dpbmVxdWFsaXR5LXJlZC5jc3ZcIiwgc2VwPSc7JykiLCJzYW1wbGUiOiJpbXBvcnQgbnVtcHkgYXMgbnBcbnByaW50KG5wLmhpc3RvZ3JhbShyZWQuYWxjb2hvbCwgYmlucz1bNyw4LDksMTAsMTEsMTIsMTMsMTQsMTVdKSlcbnByaW50KG5wLmhpc3RvZ3JhbSh3aGl0ZS5hbGNvaG9sLCBiaW5zPVs3LDgsOSwxMCwxMSwxMiwxMywxNCwxNV0pKSJ9\u003c/div\u003e\r\n\u003cbr\u003e\u003cbr\u003e\r\n\u003cp\u003eIf you\u0026rsquo;re interested in \u003ccode class=\"lang-python\"\u003ematplotlib\u003c/code\u003e tutorials, make sure to check out DataCamp\u0026rsquo;s \u003ca href=\"https://www.datacamp.com/community/tutorials/matplotlib-tutorial-python\"\u003eMatplotlib\u003c/a\u003e tutorial for beginners and \u003ca href=\"https://www.datacamp.com/community/tutorials/matplotlib-3d-volumetric-data\"\u003eViewing 3D Volumetric Data\u003c/a\u003e tutorial, which shows you how to make use of Matplotlib\u0026rsquo;s event handler API.\u003c/p\u003e\r\n\r\n\u003ch3\u003eSulphates\u003c/h3\u003e\r\n\r\n\u003cp\u003eNext, one thing that interests me is the relation between the sulphates and the quality of the wine. As you have read above, sulphates can cause people to have headaches and I\u0026rsquo;m wondering if this infuences the quality of the wine. What\u0026rsquo;s more, I often hear that women especially don\u0026rsquo;t want to drink wine exactly because it causes headaches. Maybe this affects the ratings for the red wine?\u003c/p\u003e\r\n\r\n\u003cp\u003eLet\u0026rsquo;s take a look.\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"600\"\u003eeyJsYW5ndWFnZSI6InB5dGhvbiIsInByZV9leGVyY2lzZV9jb2RlIjoiaW1wb3J0IHBhbmRhcyBhcyBwZFxuaW1wb3J0IG51bXB5IGFzIG5wXG5ucC5yYW5kb20uc2VlZCg3KVxud2hpdGUgPSBwZC5yZWFkX2NzdihcImh0dHA6Ly9hcmNoaXZlLmljcy51Y2kuZWR1L21sL21hY2hpbmUtbGVhcm5pbmctZGF0YWJhc2VzL3dpbmUtcXVhbGl0eS93aW5lcXVhbGl0eS13aGl0ZS5jc3ZcIiwgc2VwPSc7JylcbnJlZCA9IHBkLnJlYWRfY3N2KFwiaHR0cDovL2FyY2hpdmUuaWNzLnVjaS5lZHUvbWwvbWFjaGluZS1sZWFybmluZy1kYXRhYmFzZXMvd2luZS1xdWFsaXR5L3dpbmVxdWFsaXR5LXJlZC5jc3ZcIiwgc2VwPSc7JykiLCJzYW1wbGUiOiJpbXBvcnQgbWF0cGxvdGxpYi5weXBsb3QgYXMgcGx0XG5cbmZpZywgYXggPSBwbHQuc3VicGxvdHMoMSwgMiwgZmlnc2l6ZT0oOCwgNCkpXG5cbmF4WzBdLnNjYXR0ZXIocmVkWydxdWFsaXR5J10sIHJlZFtcInN1bHBoYXRlc1wiXSwgY29sb3I9XCJyZWRcIilcbmF4WzFdLnNjYXR0ZXIod2hpdGVbJ3F1YWxpdHknXSwgd2hpdGVbJ3N1bHBoYXRlcyddLCBjb2xvcj1cIndoaXRlXCIsIGVkZ2Vjb2xvcnM9XCJibGFja1wiLCBsdz0wLjUpXG5cbmF4WzBdLnNldF90aXRsZShcIlJlZCBXaW5lXCIpXG5heFsxXS5zZXRfdGl0bGUoXCJXaGl0ZSBXaW5lXCIpXG5heFswXS5zZXRfeGxhYmVsKFwiUXVhbGl0eVwiKVxuYXhbMV0uc2V0X3hsYWJlbChcIlF1YWxpdHlcIilcbmF4WzBdLnNldF95bGFiZWwoXCJTdWxwaGF0ZXNcIilcbmF4WzFdLnNldF95bGFiZWwoXCJTdWxwaGF0ZXNcIilcbmF4WzBdLnNldF94bGltKFswLDEwXSlcbmF4WzFdLnNldF94bGltKFswLDEwXSlcbmF4WzBdLnNldF95bGltKFswLDIuNV0pXG5heFsxXS5zZXRfeWxpbShbMCwyLjVdKVxuZmlnLnN1YnBsb3RzX2FkanVzdCh3c3BhY2U9MC41KVxuZmlnLnN1cHRpdGxlKFwiV2luZSBRdWFsaXR5IGJ5IEFtb3VudCBvZiBTdWxwaGF0ZXNcIilcblxucGx0LnNob3coKSJ9\u003c/div\u003e\r\n\u003cbr\u003e\u003cbr\u003e\r\n\u003cp\u003eAs you can see in the image below, the red wine seems to contain more sulphates than the white wine, which has less sulphates above 1 g/\u003cspan class=\"math inline\"\u003e\\(dm^3\\)\u003c/span\u003e. For the white wine, there only seem to be a couple of exceptions that fall just above 1 g/\u003cspan class=\"math inline\"\u003e\\(dm^3\\)\u003c/span\u003e, while this is definitely more for the red wines. This could maybe explain the general saying that red wine causes headaches, but what about the quality?\u003c/p\u003e\r\n\r\n\u003cp\u003eYou can clearly see that there is white wine with a relatively low amount of sulphates that gets a score of 9, but for the rest it\u0026rsquo;s difficult to interpret the data correctly at this point.\u003c/p\u003e\r\n\r\n\u003cp\u003eOf course, you need to take into account that the difference in observations could also affect the graphs and how you might interpret them.\u003c/p\u003e\r\n\u003cbr\u003e\r\n\u003cp\u003e\u003cimg alt=\"deep learning python with keras\" src=\"https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Keras+Python+Tutorial/content_content_content_quality-sulphates.png\" /\u003e\u003c/p\u003e\r\n\u003cbr\u003e\r\n\u003ch3\u003eAcidity\u003c/h3\u003e\r\n\r\n\u003cp\u003eApart from the sulphates, the acidity is one of the major and important wine characteristics that is necessary to achieve quality wines. Great wines often balance out acidity, tannin, alcohol and sweetness. Some more research taught me that in quantities of 0.2 to 0.4 g/L, volatile acidity doesn\u0026rsquo;t affect a wine\u0026rsquo;s quality. At higher levels, however, volatile acidity can give wine a sharp, vinegary tactile sensation. Extreme volatile acidity signifies a seriously flawed wine.\u003c/p\u003e\r\n\r\n\u003cp\u003eLet\u0026rsquo;s put the data to the test and make a scatter plot that plots the alcohol versus the volatile acidity. The data points should be colored according to their rating or \u003ccode class=\"lang-python\"\u003equality\u003c/code\u003e label:\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"900\"\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\u003c/div\u003e\r\n\u003cbr\u003e\u003cbr\u003e\r\n\u003cp\u003eNote that the colors in this image are randomly chosen with the help of the NumPy \u003ccode class=\"lang-python\"\u003erandom\u003c/code\u003e module. You can always change this by passing a list to the \u003ccode class=\"lang-python\"\u003eredcolors\u003c/code\u003e or \u003ccode class=\"lang-python\"\u003ewhitecolors\u003c/code\u003e variables. Make sure that they are the same (except for 1 because the white wine data has one unique \u003ccode class=\"lang-python\"\u003equality\u003c/code\u003e value more than the red wine data), though, otherwise your legends are not going to match!\u003c/p\u003e\r\n\r\n\u003cp\u003eCheck out the full graph here:\u003c/p\u003e\r\n\u003cbr\u003e\r\n\u003cp\u003e\u003cimg alt=\"wine quality binary classification with keras\" src=\"https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Keras+Python+Tutorial/content_content_content_alcohol-va.png\" /\u003e\u003c/p\u003e\r\n\u003cbr\u003e\r\n\u003cp\u003eIn the image above, you see that the levels that you have read about above especially hold for the white wine: most wines with label 8 have volatile acidity levels of 0.5 or below, but whether or not it has an effect on the quality is too difficult to say, since all the data points are very densely packed towards one side of the graph.\u003c/p\u003e\r\n\r\n\u003cp\u003eThis is just a quick data exploration. If you would be interested in elaborating this step in your own projects, consider DataCamp\u0026rsquo;s data exploration posts, such as \u003ca href=\"https://www.datacamp.com/community/tutorials/exploratory-data-analysis-python\"\u003ePython Exploratory Data Analysis\u003c/a\u003e and \u003ca href=\"https://www.datacamp.com/community/tutorials/python-data-profiling\"\u003ePython Data Profiling\u003c/a\u003e tutorials, which will guide you through the basics of EDA.\u003c/p\u003e\r\n\r\n\u003ch3\u003eWrapping Up The Exploratory Data Analysis\u003c/h3\u003e\r\n\r\n\u003cp\u003eThis maybe was a lot to digest, so it\u0026rsquo;s never too late for a small recap of what you have seen during your EDA that could be important for the further course of this tutorial:\u003c/p\u003e\r\n\r\n\u003cul\u003e\r\n\t\u003cli\u003eSome of the variables of your data sets have values that are considerably far apart. You can and will deal with this in the next section of the tutorial.\u003c/li\u003e\r\n\t\u003cli\u003eYou have an ideal scenario: there are no null values in the data sets.\u003c/li\u003e\r\n\t\u003cli\u003eMost wines that were included in the data set have around 9% of alcohol.\u003c/li\u003e\r\n\t\u003cli\u003eRed wine seems to contain more sulphates than the white wine, which has less sulphates above 1 g/\u003cspan class=\"math inline\"\u003e\\(dm^3\\)\u003c/span\u003e.\u003c/li\u003e\r\n\t\u003cli\u003eYou saw that most wines had a volatile acidity of 0.5 and below. At the moment, there is no direct relation to the quality of the wine.\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cbr\u003e\r\n\u003cp\u003eUp until now, you have looked at the white wine and red wine data separately. The two seem to differ somewhat when you look at some of the variables from close up, and in other cases, the two seem to be very similar. Do you think that there could there be a way to classify entries based on their variables into white or red wine?\u003c/p\u003e\r\n\r\n\u003cp\u003eThere is only one way to find out: preprocess the data and model it in such a way so that you can see what happens!\u003c/p\u003e\r\n\r\n\u003ch2 id=\"preprocess\"\u003ePreprocess Data\u003c/h2\u003e\r\n\r\n\u003cp\u003eNow that you have explored your data, it\u0026rsquo;s time to act upon the insights that you have gained! Let\u0026rsquo;s preprocess the data so that you can start building your own neural network!\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"300\"\u003eeyJsYW5ndWFnZSI6InB5dGhvbiIsInByZV9leGVyY2lzZV9jb2RlIjoiaW1wb3J0IHBhbmRhcyBhcyBwZFxuaW1wb3J0IG51bXB5IGFzIG5wXG5ucC5yYW5kb20uc2VlZCg3KVxud2hpdGUgPSBwZC5yZWFkX2NzdihcImh0dHA6Ly9hcmNoaXZlLmljcy51Y2kuZWR1L21sL21hY2hpbmUtbGVhcm5pbmctZGF0YWJhc2VzL3dpbmUtcXVhbGl0eS93aW5lcXVhbGl0eS13aGl0ZS5jc3ZcIiwgc2VwPSc7JylcbnJlZCA9IHBkLnJlYWRfY3N2KFwiaHR0cDovL2FyY2hpdmUuaWNzLnVjaS5lZHUvbWwvbWFjaGluZS1sZWFybmluZy1kYXRhYmFzZXMvd2luZS1xdWFsaXR5L3dpbmVxdWFsaXR5LXJlZC5jc3ZcIiwgc2VwPSc7JykiLCJzYW1wbGUiOiIjIEFkZCBgdHlwZWAgY29sdW1uIHRvIGByZWRgIHdpdGggdmFsdWUgMVxuX19fWyd0eXBlJ10gPSAxXG5cbiMgQWRkIGB0eXBlYCBjb2x1bW4gdG8gYHdoaXRlYCB3aXRoIHZhbHVlIDBcbl9fX19fWyd0eXBlJ10gPSAwXG5cbiMgQXBwZW5kIGB3aGl0ZWAgdG8gYHJlZGBcbndpbmVzID0gcmVkLl9fX19fXyh3aGl0ZSwgaWdub3JlX2luZGV4PVRydWUpIiwic29sdXRpb24iOiIjIEFkZCBgdHlwZWAgY29sdW1uIHRvIGByZWRgIHdpdGggdmFsdWUgMVxucmVkWyd0eXBlJ10gPSAxXG5cbiMgQWRkIGB0eXBlYCBjb2x1bW4gdG8gYHdoaXRlYCB3aXRoIHZhbHVlIDBcbndoaXRlWyd0eXBlJ10gPSAwXG5cbiMgQXBwZW5kIGB3aGl0ZWAgdG8gYHJlZGBcbndpbmVzID0gcmVkLmFwcGVuZCh3aGl0ZSwgaWdub3JlX2luZGV4PVRydWUpIiwic2N0IjoiRXgoKS50ZXN0X29iamVjdChcInJlZFwiKVxuRXgoKS50ZXN0X29iamVjdChcIndoaXRlXCIpXG5FeCgpLnRlc3Rfb2JqZWN0KFwid2luZXNcIikifQ==\u003c/div\u003e\r\n\u003cbr\u003e\u003cbr\u003e\r\n\u003cp\u003eYou set \u003ccode class=\"lang-python\"\u003eignore_index\u003c/code\u003e to \u003ccode class=\"lang-python\"\u003eTrue\u003c/code\u003e in this case because you don\u0026rsquo;t want to keep the index labels of \u003ccode class=\"lang-python\"\u003ewhite\u003c/code\u003e when you\u0026rsquo;re appending the data to \u003ccode class=\"lang-python\"\u003ered\u003c/code\u003e: you want the labels to continue from where they left off in \u003ccode class=\"lang-python\"\u003ered\u003c/code\u003e, not duplicate index labels from joining both data sets together.\u003c/p\u003e\r\n\r\n\u003cdiv class=\"section level3\" id=\"intermezzo-correlation-matrix\"\u003e\r\n\u003ch3\u003eIntermezzo: Correlation Matrix\u003c/h3\u003e\r\n\r\n\u003cp\u003eNow that you have the full data set, it\u0026rsquo;s a good idea to also do a quick data exploration; You already know some stuff from looking at the two data sets separately, and now it\u0026rsquo;s time to gather some more solid insights, perhaps.\u003c/p\u003e\r\n\r\n\u003cp\u003eSince it can be somewhat difficult to interpret graphs, it\u0026rsquo;s also a good idea to plot a correlation matrix. This will give insights more quickly about which variables correlate:\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"300\"\u003eeyJsYW5ndWFnZSI6InB5dGhvbiIsInByZV9leGVyY2lzZV9jb2RlIjoiaW1wb3J0IHBhbmRhcyBhcyBwZFxuaW1wb3J0IG51bXB5IGFzIG5wXG5ucC5yYW5kb20uc2VlZCg3KVxud2hpdGUgPSBwZC5yZWFkX2NzdihcImh0dHA6Ly9hcmNoaXZlLmljcy51Y2kuZWR1L21sL21hY2hpbmUtbGVhcm5pbmctZGF0YWJhc2VzL3dpbmUtcXVhbGl0eS93aW5lcXVhbGl0eS13aGl0ZS5jc3ZcIiwgc2VwPSc7JylcbnJlZCA9IHBkLnJlYWRfY3N2KFwiaHR0cDovL2FyY2hpdmUuaWNzLnVjaS5lZHUvbWwvbWFjaGluZS1sZWFybmluZy1kYXRhYmFzZXMvd2luZS1xdWFsaXR5L3dpbmVxdWFsaXR5LXJlZC5jc3ZcIiwgc2VwPSc7JylcbndpbmVzID0gcmVkLmFwcGVuZCh3aGl0ZSwgaWdub3JlX2luZGV4PVRydWUpIiwic2FtcGxlIjoiaW1wb3J0IHNlYWJvcm4gYXMgc25zXG5jb3JyID0gd2luZXMuY29ycigpXG5zbnMuaGVhdG1hcChjb3JyLCBcbiAgICAgICAgICAgIHh0aWNrbGFiZWxzPWNvcnIuY29sdW1ucy52YWx1ZXMsXG4gICAgICAgICAgICB5dGlja2xhYmVscz1jb3JyLmNvbHVtbnMudmFsdWVzKVxuc25zLnBsdC5zaG93KCkifQ==\u003c/div\u003e\r\n\u003cbr\u003e\u003cbr\u003e\r\n\u003cp\u003eAs you would expect, there are some variables that correlate, such as \u003ccode class=\"lang-python\"\u003edensity\u003c/code\u003e and \u003ccode class=\"lang-python\"\u003eresidual sugar\u003c/code\u003e. Also \u003ccode class=\"lang-python\"\u003evolatile acidity\u003c/code\u003e and \u003ccode class=\"lang-python\"\u003etype\u003c/code\u003e are more closely connected than you originally could have guessed by looking at the two data sets separately, and it was kind of to be expected that \u003ccode class=\"lang-python\"\u003efree sulfur dioxide\u003c/code\u003e and \u003ccode class=\"lang-python\"\u003etotal sulfur dioxide\u003c/code\u003e were going to correlate.\u003c/p\u003e\r\n\u003cbr\u003e\r\n\u003cp\u003e\u003cimg alt=\"correlation wine quality data\" src=\"http://community.datacamp.com.s3.amazonaws.com/community/production/ckeditor_assets/pictures/525/content_content_correlation-matrix.png\" /\u003e\u003c/p\u003e\r\n\u003cbr\u003e\r\n\u003cp\u003eVery interesting!\u003c/p\u003e\r\n\r\n\u003ch3\u003eTrain and Test Sets\u003c/h3\u003e\r\n\r\n\u003cp\u003eImbalanced data typically refers to a problem with classification problems where the classes are not represented equally.Most classification data sets do not have exactly equal number of instances in each class, but a small difference often does not matter. You thus need to make sure that all two classes of wine are present in the training model. What\u0026rsquo;s more, the amount of instances of all two wine types needs to be more or less equal so that you do not favour one or the other class in your predictions.\u003c/p\u003e\r\n\r\n\u003cp\u003eIn this case, there seems to be an imbalance, but you will go with this for the moment. Afterwards, you can evaluate the model and if it underperforms, you can resort to undersampling or oversampling to cover up the difference in observations.\u003c/p\u003e\r\n\r\n\u003cp\u003eFor now, import the \u003ccode class=\"lang-python\"\u003etrain_test_split\u003c/code\u003e from \u003ccode class=\"lang-python\"\u003esklearn.model_selection\u003c/code\u003e and assign the data and the target labels to the variables \u003ccode class=\"lang-python\"\u003eX\u003c/code\u003e and \u003ccode class=\"lang-python\"\u003ey\u003c/code\u003e. You\u0026rsquo;ll see that you need to flatten the array of target labels in order to be totally ready to use the \u003ccode class=\"lang-python\"\u003eX\u003c/code\u003e and \u003ccode class=\"lang-python\"\u003ey\u003c/code\u003e variables as input for the \u003ccode class=\"lang-python\"\u003etrain_test_split()\u003c/code\u003e function. Off to work, get started in the DataCamp Light chunk below!\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"300\"\u003eeyJsYW5ndWFnZSI6InB5dGhvbiIsInByZV9leGVyY2lzZV9jb2RlIjoiaW1wb3J0IHBhbmRhcyBhcyBwZFxuaW1wb3J0IG51bXB5IGFzIG5wXG5ucC5yYW5kb20uc2VlZCg3KVxud2hpdGUgPSBwZC5yZWFkX2NzdihcImh0dHA6Ly9hcmNoaXZlLmljcy51Y2kuZWR1L21sL21hY2hpbmUtbGVhcm5pbmctZGF0YWJhc2VzL3dpbmUtcXVhbGl0eS93aW5lcXVhbGl0eS13aGl0ZS5jc3ZcIiwgc2VwPSc7JylcbnJlZCA9IHBkLnJlYWRfY3N2KFwiaHR0cDovL2FyY2hpdmUuaWNzLnVjaS5lZHUvbWwvbWFjaGluZS1sZWFybmluZy1kYXRhYmFzZXMvd2luZS1xdWFsaXR5L3dpbmVxdWFsaXR5LXJlZC5jc3ZcIiwgc2VwPSc7JylcbnJlZFsndHlwZSddID0gMVxud2hpdGVbJ3R5cGUnXSA9IDBcbndpbmVzID0gcmVkLmFwcGVuZCh3aGl0ZSwgaWdub3JlX2luZGV4PVRydWUpIiwic2FtcGxlIjoiIyBJbXBvcnQgYHRyYWluX3Rlc3Rfc3BsaXRgIGZyb20gYHNrbGVhcm4ubW9kZWxfc2VsZWN0aW9uYFxuZnJvbSBza2xlYXJuLm1vZGVsX3NlbGVjdGlvbiBpbXBvcnQgdHJhaW5fdGVzdF9zcGxpdFxuXG4jIFNwZWNpZnkgdGhlIGRhdGEgXG5YPXdpbmVzLml4WzosMDoxMV1cblxuIyBTcGVjaWZ5IHRoZSB0YXJnZXQgbGFiZWxzIGFuZCBmbGF0dGVuIHRoZSBhcnJheSBcbnk9bnAucmF2ZWwod2luZXMudHlwZSlcblxuIyBTcGxpdCB0aGUgZGF0YSB1cCBpbiB0cmFpbiBhbmQgdGVzdCBzZXRzXG5YX3RyYWluLCBYX3Rlc3QsIHlfdHJhaW4sIHlfdGVzdCA9IHRyYWluX3Rlc3Rfc3BsaXQoWCwgeSwgdGVzdF9zaXplPTAuMzMsIHJhbmRvbV9zdGF0ZT00MikiLCJzb2x1dGlvbiI6IiMgSW1wb3J0IGB0cmFpbl90ZXN0X3NwbGl0YCBmcm9tIGBza2xlYXJuLm1vZGVsX3NlbGVjdGlvbmBcbmZyb20gc2tsZWFybi5tb2RlbF9zZWxlY3Rpb24gaW1wb3J0IHRyYWluX3Rlc3Rfc3BsaXRcblxuIyBTcGVjaWZ5IHRoZSBkYXRhIFxuWD13aW5lcy5peFs6LDA6MTFdXG5cbiMgU3BlY2lmeSB0aGUgdGFyZ2V0IGxhYmVscyBhbmQgZmxhdHRlbiB0aGUgYXJyYXlcbnk9IG5wLnJhdmVsKHdpbmVzLnR5cGUpXG5cbiMgU3BsaXQgdGhlIGRhdGEgdXAgaW4gdHJhaW4gYW5kIHRlc3Qgc2V0c1xuWF90cmFpbiwgWF90ZXN0LCB5X3RyYWluLCB5X3Rlc3QgPSB0cmFpbl90ZXN0X3NwbGl0KFgsIHksIHRlc3Rfc2l6ZT0wLjMzLCByYW5kb21fc3RhdGU9NDIpIiwic2N0IjoiRXgoKS50ZXN0X2ltcG9ydChcInNrbGVhcm4ubW9kZWxfc2VsZWN0aW9uLnRyYWluX3Rlc3Rfc3BsaXRcIilcbkV4KCkudGVzdF9vYmplY3QoXCJYXCIpXG5FeCgpLnRlc3Rfb2JqZWN0KFwieVwiKVxuRXgoKS50ZXN0X29iamVjdChcIlhfdHJhaW5cIilcbkV4KCkudGVzdF9vYmplY3QoXCJYX3Rlc3RcIilcbkV4KCkudGVzdF9vYmplY3QoXCJ5X3RyYWluXCIpXG5FeCgpLnRlc3Rfb2JqZWN0KFwieV90ZXN0XCIpIn0=\u003c/div\u003e\r\n\u003cbr\u003e\u003cbr\u003e\r\n\u003cp\u003eYou\u0026rsquo;re already well on your way to build your first neural network, but there is still one thing that you need to take care of! Do you still know what you discovered when you were looking at the summaries of the \u003ccode class=\"lang-python\"\u003ewhite\u003c/code\u003e and \u003ccode class=\"lang-python\"\u003ered\u003c/code\u003e data sets?\u003c/p\u003e\r\n\r\n\u003cp\u003eIndeed, some of the values were kind of far apart. It might make sense to do some standardization here.\u003c/p\u003e\r\n\r\n\u003ch3\u003eStandardize The Data\u003c/h3\u003e\r\n\r\n\u003cp\u003eStandardization is a way to deal with these values that lie so far apart. The scikit-learn package offers you a great and quick way of getting your data standardized: import the \u003ccode class=\"lang-python\"\u003eStandardScaler\u003c/code\u003e module from \u003ccode class=\"lang-python\"\u003esklearn.preprocessing\u003c/code\u003e and you\u0026rsquo;re ready to scale your train and test data!\u003c/p\u003e\r\n\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# Import `StandardScaler` from `sklearn.preprocessing`\r\nfrom sklearn.preprocessing import StandardScaler\r\n\r\n# Define the scaler \r\nscaler = StandardScaler().fit(X_train)\r\n\r\n# Scale the train set\r\nX_train = scaler.transform(X_train)\r\n\r\n# Scale the test set\r\nX_test = scaler.transform(X_test)\u003c/code\u003e\u003c/pre\u003e\r\n\r\n\u003cp\u003eNow that you\u0026rsquo;re data is preprocessed, you can move on to the real work: building your own neural network to classify wines.\u003c/p\u003e\r\n\r\n\u003ch2 id=\"modeling\"\u003eModel Data\u003c/h2\u003e\r\n\r\n\u003cp\u003eBefore you start modelling, go back to your original question: can you predict whether a wine is red or white by looking at its chemical properties, such as volatile acidity or sulphates?\u003c/p\u003e\r\n\r\n\u003cp\u003eSince you only have two classes, namely white and red, you\u0026rsquo;re going to do a binary classification. As you can imagine, \u0026ldquo;binary\u0026rdquo; means 0 or 1, yes or no. Since neural networks can only work with numerical data, you have already encoded red as 1 and white as 0.\u003c/p\u003e\r\n\r\n\u003cp\u003eA type of network that performs well on such a problem is a multi-layer perceptron. As you have read in the beginning of this tutorial, this type of neural network is often fully connected. That means that you\u0026rsquo;re looking to build a fairly simple stack of fully-connected layers to solve this problem. As for the activation function that you will use, it\u0026rsquo;s best to use one of the most common ones here for the purpose of getting familiar with Keras and neural networks, which is the relu activation function.\u003c/p\u003e\r\n\r\n\u003cp\u003eNow how do you start building your multi-layer perceptron? A quick way to get started is to use the Keras Sequential model: it\u0026rsquo;s a linear stack of layers. You can easily create the model by passing a list of layer instances to the constructor, which you set up by running \u003ccode class=\"lang-python\"\u003emodel = Sequential()\u003c/code\u003e.\u003c/p\u003e\r\n\r\n\u003cp\u003eNext, it\u0026rsquo;s best to think back about the structure of the multi-layer perceptron as you might have read about it in the beginning of this tutorial: you have an input layer, some hidden layers and an output layer. When you\u0026rsquo;re making your model, it\u0026rsquo;s therefore important to take into account that your first layer needs to make the input shape clear. The model needs to know what input shape to expect and that\u0026rsquo;s why you\u0026rsquo;ll always find the \u003ccode class=\"lang-python\"\u003einput_shape\u003c/code\u003e, \u003ccode class=\"lang-python\"\u003einput_dim\u003c/code\u003e, \u003ccode class=\"lang-python\"\u003einput_length\u003c/code\u003e, or \u003ccode class=\"lang-python\"\u003ebatch_size\u003c/code\u003e arguments in the documentation of the layers and in practical examples of those layers.\u003c/p\u003e\r\n\r\n\u003cp\u003eIn this case, you will have to use a \u003ccode class=\"lang-python\"\u003eDense\u003c/code\u003e layer, which is a fully connected layer. Dense layers implement the following operation: \u003ccode class=\"lang-python\"\u003eoutput = activation(dot(input, kernel) + bias)\u003c/code\u003e. Note that without the activation function, your Dense layer would consist only of two linear operations: a dot product and an addition.\u003c/p\u003e\r\n\r\n\u003cp\u003eIn the first layer, the \u003ccode class=\"lang-python\"\u003eactivation\u003c/code\u003e argument takes the value \u003ccode class=\"lang-python\"\u003erelu\u003c/code\u003e. Next, you also see that the \u003ccode class=\"lang-python\"\u003einput_shape\u003c/code\u003e has been defined. This is the \u003ccode class=\"lang-python\"\u003einput\u003c/code\u003e of the operation that you have just seen: the model takes as input arrays of shape \u003ccode class=\"lang-python\"\u003e(12,)\u003c/code\u003e, or \u003ccode class=\"lang-python\"\u003e(*, 12)\u003c/code\u003e. Lastly, you see that the first layer has \u003ccode class=\"lang-python\"\u003e12\u003c/code\u003e as a first value for the \u003ccode class=\"lang-python\"\u003eunits\u003c/code\u003e argument of \u003ccode class=\"lang-python\"\u003eDense()\u003c/code\u003e, which is the dimensionality of the output space and which are actually 12 hidden units. This means that the model will output arrays of shape \u003ccode class=\"lang-python\"\u003e(*, 12)\u003c/code\u003e: this is is the dimensionality of the output space. Don\u0026rsquo;t worry if you don\u0026rsquo;t get this entirely just now, you\u0026rsquo;ll read more about it later on!\u003c/p\u003e\r\n\r\n\u003cp\u003eThe \u003ccode class=\"lang-python\"\u003eunits\u003c/code\u003e actually represents the \u003ccode class=\"lang-python\"\u003ekernel\u003c/code\u003e of the above formula or the weights matrix, composed of all weights given to all input nodes, created by the layer. Note that you don\u0026rsquo;t include any bias in the example below, as you haven\u0026rsquo;t included the \u003ccode class=\"lang-python\"\u003euse_bias\u003c/code\u003e argument and set it to \u003ccode class=\"lang-python\"\u003eTRUE\u003c/code\u003e, which is also a possibility.\u003c/p\u003e\r\n\r\n\u003cp\u003eThe intermediate layer also uses the \u003ccode class=\"lang-python\"\u003erelu\u003c/code\u003e activation function. The output of this layer will be arrays of shape \u003ccode class=\"lang-python\"\u003e(*,8)\u003c/code\u003e.\u003c/p\u003e\r\n\r\n\u003cp\u003eYou are ending the network with a \u003ccode class=\"lang-python\"\u003eDense\u003c/code\u003e layer of size 1. The final layer will also use a sigmoid activation function so that your output is actually a probability; This means that this will result in a score between 0 and 1, indicating how likely the sample is to have the target \u0026ldquo;1\u0026rdquo;, or how likely the wine is to be red.\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"500\"\u003eeyJsYW5ndWFnZSI6InB5dGhvbiIsInByZV9leGVyY2lzZV9jb2RlIjoiaW1wb3J0IG51bXB5IGFzIG5wXG5ucC5yYW5kb20uc2VlZCg3KSIsInNhbXBsZSI6IiMgSW1wb3J0IGBTZXF1ZW50aWFsYCBmcm9tIGBrZXJhcy5tb2RlbHNgXG5mcm9tIGtlcmFzLm1vZGVscyBpbXBvcnQgU2VxdWVudGlhbFxuXG4jIEltcG9ydCBgRGVuc2VgIGZyb20gYGtlcmFzLmxheWVyc2BcbmZyb20ga2VyYXMubGF5ZXJzIGltcG9ydCBEZW5zZVxuXG4jIEluaXRpYWxpemUgdGhlIGNvbnN0cnVjdG9yXG5tb2RlbCA9IFNlcXVlbnRpYWwoKVxuXG4jIEFkZCBhbiBpbnB1dCBsYXllciBcbm1vZGVsLmFkZChEZW5zZSgxMiwgYWN0aXZhdGlvbj0ncmVsdScsIGlucHV0X3NoYXBlPSgxMSwpKSlcblxuIyBBZGQgb25lIGhpZGRlbiBsYXllciBcbm1vZGVsLmFkZChEZW5zZSg4LCBhY3RpdmF0aW9uPSdyZWx1JykpXG5cbiMgQWRkIGFuIG91dHB1dCBsYXllciBcbm1vZGVsLmFkZChEZW5zZSgxLCBhY3RpdmF0aW9uPSdzaWdtb2lkJykpIn0=\u003c/div\u003e\r\n\u003cbr\u003e\u003cbr\u003e\r\n\u003cp\u003eAll in all, you see that there are two key architecture decisions that you need to make to make your model: how many layers you\u0026rsquo;re going to use and how many \u0026ldquo;hidden units\u0026rdquo; you will chose for each layer.\u003c/p\u003e\r\n\r\n\u003cp\u003eIn this case, you picked \u003ccode class=\"lang-python\"\u003e12\u003c/code\u003e hidden units for the first layer of your model: as you read above, this is is the dimensionality of the output space. In other words, you\u0026rsquo;re setting the amount of freedom that you\u0026rsquo;re allowing the network to have when it\u0026rsquo;s learning representations. If you would allow more hidden units, your network will be able to learn more complex representations but it will also be a more expensive operations that can be prone to overfitting.\u003c/p\u003e\r\n\r\n\u003cp\u003eRemember that overfitting occurs when the model is too complex: it will describe random error or noise and not the underlying relationship that it needs to describe. In other words, the training data is modelled too well!\u003c/p\u003e\r\n\r\n\u003cp\u003eNote that when you don\u0026rsquo;t have that much training data available, you should prefer to use a a small network with very few hidden layers (typically only one, like in the example above).\u003c/p\u003e\r\n\r\n\u003cp\u003eIf you want to get some information on the model that you have just created, you can use the attributed \u003ccode class=\"lang-python\"\u003eoutput_shape\u003c/code\u003e or the \u003ccode class=\"lang-python\"\u003esummary()\u003c/code\u003e function, among others. Some of the most basic ones are listed below.\u003c/p\u003e\r\n\r\n\u003cp\u003eTry running them to see what results you exactly get back and what they tell you about the model that you have just created:\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"300\"\u003eeyJsYW5ndWFnZSI6InB5dGhvbiIsInByZV9leGVyY2lzZV9jb2RlIjoiaW1wb3J0IG51bXB5IGFzIG5wXG5ucC5yYW5kb20uc2VlZCg3KVxuZnJvbSBrZXJhcy5tb2RlbHMgaW1wb3J0IFNlcXVlbnRpYWxcbmZyb20ga2VyYXMubGF5ZXJzIGltcG9ydCBEZW5zZVxubW9kZWwgPSBTZXF1ZW50aWFsKClcbm1vZGVsLmFkZChEZW5zZSgxMixhY3RpdmF0aW9uPSdyZWx1JywgaW5wdXRfc2hhcGU9KDExLCkpKVxubW9kZWwuYWRkKERlbnNlKDgsYWN0aXZhdGlvbj0ncmVsdScpKVxubW9kZWwuYWRkKERlbnNlKDEsYWN0aXZhdGlvbj0nc2lnbW9pZCcpKSIsInNhbXBsZSI6IiMgTW9kZWwgb3V0cHV0IHNoYXBlXG5tb2RlbC5fX19fX19fX19fX1xuXG4jIE1vZGVsIHN1bW1hcnlcbm1vZGVsLl9fX19fX19fX19cblxuIyBNb2RlbCBjb25maWdcbm1vZGVsLmdldF9jb25maWcoKVxuXG4jIExpc3QgYWxsIHdlaWdodCB0ZW5zb3JzIFxubW9kZWwuZ2V0X3dlaWdodHMoKSIsInNvbHV0aW9uIjoiIyBNb2RlbCBvdXRwdXQgc2hhcGVcbm1vZGVsLm91dHB1dF9zaGFwZVxuXG4jIE1vZGVsIHN1bW1hcnlcbm1vZGVsLnN1bW1hcnkoKVxuXG4jIE1vZGVsIGNvbmZpZ1xubW9kZWwuZ2V0X2NvbmZpZygpXG5cbiMgTGlzdCBhbGwgd2VpZ2h0IHRlbnNvcnMgXG5tb2RlbC5nZXRfd2VpZ2h0cygpIiwic2N0IjoiRXgoKS50ZXN0X29iamVjdF9hY2Nlc3NlZChcIm1vZGVsXCIpXG5FeCgpLnRlc3Rfb2JqZWN0X2FjY2Vzc2VkKFwibW9kZWxcIilcbkV4KCkudGVzdF9mdW5jdGlvbihcIm1vZGVsLmdldF9jb25maWdcIilcbkV4KCkudGVzdF9mdW5jdGlvbihcIm1vZGVsLmdldF93ZWlnaHRzXCIpXG5zdWNjZXNzX21zZyhcIkF3ZXNvbWUgam9iIVwiKSJ9\u003c/div\u003e\r\n\u003c/div\u003e\r\n\u003cbr\u003e\u003cbr\u003e\r\n\u003ch2 id=\"compfit\"\u003eCompile and Fit\u003c/h2\u003e\r\n\r\n\u003cp\u003eNext, it\u0026rsquo;s time to compile your model and fit the model to the data: once again, make use of \u003ccode class=\"lang-python\"\u003ecompile()\u003c/code\u003e and \u003ccode class=\"lang-python\"\u003efit()\u003c/code\u003e to get this done.\u003c/p\u003e\r\n\r\n\u003cpre\u003e\r\n\u003ccode class=\"lang-python\"\u003emodel.compile(loss='binary_crossentropy',\r\n              optimizer='adam',\r\n              metrics=['accuracy'])\r\n                   \r\nmodel.fit(X_train, y_train,epochs=20, batch_size=1, verbose=1)\u003c/code\u003e\u003c/pre\u003e\r\n\r\n\u003cp\u003eIn compiling, you configure the model with the \u003ccode class=\"lang-python\"\u003eadam\u003c/code\u003e optimizer and the \u003ccode class=\"lang-python\"\u003ebinary_crossentropy\u003c/code\u003e loss function. Additionally, you can also monitor the accuracy during the training by passing \u003ccode class=\"lang-python\"\u003e[\u0026#39;accuracy\u0026#39;]\u003c/code\u003e to the \u003ccode class=\"lang-python\"\u003emetrics\u003c/code\u003e argument.\u003c/p\u003e\r\n\r\n\u003cp\u003eThe \u003ccode class=\"lang-python\"\u003eoptimizer\u003c/code\u003e and the \u003ccode class=\"lang-python\"\u003eloss\u003c/code\u003e are two arguments that are required if you want to compile the model. Some of the most popular optimization algorithms used are the Stochastic Gradient Descent (SGD), ADAM and RMSprop. Depending on whichever algorithm you choose, you\u0026rsquo;ll need to tune certain parameters, such as learning rate or momentum. The choice for a loss function depends on the task that you have at hand: for example, for a regression problem, you\u0026rsquo;ll usually use the Mean Squared Error (MSE). As you see in this example, you used \u003ccode class=\"lang-python\"\u003ebinary_crossentropy\u003c/code\u003e for the binary classification problem of determining whether a wine is red or white. Lastly, with multi-class classification, you\u0026rsquo;ll make use of \u003ccode class=\"lang-python\"\u003ecategorical_crossentropy\u003c/code\u003e.\u003c/p\u003e\r\n\r\n\u003cp\u003eAfter, you can train the model for 20 epochs or iterations over all the samples in \u003ccode class=\"lang-python\"\u003eX_train\u003c/code\u003e and \u003ccode class=\"lang-python\"\u003ey_train\u003c/code\u003e, in batches of 1 sample. You can also specify the \u003ccode class=\"lang-python\"\u003everbose\u003c/code\u003e argument. By setting it to \u003ccode class=\"lang-python\"\u003e1\u003c/code\u003e, you indicate that you want to see progress bar logging.\u003c/p\u003e\r\n\r\n\u003cp\u003eIn other words, you have to train the model for a specified number of epochs or exposures to the training dataset. An epoch is a single pass through the entire training set, followed by testing of the verification set. The batch size that you specify in the code above defines the number of samples that going to be propagated through the network. Also, by doing this, you optimize the efficiency because you make sure that you don\u0026rsquo;t load too many input patterns into memory at the same time.\u003c/p\u003e\r\n\r\n\u003ch2 id=\"predict\"\u003ePredict Values\u003c/h2\u003e\r\n\r\n\u003cp\u003eLet\u0026rsquo;s put your model to use! You can make predictions for the labels of the test set with it. Just use \u003ccode class=\"lang-python\"\u003epredict()\u003c/code\u003e and pass the test set to it to predict the labels for the data. In this case, the result is stored in \u003ccode class=\"lang-python\"\u003ey_pred\u003c/code\u003e:\u003c/p\u003e\r\n\r\n\u003cpre\u003e\r\n\u003ccode class=\"lang-python\"\u003ey_pred = model.predict(X_test)\u003c/code\u003e\u003c/pre\u003e\r\n\r\n\u003cp\u003eBefore you go and evaluate your model, you can already get a quick idea of the accuracy by checking how \u003ccode class=\"lang-python\"\u003ey_pred\u003c/code\u003e and \u003ccode class=\"lang-python\"\u003ey_test\u003c/code\u003e compare:\u003c/p\u003e\r\n\r\n\u003cpre\u003e\r\n\u003ccode class=\"lang-python\"\u003ey_pred[:5]\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\r\n\u003ccode class=\"lang-python\"\u003earray([[0],\r\n       [1],\r\n       [0],\r\n       [0],\r\n       [0]], dtype=int32)\u003c/code\u003e\u003c/pre\u003e\r\n\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003ey_test[:5]\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003earray([0, 1, 0, 0, 0])\u003c/code\u003e\u003c/pre\u003e\r\n\r\n\u003cp\u003eYou see that these values seem to add up, but what is all of this without some hard numbers?\u003c/p\u003e\r\n\r\n\u003ch2 id=\"validate\"\u003eEvaluate Model\u003c/h2\u003e\r\n\r\n\u003cp\u003eNow that you have built your model and used it to make predictions on data that your model hadn\u0026rsquo;t seen yet, it\u0026rsquo;s time to evaluate it\u0026rsquo;s performance. You can visually compare the predictions with the actual test labels (\u003ccode class=\"lang-python\"\u003ey_test\u003c/code\u003e), or you can use all types of metrics to determine the actual performance. In this case, you\u0026rsquo;ll use \u003ccode class=\"lang-python\"\u003eevaluate()\u003c/code\u003e to do this. Pass in the test data and test labels and if you want, put the \u003ccode class=\"lang-python\"\u003everbose\u003c/code\u003e argument to 1. You\u0026rsquo;ll see more logs appearing when you do this.\u003c/p\u003e\r\n\r\n\u003cpre\u003e\r\n\u003ccode class=\"lang-python\"\u003escore = model.evaluate(X_test, y_test,verbose=1)\r\n\r\nprint(score)\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e[0.025217213829228164, 0.99487179487179489]\u003c/code\u003e\u003c/pre\u003e\r\n\r\n\u003cp\u003eThe score is a list that holds the combination of the loss and the accuracy. In this case, you see that both seem very great, but in this case it\u0026rsquo;s good to remember that your data was somewhat imbalanced: you had more white wine than red wine observations. The accuracy might just be reflecting the class distribution of your data because it\u0026rsquo;ll just predict \u003ccode class=\"lang-python\"\u003ewhite\u003c/code\u003e because those observations are abundantly present!\u003c/p\u003e\r\n\r\n\u003cp\u003eBefore you start re-arranging the data and putting it together in a different way, it\u0026rsquo;s always a good idea to try out different evaluation metrics. For this, you can rely on scikit-learn (which you import as \u003ccode class=\"lang-python\"\u003esklearn\u003c/code\u003e, just like before when you were making the train and test sets) for this.\u003c/p\u003e\r\n\r\n\u003cp\u003eIn this case, you will test out some basic classification evaluation techniques, such as:\u003c/p\u003e\r\n\r\n\u003cul\u003e\r\n\t\u003cli\u003eThe confusion matrix, which is a breakdown of predictions into a table showing correct predictions and the types of incorrect predictions made. Ideally, you will only see numbers in the diagonal, which means that all your predictions were correct!\u003c/li\u003e\r\n\t\u003cli\u003ePrecision is a measure of a classifier\u0026rsquo;s exactness. The higher the precision, the more accurate the classifier.\u003c/li\u003e\r\n\t\u003cli\u003eRecall is a measure of a classifier\u0026rsquo;s completeness. The higher the recall, the more cases the classifier covers.\u003c/li\u003e\r\n\t\u003cli\u003eThe F1 Score or F-score is a weighted average of precision and recall.\u003c/li\u003e\r\n\t\u003cli\u003eThe Kappa or Cohen\u0026rsquo;s kappa is the classification accuracy normalized by the imbalance of the classes in the data.\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cbr\u003e\r\n\u003cpre\u003e\r\n\u003ccode class=\"lang-python\"\u003e# Import the modules from `sklearn.metrics`\r\nfrom sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, cohen_kappa_score\r\n\r\n# Confusion matrix\r\nconfusion_matrix(y_test, y_pred)\u003c/code\u003e\u003c/pre\u003e\r\n\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003earray([[1585,    3],\r\n       [   8,  549]])\u003c/code\u003e\u003c/pre\u003e\r\n\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# Precision \r\nprecision_score(y_test, y_pred)\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e0.994565217391\u003c/code\u003e\u003c/pre\u003e\r\n\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# Recall\r\nrecall_score(y_test, y_pred)\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e0.98563734290843807\u003c/code\u003e\u003c/pre\u003e\r\n\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# F1 score\r\nf1_score(y_test,y_pred)\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e0.99008115419296661\u003c/code\u003e\u003c/pre\u003e\r\n\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# Cohen's kappa\r\ncohen_kappa_score(y_test, y_pred)\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e0.98662321692498967\u003c/code\u003e\u003c/pre\u003e\r\n\r\n\u003cp\u003eAll these scores are very good! You have made a pretty accurate model despite the fact that you have considerably more rows that are of the white wine type.\u003c/p\u003e\r\n\r\n\u003cp\u003eGood job!\u003c/p\u003e\r\n\r\n\u003ch2\u003eSome More Experiments\u003c/h2\u003e\r\n\r\n\u003cp\u003eYou\u0026rsquo;ve successfully built your first model, but you can go even further with this one. Why not try out the following things and see what their effect is? Like you read above, the two key architectural decisions that you need to make involve the layers and the hidden nodes. These are great starting points:\u003c/p\u003e\r\n\r\n\u003cul\u003e\r\n\t\u003cli\u003eYou used 1 hidden layers. Try to use 2 or 3 hidden layers;\u003c/li\u003e\r\n\t\u003cli\u003eUse layers with more hidden units or less hidden units;\u003c/li\u003e\r\n\t\u003cli\u003eTake the \u003ccode class=\"lang-python\"\u003equality\u003c/code\u003e column as the target labels and the rest of the data (including the encoded \u003ccode class=\"lang-python\"\u003etype\u003c/code\u003e column!) as your data. You now have a multi-class classification problem!\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cbr\u003e\r\n\u003cp\u003eBut why also not try out changing the activation function? Instead of \u003ccode class=\"lang-python\"\u003erelu\u003c/code\u003e, try using the \u003ccode class=\"lang-python\"\u003etanh\u003c/code\u003e activation function and see what the result is!\u003c/p\u003e\r\n\r\n\u003cp\u003e\u003ca href=\"https://www.datacamp.com/courses/\" target=\"_blank\"\u003e\u003cimg alt=\"Learn Python for Data Science With DataCamp\" src=\"http://community.datacamp.com.s3.amazonaws.com/community/production/ckeditor_assets/pictures/293/content_blog_banner.png\" /\u003e\u003c/a\u003e\u003c/p\u003e\r\n\r\n\u003ch2 id=\"finetune\"\u003ePredicting Wine Quality\u003c/h2\u003e\r\n\r\n\u003cp\u003eYour classification model performed perfectly for a first run!\u003c/p\u003e\r\n\r\n\u003cp\u003eBut there is so much more that you can do besides going a level higher and trying out more complex structures than the multi-layer perceptron. Why not try to make a neural network to predict the wine quality?\u003c/p\u003e\r\n\r\n\u003cp\u003eIn this case, the tutorial assumes that \u003ccode class=\"lang-python\"\u003equality\u003c/code\u003e is a continuous variable: the task is then not a binary classification task but an ordinal regression task. It\u0026rsquo;s a type of regression that is used for predicting an ordinal variable: the \u003ccode class=\"lang-python\"\u003equality\u003c/code\u003e value exists on an arbitrary scale where the relative ordering between the different \u003ccode class=\"lang-python\"\u003equality\u003c/code\u003e values is significant. In this scale, the quality scale 0-10 for \u0026ldquo;very bad\u0026rdquo; to \u0026ldquo;very good\u0026rdquo; is such an example.\u003c/p\u003e\r\n\r\n\u003cp\u003eNote that you could also view this type of problem as a classification problem and consider the quality labels as fixed class labels.\u003c/p\u003e\r\n\r\n\u003cp\u003eIn any case, this situation setup would mean that your target labels are going to be the \u003ccode class=\"lang-python\"\u003equality\u003c/code\u003e column in your \u003ccode class=\"lang-python\"\u003ered\u003c/code\u003e and \u003ccode class=\"lang-python\"\u003ewhite\u003c/code\u003e DataFrames for the second part of this tutorial. This will require some additional preprocessing.\u003c/p\u003e\r\n\r\n\u003cdiv class=\"section level3\" id=\"preprocess-data-1\"\u003e\r\n\u003ch3\u003ePreprocess Data\u003c/h3\u003e\r\n\r\n\u003cp\u003eSince the \u003ccode class=\"lang-python\"\u003equality\u003c/code\u003e variable becomes your target class, you will now need to isolate the quality labels from the rest of the data set. You will put \u003ccode class=\"lang-python\"\u003ewines.quality\u003c/code\u003e in a different variable \u003ccode class=\"lang-python\"\u003ey\u003c/code\u003e and you\u0026rsquo;ll put the wines data, with exception of the \u003ccode class=\"lang-python\"\u003equality\u003c/code\u003e column in a variable \u003ccode class=\"lang-python\"\u003ex\u003c/code\u003e.\u003c/p\u003e\r\n\r\n\u003cp\u003eNext, you\u0026rsquo;re ready to split the data in train and test sets, but you won\u0026rsquo;t follow this approach in this case (even though you could!). In this second part of the tutorial, you will make use of k-fold validation, which requires you to split up the data into K partitions. Usually, K is set at 4 or 5. Next, you instantiate identical models and train each one on a partition, while also evaluating on the remaining partitions. The validation score for the model is then an average of the K validation scores obtained.\u003c/p\u003e\r\n\r\n\u003cp\u003eYou\u0026rsquo;ll see how to do this later. For now, use \u003ccode class=\"lang-python\"\u003eStandardScaler\u003c/code\u003e to make sure that your data is in a good place before you fit the data to the model, just like before.\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"300\"\u003eeyJsYW5ndWFnZSI6InB5dGhvbiIsInByZV9leGVyY2lzZV9jb2RlIjoiaW1wb3J0IHBhbmRhcyBhcyBwZFxud2hpdGUgPSBwZC5yZWFkX2NzdihcImh0dHA6Ly9hcmNoaXZlLmljcy51Y2kuZWR1L21sL21hY2hpbmUtbGVhcm5pbmctZGF0YWJhc2VzL3dpbmUtcXVhbGl0eS93aW5lcXVhbGl0eS13aGl0ZS5jc3ZcIiwgc2VwPSc7JylcbnJlZCA9IHBkLnJlYWRfY3N2KFwiaHR0cDovL2FyY2hpdmUuaWNzLnVjaS5lZHUvbWwvbWFjaGluZS1sZWFybmluZy1kYXRhYmFzZXMvd2luZS1xdWFsaXR5L3dpbmVxdWFsaXR5LXJlZC5jc3ZcIiwgc2VwPSc7JylcbndpbmVzID0gcmVkLmFwcGVuZCh3aGl0ZSwgaWdub3JlX2luZGV4PVRydWUpIiwic2FtcGxlIjoiIyBJc29sYXRlIHRhcmdldCBsYWJlbHNcbnkgPSB3aW5lcy5fX19fX19fX1xuXG4jIElzb2xhdGUgZGF0YVxuWCA9IHdpbmVzLmRyb3AoJ3F1YWxpdHknLCBheGlzPV8pICIsInNvbHV0aW9uIjoiIyBJc29sYXRlIHRhcmdldCBsYWJlbHNcbnkgPSB3aW5lcy5xdWFsaXR5XG5cbiMgSXNvbGF0ZSBkYXRhXG5YID0gd2luZXMuZHJvcCgncXVhbGl0eScsIGF4aXM9MSkgIiwic2N0IjoiRXgoKS50ZXN0X29iamVjdChcInlcIilcbkV4KCkudGVzdF9vYmplY3QoXCJYXCIpIn0=\u003c/div\u003e\r\n\u003cbr\u003e\u003cbr\u003e\r\n\u003cp\u003eRemember that you also need to perform the scaling again because you had a lot of differences in some of the values for your \u003ccode class=\"lang-python\"\u003ered\u003c/code\u003e, \u003ccode class=\"lang-python\"\u003ewhite\u003c/code\u003e (and consequently also \u003ccode class=\"lang-python\"\u003ewines\u003c/code\u003e) data.\u003c/p\u003e\r\n\r\n\u003cp\u003eTry this out in the DataCamp Light chunk below. All the necessary libraries have been loaded in for you!\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"300\"\u003eeyJsYW5ndWFnZSI6InB5dGhvbiIsInByZV9leGVyY2lzZV9jb2RlIjoiaW1wb3J0IHBhbmRhcyBhcyBwZFxud2hpdGUgPSBwZC5yZWFkX2NzdihcImh0dHA6Ly9hcmNoaXZlLmljcy51Y2kuZWR1L21sL21hY2hpbmUtbGVhcm5pbmctZGF0YWJhc2VzL3dpbmUtcXVhbGl0eS93aW5lcXVhbGl0eS13aGl0ZS5jc3ZcIiwgc2VwPSc7JylcbnJlZCA9IHBkLnJlYWRfY3N2KFwiaHR0cDovL2FyY2hpdmUuaWNzLnVjaS5lZHUvbWwvbWFjaGluZS1sZWFybmluZy1kYXRhYmFzZXMvd2luZS1xdWFsaXR5L3dpbmVxdWFsaXR5LXJlZC5jc3ZcIiwgc2VwPSc7JylcbndpbmVzID0gcmVkLmFwcGVuZCh3aGl0ZSwgaWdub3JlX2luZGV4PVRydWUpXG55ID0gd2luZXMucXVhbGl0eVxuWCA9IHdpbmVzLmRyb3AoJ3F1YWxpdHknLCBheGlzPTEpIFxuZnJvbSBza2xlYXJuLnByZXByb2Nlc3NpbmcgaW1wb3J0IFN0YW5kYXJkU2NhbGVyIiwic2FtcGxlIjoiIyBTY2FsZSB0aGUgZGF0YSB3aXRoIGBTdGFuZGFyZFNjYWxlcmBcblggPSBfX19fX19fX19fX19fX19fLmZpdF90cmFuc2Zvcm0oWCkiLCJzb2x1dGlvbiI6IiMgU2NhbGUgdGhlIGRhdGEgd2l0aCBgU3RhbmRhcmRTY2FsZXJgXG5YID0gU3RhbmRhcmRTY2FsZXIoKS5maXRfdHJhbnNmb3JtKFgpIiwic2N0IjoiRXgoKS50ZXN0X29iamVjdChcIlhcIikifQ==\u003c/div\u003e\r\n\u003cbr\u003e\u003cbr\u003e\r\n\u003cp\u003eNow you\u0026rsquo;re again at the point where you were a bit ago. You can again start modelling the neural network!\u003c/p\u003e\r\n\r\n\u003ch3\u003eModel Neural Network Architecture\u003c/h3\u003e\r\n\r\n\u003cp\u003eNow that you have preprocessed the data again, it\u0026rsquo;s once more time to construct a neural network model, a multi-layer perceptron. Even though you\u0026rsquo;ll use it for a regression task, the architecture could look very much the same, with two \u003ccode class=\"lang-python\"\u003eDense\u003c/code\u003e layers.\u003c/p\u003e\r\n\r\n\u003cp\u003eDon\u0026rsquo;t forget that the first layer is your input layer. You will need to pass the shape of your input data to it. In this case, you see that you\u0026rsquo;re going to make use of \u003ccode class=\"lang-python\"\u003einput_dim\u003c/code\u003e to pass the dimensions of the input data to the \u003ccode class=\"lang-python\"\u003eDense\u003c/code\u003e layer.\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"300\"\u003eeyJsYW5ndWFnZSI6InB5dGhvbiIsInByZV9leGVyY2lzZV9jb2RlIjoiaW1wb3J0IHBhbmRhcyBhcyBwZFxuZnJvbSBza2xlYXJuLm1vZGVsX3NlbGVjdGlvbiBpbXBvcnQgdHJhaW5fdGVzdF9zcGxpdFxuZnJvbSBza2xlYXJuLnByZXByb2Nlc3NpbmcgaW1wb3J0IFN0YW5kYXJkU2NhbGVyXG53aGl0ZSA9IHBkLnJlYWRfY3N2KFwiaHR0cDovL2FyY2hpdmUuaWNzLnVjaS5lZHUvbWwvbWFjaGluZS1sZWFybmluZy1kYXRhYmFzZXMvd2luZS1xdWFsaXR5L3dpbmVxdWFsaXR5LXdoaXRlLmNzdlwiLCBzZXA9JzsnKVxucmVkID0gcGQucmVhZF9jc3YoXCJodHRwOi8vYXJjaGl2ZS5pY3MudWNpLmVkdS9tbC9tYWNoaW5lLWxlYXJuaW5nLWRhdGFiYXNlcy93aW5lLXF1YWxpdHkvd2luZXF1YWxpdHktcmVkLmNzdlwiLCBzZXA9JzsnKVxucmVkWyd0eXBlJ10gPSAxXG53aGl0ZVsndHlwZSddID0gMFxud2luZXMgPSByZWQuYXBwZW5kKHdoaXRlLCBpZ25vcmVfaW5kZXg9VHJ1ZSlcbnkgPSB3aW5lcy5xdWFsaXR5XG5YID0gd2luZXMuZHJvcCgncXVhbGl0eScsIGF4aXM9MSkgXG5YID0gU3RhbmRhcmRTY2FsZXIoKS5maXRfdHJhbnNmb3JtKFgpIiwic2FtcGxlIjoiIyBJbXBvcnQgYFNlcXVlbnRpYWxgIGZyb20gYGtlcmFzLm1vZGVsc2BcbmZyb20ga2VyYXMubW9kZWxzIGltcG9ydCBTZXF1ZW50aWFsXG5cbiMgSW1wb3J0IGBEZW5zZWAgZnJvbSBga2VyYXMubGF5ZXJzYFxuZnJvbSBrZXJhcy5sYXllcnMgaW1wb3J0IERlbnNlXG5cbiMgSW5pdGlhbGl6ZSB0aGUgbW9kZWxcbm1vZGVsID0gU2VxdWVudGlhbCgpXG5cbiMgQWRkIGlucHV0IGxheWVyIFxubW9kZWwuYWRkKERlbnNlKDY0LCBpbnB1dF9kaW09MTIsIGFjdGl2YXRpb249J3JlbHUnKSlcbiAgICBcbiMgQWRkIG91dHB1dCBsYXllciBcbm1vZGVsLmFkZChEZW5zZSgxKSkifQ==\u003c/div\u003e\r\n\u003cbr\u003e\u003cbr\u003e\r\n\u003cp\u003eNote again that the first layer that you define is the input layer. This layer needs to know the input dimensions of your data. You pass in the input dimensions, which are 12 in this case (don\u0026rsquo;t forget that you\u0026rsquo;re also counting the \u003ccode class=\"lang-python\"\u003eType\u003c/code\u003e column which you have generated in the first part of the tutorial!). You again use the \u003ccode class=\"lang-python\"\u003erelu\u003c/code\u003e activation function, but once again there is no bias involved. The number of hidden units is \u003ccode class=\"lang-python\"\u003e64\u003c/code\u003e.\u003c/p\u003e\r\n\r\n\u003cp\u003eYour network ends with a single unit \u003ccode class=\"lang-python\"\u003eDense(1)\u003c/code\u003e, and doesn\u0026rsquo;t include an activation. This is a typical setup for scalar regression, where you are trying to predict a single continuous value).\u003c/p\u003e\r\n\r\n\u003ch3\u003eCompile The Model, Fit The Data\u003c/h3\u003e\r\n\r\n\u003cp\u003eWith your model at hand, you can again compile it and fit the data to it. But wait. Don\u0026rsquo;t you need the K fold validation partitions that you read about before? That\u0026rsquo;s right.\u003c/p\u003e\r\n\r\n\u003cpre\u003e\r\n\u003ccode class=\"lang-python\"\u003eimport numpy as np\r\nfrom sklearn.model_selection import StratifiedKFold\r\n\r\nseed = 7\r\nnp.random.seed(seed)\r\n\r\nkfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\r\nfor train, test in kfold.split(X, Y):\r\n    model = Sequential()\r\n    model.add(Dense(64, input_dim=12, activation='relu'))\r\n    model.add(Dense(1))\r\n    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\r\n    model.fit(X[train], Y[train], epochs=10, verbose=1)\u003c/code\u003e\u003c/pre\u003e\r\n\r\n\u003cp\u003eUse the \u003ccode class=\"lang-python\"\u003ecompile()\u003c/code\u003e function to compile the model and then use \u003ccode class=\"lang-python\"\u003efit()\u003c/code\u003e to fit the model to the data. To compile the model, you again make sure that you define at least the \u003ccode class=\"lang-python\"\u003eoptimizer\u003c/code\u003e and \u003ccode class=\"lang-python\"\u003eloss\u003c/code\u003e arguments. In this case, you can use \u003ccode class=\"lang-python\"\u003ersmprop\u003c/code\u003e, one of the most popular optimization algorithms, and \u003ccode class=\"lang-python\"\u003emse\u003c/code\u003e as the loss function, which is very typical for regression problems such as yours.\u003c/p\u003e\r\n\r\n\u003cp\u003eThe additional \u003ccode class=\"lang-python\"\u003emetrics\u003c/code\u003e argument that you define is actually a function that is used to judge the performance of your model. For regression problems, it\u0026rsquo;s very common to take the Mean Absolute Error (MAE) as a metric. You\u0026rsquo;ll read more about this in the next section.\u003c/p\u003e\r\n\r\n\u003cp\u003ePass in the train data and labels to \u003ccode class=\"lang-python\"\u003efit()\u003c/code\u003e, determine how many epochs you want to run the fitting, the batch size and if you want, you can put the \u003ccode class=\"lang-python\"\u003everbose\u003c/code\u003e argument to 1 to get more logs because this can take up some time.\u003c/p\u003e\r\n\r\n\u003ch3\u003eEvaluate Model\u003c/h3\u003e\r\n\r\n\u003cp\u003eJust like before, you should also evaluate your model. Besides adding \u003ccode class=\"lang-python\"\u003ey_pred = model.predict(X[test])\u003c/code\u003e to the rest of the code above, it might also be a good idea to use some of the evaluation metrics from \u003ccode class=\"lang-python\"\u003esklearn\u003c/code\u003e, like you also have done in the first part of the tutorial.\u003c/p\u003e\r\n\r\n\u003cp\u003eTo do this, you can make use of the Mean Squared Error (MSE) and the Mean Absolute Error (MAE). The former, which is also called the \u0026ldquo;mean squared deviation\u0026rdquo; (MSD) measures the average of the squares of the errors or deviations. In other words, it quantifies the difference between the estimator and what is estimated. This way, you get to know some more about the quality of your estimator: it is always non-negative, and values closer to zero are better.\u003c/p\u003e\r\n\r\n\u003cp\u003eThe latter evaluation measure, MAE, stands for Mean Absolute Error: it quantifies how close predictions are to the eventual outcomes.\u003c/p\u003e\r\n\r\n\u003cp\u003eAdd these lines to the previous code chunk, and be careful with the indentations:\u003c/p\u003e\r\n\r\n\u003cpre\u003e\r\n\u003ccode class=\"lang-python\"\u003emse_value, mae_value = model.evaluate(X[test], Y[test], verbose=0)\r\n\r\nprint(mse_value)\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e0.522478731072\u003c/code\u003e\u003c/pre\u003e\r\n\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003eprint(mae_value)\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e0.561965950103\u003c/code\u003e\u003c/pre\u003e\r\n\r\n\u003cp\u003eNote that besides the MSE and MAE scores, you could also use the R2 score or the regression score function. Here, you should go for a score of 1.0, which is the best. However, the score can also be negative!\u003c/p\u003e\r\n\r\n\u003cpre\u003e\r\n\u003ccode class=\"lang-python\"\u003efrom sklearn.metrics import r2_score\r\n\r\nr2_score(Y[test], y_pred)\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e0.3125092543\u003c/code\u003e\u003c/pre\u003e\r\n\r\n\u003cp\u003eAt first sight, these are quite horrible numbers, right? The good thing about this, though, is that you can now experiment with optimizing the code so that the results become a little bit better.\u003c/p\u003e\r\n\r\n\u003cp\u003eThat\u0026rsquo;s what the next and last section is all about!\u003c/p\u003e\r\n\r\n\u003ch3\u003eModel Fine-Tuning\u003c/h3\u003e\r\n\r\n\u003cp\u003eFine-tuning your model is probably something that you\u0026rsquo;ll be doing a lot, because not all problems are as straightforward as the one that you saw in the first part of this tutorial. As you read above, there are already two key decisions that you\u0026rsquo;ll probably want to adjust: how many layers you\u0026rsquo;re going to use and how many \u0026ldquo;hidden units\u0026rdquo; you will chose for each layer.\u003c/p\u003e\r\n\r\n\u003cp\u003eIn the beginning, this will really be quite a journey.\u003c/p\u003e\r\n\r\n\u003cdiv class=\"section level4\" id=\"adding-layers\"\u003e\r\n\u003ch4\u003eAdding Layers\u003c/h4\u003e\r\n\r\n\u003cp\u003eWhat would happen if you add another layer to your model? What if it would look like this?\u003c/p\u003e\r\n\r\n\u003cpre\u003e\r\n\u003ccode class=\"lang-python\"\u003emodel = Sequential()\r\nmodel.add(Dense(64, input_dim=12, activation='relu'))\r\nmodel.add(Dense(64, activation='relu'))\r\nmodel.add(Dense(1))\u003c/code\u003e\u003c/pre\u003e\r\n\u003c/div\u003e\r\n\r\n\u003cdiv class=\"section level4\" id=\"hidden-units\"\u003e\r\n\u003ch4\u003eHidden Units\u003c/h4\u003e\r\n\r\n\u003cp\u003eAlso try out the effect of adding more hidden units to your model\u0026rsquo;s architecture and study the effect on the evaluation, just like this:\u003c/p\u003e\r\n\r\n\u003cpre\u003e\r\n\u003ccode class=\"lang-python\"\u003emodel = Sequential()\r\nmodel.add(Dense(128, input_dim=12, activation='relu'))\r\nmodel.add(Dense(1))\u003c/code\u003e\u003c/pre\u003e\r\n\r\n\u003cp\u003eNote again that, in general, because you don\u0026rsquo;t have a ton of data, the worse overfitting can and will be. That\u0026rsquo;s why you should use a small network.\u003c/p\u003e\r\n\u003c/div\u003e\r\n\r\n\u003cdiv class=\"section level4\" id=\"some-more-experiments-optimization-parameters\"\u003e\r\n\u003ch4\u003eSome More Experiments: Optimization Parameters\u003c/h4\u003e\r\n\r\n\u003cp\u003eBesides adding layers and playing around with the hidden units, you can also try to adjust (some of) the parameters of the optimization algorithm that you give to the \u003ccode class=\"lang-python\"\u003ecompile()\u003c/code\u003e function. Up until now, you have always passed a string, such as \u003ccode class=\"lang-python\"\u003ermsprop\u003c/code\u003e, to the \u003ccode class=\"lang-python\"\u003eoptimizer\u003c/code\u003e argument.\u003c/p\u003e\r\n\r\n\u003cp\u003eBut that doesn\u0026rsquo;t always need to be like this!\u003c/p\u003e\r\n\r\n\u003cp\u003eTry, for example, importing \u003ccode class=\"lang-python\"\u003eRMSprop\u003c/code\u003e from \u003ccode class=\"lang-python\"\u003ekeras.models\u003c/code\u003e and adjust the learning rate \u003ccode class=\"lang-python\"\u003elr\u003c/code\u003e. You can also adjust the default values that have been set for the other parameters for \u003ccode class=\"lang-python\"\u003eRMSprop()\u003c/code\u003e but this is not recommended. You can get more information \u003ca href=\"https://keras.io/optimizers/\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\r\n\r\n\u003cpre\u003e\r\n\u003ccode class=\"lang-python\"\u003efrom keras.optimizers import RMSprop\r\nrmsprop = RMSprop(lr=0.0001)\r\nmodel.compile(optimizer=rmsprop, loss='mse', metrics=['mae'])\u003c/code\u003e\u003c/pre\u003e\r\n\r\n\u003cp\u003eAlso, try out experimenting with other optimization algorithms, like the Stochastic Gradient Descent (SGD). Do you notice an effect?\u003c/p\u003e\r\n\r\n\u003cpre\u003e\r\n\u003ccode class=\"lang-python\"\u003efrom keras.optimizers import SGD, RMSprop\r\nsgd=SGD(lr=0.1)\r\nmodel.compile(optimizer=sgd, loss='mse', metrics=['mae'])\u003c/code\u003e\u003c/pre\u003e\r\n\r\n\u003ch2\u003eGo Further!\u003c/h2\u003e\r\n\r\n\u003cp\u003eThis tutorial was just a start in your deep learning journey with Python and Keras. There is still a lot to cover, so why not take DataCamp\u0026rsquo;s \u003ca href=\"https://www.datacamp.com/courses/deep-learning-in-python\"\u003eDeep Learning in Python\u003c/a\u003e course? In the meantime, also make sure to check out the \u003ca href=\"https://keras.io/\"\u003eKeras documentation\u003c/a\u003e, if you haven\u0026rsquo;t done so already. You\u0026rsquo;ll find more examples and information on all functions, arguments, more layers, etc\u0026hellip; It\u0026rsquo;ll undoubtedly be an indispensable resource when you\u0026rsquo;re learning how to work with neural networks in Python! If you rather feel like reading a book that explains the fundamentals of deep learning (with Keras) together with how it\u0026#39;s used in practice, you should definitely read Fran\u0026ccedil;ois Chollet\u0026#39;s \u003ca href=\"https://www.manning.com/books/deep-learning-with-python\"\u003eDeep Learning in Python\u003c/a\u003e book.\u003c/p\u003e\r\n\u003c/div\u003e\r\n\u003c/div\u003e\r\n\u003cscript\u003e\r\n\r\n// add bootstrap table styles to pandoc tables\r\nfunction bootstrapStylePandocTables() {\r\n  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');\r\n}\r\n$(document).ready(function () {\r\n  bootstrapStylePandocTables();\r\n});\r\n\r\n\r\n\u003c/script\u003e\u003c!-- dynamically load mathjax for compatibility with self-contained --\u003e\u003cscript\u003e\r\n  (function () {\r\n    var script = document.createElement(\"script\");\r\n    script.type = \"text/javascript\";\r\n    script.src  = \"https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML\";\r\n    document.getElementsByTagName(\"head\")[0].appendChild(script);\r\n  })();\r\n\u003c/script\u003e\u003c/div\u003e\r\n\u003c/nav\u003e\r\n\u003c/div\u003e\r\n\u003c/div\u003e\r\n","contentUrl":"https://www.datacamp.com/community/tutorials/deep-learning-python","userContentUrl":null,"illustrationUrl":"http://datacamp-community.s3.amazonaws.com/cc0d8057-2e88-4de5-b14e-d3c72dbc6c0d","seoTitle":"Keras Tutorial: Deep Learning in Python","seoMetaDescription":"This Keras tutorial introduces you to deep learning in Python: learn to preprocess your data, model, evaluate and optimize neural networks. ","seoKeyword":"keras tutorial","mustRead":true,"programmingLanguage":null,"submissionDate":"2017-05-02T13:53:34.000Z","publishDate":"2017-05-02T14:05:30.000Z","episode":null,"isLatest":null,"externalUrl":null,"transcriptUrl":null,"guests":[],"links":null,"isSpam":false,"xp":0,"flaggingUsers":[],"isDisabled":false,"connectedInternalContentId":null,"createdAt":"2017-09-08T15:37:33.079Z","updatedAt":"2018-02-22T08:29:08.021Z","upvoting":{"voteCount":95,"voted":false},"tags":["python","machine learning","deep learning","neural networks","keras"],"author":{"id":494311,"slug":"karlijn","avatarUrlSquare":"https://assets.datacamp.com/users/avatars/000/494/311/square/Screenshot_2017-04-26_16.02.58.png?1493215479","fullName":"Karlijn Willems","nameFromEmail":"karlijn","isAdmin":false}},{"id":362,"externalId":null,"type":"Tutorial","status":"published","authorId":"karlijn","title":"keras: Deep Learning in R","slug":"keras-r-deep-learning","previewSlug":null,"description":"In this tutorial to deep learning in R with RStudio's keras package, you'll learn how to build a Multi-Layer Perceptron (MLP).","articles":[],"courses":[],"redirectSlug":null,"contentHtml":"\u003cscript src=\"https://cdn.datacamp.com/datacamp-light-latest.min.js\"\u003e\u003c/script\u003e\r\n\u003cp\u003eAs you know by now, machine learning is a subfield in Computer Science (CS). Deep learning, then, is a subfield of machine learning that is a set of algorithms that is inspired by the structure and function of the brain and which is usually called Artificial Neural Networks (ANN). Deep learning is one of the hottest trends in machine learning at the moment, and there are many problems where deep learning shines, such as robotics, image recognition and Artificial Intelligence (AI).\u003c/p\u003e\r\n\r\n\u003cp\u003eToday\u0026rsquo;s tutorial will give you a short introduction to deep learning in R with Keras with the \u003ccode\u003ekeras\u003c/code\u003e package:\u003c/p\u003e\r\n\r\n\u003cnav\u003e\r\n\u003cul\u003e\r\n\t\u003cli\u003eYou\u0026rsquo;ll start with a short overview of the \u003ca href=\"#overview\"\u003edeep learning packages in R\u003c/a\u003e, and\u003c/li\u003e\r\n\t\u003cli\u003eYou\u0026rsquo;ll read more about the \u003ca href=\"#differences\"\u003edifferences between the Keras, \u003ccode\u003ekerasR\u003c/code\u003e and \u003ccode\u003ekeras\u003c/code\u003e\u003c/a\u003e packages and what it means when a package is an interface to another package;\u003c/li\u003e\r\n\t\u003cli\u003eThen, you\u0026rsquo;ll really get started with RStudio\u0026rsquo;s \u003ccode\u003ekeras\u003c/code\u003e package: you\u0026rsquo;ll learn how to first \u003ca href=\"prep\"\u003eprepare your workspace\u003c/a\u003e and \u003ca href=\"#data\"\u003eload in\u003c/a\u003e built-in datasets, dummy data, and data from CSVs;\u003c/li\u003e\r\n\t\u003cli\u003eNext, you\u0026rsquo;ll see how you can \u003ca href=\"#explore\"\u003eexplore\u003c/a\u003e and \u003ca href=\"#prep\"\u003epreprocess the data\u003c/a\u003e that you loaded in from a CSV file: you\u0026rsquo;ll normalize and split the data into training and test sets.\u003c/li\u003e\r\n\t\u003cli\u003eAfter this, you\u0026rsquo;re ready to \u003ca href=\"#model\"\u003econstruct your deep learning model\u003c/a\u003e; In this case, you\u0026rsquo;ll build a Multi-Layer Perceptron (MLP) for multi-class classification.\u003c/li\u003e\r\n\t\u003cli\u003eYou\u0026rsquo;ll learn how you can \u003ca href=\"#compile\"\u003ecompile and fit\u003c/a\u003e the model to your data, how you can \u003ca href=\"viz\"\u003evisualize the training history\u003c/a\u003e, and\u003c/li\u003e\r\n\t\u003cli\u003eyou\u0026rsquo;ll \u003ca href=\"#predict\"\u003epredict target values\u003c/a\u003e based on test data;\u003c/li\u003e\r\n\t\u003cli\u003eLastly, you\u0026rsquo;ll \u003ca href=\"#evaluate\"\u003eevaluate your model\u003c/a\u003e, interpret the results and \u003ca href=\"#finetune\"\u003efinetune your model\u003c/a\u003e so that it performs better: you\u0026rsquo;ll learn how to add layers and hidden layers and you\u0026rsquo;ll see how you can adjust the optimization parameters to accomplish better results.\u003c/li\u003e\r\n\t\u003cli\u003eAdditionally, you might want to \u003ca href=\"#save\"\u003esave your (optimized) model or load it back in\u003c/a\u003e another time. You\u0026#39;ll see how this is done in the last section of this tutorial!\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003c/nav\u003e\r\n\r\n\u003cdiv id=\"scoped-content\"\u003e\r\n\u003cstyle type=\"text/css\"\u003e:target:before { content:\"\"; display:block; height:150px; margin:-150px 0 0; } h3 {font-weight:normal; margin-top:.5em} h4 { font-weight:lighter }\r\n\u003c/style\u003e\r\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\r\n\r\n\u003cp\u003eDo you want to know more about the original Keras or key concepts in deep learning such as perceptrons and Multi-Layer Perceptrons (MLPs)? Consider or taking DataCamp\u0026rsquo;s \u003ca href=\"https://www.datacamp.com/courses/deep-learning-in-python\"\u003eDeep Learning in Python\u003c/a\u003e course or doing the \u003ca href=\"https://www.datacamp.com/community/tutorials/deep-learning-python\"\u003eKeras Tutorial: Deep Learning in Python\u003c/a\u003e.\u003c/p\u003e\r\n\r\n\u003cp\u003e\u003cstrong\u003eTip\u003c/strong\u003e: find our Keras cheat sheet \u003ca href=\"https://www.datacamp.com/community/blog/keras-cheat-sheet\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\r\n\r\n\u003ch2 id=\"overview\"\u003eDeep Learning in R: Short Overview of Packages\u003c/h2\u003e\r\n\r\n\u003cp\u003eWith the rise in popularity of deep learning, CRAN has been enriched with more R deep learning packages; Below you can see an overview of these packages, taken from the \u003ca href=\"https://CRAN.R-project.org/view=MachineLearning\"\u003eMachine Learning and Statistical Learning CRAN task view\u003c/a\u003e. The \u0026ldquo;Percentile\u0026rdquo; column indicates the percentile as found on \u003ca href=\"www.rdocumentation.org\"\u003eRDocumentation\u003c/a\u003e:\u003c/p\u003e\r\n\r\n\u003ctable\u003e\r\n\t\u003ccolgroup\u003e\r\n\t\t\u003ccol width=\"9%\" /\u003e\r\n\t\t\u003ccol width=\"10%\" /\u003e\r\n\t\t\u003ccol width=\"80%\" /\u003e\r\n\t\u003c/colgroup\u003e\r\n\t\u003cthead\u003e\r\n\t\t\u003ctr class=\"header\"\u003e\r\n\t\t\t\u003cth\u003eR Package\u003c/th\u003e\r\n\t\t\t\u003cth\u003ePercentile\u003c/th\u003e\r\n\t\t\t\u003cth\u003eDescription\u003c/th\u003e\r\n\t\t\u003c/tr\u003e\r\n\t\u003c/thead\u003e\r\n\t\u003ctbody\u003e\r\n\t\t\u003ctr class=\"odd\"\u003e\r\n\t\t\t\u003ctd\u003e\u003ccode\u003ennet\u003c/code\u003e\u003c/td\u003e\r\n\t\t\t\u003ctd\u003e96th\u003c/td\u003e\r\n\t\t\t\u003ctd\u003eSoftware for feed-forward neural networks with a single hidden layer, and for multinomial log-linear models.\u003c/td\u003e\r\n\t\t\u003c/tr\u003e\r\n\t\t\u003ctr class=\"even\"\u003e\r\n\t\t\t\u003ctd\u003e\u003ccode\u003eneuralnet\u003c/code\u003e\u003c/td\u003e\r\n\t\t\t\u003ctd\u003e96th\u003c/td\u003e\r\n\t\t\t\u003ctd\u003eTraining of neural networks using backpropagation\u003c/td\u003e\r\n\t\t\u003c/tr\u003e\r\n\t\t\u003ctr class=\"odd\"\u003e\r\n\t\t\t\u003ctd\u003e\u003ccode\u003eh2o\u003c/code\u003e\u003c/td\u003e\r\n\t\t\t\u003ctd\u003e95th\u003c/td\u003e\r\n\t\t\t\u003ctd\u003eR scripting functionality for H2O\u003c/td\u003e\r\n\t\t\u003c/tr\u003e\r\n\t\t\u003ctr class=\"even\"\u003e\r\n\t\t\t\u003ctd\u003e\u003ccode\u003eRSNNS\u003c/code\u003e\u003c/td\u003e\r\n\t\t\t\u003ctd\u003e88th\u003c/td\u003e\r\n\t\t\t\u003ctd\u003eInterface to the Stuttgart Neural Network Simulator (SNNS)\u003c/td\u003e\r\n\t\t\u003c/tr\u003e\r\n\t\t\u003ctr class=\"odd\"\u003e\r\n\t\t\t\u003ctd\u003e\u003ccode\u003etensorflow\u003c/code\u003e\u003c/td\u003e\r\n\t\t\t\u003ctd\u003e88th\u003c/td\u003e\r\n\t\t\t\u003ctd\u003eInterface to TensorFlow\u003c/td\u003e\r\n\t\t\u003c/tr\u003e\r\n\t\t\u003ctr class=\"even\"\u003e\r\n\t\t\t\u003ctd\u003e\u003ccode\u003edeepnet\u003c/code\u003e\u003c/td\u003e\r\n\t\t\t\u003ctd\u003e84th\u003c/td\u003e\r\n\t\t\t\u003ctd\u003eDeep learning toolkit in R\u003c/td\u003e\r\n\t\t\u003c/tr\u003e\r\n\t\t\u003ctr class=\"odd\"\u003e\r\n\t\t\t\u003ctd\u003e\u003ccode\u003edarch\u003c/code\u003e\u003c/td\u003e\r\n\t\t\t\u003ctd\u003e79th\u003c/td\u003e\r\n\t\t\t\u003ctd\u003ePackage for Deep Architectures and Restricted Boltzmann Machines\u003c/td\u003e\r\n\t\t\u003c/tr\u003e\r\n\t\t\u003ctr class=\"even\"\u003e\r\n\t\t\t\u003ctd\u003e\u003ccode\u003ernn\u003c/code\u003e\u003c/td\u003e\r\n\t\t\t\u003ctd\u003e73rd\u003c/td\u003e\r\n\t\t\t\u003ctd\u003ePackage to implement Recurrent Neural Networks (RRNs)\u003c/td\u003e\r\n\t\t\u003c/tr\u003e\r\n\t\t\u003ctr class=\"odd\"\u003e\r\n\t\t\t\u003ctd\u003e\u003ccode\u003eFCNN4R\u003c/code\u003e\u003c/td\u003e\r\n\t\t\t\u003ctd\u003e52nd\u003c/td\u003e\r\n\t\t\t\u003ctd\u003eInterface to the FCNN library that allows user-extensible ANNs\u003c/td\u003e\r\n\t\t\u003c/tr\u003e\r\n\t\t\u003ctr class=\"even\"\u003e\r\n\t\t\t\u003ctd\u003e\u003ccode\u003ercppDL\u003c/code\u003e\u003c/td\u003e\r\n\t\t\t\u003ctd\u003e7th\u003c/td\u003e\r\n\t\t\t\u003ctd\u003eImplementation of basic machine learning methods with many layers (deep learning), including dA (Denoising Autoencoder), SdA (Stacked Denoising Autoencoder), RBM (Restricted Boltzmann machine) and DBN (Deep Belief Nets)\u003c/td\u003e\r\n\t\t\u003c/tr\u003e\r\n\t\t\u003ctr class=\"odd\"\u003e\r\n\t\t\t\u003ctd\u003e\u003ccode\u003edeepr\u003c/code\u003e\u003c/td\u003e\r\n\t\t\t\u003ctd\u003e??*\u003c/td\u003e\r\n\t\t\t\u003ctd\u003ePackage to streamline the training, fine-tuning and predicting processes for deep learning based on \u003ccode\u003edarch\u003c/code\u003e and \u003ccode\u003edeepnet\u003c/code\u003e\u003c/td\u003e\r\n\t\t\u003c/tr\u003e\r\n\t\t\u003ctr class=\"even\"\u003e\r\n\t\t\t\u003ctd\u003e\u003ccode\u003eMXNetR\u003c/code\u003e\u003c/td\u003e\r\n\t\t\t\u003ctd\u003e??*\u003c/td\u003e\r\n\t\t\t\u003ctd\u003ePackage that brings flexible and efficient GPU computing and state-of-art deep learning to R\u003c/td\u003e\r\n\t\t\u003c/tr\u003e\r\n\t\u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\r\n\u003cp\u003e\u003cstrong\u003eTip\u003c/strong\u003e: for a comparison of deep learning packages in R, read \u003ca href=\"http://www.rblog.uni-freiburg.de/2017/02/07/deep-learning-in-r/\"\u003ethis blog post\u003c/a\u003e. For more information on ranking and score in RDocumentation, check out \u003ca href=\"https://www.datacamp.com/community/blog/rdocumentation-ranking-scoring\"\u003ethis blog post\u003c/a\u003e.\u003c/p\u003e\r\n\r\n\u003cp\u003e\u003csmall\u003eThe \u003ccode\u003edeepr\u003c/code\u003e and \u003ccode\u003eMXNetR\u003c/code\u003e were not found on RDocumentation.org, so the percentile is unknown for these two packages.\u003c/small\u003e\u003c/p\u003e\r\n\r\n\u003ch2 id=\"differences\"\u003eKeras, \u003ccode\u003ekeras\u003c/code\u003e and \u003ccode\u003ekerasR\u003c/code\u003e\u003c/h2\u003e\r\n\r\n\u003cp\u003eRecently, two new packages found their way to the R community: the \u003ca href=\"https://github.com/statsmaths/kerasR\"\u003e\u003ccode\u003ekerasR\u003c/code\u003e package\u003c/a\u003e, which was authored and created by Taylor Arnold, and \u003ca href=\"https://github.com/rstudio/keras\"\u003eRStudio\u0026rsquo;s \u003ccode\u003ekeras\u003c/code\u003e package\u003c/a\u003e.\u003c/p\u003e\r\n\r\n\u003cp\u003eBoth packages provide an R interface to the Python deep learning package Keras, of which you might have already heard or maybe you have even worked with it! For those of you who don\u0026rsquo;t know what the Keras package has to offer to Python users, it\u0026rsquo;s \u0026ldquo;a high-level neural networks API, written in Python and capable of running on top of either TensorFlow, Microsoft Cognitive Toolkit (CNTK) or Theano\u0026rdquo;.\u003c/p\u003e\r\n\r\n\u003cdiv class=\"section level3\" id=\"interfaces\"\u003e\r\n\u003ch3\u003eInterfaces?\u003c/h3\u003e\r\n\r\n\u003cp\u003eYou see, getting started with Keras is one of the easiest ways to get familiar with deep learning in Python and that also explains why the \u003ccode\u003ekerasR\u003c/code\u003e and \u003ccode\u003ekeras\u003c/code\u003e packages provide an interface for this fantastic package for R users.\u003c/p\u003e\r\n\r\n\u003cp\u003eIn this case, it\u0026rsquo;s good for you to understand what it exactly means when a package, such as the R \u003ccode\u003ekeras\u003c/code\u003e, is \u0026ldquo;an interface\u0026rdquo; to another package, the Python Keras. In simple terms, this means that the \u003ccode\u003ekeras\u003c/code\u003e R package with the interface allows you to enjoy the benefit of R programming while having access to the capabilities of the Python Keras package.\u003c/p\u003e\r\n\r\n\u003cp\u003e\u003cstrong\u003eNote\u003c/strong\u003e that this is not an uncommon practice: for example, also the \u003ccode\u003eh2o\u003c/code\u003e package provides an interface, but in this case -and as the name kind of already suggests- to H2O, an open source math engine for big data that you can use to compute parallel distributed machine learning algorithms. Other packages that you might know that provide interfaces are \u003ccode\u003eRWeka\u003c/code\u003e (R interface to Weka), \u003ccode\u003etensorflow\u003c/code\u003e (R interface to TensorFlow), \u003ccode\u003eopenml-r\u003c/code\u003e (R interface to OpenML), \u0026hellip; You can keep on going on and on!\u003c/p\u003e\r\n\u003c/div\u003e\r\n\r\n\u003cdiv class=\"section level3\" id=\"whats-the-difference-between-keras-keras-and-kerasr\"\u003e\r\n\u003ch3\u003eWhat\u0026rsquo;s the difference between Keras, \u003ccode\u003ekeras\u003c/code\u003e and \u003ccode\u003ekerasR\u003c/code\u003e?\u003c/h3\u003e\r\n\r\n\u003cp\u003eNow that you know all of this, you might ask yourself the following question first: how would you compare the original Python package with the R packages?\u003c/p\u003e\r\n\r\n\u003cp\u003eIn essence, you won\u0026rsquo;t find too many differences between the R packages and the original Python package, mostly because the function names are almost all the same; The only differences that you notice are mostly in the programming languages themselves (variable assignment, library loading, \u0026hellip;), but the most important thing to notice lies in the fact of how much of the original functionality has been incorporated in the R package.\u003c/p\u003e\r\n\r\n\u003cp\u003e\u003cstrong\u003eNote\u003c/strong\u003e that this remark isn\u0026rsquo;t only valid for the \u003ccode\u003ekeras\u003c/code\u003e library, but also for the \u003ccode\u003etensorflow\u003c/code\u003e, \u003ccode\u003eopenml-r\u003c/code\u003e, \u0026hellip; and other interface packages that were mentioned above!\u003c/p\u003e\r\n\r\n\u003cp\u003eSecondly, you might also wonder what then the difference is between these two R packages. Well, if you want to consider how the two differ, you might want to consider the following points:\u003c/p\u003e\r\n\r\n\u003cul\u003e\r\n\t\u003cli\u003e\r\n\t\u003cp\u003eThe \u003ccode\u003ekeras\u003c/code\u003e package uses the pipe operator (\u003ccode\u003e%\u0026gt;%\u003c/code\u003e) to connect functions or operations together, while you won\u0026rsquo;t find this in \u003ccode\u003ekerasR\u003c/code\u003e: for example, to make your model with \u003ccode\u003ekerasR\u003c/code\u003e, you\u0026rsquo;ll find that you need to make use of the \u003ccode\u003e$\u003c/code\u003e operator. The usage of the pipe operator generally improves the readability of your code and you\u0026rsquo;ll have definitely seen this operator already if you\u0026rsquo;ve worked with \u003ca href=\"http://tidyverse.org/\"\u003eTidyverse packages\u003c/a\u003e before.\u003c/p\u003e\r\n\t\u003c/li\u003e\r\n\t\u003cli\u003e\r\n\t\u003cp\u003eYou\u0026rsquo;ll see that \u003ccode\u003ekerasR\u003c/code\u003e contains functions that are named in a similar, but not in completely the same way as the original Keras package. For example, the original (Python) \u003ccode\u003ecompile()\u003c/code\u003e function is called \u003ccode\u003ekeras_compile()\u003c/code\u003e; The same holds for other functions, such as for example \u003ccode\u003efit()\u003c/code\u003e, which becomes \u003ccode\u003ekeras_fit()\u003c/code\u003e, or \u003ccode\u003epredict()\u003c/code\u003e, which is \u003ccode\u003ekeras_predict\u003c/code\u003e when you make use of the \u003ccode\u003ekerasR\u003c/code\u003e package. These are all custom wrappers.\u003c/p\u003e\r\n\t\u003c/li\u003e\r\n\t\u003cli\u003e\r\n\t\u003cp\u003eYou can argue that the installation of RStudio\u0026rsquo;s \u003ccode\u003ekeras\u003c/code\u003e package is easier than the installation of the \u003ccode\u003ekerasR\u003c/code\u003e package; To get the latter installed, you need to first make sure that you configure which Python version to use and this can get tricky if you\u0026rsquo;re working on a pc that has multiple environments or Python versions installed. But I\u0026rsquo;ll leave you to decide on this :)\u003c/p\u003e\r\n\t\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\r\n\u003cp\u003e\u003ca href=\"https://www.datacamp.com/courses/\" target=\"_blank\"\u003e\u003cimg alt=\"Learn Python for Data Science With DataCamp\" src=\"http://community.datacamp.com.s3.amazonaws.com/community/production/ckeditor_assets/pictures/293/content_blog_banner.png\" /\u003e\u003c/a\u003e\u003c/p\u003e\r\n\r\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\r\n\u003c/div\u003e\r\n\r\n\u003cp\u003eNow that you have gathered some background, it\u0026rsquo;s time to get started with Keras in R for real. As you will have read in the introduction of this tutorial, you\u0026rsquo;ll first go over the setup of you workspace. Then, you\u0026rsquo;ll load in some data and after a short data exploration and preprocessing step, you will be able to start constructing your MLP!\u003c/p\u003e\r\n\r\n\u003cp\u003eLet\u0026rsquo;s get on with it!\u003c/p\u003e\r\n\r\n\u003ch2\u003eInstalling The \u003ccode\u003ekeras\u003c/code\u003e Package\u003c/h2\u003e\r\n\r\n\u003cp\u003eAs always, the first step to getting started with any package is to set up your workspace: install and load in the library into RStudio or whichever environment you\u0026rsquo;re working in.\u003c/p\u003e\r\n\r\n\u003cp\u003eNo worries, for this tutorial, the package will be loaded in for you!\u003c/p\u003e\r\n\r\n\u003cp\u003eFirst, make sure that you install the \u003ccode\u003ekeras\u003c/code\u003e: you can easily do this by running \u003ccode\u003edevtools::install_github(\u0026quot;rstudio/keras\u0026quot;)\u003c/code\u003e in your console. Next, you can load in the package and install TensorFlow:\u003c/p\u003e\r\n\r\n\u003cpre\u003e\r\n\u003ccode\u003e# Load in the keras package\r\nlibrary(keras)\r\n\r\n# Install TensorFlow\r\ninstall_tensorflow()\u003c/code\u003e\u003c/pre\u003e\r\n\r\n\u003cp\u003eWhen you have done this, you\u0026rsquo;re good to go! That\u0026rsquo;s fast, right?\u003c/p\u003e\r\n\r\n\u003cp\u003e\u003cstrong\u003eTip\u003c/strong\u003e: for more information on the installation process, check out the \u003ca href=\"https://rstudio.github.io/keras/\"\u003epackage website\u003c/a\u003e.\u003c/p\u003e\r\n\u003c/div\u003e\r\n\r\n\u003ch2 id=\"data\"\u003eLoading The Data\u003c/h2\u003e\r\n\r\n\u003cp\u003eNow that the installation process is clear and your workspace is ready, you can start loading in your data! At this point, you have three big options when it comes to your data: you can pick to use one of the built-in datasets that comes with the \u003ccode\u003ekeras\u003c/code\u003e package, you can load your own dataset from, for example, CSV files, or you can make some dummy data.\u003c/p\u003e\r\n\r\n\u003cp\u003eWhichever situation you\u0026rsquo;re in, you\u0026rsquo;ll see that you\u0026rsquo;ll be able to quickly get started with the package. This section will quickly go over the three options and explain how you can load (or create) in the data that you need to get started!\u003c/p\u003e\r\n\r\n\u003cdiv class=\"section level4\" id=\"built-in-datasets\"\u003e\r\n\u003ch3\u003eBuilt-in Datasets\u003c/h3\u003e\r\n\r\n\u003cp\u003eIf you have some previous experience with the Keras package in Python, you probably will have already accessed the \u003ca href=\"https://github.com/fchollet/keras/tree/master/keras/datasets\"\u003eKeras built-in datasets\u003c/a\u003e with functions such as \u003ccode\u003emnist.load_data()\u003c/code\u003e, \u003ccode\u003ecifar10.load_data()\u003c/code\u003e, or \u003ccode\u003eimdb.load_data()\u003c/code\u003e.\u003c/p\u003e\r\n\r\n\u003cp\u003eHere are some examples where you load in the MNIST, CIFAR10 and IMDB data with the \u003ccode\u003ekeras\u003c/code\u003e package:\u003c/p\u003e\r\n\r\n\u003cpre\u003e\r\n\u003ccode\u003e# Read in MNIST data\r\nmnist \u0026lt;- dataset_mnist()\r\n\r\n# Read in CIFAR10 data\r\ncifar10 \u0026lt;- dataset_cifar10()\r\n\r\n# Read in IMDB data\r\nimdb \u0026lt;- dataset_imdb()\u003c/code\u003e\u003c/pre\u003e\r\n\r\n\u003cp\u003e\u003cstrong\u003eNote\u003c/strong\u003e that all functions to load in built-in data sets with \u003ccode\u003ekeras\u003c/code\u003e follow the same pattern; For MNIST data, you\u0026rsquo;ll use the \u003ccode\u003edataset_mnist()\u003c/code\u003e function to load in your data.\u003c/p\u003e\r\n\u003c/div\u003e\r\n\r\n\u003cdiv class=\"section level4\" id=\"dummy-data\"\u003e\r\n\u003ch3\u003eDummy Data\u003c/h3\u003e\r\n\r\n\u003cp\u003eAlternatively, you can also quickly make some dummy data to get started. You can easily use the \u003ccode\u003ematrix()\u003c/code\u003e function to accomplish this:\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"300\"\u003eeyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIE1ha2UgeW91ciBkdW1teSBkYXRhXG5kYXRhIDwtIG1hdHJpeChyZXhwKDEwMDAqNzg0KSwgbnJvdyA9IDEwMDAsIG5jb2wgPSA3ODQpXG5cbiMgTWFrZSBkdW1teSB0YXJnZXQgdmFsdWVzIGZvciB5b3VyIGR1bW15IGRhdGFcbmxhYmVscyA8LSBtYXRyaXgocm91bmQocnVuaWYoMTAwMCoxMCwgbWluID0gMCwgbWF4ID0gOSkpLCBucm93ID0gMTAwMCwgbmNvbCA9IDEwKSJ9\u003c/div\u003e\r\n\r\n\u003cp\u003e\u003cstrong\u003eNote\u003c/strong\u003e that it\u0026rsquo;s definitely a good idea to check out the data structure of your data; It\u0026rsquo;s very important to already be aware of what data you\u0026rsquo;re working with because it will be important for the later steps that you\u0026rsquo;ll need to take. You\u0026rsquo;ll learn more about this later on in the tutorial!\u003c/p\u003e\r\n\u003c/div\u003e\r\n\r\n\u003cdiv class=\"section level4\" id=\"reading-data-from-files\"\u003e\r\n\u003ch3\u003eReading Data From Files\u003c/h3\u003e\r\n\r\n\u003cp\u003eBesides the built-in datasets, you can also load in data from files. For this tutorial, you\u0026rsquo;ll focus on loading in data from CSV files, but if you want to know more about importing files in R, consider DataCamp\u0026rsquo;s \u003ca href=\"https://www.datacamp.com/community/tutorials/r-data-import-tutorial\"\u003eR Data Import Tutorial\u003c/a\u003e.\u003c/p\u003e\r\n\r\n\u003cp\u003eLet\u0026rsquo;s use the \u003ccode\u003eread.csv()\u003c/code\u003e function from the \u003ccode\u003eread.table\u003c/code\u003e package to load in a data set from the \u003ca href=\"http://archive.ics.uci.edu/ml/index.php\"\u003eUCI Machine Learning Repository\u003c/a\u003e:\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"300\"\u003eeyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIFJlYWQgaW4gYGlyaXNgIGRhdGFcbmlyaXMgPC0gcmVhZC5jc3YodXJsKFwiaHR0cDovL2FyY2hpdmUuaWNzLnVjaS5lZHUvbWwvbWFjaGluZS1sZWFybmluZy1kYXRhYmFzZXMvaXJpcy9pcmlzLmRhdGFcIiksIGhlYWRlciA9IEZBTFNFKSBcblxuIyBSZXR1cm4gdGhlIGZpcnN0IHBhcnQgb2YgYGlyaXNgXG5oZWFkKC4uLi4pXG5cbiMgSW5zcGVjdCB0aGUgc3RydWN0dXJlXG5zdHIoLi4uLilcblxuIyBPYnRhaW4gdGhlIGRpbWVuc2lvbnNcbmRpbSguLi4uKSIsInNvbHV0aW9uIjoiIyBSZWFkIGluIGBpcmlzYCBkYXRhXG5pcmlzIDwtIHJlYWQuY3N2KHVybChcImh0dHA6Ly9hcmNoaXZlLmljcy51Y2kuZWR1L21sL21hY2hpbmUtbGVhcm5pbmctZGF0YWJhc2VzL2lyaXMvaXJpcy5kYXRhXCIpLCBoZWFkZXIgPSBGQUxTRSkgXG5cbiMgUmV0dXJuIHRoZSBmaXJzdCBwYXJ0IG9mIGBpcmlzYFxuaGVhZChpcmlzKVxuXG4jIEluc3BlY3QgdGhlIHN0cnVjdHVyZVxuc3RyKGlyaXMpXG5cbiMgT2J0YWluIHRoZSBkaW1lbnNpb25zXG5kaW0oaXJpcykiLCJzY3QiOiJtc2dfdW5kZWZpbmVkIDwtIFwiRGlkIHlvdSBsb2FkIGluIHRoZSBpcmlzIGRhdGEgY29ycmVjdGx5P1wiXG5leCgpICU+JSBjaGVja19vYmplY3QoJ2lyaXMnLCBtc2dfdW5kZWZpbmVkKSAlPiUgY2hlY2tfZXF1YWwobXNnX3VuZGVmaW5lZClcbmV4KCkgJT4lIGNoZWNrX2Z1bmN0aW9uKFwiaGVhZFwiKSAlPiUgY2hlY2tfcmVzdWx0KCkgJT4lIGNoZWNrX2VxdWFsKClcbmV4KCkgJT4lIGNoZWNrX2Z1bmN0aW9uKFwic3RyXCIpICU+JSBjaGVja19yZXN1bHQoKSAlPiUgY2hlY2tfZXF1YWwoKVxuZXgoKSAlPiUgY2hlY2tfZnVuY3Rpb24oXCJkaW1cIikgJT4lIGNoZWNrX3Jlc3VsdCgpICU+JSBjaGVja19lcXVhbCgpXG5zdWNjZXNzX21zZyhcIkdyZWF0IGpvYiEgTm93LCBkb2VzIHRoaXMgcmVzdWx0IGNvbmZpcm0geW91ciBpbml0aWFsIGh5cG90aGVzaXMgb2YgYSBwb3NpdGl2ZSBpbmRpY2F0aW9uIGJldHdlZW4gdGhlc2UgdHdvIGF0dHJpYnV0ZXM/XCIpIn0=\u003c/div\u003e\r\n\r\n\u003cp\u003eIt\u0026rsquo;s always a good idea to check out whether your data import was successful. You usually use functions such as \u003ccode\u003ehead()\u003c/code\u003e, \u003ccode\u003estr()\u003c/code\u003e and \u003ccode\u003edim()\u003c/code\u003e like in the DataCamp Light chunk above to quickly do this.\u003c/p\u003e\r\n\r\n\u003cp\u003eThe results of these three functions do not immediately point out anything out of the ordinary; By looking at the output of the \u003ccode\u003estr()\u003c/code\u003e function, you see that the strings of the \u003ccode\u003eSpecies\u003c/code\u003e column are read in as factors. This is no problem, but it\u0026rsquo;s definitely good to know for the next steps, where you\u0026rsquo;re going to explore and preprocess the data.\u003c/p\u003e\r\n\u003c/div\u003e\r\n\r\n\u003ch2 id=\"explore\"\u003eData Exploration\u003c/h2\u003e\r\n\r\n\u003cp\u003eFor this tutorial, you\u0026rsquo;ll continue to work with the famous \u003ccode\u003eiris\u003c/code\u003e dataset that you imported with the \u003ccode\u003eread.csv()\u003c/code\u003e function.\u003c/p\u003e\r\n\r\n\u003cp\u003eFor those of you who don\u0026rsquo;t have the biology knowledge that is needed to work with this data, here\u0026rsquo;s some background information: all flowers contain a sepal and a petal. The sepal encloses the petals and is typically green and leaf-like, while the petals are typically colored leaves. For the iris flowers, this is just a little bit different, as you can see in the following picture:\u003c/p\u003e\r\n\r\n\u003cp\u003e\u003cimg alt=\"deep learning Python\" src=\"https://s3.amazonaws.com/assets.datacamp.com/blog_assets/iris-machinelearning.png\" /\u003e\u003c/p\u003e\r\n\r\n\u003cp\u003eYou might have already seen in the previous seciton that the \u003ccode\u003eiris\u003c/code\u003e data frame didn\u0026rsquo;t have any column names after the import. Now, for the remainder of the tutorial, that\u0026rsquo;s not too important: even though the \u003ccode\u003eread.csv()\u003c/code\u003e function returns the data in a \u003ccode\u003edata.frame\u003c/code\u003e to you, the data that you\u0026rsquo;ll need to pass to the \u003ccode\u003efit()\u003c/code\u003e function needs to be a matrix or array.\u003c/p\u003e\r\n\r\n\u003cp\u003eSome things to keep in mind about these two data structures that were just mentioned: - Matrices and arrays don\u0026rsquo;t have column names; - Matrices are two-dimensional objects of a single data type; - Arrays are multi-dimensional objects of a single data type;\u003c/p\u003e\r\n\r\n\u003cp\u003e\u003cstrong\u003eTip\u003c/strong\u003e: Check out \u003ca href=\"https://vimeo.com/130411487\"\u003ethis video\u003c/a\u003e if you want a recap of the data structures in R!\u003c/p\u003e\r\n\r\n\u003cp\u003e\u003cstrong\u003eNote\u003c/strong\u003e that the data frame, on the other hand, is a special kind of named list where all elements have the same length. It\u0026rsquo;s a multi-dimensional object that can contain multiple data types. You already saw that this is true when you checked out the structure of the \u003ccode\u003eiris\u003c/code\u003e data frame in the previous section. Knowing this and taking into account that you\u0026rsquo;ll need to work towards a two- or multi-dimensional object of a \u003cem\u003esingle\u003c/em\u003e data type, you should already prepare to do some preprocessing before you start building your neural network!\u003c/p\u003e\r\n\r\n\u003cp\u003eFor now, column names can be handy for exploring purposes and they will most definitely facilitate your understanding of the data, so let\u0026rsquo;s just add some column names with the help of the \u003ccode\u003enames()\u003c/code\u003e function. Next, you can immediately use the \u003ccode\u003eiris\u003c/code\u003e variable in your data exploration! Plot, for example, how the petal length and the petal width correlate with the \u003ccode\u003eplot()\u003c/code\u003e function.\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"300\"\u003eeyJsYW5ndWFnZSI6InIiLCJwcmVfZXhlcmNpc2VfY29kZSI6ImlyaXMgPC0gcmVhZC5jc3YodXJsKFwiaHR0cDovL2FyY2hpdmUuaWNzLnVjaS5lZHUvbWwvbWFjaGluZS1sZWFybmluZy1kYXRhYmFzZXMvaXJpcy9pcmlzLmRhdGFcIiksIGhlYWRlciA9IEZBTFNFKSAiLCJzYW1wbGUiOiJuYW1lcyhpcmlzKSA8LSBjKFwiU2VwYWwuTGVuZ3RoXCIsIFwiU2VwYWwuV2lkdGhcIiwgXCJQZXRhbC5MZW5ndGhcIiwgXCJQZXRhbC5XaWR0aFwiLCBcIlNwZWNpZXNcIilcblxucGxvdChpcmlzJFBldGFsLkxlbmd0aCwgXG4gICAgIGlyaXMkUGV0YWwuV2lkdGgsIFxuICAgICBwY2g9MjEsIGJnPWMoXCJyZWRcIixcImdyZWVuM1wiLFwiYmx1ZVwiKVt1bmNsYXNzKGlyaXMkU3BlY2llcyldLCBcbiAgICAgeGxhYj1cIlBldGFsIExlbmd0aFwiLCBcbiAgICAgeWxhYj1cIlBldGFsIFdpZHRoXCIpIn0=\u003c/div\u003e\r\n\r\n\u003cp\u003e\u003cstrong\u003eNote\u003c/strong\u003e that you use the \u003ccode\u003eunclass()\u003c/code\u003e function to convert the names of the species, that is, \u0026ldquo;setosa, versicolor\u0026rdquo;, and \u0026ldquo;virginica\u0026rdquo;, to the numeric 1, 2, and 3.\u003c/p\u003e\r\n\r\n\u003cp\u003eNow take a closer look at the result of the plotting function:\u003c/p\u003e\r\n\r\n\u003cp\u003e\u003cimg src=\"https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Correlation+Iris.png\" /\u003e\u003c/p\u003e\r\n\r\n\u003cp\u003eThe graph indicates a positive correlation between the \u003ccode\u003ePetal.Length\u003c/code\u003e and the \u003ccode\u003ePetal.Width\u003c/code\u003e for the different species of the iris flowers. However, this is something that you probably want to test with the \u003ccode\u003ecor()\u003c/code\u003e function, which will give you the overall correlation between all attributes that are included in the data set:\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"300\"\u003eeyJsYW5ndWFnZSI6InIiLCJwcmVfZXhlcmNpc2VfY29kZSI6ImlyaXMgPC0gcmVhZC5jc3YodXJsKFwiaHR0cDovL2FyY2hpdmUuaWNzLnVjaS5lZHUvbWwvbWFjaGluZS1sZWFybmluZy1kYXRhYmFzZXMvaXJpcy9pcmlzLmRhdGFcIiksIGhlYWRlciA9IEZBTFNFKSBcbm5hbWVzKGlyaXMpIDwtIGMoXCJTZXBhbC5MZW5ndGhcIiwgXCJTZXBhbC5XaWR0aFwiLCBcIlBldGFsLkxlbmd0aFwiLCBcIlBldGFsLldpZHRoXCIsIFwiU3BlY2llc1wiKSIsInNhbXBsZSI6IiMgT3ZlcmFsbCBjb3JyZWxhdGlvbiBiZXR3ZWVuIGBQZXRhbC5MZW5ndGhgIGFuZCBgUGV0YWwuV2lkdGhgIFxuY29yKC4uLi4uLi4uLi4uLi4uLi4uLCBpcmlzJFBldGFsLldpZHRoKSIsInNvbHV0aW9uIjoiIyBPdmVyYWxsIGNvcnJlbGF0aW9uIGJldHdlZW4gYFBldGFsLkxlbmd0aGAgYW5kIGBQZXRhbC5XaWR0aGAgXG5jb3IoaXJpcyRQZXRhbC5MZW5ndGgsIGlyaXMkUGV0YWwuV2lkdGgpIiwic2N0IjoiZXgoKSAlPiUgY2hlY2tfZnVuY3Rpb24oXCJjb3JcIikgJT4lIGNoZWNrX3Jlc3VsdCgpICU+JSBjaGVja19lcXVhbCgpXG5zdWNjZXNzX21zZyhcIkdyZWF0IGpvYiEgTm93LCBkb2VzIHRoaXMgcmVzdWx0IGNvbmZpcm0geW91ciBpbml0aWFsIGh5cG90aGVzaXMgb2YgYSBwb3NpdGl2ZSBpbmRpY2F0aW9uIGJldHdlZW4gdGhlc2UgdHdvIGF0dHJpYnV0ZXM/XCIpIn0=\u003c/div\u003e\r\n\r\n\u003cp\u003eAdditionally, you can use the \u003ccode\u003ecorrplot\u003c/code\u003e package in combination with the \u003ccode\u003ecor()\u003c/code\u003e function to plot the correlations between your data\u0026rsquo;s attributes; In this case, you calculate the overall correlation for all attributes of the \u003ccode\u003eiris\u003c/code\u003e data frame. You store the result of this calculation in a variable \u003ccode\u003eM\u003c/code\u003e and pass it to the \u003ccode\u003ecorrplot()\u003c/code\u003e function.\u003c/p\u003e\r\n\r\n\u003cp\u003eAlso, don\u0026rsquo;t forget to specify a \u003ccode\u003emethod\u003c/code\u003e argument to indicate how you want the data to be plotted!\u003c/p\u003e\r\n\r\n\u003cp\u003eYou can further experiment with the visualization method in the DataCamp Light chunk below:\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"300\"\u003eeyJsYW5ndWFnZSI6InIiLCJwcmVfZXhlcmNpc2VfY29kZSI6ImxpYnJhcnkoY29ycnBsb3QpXG5pcmlzIDwtIHJlYWQuY3N2KHVybChcImh0dHA6Ly9hcmNoaXZlLmljcy51Y2kuZWR1L21sL21hY2hpbmUtbGVhcm5pbmctZGF0YWJhc2VzL2lyaXMvaXJpcy5kYXRhXCIpLCBoZWFkZXIgPSBGQUxTRSkgXG5uYW1lcyhpcmlzKSA8LSBjKFwiU2VwYWwuTGVuZ3RoXCIsIFwiU2VwYWwuV2lkdGhcIiwgXCJQZXRhbC5MZW5ndGhcIiwgXCJQZXRhbC5XaWR0aFwiLCBcIlNwZWNpZXNcIikiLCJzYW1wbGUiOiIjIFN0b3JlIHRoZSBvdmVyYWxsIGNvcnJlbGF0aW9uIGluIGBNYFxuTSA8LSBjb3IoaXJpc1ssMTo0XSlcblxuIyBQbG90IHRoZSBjb3JyZWxhdGlvbiBwbG90IHdpdGggYE1gXG5jb3JycGxvdChNLCBtZXRob2Q9XCJjaXJjbGVcIikifQ==\u003c/div\u003e\r\n\r\n\u003cp\u003e\u003cimg src=\"https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Correlation+Plot.png\" /\u003e\u003c/p\u003e\r\n\r\n\u003cp\u003eMake use of the R console to explore your data further.\u003c/p\u003e\r\n\r\n\u003cp\u003eIf you want to make plots for this data with the \u003ccode\u003eggvis\u003c/code\u003e package, which is the interactive grammar of graphics, take a look at DataCamp\u0026rsquo;s \u003ca href=\"https://www.datacamp.com/community/tutorials/machine-learning-in-r\"\u003eMachine Learning in R For Beginners\u003c/a\u003e tutorial or take DataCamp\u0026rsquo;s \u003ca href=\"https://www.datacamp.com/courses/ggvis-data-visualization-r-tutorial/\"\u003eggvis course\u003c/a\u003e.\u003c/p\u003e\r\n\r\n\u003ch2 id=\"prep\"\u003eData Preprocessing\u003c/h2\u003e\r\n\r\n\u003cp\u003eBefore you can build your model, you also need to make sure that your data is cleaned, normalized (if applicable) and divided into training and test sets. Since the dataset comes from the UCI Machine Learning Repository, you can expect it to already be somewhat clean, but let\u0026rsquo;s double check the quality of your data anyway.\u003c/p\u003e\r\n\r\n\u003cp\u003eAt first sight, when you inspected the data with \u003ccode\u003ehead()\u003c/code\u003e, you didn\u0026rsquo;t really see anything out of the ordinary, right? Let\u0026rsquo;s make use of \u003ccode\u003esummary()\u003c/code\u003e and \u003ccode\u003estr()\u003c/code\u003e to briefly recap what you learned when you checked whether the import of your data was successful:\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"300\"\u003eeyJsYW5ndWFnZSI6InIiLCJwcmVfZXhlcmNpc2VfY29kZSI6ImlyaXMgPC0gcmVhZC5jc3YodXJsKFwiaHR0cDovL2FyY2hpdmUuaWNzLnVjaS5lZHUvbWwvbWFjaGluZS1sZWFybmluZy1kYXRhYmFzZXMvaXJpcy9pcmlzLmRhdGFcIiksIGhlYWRlciA9IEZBTFNFKSBcbm5hbWVzKGlyaXMpIDwtIGMoXCJTZXBhbC5MZW5ndGhcIiwgXCJTZXBhbC5XaWR0aFwiLCBcIlBldGFsLkxlbmd0aFwiLCBcIlBldGFsLldpZHRoXCIsIFwiU3BlY2llc1wiKSIsInNhbXBsZSI6IiMgUHVsbCB1cCBhIHN1bW1hcnkgb2YgYGlyaXNgXG5zdW1tYXJ5KC4uLi4pXG5cbiMgSW5zcGVjdCB0aGUgc3RydWN0dXJlIG9mIGBpcmlzYFxuc3RyKC4uLi4pIiwic29sdXRpb24iOiIjIFB1bGwgdXAgYSBzdW1tYXJ5IG9mIGBpcmlzYFxuc3VtbWFyeShpcmlzKVxuXG4jIEluc3BlY3QgdGhlIHN0cnVjdHVyZSBvZiBgaXJpc2BcbnN0cihpcmlzKSIsInNjdCI6ImV4KCkgJT4lIGNoZWNrX2Z1bmN0aW9uKFwic3VtbWFyeVwiKSAlPiUgY2hlY2tfcmVzdWx0KCkgJT4lIGNoZWNrX2VxdWFsKClcbmV4KCkgJT4lIGNoZWNrX2Z1bmN0aW9uKFwic3RyXCIpICU+JSBjaGVja19yZXN1bHQoKSAlPiUgY2hlY2tfZXF1YWwoKVxuc3VjY2Vzc19tc2coXCJHb29kIGpvYiEgTm93LCB3aGF0IGRvIHlvdSBsZWFybiBmcm9tIHRoZSBvdXRwdXQgb2YgdGhlc2UgbGluZXMgb2YgY29kZT9cIikifQ==\u003c/div\u003e\r\n\r\n\u003cp\u003eNow that you\u0026rsquo;re sure that the data is clean enough, you can start by checking if the normalization is necessary for any of the data with which you\u0026rsquo;re working for this tutorial.\u003c/p\u003e\r\n\r\n\u003cdiv class=\"section level3\" id=\"normalizing-your-data-with-a-user-defined-function-udf\"\u003e\r\n\u003ch3\u003eNormalizing Your Data With A User Defined Function (UDF)\u003c/h3\u003e\r\n\r\n\u003cp\u003eFrom the result of the \u003ccode\u003esummary()\u003c/code\u003e function in the DataCamp Light chunk above, you see that the Iris data set doesn\u0026rsquo;t need to be normalized: the \u003ccode\u003eSepal.Length\u003c/code\u003e attribute has values that go from \u003ccode\u003e4.3\u003c/code\u003e to \u003ccode\u003e7.9\u003c/code\u003e and \u003ccode\u003eSepal.Width\u003c/code\u003e contains values from \u003ccode\u003e2\u003c/code\u003e to \u003ccode\u003e4.4\u003c/code\u003e, while \u003ccode\u003ePetal.Length\u003c/code\u003e\u0026rsquo;s values range from \u003ccode\u003e1\u003c/code\u003e to \u003ccode\u003e6.9\u003c/code\u003e and \u003ccode\u003ePetal.Width\u003c/code\u003e goes from \u003ccode\u003e0.1\u003c/code\u003e to \u003ccode\u003e2.5\u003c/code\u003e. In other words, all values of all the attributes of the Iris data set are contained within the range of \u003ccode\u003e0.1\u003c/code\u003e and \u003ccode\u003e7.9\u003c/code\u003e, which you can consider acceptable.\u003c/p\u003e\r\n\r\n\u003cp\u003eHowever, it can still be a good idea to study the effect of normalization on your data; You can even go as far as passing the normalized data to your model to see if there is any effect. This is outside the scope of this tutorial, but feel free to try it out on your own! The code is all here in this tutorial :)\u003c/p\u003e\r\n\r\n\u003cp\u003eYou can make your own function to normalize the iris data; In this case, it\u0026rsquo;s a min-max normalization function, which linearly transforms your data to the function \u003cem\u003e(x-min)/(max-min)\u003c/em\u003e. From that perspective, translating this formula to R is pretty simple: you make a function to which you pass \u003ccode\u003ex\u003c/code\u003e or some data. You\u0026rsquo;ll then calculate the result of the first subtraction \u003cem\u003ex-min\u003c/em\u003e and store the result in \u003ccode\u003enum\u003c/code\u003e. Next, you also calculate \u003cem\u003emax-min\u003c/em\u003e and store the result in \u003ccode\u003edenom\u003c/code\u003e. The result of your \u003ccode\u003enormalize()\u003c/code\u003e function should return the division of \u003ccode\u003enum\u003c/code\u003e by \u003ccode\u003emax\u003c/code\u003e.\u003c/p\u003e\r\n\r\n\u003cp\u003eTo apply this user-defined function on your \u003ccode\u003eiris\u003c/code\u003e data (target values excluded), you need to not only use \u003ccode\u003enormalize\u003c/code\u003e, but also the \u003ccode\u003elapply()\u003c/code\u003e function to normalize the data, just like here below:\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"300\"\u003eeyJsYW5ndWFnZSI6InIiLCJwcmVfZXhlcmNpc2VfY29kZSI6ImlyaXMgPC0gcmVhZC5jc3YodXJsKFwiaHR0cDovL2FyY2hpdmUuaWNzLnVjaS5lZHUvbWwvbWFjaGluZS1sZWFybmluZy1kYXRhYmFzZXMvaXJpcy9pcmlzLmRhdGFcIiksIGhlYWRlciA9IEZBTFNFKSBcbm5hbWVzKGlyaXMpIDwtIGMoXCJTZXBhbC5MZW5ndGhcIiwgXCJTZXBhbC5XaWR0aFwiLCBcIlBldGFsLkxlbmd0aFwiLCBcIlBldGFsLldpZHRoXCIsIFwiU3BlY2llc1wiKSIsInNhbXBsZSI6IiMgQnVpbGQgeW91ciBvd24gYG5vcm1hbGl6ZSgpYCBmdW5jdGlvblxubm9ybWFsaXplIDwtIGZ1bmN0aW9uKHgpIHtcbiAgbnVtIDwtIHggLSBtaW4oeClcbiAgZGVub20gPC0gbWF4KHgpIC0gbWluKHgpXG4gIHJldHVybiAobnVtL2Rlbm9tKVxufVxuXG4jIE5vcm1hbGl6ZSB0aGUgYGlyaXNgIGRhdGFcbmlyaXNfbm9ybSA8LSBhcy5kYXRhLmZyYW1lKGxhcHBseShpcmlzWzE6NF0sIC4uLi4uLi4uLikpXG5cbiMgUmV0dXJuIHRoZSBmaXJzdCBwYXJ0IG9mIGBpcmlzYCBcbmhlYWQoLi4uLikiLCJzb2x1dGlvbiI6IiMgQnVpbGQgeW91ciBvd24gYG5vcm1hbGl6ZSgpYCBmdW5jdGlvblxubm9ybWFsaXplIDwtIGZ1bmN0aW9uKHgpIHtcbiAgbnVtIDwtIHggLSBtaW4oeClcbiAgZGVub20gPC0gbWF4KHgpIC0gbWluKHgpXG4gIHJldHVybiAobnVtL2Rlbm9tKVxufVxuXG4jIE5vcm1hbGl6ZSB0aGUgYGlyaXNgIGRhdGFcbmlyaXNfbm9ybSA8LSBhcy5kYXRhLmZyYW1lKGxhcHBseShpcmlzWzE6NF0sIG5vcm1hbGl6ZSkpXG5cbiMgUmV0dXJuIHRoZSBmaXJzdCBwYXJ0IG9mIGBpcmlzYCBcbmhlYWQoaXJpcykiLCJzY3QiOiJtc2dfdW5kZWZpbmVkIDwtIFwiTWFrZSBzdXJlIHRvIGRlZmluZSBhIHZhcmlhYmxlIGBpcmlzX25vcm1gLlwiXG5tc2dfaW5jb3JyZWN0IDwtIFwiTWFrZSBzdXJlIHRoYXQgeW91IGFzc2lnbiB0aGUgY29ycmVjdCB2YWx1ZSB0byBgaXJpc19ub3JtYC5cIlxuXG5mdW5fZGVmIDwtIGV4KCkgJT4lIGNoZWNrX2Z1bl9kZWYoXCJub3JtYWxpemVcIilcbmZ1bl9kZWYgJT4lIGNoZWNrX2JvZHkoKVxuZXgoKSAlPiUgY2hlY2tfb2JqZWN0KCdpcmlzX25vcm0nLCBtc2dfdW5kZWZpbmVkKSAlPiUgY2hlY2tfZXF1YWwobXNnX2luY29ycmVjdClcbmV4KCkgJT4lIGNoZWNrX2Z1bmN0aW9uKFwiaGVhZFwiKSAlPiUgY2hlY2tfcmVzdWx0KCkgJT4lIGNoZWNrX2VxdWFsKClcbnN1Y2Nlc3NfbXNnKFwiV2VsbCBkb25lISBOb3cgeW91IGNhbiBtb3ZlIG9uIHRvIHNlZSBob3cgeW91IGNhbiBub3JtYWxpemUgeW91ciBkYXRhIHdpdGgga2VyYXMhXCIpIn0=\u003c/div\u003e\r\n\r\n\u003cp\u003e\u003cstrong\u003eTip\u003c/strong\u003e use the \u003ccode\u003ehist()\u003c/code\u003e function in the R console to to study the distribution of the Iris data before (\u003ccode\u003eiris\u003c/code\u003e) and after the normalization (\u003ccode\u003eiris_norm\u003c/code\u003e).\u003c/p\u003e\r\n\u003c/div\u003e\r\n\r\n\u003cdiv class=\"section level3\" id=\"normalize-your-data-with-keras\"\u003e\r\n\u003ch3\u003eNormalize Your Data With \u003ccode\u003ekeras\u003c/code\u003e\u003c/h3\u003e\r\n\r\n\u003cp\u003eTo use the \u003ccode\u003enormalize()\u003c/code\u003e function from the \u003ccode\u003ekeras\u003c/code\u003e package, you first need to make sure that you\u0026rsquo;re working with a matrix. As you probably remember from earlier, the characteristic of matrices is that the matrix data elements are of the same basic type; In this case, you have target values that are of type factor, while the rest is all numeric.\u003c/p\u003e\r\n\r\n\u003cp\u003eThis needs to change first.\u003c/p\u003e\r\n\r\n\u003cp\u003eYou can use the \u003ccode\u003eas.numeric()\u003c/code\u003e function to convert the data to numbers:\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"300\"\u003eeyJsYW5ndWFnZSI6InIiLCJwcmVfZXhlcmNpc2VfY29kZSI6ImlyaXMgPC0gcmVhZC5jc3YodXJsKFwiaHR0cDovL2FyY2hpdmUuaWNzLnVjaS5lZHUvbWwvbWFjaGluZS1sZWFybmluZy1kYXRhYmFzZXMvaXJpcy9pcmlzLmRhdGFcIiksIGhlYWRlciA9IEZBTFNFKSBcbm5hbWVzKGlyaXMpIDwtIGMoXCJTZXBhbC5MZW5ndGhcIiwgXCJTZXBhbC5XaWR0aFwiLCBcIlBldGFsLkxlbmd0aFwiLCBcIlBldGFsLldpZHRoXCIsIFwiU3BlY2llc1wiKSIsInNhbXBsZSI6ImlyaXNbLDVdIDwtIC4uLi4uLi4uLi4uKGlyaXNbLDVdKSAtMVxuXG4jIFR1cm4gYGlyaXNgIGludG8gYSBtYXRyaXhcbmlyaXMgPC0gYXMubWF0cml4KGlyaXMpXG5cbiMgU2V0IGBpcmlzYCBgZGltbmFtZXNgIHRvIGBOVUxMYFxuZGltbmFtZXMoLi4uLikgPC0gTlVMTCIsInNvbHV0aW9uIjoiaXJpc1ssNV0gPC0gYXMubnVtZXJpYyhpcmlzWyw1XSkgLTFcblxuIyBUdXJuIGBpcmlzYCBpbnRvIGEgbWF0cml4XG5pcmlzIDwtIGFzLm1hdHJpeChpcmlzKVxuXG4jIFNldCBpcmlzIGBkaW1uYW1lc2AgdG8gYE5VTExgXG5kaW1uYW1lcyhpcmlzKSA8LSBOVUxMIiwic2N0IjoibXNnX3VuZGVmaW5lZCA8LSBcIkRpZCB5b3UgdXNlIGBhcy5udW1lcmljKClgIHRvIGNvbnZlcnQgYGlyaXNbLDVdYCB0byBudW1lcmljP1wiXG5leCgpICU+JSBjaGVja19vYmplY3QoJ2lyaXMnLCBtc2dfdW5kZWZpbmVkKSAlPiUgY2hlY2tfZXF1YWwobXNnX3VuZGVmaW5lZClcbm1zZ191bmRlZmluZWQyIDwtIFwiRGlkIHlvdSB1c2UgYGFzLm1hdHJpeGAgdG8gY29udmVydCBgaXJpc2AgdG8gYSBtYXRyaXg/XCJcbmV4KCkgJT4lIGNoZWNrX29iamVjdCgnaXJpcycsIG1zZ191bmRlZmluZWQyKSAlPiUgY2hlY2tfZXF1YWwobXNnX3VuZGVmaW5lZDIpXG5leCgpICU+JSBjaGVja19mdW5jdGlvbihcImRpbW5hbWVzXCIpICU+JSBjaGVja19yZXN1bHQoKSAlPiUgY2hlY2tfZXF1YWwoKVxuc3VjY2Vzc19tc2coXCJBd2Vzb21lIVwiKSJ9\u003c/div\u003e\r\n\r\n\u003cp\u003eA numerical data frame is alright, but you\u0026rsquo;ll need to convert the data to an array or a matrix if you want to make use of the \u003ccode\u003ekeras\u003c/code\u003e package. You can easily do this with the \u003ccode\u003eas.matrix()\u003c/code\u003e function; Don\u0026rsquo;t forget here to set the \u003ccode\u003edimnames\u003c/code\u003e to \u003ccode\u003eNULL\u003c/code\u003e.\u003c/p\u003e\r\n\r\n\u003cp\u003eAs you might have read in the section above, normalizing the Iris data is not necessary. Nevertheless, it\u0026rsquo;s still a good idea to study normalization and its effect, and to see how this can not only be done with a UDF but also with the \u003ccode\u003ekeras\u003c/code\u003e built-in \u003ccode\u003enormalize()\u003c/code\u003e function.\u003c/p\u003e\r\n\r\n\u003cp\u003eWith your data converted to a matrix, you can indeed also use the \u003ccode\u003ekeras\u003c/code\u003e package to study the effect of a possible normalization on your data:\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"300\"\u003eeyJsYW5ndWFnZSI6InIiLCJwcmVfZXhlcmNpc2VfY29kZSI6ImxpYnJhcnkoa2VyYXMpXG5pcmlzIDwtIHJlYWQuY3N2KHVybChcImh0dHA6Ly9hcmNoaXZlLmljcy51Y2kuZWR1L21sL21hY2hpbmUtbGVhcm5pbmctZGF0YWJhc2VzL2lyaXMvaXJpcy5kYXRhXCIpLCBoZWFkZXIgPSBGQUxTRSkgXG5uYW1lcyhpcmlzKSA8LSBjKFwiU2VwYWwuTGVuZ3RoXCIsIFwiU2VwYWwuV2lkdGhcIiwgXCJQZXRhbC5MZW5ndGhcIiwgXCJQZXRhbC5XaWR0aFwiLCBcIlNwZWNpZXNcIilcbmlyaXNbLDVdIDwtIGFzLm51bWVyaWMoaXJpc1ssNV0pIC0xXG5pcmlzIDwtIGFzLm1hdHJpeChpcmlzKVxuZGltbmFtZXMoaXJpcykgPC0gTlVMTCIsInNhbXBsZSI6IiMgTm9ybWFsaXplIHRoZSBgaXJpc2AgZGF0YVxuaXJpcyA8LSBub3JtYWxpemUoLi4uLlssMTo0XSlcblxuIyBSZXR1cm4gdGhlIHN1bW1hcnkgb2YgYGlyaXNgXG5zdW1tYXJ5KC4uLi4pIiwic29sdXRpb24iOiIjIE5vcm1hbGl6ZSB0aGUgYGlyaXNgIGRhdGFcbmlyaXMgPC0gbm9ybWFsaXplKGlyaXNbLDE6NF0pXG5cbiMgUmV0dXJuIHRoZSBzdW1tYXJ5IG9mIGBpcmlzYFxuc3VtbWFyeShpcmlzKSIsInNjdCI6Im1zZ191bmRlZmluZWQgPC0gXCJEaWQgeW91IG5vcm1hbGl6ZSB0aGUgYGlyaXNgIGRhdGE/XCJcbmV4KCkgJT4lIGNoZWNrX29iamVjdChcImlyaXNcIiwgbXNnX3VuZGVmaW5lZCkgJT4lIGNoZWNrX2VxdWFsKG1zZ191bmRlZmluZWQpXG5leCgpICU+JSBjaGVja19mdW5jdGlvbihcInN1bW1hcnlcIikgJT4lIGNoZWNrX3Jlc3VsdCgpICU+JSBjaGVja19lcXVhbCgpXG5zdWNjZXNzX21zZyhcIkF3ZXNvbWUhIE5vdywgaG93IGRvZXMgdGhpcyBzdW1tYXJ5IGNvbXBhcmUgdG8gdGhlIHByZXZpb3VzIHN1bW1hcnkgdGhhdCB5b3UgcmV0cmlldmVkIGluIHRoZSBEYXRhQ2FtcCBMaWdodCBjaHVuayBhYm92ZT9cIikifQ==\u003c/div\u003e\r\n\r\n\u003cp\u003e\u003cstrong\u003eNote\u003c/strong\u003e that here, you use \u003ccode\u003edimnames()\u003c/code\u003e to set the dimnames of \u003ccode\u003eiris\u003c/code\u003e to \u003ccode\u003eNULL\u003c/code\u003e. This ensures that there are no column names in your data.\u003c/p\u003e\r\n\u003c/div\u003e\r\n\r\n\u003cdiv class=\"section level3\" id=\"training-and-test-sets\"\u003e\r\n\u003ch3\u003eTraining And Test Sets\u003c/h3\u003e\r\n\r\n\u003cp\u003eNow that you have checked the quality of your data and you know that it\u0026rsquo;s not necessary to normalize your data, you can continue to work with the original data and split it into training and test sets so that you\u0026rsquo;re finally ready to start building your model. By doing this, you ensure that you can make honest assessments of the performance of your predicte model afterwards.\u003c/p\u003e\r\n\r\n\u003cp\u003eBefore you split your data into training and test sets, you best first set a seed. You can easily do this with \u003ccode\u003eset.seed()\u003c/code\u003e: use this exact function and just pass a random integer to it. A seed is a number of R\u0026rsquo;s random number generator. The major advantage of setting a seed is that you can get the same sequence of random numbers whenever you supply the same seed in the random number generator.\u003c/p\u003e\r\n\r\n\u003cp\u003eThis is great for the reproducibility of your code!\u003c/p\u003e\r\n\r\n\u003cp\u003eYou use the \u003ccode\u003esample()\u003c/code\u003e function to take a sample with a size that is set as the number of rows of the Iris data set, or 150. You sample with replacement: you choose from a vector of 2 elements and assign either 1 or 2 to the 150 rows of the Iris data set. The assignment of the elements is subject to probability weights of \u003ccode\u003e0.67\u003c/code\u003e and \u003ccode\u003e0.33\u003c/code\u003e.\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"300\"\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\u003c/div\u003e\r\n\r\n\u003cp\u003eThe \u003ccode\u003ereplace\u003c/code\u003e argument of the \u003ccode\u003esample()\u003c/code\u003e function is set to \u003ccode\u003eTRUE\u003c/code\u003e, which means that you assign a \u003ccode\u003e1\u003c/code\u003e or a \u003ccode\u003e2\u003c/code\u003e to a certain row and then reset the vector of \u003ccode\u003e2\u003c/code\u003e to its original state.\u003c/p\u003e\r\n\r\n\u003cp\u003eIn other words, for the next rows in your data set, you can either assign a \u003ccode\u003e1\u003c/code\u003e or a \u003ccode\u003e2\u003c/code\u003e, each time again. The probability of choosing a \u003ccode\u003e1\u003c/code\u003e or a \u003ccode\u003e2\u003c/code\u003e should not be proportional to the weights amongst the remaining items, so you specify probability weights.\u003c/p\u003e\r\n\r\n\u003cp\u003e\u003cem\u003eSide note:\u003c/em\u003e if you would have used a built-in dataset with the specific \u003ccode\u003edataset_imdb()\u003c/code\u003e function, for example, your data can easily be split by using the \u003ccode\u003e$\u003c/code\u003e operator:\u003c/p\u003e\r\n\r\n\u003cpre\u003e\r\n\u003ccode\u003ex_train \u0026lt;- imdb$train$x\r\ny_train \u0026lt;- imdb$train$y\r\nx_test \u0026lt;- imdb$test$x\r\ny_test \u0026lt;- imdb$test$y\u003c/code\u003e\u003c/pre\u003e\r\n\u003c/div\u003e\r\n\r\n\u003cdiv class=\"section level3\" id=\"one-hot-encoding\"\u003e\r\n\u003ch3\u003eOne-Hot Encoding\u003c/h3\u003e\r\n\r\n\u003cp\u003eYou have successfully split your data but there is still one step that you need to go through to start building your model. Can you guess which one?\u003c/p\u003e\r\n\r\n\u003cp\u003eWhen you want to model multi-class classification problems with neural networks, it is generally a good practice to make sure that you transform your target attribute from a vector that contains values for each class value to a matrix with a boolean for each class value and whether or not a given instance has that class value or not.\u003c/p\u003e\r\n\r\n\u003cp\u003eThis is a loose explanation of One Hot Encoding (OHE). It sounds quite complex, doesn\u0026rsquo;t it?\u003c/p\u003e\r\n\r\n\u003cp\u003eLuckily, the \u003ccode\u003ekeras\u003c/code\u003e package has a \u003ccode\u003eto_categorical()\u003c/code\u003e function that will do all of this for you; Pass in the \u003ccode\u003eiris.trainingtarget\u003c/code\u003e and the \u003ccode\u003eiris.testtarget\u003c/code\u003e to this function and store the result in \u003ccode\u003eiris.trainLabels\u003c/code\u003e and \u003ccode\u003eiris.testLabels\u003c/code\u003e:\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"300\"\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\u003c/div\u003e\r\n\r\n\u003cp\u003eNow you have officially reached the end of the exploration and preprocessing steps in this tutorial. You can now go on to building your neural network with \u003ccode\u003ekeras\u003c/code\u003e!\u003c/p\u003e\r\n\u003c/div\u003e\r\n\r\n\u003ch2 id=\"model\"\u003eConstructing the Model\u003c/h2\u003e\r\n\r\n\u003cp\u003eTo start constructing a model, you should first initialize a sequential model with the help of the \u003ccode\u003ekeras_model_sequential()\u003c/code\u003e function. Then, you\u0026rsquo;re ready to start modeling.\u003c/p\u003e\r\n\r\n\u003cp\u003eHowever, before you begin, it\u0026rsquo;s a good idea to revisit your original question about this data set: can you predict the species of a certain Iris flower? It\u0026rsquo;s easier to work with numerical data and you have preprocessed the data and one hot encoded the values of the target variable: a flower is either of type versicolor, setosa or virginica and this is reflected with binary \u003ccode\u003e1\u003c/code\u003e and \u003ccode\u003e0\u003c/code\u003e values.\u003c/p\u003e\r\n\r\n\u003cp\u003eA type of network that performs well on such a problem is a multi-layer perceptron. This type of neural network is often fully connected. That means that you\u0026rsquo;re looking to build a fairly simple stack of fully-connected layers to solve this problem. As for the activation functions that you will use, it\u0026rsquo;s best to use one of the most common ones here for the purpose of getting familiar with Keras and neural networks, which is the relu activation function. This rectifier activation function is used in a hidden layer, which is generally speaking a good practice.\u003c/p\u003e\r\n\r\n\u003cp\u003eIn addition, you also see that the softmax activation function is used in the output layer. You do this because you want to make sure that the output values are in the range of 0 and 1 and may be used as predicted probabilities:\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"300\"\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\u003c/div\u003e\r\n\r\n\u003cp\u003e\u003cstrong\u003eNote\u003c/strong\u003e how the output layer creates 3 output values, one for each Iris class (versicolor, virginica or setosa). The first layer, which contains 8 hidden notes, on the other hand, has an \u003ccode\u003einput_shape\u003c/code\u003e of 4. This is because your training data \u003ccode\u003eiris.training\u003c/code\u003e has 4 columns.\u003c/p\u003e\r\n\r\n\u003cp\u003eYou can further inspect your model with the following functions:\u003c/p\u003e\r\n\r\n\u003cul\u003e\r\n\t\u003cli\u003eYou can use the \u003ccode\u003esummary()\u003c/code\u003e function to print a summary representation of your model;\u003c/li\u003e\r\n\t\u003cli\u003e\u003ccode\u003eget_config()\u003c/code\u003e will return a list that contains the configuration of the model;\u003c/li\u003e\r\n\t\u003cli\u003e\u003ccode\u003eget_layer()\u003c/code\u003e will return the layer configuration.\u003c/li\u003e\r\n\t\u003cli\u003e\u003ccode\u003elayers\u003c/code\u003e attribute can be used to retrieve a flattened list of the model\u0026rsquo;s layers;\u003c/li\u003e\r\n\t\u003cli\u003eTo list the input tensors, you can use the \u003ccode\u003einputs\u003c/code\u003e attribute; and\u003c/li\u003e\r\n\t\u003cli\u003eLastly, to retrieve the output tensors, you can make use of the \u003ccode\u003eoutputs\u003c/code\u003e attribute.\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"400\"\u003eeyJsYW5ndWFnZSI6InIiLCJwcmVfZXhlcmNpc2VfY29kZSI6InNldC5zZWVkKDEyMzQpXG5saWJyYXJ5KGtlcmFzKVxuaXJpcyA8LSByZWFkLmNzdih1cmwoXCJodHRwOi8vYXJjaGl2ZS5pY3MudWNpLmVkdS9tbC9tYWNoaW5lLWxlYXJuaW5nLWRhdGFiYXNlcy9pcmlzL2lyaXMuZGF0YVwiKSwgaGVhZGVyID0gRkFMU0UpIFxubmFtZXMoaXJpcykgPC0gYyhcIlNlcGFsLkxlbmd0aFwiLCBcIlNlcGFsLldpZHRoXCIsIFwiUGV0YWwuTGVuZ3RoXCIsIFwiUGV0YWwuV2lkdGhcIiwgXCJTcGVjaWVzXCIpXG5pcmlzWyw1XSA8LSBhcy5udW1lcmljKGlyaXNbLDVdKSAtMVxuaXJpcyA8LSBhcy5tYXRyaXgoaXJpcylcbmRpbW5hbWVzKGlyaXMpIDwtIE5VTExcbmluZCA8LSBzYW1wbGUoMiwgbnJvdyhpcmlzKSwgcmVwbGFjZT1UUlVFLCBwcm9iPWMoMC42NywgMC4zMykpXG5pcmlzLnRyYWluaW5nIDwtIGlyaXNbaW5kPT0xLCAxOjRdXG5pcmlzLnRlc3QgPC0gaXJpc1tpbmQ9PTIsIDE6NF1cbmlyaXMudHJhaW5pbmd0YXJnZXQgPC0gaXJpc1tpbmQ9PTEsNV1cbmlyaXMudGVzdHRhcmdldCA8LSBpcmlzW2luZD09MiwgNV1cbmlyaXMudHJhaW5MYWJlbHMgPC0gdG9fY2F0ZWdvcmljYWwoaXJpcy50cmFpbmluZ3RhcmdldClcbmlyaXMudGVzdExhYmVscyA8LSB0b19jYXRlZ29yaWNhbChpcmlzLnRlc3R0YXJnZXQpXG5tb2RlbCA8LSBrZXJhc19tb2RlbF9zZXF1ZW50aWFsKCkgXG5tb2RlbCAlPiUgXG4gICAgbGF5ZXJfZGVuc2UodW5pdHMgPSA4LCBhY3RpdmF0aW9uID0gJ3JlbHUnLCBpbnB1dF9zaGFwZSA9IGMoNCkpICU+JSBcbiAgICBsYXllcl9kZW5zZSh1bml0cyA9IDMsIGFjdGl2YXRpb24gPSAnc29mdG1heCcpIiwic2FtcGxlIjoiIyBQcmludCBhIHN1bW1hcnkgb2YgYSBtb2RlbFxuc3VtbWFyeShtb2RlbClcblxuIyBHZXQgbW9kZWwgY29uZmlndXJhdGlvblxuZ2V0X2NvbmZpZyhtb2RlbClcblxuIyBHZXQgbGF5ZXIgY29uZmlndXJhdGlvblxuZ2V0X2xheWVyKG1vZGVsLCBpbmRleCA9IDEpXG5cbiMgTGlzdCB0aGUgbW9kZWwncyBsYXllcnNcbm1vZGVsJGxheWVyc1xuXG4jIExpc3QgdGhlIGlucHV0IHRlbnNvcnNcbm1vZGVsJGlucHV0c1xuXG4jIExpc3QgdGhlIG91dHB1dCB0ZW5zb3JzXG5tb2RlbCRvdXRwdXRzIn0=\u003c/div\u003e\r\n\r\n\u003ch2 id=\"compile\"\u003eCompile And Fit The Model\u003c/h2\u003e\r\n\r\n\u003cp\u003eNow that you have set up the architecture of your model, it\u0026rsquo;s time to compile and fit the model to the data. To compile your model, you configure the model with the \u003ccode\u003eadam\u003c/code\u003e optimizer and the \u003ccode\u003ecategorical_crossentropy\u003c/code\u003e loss function. Additionally, you also monitor the accuracy during the training by passing \u003ccode\u003e\u0026#39;accuracy\u0026#39;\u003c/code\u003e to the metrics argument.\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"300\"\u003eeyJsYW5ndWFnZSI6InIiLCJwcmVfZXhlcmNpc2VfY29kZSI6InNldC5zZWVkKDEyMzQpXG5saWJyYXJ5KGtlcmFzKVxuaXJpcyA8LSByZWFkLmNzdih1cmwoXCJodHRwOi8vYXJjaGl2ZS5pY3MudWNpLmVkdS9tbC9tYWNoaW5lLWxlYXJuaW5nLWRhdGFiYXNlcy9pcmlzL2lyaXMuZGF0YVwiKSwgaGVhZGVyID0gRkFMU0UpIFxubmFtZXMoaXJpcykgPC0gYyhcIlNlcGFsLkxlbmd0aFwiLCBcIlNlcGFsLldpZHRoXCIsIFwiUGV0YWwuTGVuZ3RoXCIsIFwiUGV0YWwuV2lkdGhcIiwgXCJTcGVjaWVzXCIpXG5pcmlzWyw1XSA8LSBhcy5udW1lcmljKGlyaXNbLDVdKSAtMVxuaXJpcyA8LSBhcy5tYXRyaXgoaXJpcylcbmRpbW5hbWVzKGlyaXMpIDwtIE5VTExcbmluZCA8LSBzYW1wbGUoMiwgbnJvdyhpcmlzKSwgcmVwbGFjZT1UUlVFLCBwcm9iPWMoMC42NywgMC4zMykpXG5pcmlzLnRyYWluaW5nIDwtIGlyaXNbaW5kPT0xLCAxOjRdXG5pcmlzLnRlc3QgPC0gaXJpc1tpbmQ9PTIsIDE6NF1cbmlyaXMudHJhaW5pbmd0YXJnZXQgPC0gaXJpc1tpbmQ9PTEsNV1cbmlyaXMudGVzdHRhcmdldCA8LSBpcmlzW2luZD09MiwgNV1cbmlyaXMudHJhaW5MYWJlbHMgPC0gdG9fY2F0ZWdvcmljYWwoaXJpcy50cmFpbmluZ3RhcmdldClcbmlyaXMudGVzdExhYmVscyA8LSB0b19jYXRlZ29yaWNhbChpcmlzLnRlc3R0YXJnZXQpXG5tb2RlbCA8LSBrZXJhc19tb2RlbF9zZXF1ZW50aWFsKCkgXG5tb2RlbCAlPiUgXG4gICAgbGF5ZXJfZGVuc2UodW5pdHMgPSA4LCBhY3RpdmF0aW9uID0gJ3JlbHUnLCBpbnB1dF9zaGFwZSA9IGMoNCkpICU+JSBcbiAgICBsYXllcl9kZW5zZSh1bml0cyA9IDMsIGFjdGl2YXRpb24gPSAnc29mdG1heCcpIiwic2FtcGxlIjoiIyBDb21waWxlIHRoZSBtb2RlbFxubW9kZWwgJT4lIGNvbXBpbGUoXG4gICAgIGxvc3MgPSAnY2F0ZWdvcmljYWxfY3Jvc3NlbnRyb3B5JyxcbiAgICAgb3B0aW1pemVyID0gJ2FkYW0nLFxuICAgICBtZXRyaWNzID0gJ2FjY3VyYWN5J1xuICkifQ==\u003c/div\u003e\r\n\r\n\u003cp\u003eThe optimizer and the loss are two arguments that are required if you want to compile the model.\u003c/p\u003e\r\n\r\n\u003cp\u003eSome of the most popular optimization algorithms used are the Stochastic Gradient Descent (SGD), ADAM and RMSprop. Depending on whichever algorithm you choose, you\u0026rsquo;ll need to tune certain parameters, such as learning rate or momentum. The choice for a loss function depends on the task that you have at hand: for example, for a regression problem, you\u0026rsquo;ll usually use the Mean Squared Error (MSE).\u003c/p\u003e\r\n\r\n\u003cp\u003eAs you see in this example, you used \u003ccode\u003ecategorical_crossentropy\u003c/code\u003e loss function for the multi-class classification problem of determining whether an iris is of type versicolor, virginica or setosa. However, note that if you would have had a binary-class classification problem, you should have made use of the \u003ccode\u003ebinary_crossentropy\u003c/code\u003e loss function.\u003c/p\u003e\r\n\r\n\u003cp\u003eNext, you can also fit the model to your data; In this case, you train the model for 200 epochs or iterations over all the samples in \u003ccode\u003eiris.training\u003c/code\u003e and \u003ccode\u003eiris.trainLabels\u003c/code\u003e, in batches of 5 samples.\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"300\"\u003eeyJsYW5ndWFnZSI6InIiLCJwcmVfZXhlcmNpc2VfY29kZSI6InNldC5zZWVkKDEyMzQpXG5saWJyYXJ5KGtlcmFzKVxuaXJpcyA8LSByZWFkLmNzdih1cmwoXCJodHRwOi8vYXJjaGl2ZS5pY3MudWNpLmVkdS9tbC9tYWNoaW5lLWxlYXJuaW5nLWRhdGFiYXNlcy9pcmlzL2lyaXMuZGF0YVwiKSwgaGVhZGVyID0gRkFMU0UpIFxubmFtZXMoaXJpcykgPC0gYyhcIlNlcGFsLkxlbmd0aFwiLCBcIlNlcGFsLldpZHRoXCIsIFwiUGV0YWwuTGVuZ3RoXCIsIFwiUGV0YWwuV2lkdGhcIiwgXCJTcGVjaWVzXCIpXG5pcmlzWyw1XSA8LSBhcy5udW1lcmljKGlyaXNbLDVdKSAtMVxuaXJpcyA8LSBhcy5tYXRyaXgoaXJpcylcbmRpbW5hbWVzKGlyaXMpIDwtIE5VTExcbmluZCA8LSBzYW1wbGUoMiwgbnJvdyhpcmlzKSwgcmVwbGFjZT1UUlVFLCBwcm9iPWMoMC42NywgMC4zMykpXG5pcmlzLnRyYWluaW5nIDwtIGlyaXNbaW5kPT0xLCAxOjRdXG5pcmlzLnRlc3QgPC0gaXJpc1tpbmQ9PTIsIDE6NF1cbmlyaXMudHJhaW5pbmd0YXJnZXQgPC0gaXJpc1tpbmQ9PTEsNV1cbmlyaXMudGVzdHRhcmdldCA8LSBpcmlzW2luZD09MiwgNV1cbmlyaXMudHJhaW5MYWJlbHMgPC0gdG9fY2F0ZWdvcmljYWwoaXJpcy50cmFpbmluZ3RhcmdldClcbmlyaXMudGVzdExhYmVscyA8LSB0b19jYXRlZ29yaWNhbChpcmlzLnRlc3R0YXJnZXQpXG5tb2RlbCA8LSBrZXJhc19tb2RlbF9zZXF1ZW50aWFsKCkgXG5tb2RlbCAlPiUgXG4gICAgbGF5ZXJfZGVuc2UodW5pdHMgPSA4LCBhY3RpdmF0aW9uID0gJ3JlbHUnLCBpbnB1dF9zaGFwZSA9IGMoNCkpICU+JSBcbiAgICBsYXllcl9kZW5zZSh1bml0cyA9IDMsIGFjdGl2YXRpb24gPSAnc29mdG1heCcpXG5tb2RlbCAlPiUgY29tcGlsZShcbiAgICAgbG9zcyA9ICdjYXRlZ29yaWNhbF9jcm9zc2VudHJvcHknLFxuICAgICBvcHRpbWl6ZXIgPSAnYWRhbScsXG4gICAgIG1ldHJpY3MgPSAnYWNjdXJhY3knXG4gKSIsInNhbXBsZSI6IiMgRml0IHRoZSBtb2RlbCBcbm1vZGVsICU+JSBmaXQoXG4gICAgIGlyaXMudHJhaW5pbmcsIFxuICAgICBpcmlzLnRyYWluTGFiZWxzLCBcbiAgICAgZXBvY2hzID0gMjAwLCBcbiAgICAgYmF0Y2hfc2l6ZSA9IDUsIFxuICAgICB2YWxpZGF0aW9uX3NwbGl0ID0gMC4yXG4gKSJ9\u003c/div\u003e\r\n\r\n\u003cp\u003e\u003cstrong\u003eTip\u003c/strong\u003e if you want, you can also specify the verbose argument in the \u003ccode\u003efit()\u003c/code\u003e function. By setting this argument to \u003ccode\u003e1\u003c/code\u003e, you indicate that you want to see progress bar logging.\u003c/p\u003e\r\n\r\n\u003cp\u003eWhat you do with the code above is training the model for a specified number of epochs or exposures to the training dataset. An epoch is a single pass through the entire training set, followed by testing of the verification set. The batch size that you specify in the code above defines the number of samples that going to be propagated through the network. Also, by doing this, you optimize the efficiency because you make sure that you don\u0026rsquo;t load too many input patterns into memory at the same time.\u003c/p\u003e\r\n\r\n\u003ch2 id=\"viz\"\u003eVisualize The Model Training History\u003c/h2\u003e\r\n\r\n\u003cp\u003eAlso, it\u0026rsquo;s good to know that you can also visualize the fitting if you assign the lines of code in the DataCamp Light chunk above to a variable. You can then pass the variable to the \u003ccode\u003eplot()\u003c/code\u003e function, like you see in this particular code chunk!\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"300\"\u003eeyJsYW5ndWFnZSI6InIiLCJwcmVfZXhlcmNpc2VfY29kZSI6InNldC5zZWVkKDEyMzQpXG5saWJyYXJ5KGtlcmFzKVxuaXJpcyA8LSByZWFkLmNzdih1cmwoXCJodHRwOi8vYXJjaGl2ZS5pY3MudWNpLmVkdS9tbC9tYWNoaW5lLWxlYXJuaW5nLWRhdGFiYXNlcy9pcmlzL2lyaXMuZGF0YVwiKSwgaGVhZGVyID0gRkFMU0UpIFxubmFtZXMoaXJpcykgPC0gYyhcIlNlcGFsLkxlbmd0aFwiLCBcIlNlcGFsLldpZHRoXCIsIFwiUGV0YWwuTGVuZ3RoXCIsIFwiUGV0YWwuV2lkdGhcIiwgXCJTcGVjaWVzXCIpXG5pcmlzWyw1XSA8LSBhcy5udW1lcmljKGlyaXNbLDVdKSAtMVxuaXJpcyA8LSBhcy5tYXRyaXgoaXJpcylcbmRpbW5hbWVzKGlyaXMpIDwtIE5VTExcbmluZCA8LSBzYW1wbGUoMiwgbnJvdyhpcmlzKSwgcmVwbGFjZT1UUlVFLCBwcm9iPWMoMC42NywgMC4zMykpXG5pcmlzLnRyYWluaW5nIDwtIGlyaXNbaW5kPT0xLCAxOjRdXG5pcmlzLnRlc3QgPC0gaXJpc1tpbmQ9PTIsIDE6NF1cbmlyaXMudHJhaW5pbmd0YXJnZXQgPC0gaXJpc1tpbmQ9PTEsNV1cbmlyaXMudGVzdHRhcmdldCA8LSBpcmlzW2luZD09MiwgNV1cbmlyaXMudHJhaW5MYWJlbHMgPC0gdG9fY2F0ZWdvcmljYWwoaXJpcy50cmFpbmluZ3RhcmdldClcbmlyaXMudGVzdExhYmVscyA8LSB0b19jYXRlZ29yaWNhbChpcmlzLnRlc3R0YXJnZXQpXG5tb2RlbCA8LSBrZXJhc19tb2RlbF9zZXF1ZW50aWFsKCkgXG5tb2RlbCAlPiUgXG4gICAgbGF5ZXJfZGVuc2UodW5pdHMgPSA4LCBhY3RpdmF0aW9uID0gJ3JlbHUnLCBpbnB1dF9zaGFwZSA9IGMoNCkpICU+JSBcbiAgICBsYXllcl9kZW5zZSh1bml0cyA9IDMsIGFjdGl2YXRpb24gPSAnc29mdG1heCcpXG5tb2RlbCAlPiUgY29tcGlsZShcbiAgICAgbG9zcyA9ICdjYXRlZ29yaWNhbF9jcm9zc2VudHJvcHknLFxuICAgICBvcHRpbWl6ZXIgPSAnYWRhbScsXG4gICAgIG1ldHJpY3MgPSAnYWNjdXJhY3knXG4gKSIsInNhbXBsZSI6IiMgU3RvcmUgdGhlIGZpdHRpbmcgaGlzdG9yeSBpbiBgaGlzdG9yeWAgXG5oaXN0b3J5IDwtIG1vZGVsICU+JSBmaXQoXG4gICAgIGlyaXMudHJhaW5pbmcsIFxuICAgICBpcmlzLnRyYWluTGFiZWxzLCBcbiAgICAgZXBvY2hzID0gMjAwLFxuICAgICBiYXRjaF9zaXplID0gNSwgXG4gICAgIHZhbGlkYXRpb25fc3BsaXQgPSAwLjJcbiApXG5cbiMgUGxvdCB0aGUgaGlzdG9yeVxucGxvdChoaXN0b3J5KSJ9\u003c/div\u003e\r\n\r\n\u003cp\u003eMake sure to study the plot in more detail.\u003c/p\u003e\r\n\r\n\u003cp\u003e\u003cimg src=\"https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Fitting-Plot.png\" /\u003e\u003c/p\u003e\r\n\r\n\u003cp\u003eAt first sight, it\u0026rsquo;s no surprise that this all looks a tad messy. You might not entirely know what you\u0026rsquo;re looking at, right?\u003c/p\u003e\r\n\r\n\u003cp\u003eOne good thing to know is that the \u003ccode\u003eloss\u003c/code\u003e and \u003ccode\u003eacc\u003c/code\u003e indicate the loss and accuracy of the model for the training data, while the \u003ccode\u003eval_loss\u003c/code\u003e and \u003ccode\u003eval_acc\u003c/code\u003e are the same metrics, loss and accuracy, for the test or validation data.\u003c/p\u003e\r\n\r\n\u003cp\u003eBut, even as you know this, it\u0026rsquo;s not easy to interpret these two graphs. Let\u0026rsquo;s try to break this up into pieces that you might understand more easily! You\u0026rsquo;ll split up these two plots and make two separate ones instead: you\u0026rsquo;ll make one for the model loss and another one for the model accuracy. Luckily, you can easily make use of the \u003ccode\u003e$\u003c/code\u003e operator to access the data and plot it step by step.\u003c/p\u003e\r\n\r\n\u003cp\u003eCheck out the DataCamp Light box below to see how you can do this:\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"300\"\u003eeyJsYW5ndWFnZSI6InIiLCJwcmVfZXhlcmNpc2VfY29kZSI6InNldC5zZWVkKDEyMzQpXG5saWJyYXJ5KGtlcmFzKVxuaXJpcyA8LSByZWFkLmNzdih1cmwoXCJodHRwOi8vYXJjaGl2ZS5pY3MudWNpLmVkdS9tbC9tYWNoaW5lLWxlYXJuaW5nLWRhdGFiYXNlcy9pcmlzL2lyaXMuZGF0YVwiKSwgaGVhZGVyID0gRkFMU0UpIFxubmFtZXMoaXJpcykgPC0gYyhcIlNlcGFsLkxlbmd0aFwiLCBcIlNlcGFsLldpZHRoXCIsIFwiUGV0YWwuTGVuZ3RoXCIsIFwiUGV0YWwuV2lkdGhcIiwgXCJTcGVjaWVzXCIpXG5pcmlzWyw1XSA8LSBhcy5udW1lcmljKGlyaXNbLDVdKSAtMVxuaXJpcyA8LSBhcy5tYXRyaXgoaXJpcylcbmRpbW5hbWVzKGlyaXMpIDwtIE5VTExcbmluZCA8LSBzYW1wbGUoMiwgbnJvdyhpcmlzKSwgcmVwbGFjZT1UUlVFLCBwcm9iPWMoMC42NywgMC4zMykpXG5pcmlzLnRyYWluaW5nIDwtIGlyaXNbaW5kPT0xLCAxOjRdXG5pcmlzLnRlc3QgPC0gaXJpc1tpbmQ9PTIsIDE6NF1cbmlyaXMudHJhaW5pbmd0YXJnZXQgPC0gaXJpc1tpbmQ9PTEsNV1cbmlyaXMudGVzdHRhcmdldCA8LSBpcmlzW2luZD09MiwgNV1cbmlyaXMudHJhaW5MYWJlbHMgPC0gdG9fY2F0ZWdvcmljYWwoaXJpcy50cmFpbmluZ3RhcmdldClcbmlyaXMudGVzdExhYmVscyA8LSB0b19jYXRlZ29yaWNhbChpcmlzLnRlc3R0YXJnZXQpXG5tb2RlbCA8LSBrZXJhc19tb2RlbF9zZXF1ZW50aWFsKCkgXG5tb2RlbCAlPiUgXG4gICAgbGF5ZXJfZGVuc2UodW5pdHMgPSA4LCBhY3RpdmF0aW9uID0gJ3JlbHUnLCBpbnB1dF9zaGFwZSA9IGMoNCkpICU+JSBcbiAgICBsYXllcl9kZW5zZSh1bml0cyA9IDMsIGFjdGl2YXRpb24gPSAnc29mdG1heCcpXG5tb2RlbCAlPiUgY29tcGlsZShcbiAgICAgbG9zcyA9ICdjYXRlZ29yaWNhbF9jcm9zc2VudHJvcHknLFxuICAgICBvcHRpbWl6ZXIgPSAnYWRhbScsXG4gICAgIG1ldHJpY3MgPSAnYWNjdXJhY3knXG4gKVxuaGlzdG9yeSA8LSBtb2RlbCAlPiUgZml0KFxuICAgICBpcmlzLnRyYWluaW5nLCBcbiAgICAgaXJpcy50cmFpbkxhYmVscywgXG4gICAgIGVwb2NocyA9IDIwMCxcbiAgICAgYmF0Y2hfc2l6ZSA9IDUsIFxuICAgICB2YWxpZGF0aW9uX3NwbGl0ID0gMC4yXG4gKSIsInNhbXBsZSI6IiMgUGxvdCB0aGUgbW9kZWwgbG9zcyBvZiB0aGUgdHJhaW5pbmcgZGF0YVxucGxvdChoaXN0b3J5JG1ldHJpY3MkbG9zcywgbWFpbj1cIk1vZGVsIExvc3NcIiwgeGxhYiA9IFwiZXBvY2hcIiwgeWxhYj1cImxvc3NcIiwgY29sPVwiYmx1ZVwiLCB0eXBlPVwibFwiKVxuXG4jIFBsb3QgdGhlIG1vZGVsIGxvc3Mgb2YgdGhlIHRlc3QgZGF0YVxubGluZXMoaGlzdG9yeSRtZXRyaWNzJHZhbF9sb3NzLCBjb2w9XCJncmVlblwiKVxuXG4jIEFkZCBsZWdlbmRcbmxlZ2VuZChcInRvcHJpZ2h0XCIsIGMoXCJ0cmFpblwiLFwidGVzdFwiKSwgY29sPWMoXCJibHVlXCIsIFwiZ3JlZW5cIiksIGx0eT1jKDEsMSkpIn0=\u003c/div\u003e\r\n\r\n\u003cp\u003e\u003cimg src=\"https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Model-Loss.png\" /\u003e\u003c/p\u003e\r\n\r\n\u003cp\u003eIn this first plot, you plotted the loss of the model on the training and test data. Now it\u0026rsquo;s time to also do the same, but then for the accuracy of the model:\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"300\"\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\u003c/div\u003e\r\n\r\n\u003cp\u003e\u003cimg src=\"https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Model-Accuracy.png\" /\u003e\u003c/p\u003e\r\n\r\n\u003cp\u003eSome things to keep in mind here are the following:\u003c/p\u003e\r\n\r\n\u003cul\u003e\r\n\t\u003cli\u003eIf your training data accuracy keeps improving while your validation data accuracy gets worse, you are probably overfitting: your model starts to just memorize the data instead of learning from it.\u003c/li\u003e\r\n\t\u003cli\u003eIf the trend for accuracy on both datasets is still rising for the last few epochs, you can clearly see that the model has not yet over-learned the training dataset.\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\r\n\u003ch2 id=\"predict\"\u003ePredict Labels of New Data\u003c/h2\u003e\r\n\r\n\u003cp\u003eNow that your model is created, compiled and has been fitted to the data, it\u0026rsquo;s time to actually use your model to predict the labels for your test set \u003ccode\u003eiris.test\u003c/code\u003e. As you might have expected, you can use the \u003ccode\u003epredict()\u003c/code\u003e function to do this. After, you can print out the confusion matrix to check out the predictions and the real labels of the \u003ccode\u003eiris.test\u003c/code\u003e data with the help of the \u003ccode\u003etable()\u003c/code\u003e function.\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-height=\"300\" data-encoded=\"true\"\u003e\r\neyJsYW5ndWFnZSI6InIiLCJwcmVfZXhlcmNpc2VfY29kZSI6InNldC5zZWVkKDEyMzQpXG5saWJyYXJ5KGtlcmFzKVxuaXJpcyA8LSByZWFkLmNzdih1cmwoXCJodHRwOi8vYXJjaGl2ZS5pY3MudWNpLmVkdS9tbC9tYWNoaW5lLWxlYXJuaW5nLWRhdGFiYXNlcy9pcmlzL2lyaXMuZGF0YVwiKSwgaGVhZGVyID0gRkFMU0UpIFxubmFtZXMoaXJpcykgPC0gYyhcIlNlcGFsLkxlbmd0aFwiLCBcIlNlcGFsLldpZHRoXCIsIFwiUGV0YWwuTGVuZ3RoXCIsIFwiUGV0YWwuV2lkdGhcIiwgXCJTcGVjaWVzXCIpXG5pcmlzWyw1XSA8LSBhcy5udW1lcmljKGlyaXNbLDVdKSAtMVxuaXJpcyA8LSBhcy5tYXRyaXgoaXJpcylcbmRpbW5hbWVzKGlyaXMpIDwtIE5VTExcbmluZCA8LSBzYW1wbGUoMiwgbnJvdyhpcmlzKSwgcmVwbGFjZT1UUlVFLCBwcm9iPWMoMC42NywgMC4zMykpXG5pcmlzLnRyYWluaW5nIDwtIGlyaXNbaW5kPT0xLCAxOjRdXG5pcmlzLnRlc3QgPC0gaXJpc1tpbmQ9PTIsIDE6NF1cbmlyaXMudHJhaW5pbmd0YXJnZXQgPC0gaXJpc1tpbmQ9PTEsNV1cbmlyaXMudGVzdHRhcmdldCA8LSBpcmlzW2luZD09MiwgNV1cbmlyaXMudHJhaW5MYWJlbHMgPC0gdG9fY2F0ZWdvcmljYWwoaXJpcy50cmFpbmluZ3RhcmdldClcbmlyaXMudGVzdExhYmVscyA8LSB0b19jYXRlZ29yaWNhbChpcmlzLnRlc3R0YXJnZXQpXG5tb2RlbCA8LSBrZXJhc19tb2RlbF9zZXF1ZW50aWFsKCkgXG5tb2RlbCAlPiUgXG4gICAgbGF5ZXJfZGVuc2UodW5pdHMgPSA4LCBhY3RpdmF0aW9uID0gJ3JlbHUnLCBpbnB1dF9zaGFwZSA9IGMoNCkpICU+JSBcbiAgICBsYXllcl9kZW5zZSh1bml0cyA9IDMsIGFjdGl2YXRpb24gPSAnc29mdG1heCcpXG5tb2RlbCAlPiUgY29tcGlsZShcbiAgICAgbG9zcyA9ICdjYXRlZ29yaWNhbF9jcm9zc2VudHJvcHknLFxuICAgICBvcHRpbWl6ZXIgPSAnYWRhbScsXG4gICAgIG1ldHJpY3MgPSAnYWNjdXJhY3knXG4gKVxubW9kZWwgJT4lIGZpdChcbiAgICAgaXJpcy50cmFpbmluZywgaXJpcy50cmFpbkxhYmVscywgXG4gICAgIGVwb2NocyA9IDIwMCwgYmF0Y2hfc2l6ZSA9IDUsIFxuICAgICB2YWxpZGF0aW9uX3NwbGl0ID0gMC4yXG4gKSIsInNhbXBsZSI6IiMgUHJlZGljdCB0aGUgY2xhc3NlcyBmb3IgdGhlIHRlc3QgZGF0YVxuY2xhc3NlcyA8LSBtb2RlbCAlPiUgcHJlZGljdF9jbGFzc2VzKGlyaXMudGVzdCwgYmF0Y2hfc2l6ZSA9IDEyOClcblxuIyBDb25mdXNpb24gbWF0cml4XG50YWJsZShpcmlzLnRlc3R0YXJnZXQsIGNsYXNzZXMpIn0=\r\n\u003c/div\u003e\r\n\r\n\u003cp\u003eWhat do you think of the results? At first sight, does this model that you have created make the right predictions?\u003c/p\u003e\r\n\r\n\u003ch2 id=\"evaluate\"\u003eEvaluating Your Model\u003c/h2\u003e\r\n\r\n\u003cp\u003eEven though you already have a slight idea of how your model performed by looking at the predicted labels for \u003ccode\u003eiris.test\u003c/code\u003e, it\u0026rsquo;s still important that you take the time to evaluate your model. Use the \u003ccode\u003eevaluate()\u003c/code\u003e function to do this: pass in the test data \u003ccode\u003eiris.test\u003c/code\u003e, the test labels \u003ccode\u003eiris.testLabels\u003c/code\u003e and define the batch size. Store the result in a variable \u003ccode\u003escore\u003c/code\u003e, like in the code example below:\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"300\"\u003eeyJsYW5ndWFnZSI6InIiLCJwcmVfZXhlcmNpc2VfY29kZSI6InNldC5zZWVkKDEyMzQpXG5saWJyYXJ5KGtlcmFzKVxuaXJpcyA8LSByZWFkLmNzdih1cmwoXCJodHRwOi8vYXJjaGl2ZS5pY3MudWNpLmVkdS9tbC9tYWNoaW5lLWxlYXJuaW5nLWRhdGFiYXNlcy9pcmlzL2lyaXMuZGF0YVwiKSwgaGVhZGVyID0gRkFMU0UpIFxubmFtZXMoaXJpcykgPC0gYyhcIlNlcGFsLkxlbmd0aFwiLCBcIlNlcGFsLldpZHRoXCIsIFwiUGV0YWwuTGVuZ3RoXCIsIFwiUGV0YWwuV2lkdGhcIiwgXCJTcGVjaWVzXCIpXG5pcmlzWyw1XSA8LSBhcy5udW1lcmljKGlyaXNbLDVdKSAtMVxuaXJpcyA8LSBhcy5tYXRyaXgoaXJpcylcbmRpbW5hbWVzKGlyaXMpIDwtIE5VTExcbmluZCA8LSBzYW1wbGUoMiwgbnJvdyhpcmlzKSwgcmVwbGFjZT1UUlVFLCBwcm9iPWMoMC42NywgMC4zMykpXG5pcmlzLnRyYWluaW5nIDwtIGlyaXNbaW5kPT0xLCAxOjRdXG5pcmlzLnRlc3QgPC0gaXJpc1tpbmQ9PTIsIDE6NF1cbmlyaXMudHJhaW5pbmd0YXJnZXQgPC0gaXJpc1tpbmQ9PTEsNV1cbmlyaXMudGVzdHRhcmdldCA8LSBpcmlzW2luZD09MiwgNV1cbmlyaXMudHJhaW5MYWJlbHMgPC0gdG9fY2F0ZWdvcmljYWwoaXJpcy50cmFpbmluZ3RhcmdldClcbmlyaXMudGVzdExhYmVscyA8LSB0b19jYXRlZ29yaWNhbChpcmlzLnRlc3R0YXJnZXQpXG5tb2RlbCA8LSBrZXJhc19tb2RlbF9zZXF1ZW50aWFsKCkgXG5tb2RlbCAlPiUgXG4gICAgbGF5ZXJfZGVuc2UodW5pdHMgPSA4LCBhY3RpdmF0aW9uID0gJ3JlbHUnLCBpbnB1dF9zaGFwZSA9IGMoNCkpICU+JSBcbiAgICBsYXllcl9kZW5zZSh1bml0cyA9IDMsIGFjdGl2YXRpb24gPSAnc29mdG1heCcpXG5tb2RlbCAlPiUgY29tcGlsZShcbiAgICAgbG9zcyA9ICdjYXRlZ29yaWNhbF9jcm9zc2VudHJvcHknLFxuICAgICBvcHRpbWl6ZXIgPSAnYWRhbScsXG4gICAgIG1ldHJpY3MgPSAnYWNjdXJhY3knXG4gKVxubW9kZWwgJT4lIGZpdChcbiAgICAgaXJpcy50cmFpbmluZywgaXJpcy50cmFpbkxhYmVscywgXG4gICAgIGVwb2NocyA9IDIwMCwgYmF0Y2hfc2l6ZSA9IDUsIFxuICAgICB2YWxpZGF0aW9uX3NwbGl0ID0gMC4yXG4gKSIsInNhbXBsZSI6IiMgRXZhbHVhdGUgb24gdGVzdCBkYXRhIGFuZCBsYWJlbHNcbnNjb3JlIDwtIG1vZGVsICU+JSBldmFsdWF0ZShpcmlzLnRlc3QsIGlyaXMudGVzdExhYmVscywgYmF0Y2hfc2l6ZSA9IDEyOClcblxuIyBQcmludCB0aGUgc2NvcmVcbnByaW50KHNjb3JlKSJ9\u003c/div\u003e\r\n\r\n\u003cp\u003eBy printing \u003ccode\u003escore\u003c/code\u003e, you\u0026rsquo;ll get back the loss value and the metric value (in this case \u003ccode\u003e\u0026#39;accuracy\u0026#39;\u003c/code\u003e) back.\u003c/p\u003e\r\n\r\n\u003ch2 id=\"finetune\"\u003eFine-tuning Your Model\u003c/h2\u003e\r\n\r\n\u003cp\u003eFine-tuning your model is probably something that you\u0026rsquo;ll be doing a lot, especially in the beginning, because not all classification and regression problems are as straightforward as the one that you saw in the first part of this tutorial. As you read above, there are already two key decisions that you\u0026rsquo;ll probably want to adjust: how many layers you\u0026rsquo;re going to use and how many \u0026ldquo;hidden units\u0026rdquo; you will chose for each layer.\u003c/p\u003e\r\n\r\n\u003cp\u003eIn the beginning, this will really be quite a journey.\u003c/p\u003e\r\n\r\n\u003cp\u003eBesides playing around with the number of epochs or the batch size, there are other ways in which you can tweak your model in the hopes that it will perform better: by adding layers, by increasing the number of hidden units and by passing your own optimization parameters to the \u003ccode\u003ecompile()\u003c/code\u003e function. This section will go over these three options.\u003c/p\u003e\r\n\r\n\u003cdiv class=\"section level3\" id=\"adding-layers\"\u003e\r\n\u003ch3\u003eAdding Layers\u003c/h3\u003e\r\n\r\n\u003cp\u003eWhat would happen if you add another layer to your model? What if it would look like this?\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"600\"\u003eeyJsYW5ndWFnZSI6InIiLCJwcmVfZXhlcmNpc2VfY29kZSI6InNldC5zZWVkKDEyMzQpXG5saWJyYXJ5KGtlcmFzKVxuaXJpcyA8LSByZWFkLmNzdih1cmwoXCJodHRwOi8vYXJjaGl2ZS5pY3MudWNpLmVkdS9tbC9tYWNoaW5lLWxlYXJuaW5nLWRhdGFiYXNlcy9pcmlzL2lyaXMuZGF0YVwiKSwgaGVhZGVyID0gRkFMU0UpIFxubmFtZXMoaXJpcykgPC0gYyhcIlNlcGFsLkxlbmd0aFwiLCBcIlNlcGFsLldpZHRoXCIsIFwiUGV0YWwuTGVuZ3RoXCIsIFwiUGV0YWwuV2lkdGhcIiwgXCJTcGVjaWVzXCIpXG5pcmlzWyw1XSA8LSBhcy5udW1lcmljKGlyaXNbLDVdKSAtMVxuaXJpcyA8LSBhcy5tYXRyaXgoaXJpcylcbmRpbW5hbWVzKGlyaXMpIDwtIE5VTExcbmluZCA8LSBzYW1wbGUoMiwgbnJvdyhpcmlzKSwgcmVwbGFjZT1UUlVFLCBwcm9iPWMoMC42NywgMC4zMykpXG5pcmlzLnRyYWluaW5nIDwtIGlyaXNbaW5kPT0xLCAxOjRdXG5pcmlzLnRlc3QgPC0gaXJpc1tpbmQ9PTIsIDE6NF1cbmlyaXMudHJhaW5pbmd0YXJnZXQgPC0gaXJpc1tpbmQ9PTEsNV1cbmlyaXMudGVzdHRhcmdldCA8LSBpcmlzW2luZD09MiwgNV1cbmlyaXMudHJhaW5MYWJlbHMgPC0gdG9fY2F0ZWdvcmljYWwoaXJpcy50cmFpbmluZ3RhcmdldClcbmlyaXMudGVzdExhYmVscyA8LSB0b19jYXRlZ29yaWNhbChpcmlzLnRlc3R0YXJnZXQpIiwic2FtcGxlIjoiIyBJbml0aWFsaXplIHRoZSBzZXF1ZW50aWFsIG1vZGVsXG5tb2RlbCA8LSBrZXJhc19tb2RlbF9zZXF1ZW50aWFsKCkgXG5cbiMgQWRkIGxheWVycyB0byBtb2RlbFxubW9kZWwgJT4lIFxuICAgIGxheWVyX2RlbnNlKHVuaXRzID0gOCwgYWN0aXZhdGlvbiA9ICdyZWx1JywgaW5wdXRfc2hhcGUgPSBjKDQpKSAlPiUgXG4gICAgbGF5ZXJfZGVuc2UodW5pdHMgPSA1LCBhY3RpdmF0aW9uID0gJ3JlbHUnKSAlPiUgXG4gICAgbGF5ZXJfZGVuc2UodW5pdHMgPSAzLCBhY3RpdmF0aW9uID0gJ3NvZnRtYXgnKVxuXG4jIENvbXBpbGUgdGhlIG1vZGVsXG5tb2RlbCAlPiUgY29tcGlsZShcbiAgICAgbG9zcyA9ICdjYXRlZ29yaWNhbF9jcm9zc2VudHJvcHknLFxuICAgICBvcHRpbWl6ZXIgPSAnYWRhbScsXG4gICAgIG1ldHJpY3MgPSAnYWNjdXJhY3knXG4gKVxuXG4jIEZpdCB0aGUgbW9kZWwgdG8gdGhlIGRhdGFcbm1vZGVsICU+JSBmaXQoXG4gICAgIGlyaXMudHJhaW5pbmcsIGlyaXMudHJhaW5MYWJlbHMsIFxuICAgICBlcG9jaHMgPSAyMDAsIGJhdGNoX3NpemUgPSA1LCBcbiAgICAgdmFsaWRhdGlvbl9zcGxpdCA9IDAuMlxuIClcblxuIyBFdmFsdWF0ZSB0aGUgbW9kZWxcbnNjb3JlIDwtIG1vZGVsICU+JSBldmFsdWF0ZShpcmlzLnRlc3QsIGlyaXMudGVzdExhYmVscywgYmF0Y2hfc2l6ZSA9IDEyOClcblxuIyBQcmludCB0aGUgc2NvcmVcbnByaW50KHNjb3JlKSJ9\u003c/div\u003e\r\n\r\n\u003cp\u003e\u003cstrong\u003eNote\u003c/strong\u003e that you can also visualize the loss and accuracy metrics of this new model! Try this out in the DataCamp Light chunk below:\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"800\"\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\u003c/div\u003e\r\n\r\n\u003ctable align=\"center\" border=\"0\" cellpadding=\"1\" cellspacing=\"1\" style=\"width: 800px;\"\u003e\r\n\t\u003ctbody\u003e\r\n\t\t\u003ctr\u003e\r\n\t\t\t\u003ctd align=\"center\"\u003e\r\n\t\t\t\u003cp\u003e\u003cimg alt=\"deep learning model layers\" src=\"https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Modelfinetune-1a.png\" style=\"width: 430px; height: 304px;\" /\u003e\u003c/p\u003e\r\n\t\t\t\u003c/td\u003e\r\n\t\t\t\u003ctd align=\"center\"\u003e\r\n\t\t\t\u003cp\u003e\u003cimg alt=\"Keras Layers model\" src=\"https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Modelfinetune-1b.png\" style=\"width: 430px; height: 304px;\" /\u003e\u003c/p\u003e\r\n\t\t\t\u003c/td\u003e\r\n\t\t\u003c/tr\u003e\r\n\t\u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003c/div\u003e\r\n\r\n\u003cdiv class=\"section level3\" id=\"hidden-units\"\u003e\r\n\u003ch3\u003eHidden Units\u003c/h3\u003e\r\n\r\n\u003cp\u003eAlso try out the effect of adding more hidden units to your model\u0026rsquo;s architecture and study the effect on the evaluation, just like this:\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"600\"\u003eeyJsYW5ndWFnZSI6InIiLCJwcmVfZXhlcmNpc2VfY29kZSI6InNldC5zZWVkKDEyMzQpXG5saWJyYXJ5KGtlcmFzKVxuaXJpcyA8LSByZWFkLmNzdih1cmwoXCJodHRwOi8vYXJjaGl2ZS5pY3MudWNpLmVkdS9tbC9tYWNoaW5lLWxlYXJuaW5nLWRhdGFiYXNlcy9pcmlzL2lyaXMuZGF0YVwiKSwgaGVhZGVyID0gRkFMU0UpIFxubmFtZXMoaXJpcykgPC0gYyhcIlNlcGFsLkxlbmd0aFwiLCBcIlNlcGFsLldpZHRoXCIsIFwiUGV0YWwuTGVuZ3RoXCIsIFwiUGV0YWwuV2lkdGhcIiwgXCJTcGVjaWVzXCIpXG5pcmlzWyw1XSA8LSBhcy5udW1lcmljKGlyaXNbLDVdKSAtMVxuaXJpcyA8LSBhcy5tYXRyaXgoaXJpcylcbmRpbW5hbWVzKGlyaXMpIDwtIE5VTExcbmluZCA8LSBzYW1wbGUoMiwgbnJvdyhpcmlzKSwgcmVwbGFjZT1UUlVFLCBwcm9iPWMoMC42NywgMC4zMykpXG5pcmlzLnRyYWluaW5nIDwtIGlyaXNbaW5kPT0xLCAxOjRdXG5pcmlzLnRlc3QgPC0gaXJpc1tpbmQ9PTIsIDE6NF1cbmlyaXMudHJhaW5pbmd0YXJnZXQgPC0gaXJpc1tpbmQ9PTEsNV1cbmlyaXMudGVzdHRhcmdldCA8LSBpcmlzW2luZD09MiwgNV1cbmlyaXMudHJhaW5MYWJlbHMgPC0gdG9fY2F0ZWdvcmljYWwoaXJpcy50cmFpbmluZ3RhcmdldClcbmlyaXMudGVzdExhYmVscyA8LSB0b19jYXRlZ29yaWNhbChpcmlzLnRlc3R0YXJnZXQpIiwic2FtcGxlIjoiIyBJbml0aWFsaXplIGEgc2VxdWVudGlhbCBtb2RlbFxubW9kZWwgPC0ga2VyYXNfbW9kZWxfc2VxdWVudGlhbCgpIFxuXG4jIEFkZCBsYXllcnMgdG8gdGhlIG1vZGVsXG5tb2RlbCAlPiUgXG4gICAgbGF5ZXJfZGVuc2UodW5pdHMgPSAyOCwgYWN0aXZhdGlvbiA9ICdyZWx1JywgaW5wdXRfc2hhcGUgPSBjKDQpKSAlPiUgXG4gICAgbGF5ZXJfZGVuc2UodW5pdHMgPSAzLCBhY3RpdmF0aW9uID0gJ3NvZnRtYXgnKVxuXG4jIENvbXBpbGUgdGhlIG1vZGVsXG5tb2RlbCAlPiUgY29tcGlsZShcbiAgICAgbG9zcyA9ICdjYXRlZ29yaWNhbF9jcm9zc2VudHJvcHknLFxuICAgICBvcHRpbWl6ZXIgPSAnYWRhbScsXG4gICAgIG1ldHJpY3MgPSAnYWNjdXJhY3knXG4gKVxuXG4jIEZpdCB0aGUgbW9kZWwgdG8gdGhlIGRhdGFcbm1vZGVsICU+JSBmaXQoXG4gICAgIGlyaXMudHJhaW5pbmcsIGlyaXMudHJhaW5MYWJlbHMsIFxuICAgICBlcG9jaHMgPSAyMDAsIGJhdGNoX3NpemUgPSA1LCBcbiAgICAgdmFsaWRhdGlvbl9zcGxpdCA9IDAuMlxuIClcblxuIyBFdmFsdWF0ZSB0aGUgbW9kZWxcbnNjb3JlIDwtIG1vZGVsICU+JSBldmFsdWF0ZShpcmlzLnRlc3QsIGlyaXMudGVzdExhYmVscywgYmF0Y2hfc2l6ZSA9IDEyOClcblxuIyBQcmludCB0aGUgc2NvcmVcbnByaW50KHNjb3JlKSJ9\u003c/div\u003e\r\n\r\n\u003cp\u003eNote that, in general, this is not always the best optimilization because, if you don\u0026rsquo;t have a ton of data, the overfitting can and will be worse. That\u0026rsquo;s why you should try use a small network with small datasets as this one.\u003c/p\u003e\r\n\r\n\u003cp\u003eWhy don\u0026rsquo;t you try visualizing the effect of the addition of the hidden nodes in your model? Try it out below:\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"800\"\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\u003c/div\u003e\r\n\r\n\u003ctable align=\"center\" border=\"0\" cellpadding=\"1\" cellspacing=\"1\" style=\"width: 800px;\"\u003e\r\n\t\u003ctbody\u003e\r\n\t\t\u003ctr\u003e\r\n\t\t\t\u003ctd align=\"center\"\u003e\r\n\t\t\t\u003cp\u003e\u003cimg alt=\"neural network model\" src=\"https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Modelfinetune-2a.png\" style=\"width: 430px; height: 304px;\" /\u003e\u003c/p\u003e\r\n\t\t\t\u003c/td\u003e\r\n\t\t\t\u003ctd align=\"center\"\u003e\r\n\t\t\t\u003cp\u003e\u003cimg alt=\"hidden units ann\" src=\"https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Modelfinetune-2b.png\" style=\"width: 430px; height: 304px;\" /\u003e\u003c/p\u003e\r\n\t\t\t\u003c/td\u003e\r\n\t\t\u003c/tr\u003e\r\n\t\u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003c/div\u003e\r\n\r\n\u003cdiv class=\"section level3\" id=\"optimization-parameters\"\u003e\r\n\u003ch3\u003eOptimization Parameters\u003c/h3\u003e\r\n\r\n\u003cp\u003eBesides adding layers and playing around with the hidden units, you can also try to adjust (some of) the parameters of the optimization algorithm that you give to the \u003ccode\u003ecompile()\u003c/code\u003e function. Up until now, you have always passed a vector with a string, \u003ccode\u003eadam\u003c/code\u003e, to the \u003ccode\u003eoptimizer\u003c/code\u003e argument.\u003c/p\u003e\r\n\r\n\u003cp\u003eBut that doesn\u0026rsquo;t always need to be like this!\u003c/p\u003e\r\n\r\n\u003cp\u003eAlso, try out experimenting with other optimization algorithms, like the Stochastic Gradient Descent (SGD). Try, for example, using the \u003ccode\u003eoptimizer_sgd()\u003c/code\u003e function to adjust the learning rate \u003ccode\u003elr\u003c/code\u003e. Do you notice an effect?\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"600\"\u003eeyJsYW5ndWFnZSI6InIiLCJwcmVfZXhlcmNpc2VfY29kZSI6ImxpYnJhcnkoa2VyYXMpXG5pcmlzIDwtIHJlYWQuY3N2KHVybChcImh0dHA6Ly9hcmNoaXZlLmljcy51Y2kuZWR1L21sL21hY2hpbmUtbGVhcm5pbmctZGF0YWJhc2VzL2lyaXMvaXJpcy5kYXRhXCIpLCBoZWFkZXIgPSBGQUxTRSkgXG5uYW1lcyhpcmlzKSA8LSBjKFwiU2VwYWwuTGVuZ3RoXCIsIFwiU2VwYWwuV2lkdGhcIiwgXCJQZXRhbC5MZW5ndGhcIiwgXCJQZXRhbC5XaWR0aFwiLCBcIlNwZWNpZXNcIilcbmlyaXNbLDVdIDwtIGFzLm51bWVyaWMoaXJpc1ssNV0pIC0xXG5pcmlzIDwtIGFzLm1hdHJpeChpcmlzKVxuZGltbmFtZXMoaXJpcykgPC0gTlVMTFxuaW5kIDwtIHNhbXBsZSgyLCBucm93KGlyaXMpLCByZXBsYWNlPVRSVUUsIHByb2I9YygwLjY3LCAwLjMzKSlcbmlyaXMudHJhaW5pbmcgPC0gaXJpc1tpbmQ9PTEsIDE6NF1cbmlyaXMudGVzdCA8LSBpcmlzW2luZD09MiwgMTo0XVxuaXJpcy50cmFpbmluZ3RhcmdldCA8LSBpcmlzW2luZD09MSw1XVxuaXJpcy50ZXN0dGFyZ2V0IDwtIGlyaXNbaW5kPT0yLCA1XVxuaXJpcy50cmFpbkxhYmVscyA8LSB0b19jYXRlZ29yaWNhbChpcmlzLnRyYWluaW5ndGFyZ2V0KVxuaXJpcy50ZXN0TGFiZWxzIDwtIHRvX2NhdGVnb3JpY2FsKGlyaXMudGVzdHRhcmdldCkiLCJzYW1wbGUiOiIjIEluaXRpYWxpemUgYSBzZXF1ZW50aWFsIG1vZGVsXG5tb2RlbCA8LSBrZXJhc19tb2RlbF9zZXF1ZW50aWFsKCkgXG5cbiMgQnVpbGQgdXAgeW91ciBtb2RlbCBieSBhZGRpbmcgbGF5ZXJzIHRvIGl0XG5tb2RlbCAlPiUgXG4gICAgbGF5ZXJfZGVuc2UodW5pdHMgPSA4LCBhY3RpdmF0aW9uID0gJ3JlbHUnLCBpbnB1dF9zaGFwZSA9IGMoNCkpICU+JSBcbiAgICBsYXllcl9kZW5zZSh1bml0cyA9IDMsIGFjdGl2YXRpb24gPSAnc29mdG1heCcpXG5cbiMgRGVmaW5lIGFuIG9wdGltaXplclxuc2dkIDwtIG9wdGltaXplcl9zZ2QobHIgPSAwLjAxKVxuXG4jIFVzZSB0aGUgb3B0aW1pemVyIHRvIGNvbXBpbGUgdGhlIG1vZGVsXG5tb2RlbCAlPiUgY29tcGlsZShvcHRpbWl6ZXI9c2dkLCBcbiAgICAgICAgICAgICAgICAgIGxvc3M9J2NhdGVnb3JpY2FsX2Nyb3NzZW50cm9weScsIFxuICAgICAgICAgICAgICAgICAgbWV0cmljcz0nYWNjdXJhY3knKVxuXG4jIEZpdCB0aGUgbW9kZWwgdG8gdGhlIHRyYWluaW5nIGRhdGFcbm1vZGVsICU+JSBmaXQoXG4gICAgIGlyaXMudHJhaW5pbmcsIGlyaXMudHJhaW5MYWJlbHMsIFxuICAgICBlcG9jaHMgPSAyMDAsIGJhdGNoX3NpemUgPSA1LCBcbiAgICAgdmFsaWRhdGlvbl9zcGxpdCA9IDAuMlxuIClcblxuIyBFdmFsdWF0ZSB0aGUgbW9kZWxcbnNjb3JlIDwtIG1vZGVsICU+JSBldmFsdWF0ZShpcmlzLnRlc3QsIGlyaXMudGVzdExhYmVscywgYmF0Y2hfc2l6ZSA9IDEyOClcblxuIyBQcmludCB0aGUgbG9zcyBhbmQgYWNjdXJhY3kgbWV0cmljc1xucHJpbnQoc2NvcmUpIn0=\u003c/div\u003e\r\n\r\n\u003cp\u003eBesides using another optimizer, you can also try using a smaller learning rate to train your network. This is one of the most common fine-tuning techniques; A common practice is to make the initial learning rate 10 times smaller than the one that you used to train the model before.\u003c/p\u003e\r\n\r\n\u003cp\u003eLet\u0026rsquo;s visualize the training history one more time to see the effect of this small adjustment:\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"700\"\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\u003c/div\u003e\r\n\r\n\u003ctable align=\"center\" border=\"0\" cellpadding=\"1\" cellspacing=\"1\" style=\"width: 800px;\"\u003e\r\n\t\u003ctbody\u003e\r\n\t\t\u003ctr\u003e\r\n\t\t\t\u003ctd align=\"center\"\u003e\r\n\t\t\t\u003cp\u003e\u003cimg alt=\"neural network model\" src=\"https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Modelfinetune-3a.png\" style=\"width: 430px; height: 304px;\" /\u003e\u003c/p\u003e\r\n\t\t\t\u003c/td\u003e\r\n\t\t\t\u003ctd align=\"center\"\u003e\r\n\t\t\t\u003cp\u003e\u003cimg alt=\"hidden units ann\" src=\"https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Modelfinetune-3b.png\" style=\"width: 430px; height: 304px;\" /\u003e\u003c/p\u003e\r\n\t\t\t\u003c/td\u003e\r\n\t\t\u003c/tr\u003e\r\n\t\u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003c/div\u003e\r\n\r\n\u003ch2 id=\"save\"\u003eSaving, Loading or Exporting Your Model\u003c/h2\u003e\r\n\r\n\u003cp\u003eThere is one last thing that remains in your journey with the \u003ccode\u003ekeras\u003c/code\u003e package and that is saving or exporting your model so that you can load it back in at another moment.\u003c/p\u003e\r\n\r\n\u003cul\u003e\r\n\t\u003cli\u003eFirstly, you can easily make use of the \u003ccode\u003esave_model_hdf5()\u003c/code\u003e and \u003ccode\u003eload_model_hdf5()\u003c/code\u003e functions to save and load your model into your workspace:\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\r\n\u003cpre\u003e\r\n\u003ccode\u003esave_model_hdf5(model, \"my_model.h5\")\r\nmodel \u0026lt;- load_model_hdf5(\"my_model.h5\")\u003c/code\u003e\u003c/pre\u003e\r\n\r\n\u003cul\u003e\r\n\t\u003cli\u003eAdditionally, you can also save and load the model weights with the \u003ccode\u003esave_model_weights_hdf5()\u003c/code\u003e and \u003ccode\u003eload_model_weights_hdf5()\u003c/code\u003e functions:\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\r\n\u003cpre\u003e\r\n\u003ccode\u003esave_model_weights_hdf5(\"my_model_weights.h5\")\r\nmodel %\u0026gt;% load_model_weights_hdf5(\"my_model_weights.h5\")\u003c/code\u003e\u003c/pre\u003e\r\n\r\n\u003cul\u003e\r\n\t\u003cli\u003eLastly, it\u0026rsquo;s good to know that you can also export your model configuration to JSON or YAML. Here, the functions \u003ccode\u003emodel_to_json()\u003c/code\u003e and \u003ccode\u003emodel_to_yaml()\u003c/code\u003e will help you out. To load the configurations back into your workspace, you can just use the \u003ccode\u003emodel_from_json()\u003c/code\u003e and \u003ccode\u003emodel_from yaml()\u003c/code\u003e functions:\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\r\n\u003cpre\u003e\r\n\u003ccode\u003ejson_string \u0026lt;- model_to_json(model)\r\nmodel \u0026lt;- model_from_json(json_string)\r\n\r\nyaml_string \u0026lt;- model_to_yaml(model)\r\nmodel \u0026lt;- model_from_yaml(yaml_string)\u003c/code\u003e\u003c/pre\u003e\r\n\r\n\u003cp\u003e\u003ca href=\"https://www.datacamp.com/courses/\" target=\"_blank\"\u003e\u003cimg alt=\"Learn Python for Data Science With DataCamp\" src=\"http://community.datacamp.com.s3.amazonaws.com/community/production/ckeditor_assets/pictures/293/content_blog_banner.png\" /\u003e\u003c/a\u003e\u003c/p\u003e\r\n\r\n\u003cdiv class=\"section level2\" id=\"deep-learning-with-keras\"\u003e\r\n\u003ch2\u003eDeep Learning With Keras\u003c/h2\u003e\r\n\r\n\u003cp\u003eCongrats! You\u0026rsquo;ve made it through this deep learning tutorial in R with \u003ccode\u003ekeras\u003c/code\u003e. This tutorial was just one small step in your deep learning journey with R; There\u0026rsquo;s much more to cover! If you haven\u0026rsquo;t taken DataCamp\u0026rsquo;s \u003ca href=\"https://www.datacamp.com/courses/deep-learning-in-python\"\u003eDeep Learning in Python\u003c/a\u003e course, you might consider doing so.\u003c/p\u003e\r\n\r\n\u003cp\u003eIn the meantime, also make sure to check out the \u003ca href=\"https://keras.io/\"\u003eKeras documentation\u003c/a\u003e and the RStudio \u003ca href=\"https://rstudio.github.io/keras/\"\u003e\u003ccode\u003ekeras\u003c/code\u003e documentation\u003c/a\u003e if you haven\u0026rsquo;t done so already. You\u0026rsquo;ll find more examples and information on all functions, arguments, more layers, etc\u0026hellip; Also check out Fran\u0026ccedil;ois Chollet\u0026rsquo;s book \u003ca href=\"https://www.manning.com/books/deep-learning-with-python\"\u003e\u0026ldquo;Deep Learning with Python\u0026rdquo;\u003c/a\u003e. All these resources will undoubtedly be indispensable in learning how to work with neural networks in R!\u003c/p\u003e\r\n\u003c/div\u003e\r\n","contentUrl":"https://www.datacamp.com/community/tutorials/keras-r-deep-learning","userContentUrl":null,"illustrationUrl":null,"seoTitle":"keras: Deep Learning in R","seoMetaDescription":"In this tutorial to deep learning in R with RStudio's keras package, you'll learn how to build a Multi-Layer Perceptron (MLP).","seoKeyword":"keras R","mustRead":true,"programmingLanguage":null,"submissionDate":"2017-06-28T12:50:19.000Z","publishDate":"2017-06-28T14:09:19.000Z","episode":null,"isLatest":null,"externalUrl":null,"transcriptUrl":null,"guests":[],"links":null,"isSpam":false,"xp":0,"flaggingUsers":[],"isDisabled":false,"connectedInternalContentId":null,"createdAt":"2017-09-08T15:37:41.007Z","updatedAt":"2018-02-22T08:28:49.917Z","upvoting":{"voteCount":40,"voted":false},"tags":["r programming","machine learning","keras","deep learning","neural networks"],"author":{"id":494311,"slug":"karlijn","avatarUrlSquare":"https://assets.datacamp.com/users/avatars/000/494/311/square/Screenshot_2017-04-26_16.02.58.png?1493215479","fullName":"Karlijn Willems","nameFromEmail":"karlijn","isAdmin":false}}]},"isFetched":true,"isFetching":false,"statusMessage":""},"countdownBanner":{"isBannerOpen":false},"form":{},"list":{"isFetched":false,"isFetching":false,"statusMessage":""},"menu":{"isSidebarMenuOpen":false},"notifications":{"isFetched":false,"isFetching":false,"isReadFetched":false,"isReadFetching":false,"statusMessage":"","readStatusMessage":"","Notifications":[],"NotificationsTotal":0,"unReadCount":0},"preview":{"isFetching":false,"isFetched":false,"statusMessage":"","content":{}},"recommendCS":{"isPosting":false,"isPosted":false,"statusMessage":"","isModalOpen":false,"currentStep":"form"},"spam":{"isFlagging":false,"isSucceeded":false,"statusMessage":"","isSpamModalOpen":false,"isUnSpamModalOpen":false},"tag":{"isRequesting":false,"isSucceeded":false,"statusMessage":"","isDeleteTagModalOpen":false},"tagList":{"isFetched":false,"isFetching":false,"statusMessage":"","list":[],"total":0},"tagSearch":{"isFetching":false,"isFetched":false,"statusMessage":"","content":{}},"user":{"isFetching":false,"isFetched":false,"statusMessage":"","unBan":{"isUnBanning":false,"isSucceeded":false,"statusMessage":"","isUnBanUserModalOpen":false},"ban":{"isBanning":false,"isSucceeded":false,"statusMessage":"","isBanUserModalOpen":false}},"writeTutorial":{"isPosting":false,"isPosted":false,"statusMessage":"","isModalOpen":false,"currentStep":"form"},"submitArticle":{"isPosting":false,"isPosted":false,"statusMessage":"","timer":0,"articleSlug":"","isModalOpen":false,"currentStep":"form","slug":"","externalUrl":""},"rss":{"isCreating":false,"isSucceeded":false,"statusMessage":""},"rssFeedList":{"isFetched":false,"isFetching":false,"statusMessage":"","list":[],"disconnectModal":{"isFetched":true,"isFetching":false,"isOpen":false,"rssFeedIdToDisconnect":null,"statusMessage":""}},"setAsHomePage":{"isSetAsHomePageModalOpen":false},"analytics":{}},"initialProps":{"asPath":"/community/tutorials/convolutional-neural-networks-python"}},"pathname":"/community/tutorial","query":{"slug":"convolutional-neural-networks-python"},"buildId":"9a2dc712-9af7-4e21-a9d3-69df29804418","buildStats":{"app.js":{"hash":"14f0f4b894fba68b2c2a3eb40ff1bbd4"}},"assetPrefix":"/community","nextExport":false,"err":null,"chunks":[]}
          module={}
          __NEXT_LOADED_PAGES__ = []
          __NEXT_LOADED_CHUNKS__ = []

          __NEXT_REGISTER_PAGE = function (route, fn) {
            __NEXT_LOADED_PAGES__.push({ route: route, fn: fn })
          }

          __NEXT_REGISTER_CHUNK = function (chunkName, fn) {
            __NEXT_LOADED_CHUNKS__.push({ chunkName: chunkName, fn: fn })
          }
        </script><script async="" id="__NEXT_PAGE__/community/tutorial" type="text/javascript" src="./Convolutional Neural Networks in Python (article) - DataCamp_files/tutorial.js"></script><script async="" id="__NEXT_PAGE__/_error" type="text/javascript" src="./Convolutional Neural Networks in Python (article) - DataCamp_files/_error.js"></script><script type="text/javascript" src="./Convolutional Neural Networks in Python (article) - DataCamp_files/app.js" async=""></script>
<script type="text/javascript" id="">!function(b,e,f,g,a,c,d){b.fbq||(a=b.fbq=function(){a.callMethod?a.callMethod.apply(a,arguments):a.queue.push(arguments)},b._fbq||(b._fbq=a),a.push=a,a.loaded=!0,a.version="2.0",a.queue=[],c=e.createElement(f),c.async=!0,c.src=g,d=e.getElementsByTagName(f)[0],d.parentNode.insertBefore(c,d))}(window,document,"script","https://connect.facebook.net/en_US/fbevents.js");fbq("init","286618111707433");fbq("track","PageView");</script>
<noscript>&lt;img height="1" width="1" style="display:none" src="https://www.facebook.com/tr?id=286618111707433&amp;amp;ev=PageView&amp;amp;noscript=1"&gt;</noscript>


<script type="text/javascript" id="">window._fs_debug=!1;window._fs_host="fullstory.com";window._fs_org="9HWCZ";window._fs_namespace="FS";
(function(e,f,k,l,g,c,b,h){k in e?e.console&&e.console.log&&e.console.log('FullStory namespace conflict. Please set window["_fs_namespace"].'):(b=e[k]=function(d,a){b.q?b.q.push([d,a]):b._api(d,a)},b.q=[],c=f.createElement(l),c.async=1,c.src="https://"+_fs_host+"/s/fs.js",h=f.getElementsByTagName(l)[0],h.parentNode.insertBefore(c,h),b.identify=function(d,a){b(g,{uid:d});a&&b(g,a)},b.setUserVars=function(d){b(g,d)},b.identifyAccount=function(d,a){c="account";a=a||{};a.acctId=d;b(c,a)},b.clearUserCookie=
function(b,a,c){if(!b||document.cookie.match("fs_uid\x3d[`;`]*`[`;`]*`[`;`]*`"))for(a=f.domain;;){f.cookie="fs_uid\x3d;domain\x3d"+a+";path\x3d/;expires\x3d"+(new Date(0)).toUTCString();c=a.indexOf(".");if(0>c)break;a=a.slice(c+1)}})})(window,document,window._fs_namespace,"script","user");</script>

<script type="text/javascript" id="">!function(d,e,f,a,b,c){d.qp||(a=d.qp=function(){a.qp?a.qp.apply(a,arguments):a.queue.push(arguments)},a.queue=[],b=document.createElement(e),b.async=!0,b.src=f,c=document.getElementsByTagName(e)[0],c.parentNode.insertBefore(b,c))}(window,"script","https://a.quora.com/qevents.js");qp("init","22bfea26b11042efa6e75ebd5c7e82b4");qp("track","ViewContent");</script>
<noscript>&lt;img height="1" width="1" style="display:none" src="https://q.quora.com/_/ad/22bfea26b11042efa6e75ebd5c7e82b4/pixel?tag=ViewContent&amp;amp;noscript=1"&gt;</noscript>

<script type="text/javascript" id="">qp("track","Generic");</script>
<script type="text/javascript" id="">!function(d,e){var b="001b340da40499a7b1f011e1db6e25ce11";if(d.obApi){var c=function(a){return"[object Array]"===Object.prototype.toString.call(a)?a:[a]};d.obApi.marketerId=c(d.obApi.marketerId).concat(c(b))}else{var a=d.obApi=function(){a.dispatch?a.dispatch.apply(a,arguments):a.queue.push(arguments)};a.version="1.1";a.loaded=!0;a.marketerId=b;a.queue=[];b=e.createElement("script");b.async=!0;b.src="//amplify.outbrain.com/cp/obtp.js";b.type="text/javascript";c=e.getElementsByTagName("script")[0];
c.parentNode.insertBefore(b,c)}}(window,document);obApi("track","PAGE_VIEW");</script>
<div class="ReactModalPortal"></div><div class="ReactModalPortal"></div><div class="ReactModalPortal"></div><div class="ReactModalPortal"></div><script src="./Convolutional Neural Networks in Python (article) - DataCamp_files/saved_resource" type="text/javascript"></script><div class="ReactModalPortal"></div><div class="ReactModalPortal"></div><div class="ReactModalPortal"></div><div class="ReactModalPortal"></div><script type="text/javascript" src="./Convolutional Neural Networks in Python (article) - DataCamp_files/script-8fa338a2dc.js" charset="utf-8"></script></body></html>