<!DOCTYPE html>
<!-- saved from url=(0069)https://www.datacamp.com/community/tutorials/lstm-python-stock-market -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><style type="text/css">@charset "UTF-8";[ng\:cloak],[ng-cloak],[data-ng-cloak],[x-ng-cloak],.ng-cloak,.x-ng-cloak,.ng-hide:not(.ng-hide-animate){display:none !important;}ng\:form{display:block;}.ng-animate-shim{visibility:hidden;}.ng-anchor{position:absolute;}</style><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" class="next-head"><meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" class="next-head"><meta name="google-site-verification" content="NXbTi7gyLQESV4NIskeE9Ka0Am8KjAtzg5gm8g38HbU" class="next-head"><title class="next-head">LSTM in Python: Stock Market Predictions (article) - DataCamp</title><link rel="author" href="https://plus.google.com/u/0/+Datacamp/" class="next-head"><link rel="shortcut icon" type="image/x-icon" href="https://cdn.datacamp.com/main-app/assets/favicon-335cd0394b32102a39221d79e5fd7e51078e6d32a0c8aea59676a6869f84e9d8.ico" class="next-head"><link rel="chrome-webstore-item" href="https://chrome.google.com/webstore/detail/lbbhbkehmgbndgfdbncbmikooblghdbi" class="next-head"><meta property="og:site_name" content="DataCamp Community" class="next-head"><meta name="twitter:card" content="summary" class="next-head"><meta name="twitter:site" content="@DataCamp" class="next-head"><meta name="twitter:creator" content="@DataCamp" class="next-head"><meta name="twitter:domain" content="www.datacamp.com" class="next-head"><meta name="twitter:image:width" content="1200" class="next-head"><meta name="twitter:image:height" content="628" class="next-head"><meta name="article:publisher" content="https://www.facebook.com/DataCamp-726282547396228" class="next-head"><meta name="fb:app_id" content="726282547396228" class="next-head"><script type="text/javascript" async="" src="./LSTM in Python_ Stock Market Predictions (article) - DataCamp_files/ga.js"></script><script type="text/javascript" async="" src="./LSTM in Python_ Stock Market Predictions (article) - DataCamp_files/linkid.js"></script><script async="" src="./LSTM in Python_ Stock Market Predictions (article) - DataCamp_files/obtp.js" type="text/javascript"></script><script async="" src="./LSTM in Python_ Stock Market Predictions (article) - DataCamp_files/qevents.js"></script><script src="./LSTM in Python_ Stock Market Predictions (article) - DataCamp_files/286618111707433" async=""></script><script async="" src="./LSTM in Python_ Stock Market Predictions (article) - DataCamp_files/fbevents.js"></script><script type="text/javascript" async="" src="./LSTM in Python_ Stock Market Predictions (article) - DataCamp_files/bat.js"></script><script type="text/javascript" async="" src="./LSTM in Python_ Stock Market Predictions (article) - DataCamp_files/insight.min.js"></script><script type="text/javascript" async="" src="./LSTM in Python_ Stock Market Predictions (article) - DataCamp_files/analytics.js"></script><script async="" src="./LSTM in Python_ Stock Market Predictions (article) - DataCamp_files/get-loader.js"></script><script async="" src="./LSTM in Python_ Stock Market Predictions (article) - DataCamp_files/BuKMCyKUvvyXZkMi44LjI.js"></script><script async="" src="./LSTM in Python_ Stock Market Predictions (article) - DataCamp_files/gtm.js"></script><script class="next-head">
      (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
      new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
      j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
      'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
      })(window,document,'script','dataLayer','GTM-TGGWB2P');
    </script><link rel="preload" href="./LSTM in Python_ Stock Market Predictions (article) - DataCamp_files/tutorials.js" as="script"><link rel="preload" href="./LSTM in Python_ Stock Market Predictions (article) - DataCamp_files/_error.js" as="script"><link rel="preload" href="./LSTM in Python_ Stock Market Predictions (article) - DataCamp_files/app.js" as="script"><style id="__jsx-2090414051">.Logo.jsx-2090414051{-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;}
.Logo__image.jsx-2090414051{display:block;width:122px;height:28px;margin-left:8px;}
.Logo__image.jsx-2090414051 svg{fill:#FFFFFF;}
@media (min-width:800px) and (min-height:650px){.Logo.jsx-2090414051{height:59px;}.Logo__image.jsx-2090414051{margin:17px auto 0;}}</style><style id="__jsx-2803075824">.SidebarMenu.jsx-2803075824{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;position:fixed;z-index:300;width:100vw;height:50px;background-image: linear-gradient(207deg, #2388B0, #33AACC);}
.Layout--banner .SidebarMenu.jsx-2803075824{top:55px;}
.icon.jsx-2803075824{text-align:right;}
.icon.jsx-2803075824 svg{margin-right:9px;width:20px;height:20px;fill:#FFFFFF;}
@media (min-width:800px) and (min-height:650px){.SidebarMenu.jsx-2803075824{z-index:200;width:220px;top:0;left:0;background-image:none;}.Layout--banner .SidebarMenu.jsx-2803075824{top:80px;}}</style><style id="__jsx-2919104997">.Menu.jsx-2919104997{-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;margin-top:50px;}
.Layout--banner .Menu.jsx-2919104997{margin-top:105px;}
.Layout--openMenu .Menu.jsx-2919104997{min-height:calc(100vh - 50px - 134px);}
.Layout--openMenu.Layout--banner .Menu.jsx-2919104997{min-height:calc(100vh - 105px - 134px);}
.section.jsx-2919104997{margin-bottom:20px;}
.section.jsx-2919104997 h5.jsx-2919104997{margin:0;padding-left:17px;font-size:13px;-webkit-letter-spacing:3.3px;-moz-letter-spacing:3.3px;-ms-letter-spacing:3.3px;letter-spacing:3.3px;line-height:36px;text-align:left;text-transform:uppercase;background-color:#195B73;color:#7ECCE2;}
.item.jsx-2919104997{margin-bottom:1px;padding-left:12px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-align-content:center;-ms-flex-line-pack:center;align-content:center;font-size:15px;-webkit-letter-spacing:0.2px;-moz-letter-spacing:0.2px;-ms-letter-spacing:0.2px;letter-spacing:0.2px;line-height:40px;text-decoration:none;color:#FFFFFF;}
.statusIcon.jsx-2919104997{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-self:center;-ms-flex-item-align:center;align-self:center;padding:10px;}
.active.jsx-2919104997{background-color:#55AECB;}
a.jsx-2919104997:hover{background-color:#55AECB;}
.image.jsx-2919104997{margin-top:2px;-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;width:30px;height:30px;text-align:center;}
.image.jsx-2919104997 svg{fill:#195B73;}
.active.jsx-2919104997 svg,a.jsx-2919104997:hover svg{fill:#FFFFFF;}
.text.jsx-2919104997{-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;}
.subMenu.jsx-2919104997{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}
@media (min-width:800px) and (min-height:650px){.Menu.jsx-2919104997{position:fixed;width:220px;margin-top:50px;}.Layout--banner .Menu.jsx-2919104997{margin-top:130px;}.section.jsx-2919104997 h5.jsx-2919104997{padding-left:0;text-align:center;}}</style><style id="__jsx-322537325">.Button.jsx-322537325{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;height:33px;margin:auto 5px;padding:0 15px;font-size:13px;font-weight:bold;-webkit-letter-spacing:0.2px;-moz-letter-spacing:0.2px;-ms-letter-spacing:0.2px;letter-spacing:0.2px;white-space:nowrap;color:#3A3A3A;border:1px solid transparent;border-radius:4px;background-color:transparent;cursor:pointer;outline:none;}
.Button.jsx-322537325::before,.Button.jsx-322537325::after{content:'';-webkit-flex:1 0 auto;-ms-flex:1 0 auto;flex:1 0 auto;}
.icon.jsx-322537325{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;min-height:20px;}
.icon.jsx-322537325 svg{-webkit-flex:1 1 0;-ms-flex:1 1 0;flex:1 1 0;height:20px;-webkit-align-self:center;-ms-flex-item-align:center;align-self:center;fill:#33AACC;}
.greyIcon.jsx-322537325 .icon.jsx-322537325 svg{min-width:16px;min-height:16px;fill:#3A3A3A;}
.same.jsx-322537325 .icon.jsx-322537325{min-width:13px;height:13px;margin-right:5px;}
.same.jsx-322537325 .icon.jsx-322537325 svg{height:13px;}
.Button.jsx-322537325:disabled,.Button.jsx-322537325:hover.jsx-322537325:disabled{color:#D1D3D8;background-color:#E6EAEB;}
.primary.jsx-322537325{background-color:#FFC844;}
.primary.jsx-322537325:hover{background-color:#FBE28D;}
.secondary.jsx-322537325{color:#FFFFFF;background-color:#33AACC;}
.secondary.jsx-322537325:hover{background-color:#7ECCE2;}
.red.jsx-322537325{color:#FFFFFF;background-color:#FE5C5C;}
.green.jsx-322537325{height:35px;color:#FFFFFF;background-color:#FFFFFF;}
.green.jsx-322537325 .icon.jsx-322537325 svg{fill:#36D57D;width:35px;height:35px;}
.grey.jsx-322537325{color:#3D4251;background-color:#D1D3D8;}
.grey.jsx-322537325:hover{color:#3D4251;background-color:#E6EAEB;}
.big.jsx-322537325{font-size:15px;height:42px;}
.extra.jsx-322537325{font-size:17px;height:45px;}
.border.jsx-322537325{border:1px solid #E3E7E8;}
.border.jsx-322537325:hover{border:1px solid #33AACC;}
.seeAll.jsx-322537325{border:1px solid #33AACC;}
.seeAll.jsx-322537325:hover{border:1px solid #FFC844;}
.iconButton.jsx-322537325:hover{color:#33AACC;}
.minWidth.jsx-322537325{min-width:85px;}
.noPadding.jsx-322537325{padding:0;}
@media (min-width:800px) and (min-height:650px){.icon.jsx-322537325{min-width:13px;height:13px;margin-right:5px;}.icon.jsx-322537325 svg{height:13px;}.big.jsx-322537325 .icon.jsx-322537325{min-width:15px;height:15px;}.big.jsx-322537325 svg{height:15px;}.extra.jsx-322537325 .icon.jsx-322537325,.extraIcon.jsx-322537325{min-width:17px;height:17px;}.extra.jsx-322537325 svg,.extraIcon.jsx-322537325 svg{height:17px;}.green.jsx-322537325{padding:0 15px;color:#FFFFFF;background-color:#36D57D;}.green.jsx-322537325 .icon.jsx-322537325 svg{width:13px;height:13px;fill:#FFFFFF;}.forcePadding.jsx-322537325{padding:0 15px;}}</style><style id="__jsx-3863678361">.ActionBarSearch.jsx-3863678361{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:start;-webkit-justify-content:flex-start;-ms-flex-pack:start;justify-content:flex-start;}</style><style id="__jsx-3666761727">.SubmitAnArticleButton.jsx-3666761727{margin-left:5px;}
.mobileButton.jsx-3666761727{display:block !important;}
.mobileButton.jsx-3666761727 svg{fill:#36D57D;width:35px;height:35px;}
.SubmitAnArticleButton.jsx-3666761727 .desktopButton{display:none !important;}
@media (min-width:800px) and (min-height:650px){.mobileButton.jsx-3666761727{display:none !important;}.SubmitAnArticleButton.jsx-3666761727 .desktopButton{display:-webkit-box !important;display:-webkit-flex !important;display:-ms-flexbox !important;display:flex !important;}}</style><style id="__jsx-3196442269">.ActionBarAuth.jsx-3196442269{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:end;-webkit-justify-content:flex-end;-ms-flex-pack:end;justify-content:flex-end;}
.wrapper.jsx-3196442269{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;cursor:pointer;}
.name.jsx-3196442269{margin-right:9px;font-size:13px;font-weight:bold;color:#3D4251;text-decoration:none;}
.name.jsx-3196442269:hover{color:#33AACC;}
.logout.jsx-3196442269{font-size:15px;padding:10px;color:#3D4251;display:inline-block;min-width:100px;}
.logout.jsx-3196442269:hover{background-color:#F0F4F5;border-bottom:solid 1px #E3E7E8;}
.menuList.jsx-3196442269 a.jsx-3196442269{display:block;}</style><style id="__jsx-702933904">.ActionBar.jsx-702933904{height:50px;margin-top:50px;padding:0 5px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;background-color:#FFFFFF;border-bottom:1px solid #E3E7E8;}
.authBlock.jsx-702933904{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-fles-direction:row;-ms-fles-direction:row;fles-direction:row;}
.Page.content .ActionBar{margin-bottom:10px;}
@media (min-width:800px) and (min-height:650px){.ActionBar.jsx-702933904{width:calc(100% - 220px);height:50px;margin-top:0;margin-bottom:0;padding:0 25px;position:fixed;z-index:300;}}</style><style id="__jsx-3889859319">.Title.jsx-3889859319{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}
.Title.jsx-3889859319 .icon.jsx-3889859319{-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;min-width:18px;height:18px;}
.icon.jsx-3889859319 svg{-webkit-flex:1 1 0;-ms-flex:1 1 0;flex:1 1 0;height:18px;-webkit-align-self:center;-ms-flex-item-align:center;align-self:center;fill:#33AACC;}
.Title.jsx-3889859319 .h1.jsx-3889859319,.Title.jsx-3889859319 h1.jsx-3889859319{-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;margin:auto 0 auto 9px;font-size:22px;text-transform:capitalize;}
.Title.jsx-3889859319 .status.jsx-3889859319{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-self:center;-ms-flex-item-align:center;align-self:center;padding:10px;}</style><style id="__jsx-1374485364">.TitleBar.jsx-1374485364{height:50px;padding:0 5px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;line-height:50px;background-color:#FFFFFF;border-bottom:1px solid #E3E7E8;margin-bottom:65px;}
.filter.jsx-1374485364{-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;height:48px;}
.action.jsx-1374485364{-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;line-height:normal;}
.title.jsx-1374485364{height:65px;line-height:65px;-webkit-flex:0 0 100%;-ms-flex:0 0 100%;flex:0 0 100%;-webkit-order:1;-ms-flex-order:1;order:1;text-align:center;}
h1.jsx-1374485364{margin:0 0;}
.Page.content .TitleBar{display:none;}
@media (min-width:800px) and (min-height:650px){.TitleBar.jsx-1374485364{height:50px;padding:0 25px;display:-webkit-box !important;display:-webkit-flex !important;display:-ms-flexbox !important;display:flex !important;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-flex-wrap:nowrap;-ms-flex-wrap:nowrap;flex-wrap:nowrap;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;margin-bottom:29px;margin-top:50px;background-color:#FFFFFF;border-bottom:1px solid #E3E7E8;}.filter.jsx-1374485364{-webkit-flex:0 0 33%;-ms-flex:0 0 33%;flex:0 0 33%;line-height:normal;}.action.jsx-1374485364{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:end;-webkit-justify-content:flex-end;-ms-flex-pack:end;justify-content:flex-end;line-height:normal;-webkit-flex:0 0 33%;-ms-flex:0 0 33%;flex:0 0 33%;}.action.jsx-1374485364 a{line-height:0;}.title.jsx-1374485364{-webkit-order:0;-ms-flex-order:0;order:0;-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;text-align:center;}h1.jsx-1374485364{margin:0 0;}}</style><style id="__jsx-3208234818">.Avatar.jsx-3208234818{display:inline-block;background-size:cover;background-color:#E6EAEB;background-repeat:no-repeat;}</style><style id="__jsx-3269835606">.SidebarSocial.jsx-3269835606{-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;font-size:11px;font-weight:bold;}
.rss.jsx-3269835606{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;line-height:50px;}
.rss.jsx-3269835606 svg{padding-right:7px;fill:#FFC844;}
.rss.jsx-3269835606 a.jsx-3269835606{text-decoration:none;color:#FFFFFF;}
.rss.jsx-3269835606 a.jsx-3269835606:hover{text-decoration:none;color:#FFC844;}
.icons.jsx-3269835606{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}
.icon.jsx-3269835606{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;margin:0 7px;width:30px;height:30px;background-color:#195B73;border-radius:50%;}
.icon.jsx-3269835606 svg{fill:#7ECCE2;-webkit-align-self:center;-ms-flex-item-align:center;align-self:center;-webkit-flex:1 1 0;-ms-flex:1 1 0;flex:1 1 0;}
.icon.jsx-3269835606:hover svg{fill:#FFFFFF;}
.menu.jsx-3269835606{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;line-height:44px;}
.menuItem.jsx-3269835606{-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;padding:5px;text-decoration:none;color:#195B73;}
.menuItem--active.jsx-3269835606,a.jsx-3269835606:hover{color:#F0F4F5;}
@media (min-width:800px) and (min-height:650px){.SidebarSocial.jsx-3269835606{width:220px;position:fixed;bottom:0;left:0;}}</style><style id="__jsx-1902599493">.Layout.jsx-1902599493{-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-box-pack:start;-webkit-justify-content:flex-start;-ms-flex-pack:start;justify-content:flex-start;-webkit-align-items:stretch;-webkit-box-align:stretch;-ms-flex-align:stretch;align-items:stretch;}
.Layout--openMenu.jsx-1902599493{min-height:100vh;}
.Main.jsx-1902599493{min-height:100vh;-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;background-color:#F0F4F5;}
.Layout--banner.jsx-1902599493 .Main.jsx-1902599493{margin-top:55px;min-height:calc(100vh - 55px);}
.Layout.bar.jsx-1902599493:not(.Layout--openMenu) .SidebarSocial{margin-bottom:90px;}
.Layout.editor.jsx-1902599493:not(.Layout--openMenu) .SidebarSocial{margin-bottom:300px;}
@media (min-width:800px) and (min-height:650px){.Main.jsx-1902599493{margin-left:220px;}.Layout--banner.jsx-1902599493 .Main.jsx-1902599493{margin-top:80px;min-height:calc(100vh - 80px);}.Layout.bar.jsx-1902599493:not(.Layout--openMenu) .SidebarSocial,.Layout.editor.jsx-1902599493:not(.Layout--openMenu) .SidebarSocial{margin-bottom:0;}.Layout.bar.jsx-1902599493 .Main > div:last-child{margin-bottom:90px;}.Layout.editor.jsx-1902599493 .Main > div:last-child{margin-bottom:300px;}}</style><style id="__jsx-2361248863">*{box-sizing:border-box;}
html,body{min-height:100vh;margin:0;padding:0;background-image: linear-gradient(207deg, #2388B0, #33AACC); background-size: 100vw 100vh; background-attachment: fixed; background-repeat: no-repeat;}
body.ReactModal__Body--open{overflow:hidden;}
.ReactModal__Content{width:100%;}
img{margin:auto;}
.mobileOnlyShow{display:block !important;}
.mobileOnlyHide{display:none !important;}
.mobileOnly{display:block !important;}
.desktopOnly{display:none !important;}
@media (min-width:800px) and (min-height:650px){body{background-image: linear-gradient(207deg, #2388B0, #33AACC); background-size: 220px 100vh; background-attachment: fixed; background-repeat: no-repeat;}.ReactModal__Content{width:auto;}.mobileOnlyShow{display:block !important;}.mobileOnlyHide{display:block !important;}.mobileOnly{display:none !important;}.desktopOnly{display:block !important;}}</style><style id="__jsx-1302975859">body,input,button,select,textarea{font-family:'Lato',sans-serif;color:#686F75;font-size:15px;}
h1,.h1,h2,h3,h4,h5{font-family:'Lato',sans-serif;}
.pageTitle{font-family:'Lato',sans-serif;font-size:32px;font-weight:bold;line-height:1.3em;margin-bottom:0.5em;}
.pageDescription{font-family:'Lora',serif;font-size:20.8px;line-height:1.5em;margin-bottom:1.4em;color:#3D4251;}
h1,.h1{font-size:29px;color:#3D4251;font-weight:bold;}
h2{font-size:20px;-webkit-letter-spacing:0.3px;-moz-letter-spacing:0.3px;-ms-letter-spacing:0.3px;letter-spacing:0.3px;line-height:1.33;font-weight:bold;margin:18px 0px;color:#3D4251;}
h2.blue{color:#33AACC;}
a{color:#33AACC;text-decoration:none;}
.blocText{font-size:15px;-webkit-letter-spacing:0.2px;-moz-letter-spacing:0.2px;-ms-letter-spacing:0.2px;letter-spacing:0.2px;line-height:1.47;color:#686F75;}
label{display:block;width:100%;margin-bottom:8px;font-size:13px;}
label span{float:right;font-weight:300;}
input,textarea{padding:15px;font-weight:300;color:#3D4251;background-color:#F0F4F5;border:1px solid transparent;border-radius:4px;outline-style:none;}
input:disabled,textarea:disabled{color:#686F75;background-color:#E6EAEB;}
input.error,textarea.error{border:1px solid #FE5C5C;}
input:focus,textarea:focus{border:1px solid #33AACC;-webkit-transition:border 150ms ease-out;transition:border 150ms ease-out;}
input::-webkit-input-placeholder,textarea::-webkit-input-placeholder{color:#33AACC;-webkit-transition:color 150ms ease-out;transition:color 150ms ease-out;}
input::-moz-placeholder,textarea::-moz-placeholder{color:#33AACC;-webkit-transition:color 150ms ease-out;transition:color 150ms ease-out;}
input:-ms-input-placeholder,textarea:-ms-input-placeholder{color:#33AACC;-webkit-transition:color 150ms ease-out;transition:color 150ms ease-out;}
input::placeholder,textarea::placeholder{color:#33AACC;-webkit-transition:color 150ms ease-out;transition:color 150ms ease-out;}
input:focus::-webkit-input-placeholder,textarea:focus::-webkit-input-placeholder{color:transparent;}
input:focus::-moz-placeholder,textarea:focus::-moz-placeholder{color:transparent;}
input:focus:-ms-input-placeholder,textarea:focus:-ms-input-placeholder{color:transparent;}
input:focus::placeholder,textarea:focus::placeholder{color:transparent;}
input.small,textarea.small{margin-bottom:19px;padding:8px 10px;font-size:13px;}
textarea.small{min-height:55px;}
@media (min-width:800px) and (min-height:650px){h1,.h1{font-size:36px;}h2{font-size:32px;}.pageTitle{font-size:40px;}.pageDescription{font-size:26px;}}</style><style type="text/css" data-styled-jsx=""></style><style id="wisepops-default-style" type="text/css"> /* RESET */ .wisepop-popin div, .wisepop-popin span, .wisepop-popin applet, .wisepop-popin object, .wisepop-popin iframe, .wisepop-popin h1, .wisepop-popin h2, .wisepop-popin h3, .wisepop-popin h4, .wisepop-popin h5, .wisepop-popin h6, .wisepop-popin p, .wisepop-popin blockquote, .wisepop-popin pre, .wisepop-popin a, .wisepop-popin abbr, .wisepop-popin acronym, .wisepop-popin address, .wisepop-popin big, .wisepop-popin cite, .wisepop-popin code, .wisepop-popin del, .wisepop-popin dfn, .wisepop-popin em, .wisepop-popin img, .wisepop-popin ins, .wisepop-popin kbd, .wisepop-popin q, .wisepop-popin s, .wisepop-popin samp, .wisepop-popin small, .wisepop-popin strike, .wisepop-popin strong, .wisepop-popin sub, .wisepop-popin sup, .wisepop-popin tt, .wisepop-popin var, .wisepop-popin b, .wisepop-popin u, .wisepop-popin i, .wisepop-popin center, .wisepop-popin dl, .wisepop-popin dt, .wisepop-popin dd, .wisepop-popin ol, .wisepop-popin ul, .wisepop-popin li, .wisepop-popin fieldset, .wisepop-popin form, .wisepop-popin label, .wisepop-popin legend, .wisepop-popin table, .wisepop-popin caption, .wisepop-popin tbody, .wisepop-popin tfoot, .wisepop-popin thead, .wisepop-popin tr, .wisepop-popin th, .wisepop-popin td, .wisepop-popin article, .wisepop-popin aside, .wisepop-popin canvas, .wisepop-popin details, .wisepop-popin embed, .wisepop-popin figure, .wisepop-popin figcaption, .wisepop-popin footer, .wisepop-popin header, .wisepop-popin hgroup, .wisepop-popin menu, .wisepop-popin nav, .wisepop-popin output, .wisepop-popin ruby, .wisepop-popin section, .wisepop-popin summary, .wisepop-popin time, .wisepop-popin mark, .wisepop-popin audio, .wisepop-popin video { margin: 0; padding: 0; border: 0; font: inherit; color: inherit; text-transform: initial; vertical-align: baseline; clear: none; } .wisepop-popin h1 { font-size: 26px; } .wisepop-popin h2 { font-size: 20px; } .wisepop-popin h3 { font-size: 14px; } .wisepop-popin h4 { font-size: 13px; } .wisepop-popin h5 { font-size: 12px; } .wisepop-popin h6 { font-size: 10px; } .wisepop-popin h1, .wisepop-popin h2, .wisepop-popin h3, .wisepop-popin h4, .wisepop-popin h5, .wisepop-popin h6 { line-height: initial; } .wisepop-popin input, .wisepop-popin input[type="text"], .wisepop-popin input[type="password"], .wisepop-popin input[type="email"], .wisepop-popin button, .wisepop-popin select, .wisepop-popin textarea{ margin: 0; padding: 0; font-family: inherit; font-weight: inherit; clear: none; display: inline-block; float: none; resize: none; } .wisepop-popin hr { border: 0; border-top: 1px solid #eee; border-bottom: 1px solid #fff; } .wisepop-popin p { margin-bottom: 10px; } .wisepop-popin strong, .wisepop-popin b { font-weight: bold; } .wisepop-popin em, .wisepop-popin i { font-style: italic; } /* DEFAULT STYLE */ .wisepop-popin { padding: 20px; font-family: Arial, Helvetica, sans-serif; font-weight: normal; color: #5e5e64; background-clip: padding-box; -webkit-font-smoothing: antialiased; display: flex; flex-direction: column; box-sizing: content-box; } .wise-tab { box-sizing: content-box; background-size: cover; background-position: center; } .wisepop-popin > div:last-child, #wisepop-content > div:last-child { margin-bottom: 0 !important; } .wisepop-content { position: relative; flex-grow: 1; min-height: 1px; } .wisepop-popin .optin-block input:first-child{ margin-right: 0; } .wisepop-popin input{ padding: 4px 6px; margin-right: 0; } .wisepop-popin input[type="text"], .wisepop-popin select, .wisepop-popin textarea { color: #444; border: 1px solid #cccccc; -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075); -moz-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075); box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075); -webkit-transition: border linear 0.2s, box-shadow linear 0.2s; -moz-transition: border linear 0.2s, box-shadow linear 0.2s; -o-transition: border linear 0.2s, box-shadow linear 0.2s; transition: border linear 0.2s, box-shadow linear 0.2s; font-size: 14px; line-height: 20px; vertical-align: middle; -webkit-border-radius: 4px; -moz-border-radius: 4px; border-radius: 4px; background-color: #ffffff; } .wisepop-popin select.empty-value { color: #999; } .wisepop-popin select option:not(.placeholder) { color: #444; } .wisepop-popin .optin-block { margin: 0 auto; text-align: center; } .wisepop-background-image { width: 100%; height: 100%; position: absolute; top: 0; left: 0; z-index: 0; } .wisepop-close { display: inline-block; position: absolute; top:11px; right:12px; color: #fff; font-weight: bold; z-index: 1; } @-webkit-keyframes wisepops-bounce-arrow { 0%,to { -webkit-transform: translateX(0); transform: translateX(0); -webkit-animation-timing-function: cubic-bezier(.215,.61,.355,1); animation-timing-function: cubic-bezier(.215,.61,.355,1) } 50% { -webkit-transform: translateX(6px); transform: translateX(6px); -webkit-animation-timing-function: cubic-bezier(.55,.055,.675,.19); animation-timing-function: cubic-bezier(.55,.055,.675,.19) } } @keyframes wisepops-bounce-arrow { 0%,to { -webkit-transform: translateX(0); transform: translateX(0); -webkit-animation-timing-function: cubic-bezier(.215,.61,.355,1); animation-timing-function: cubic-bezier(.215,.61,.355,1) } 50% { -webkit-transform: translateX(6px); transform: translateX(6px); -webkit-animation-timing-function: cubic-bezier(.55,.055,.675,.19); animation-timing-function: cubic-bezier(.55,.055,.675,.19) } } </style><style type="text/css">@font-face { font-family: 'Lato'; font-style: normal; font-weight: 400; src: local('Lato Regular'), local('Lato-Regular'), url(//themes.googleusercontent.com/static/fonts/lato/v7/gvU2Gsy-6VVrDSxbk9hveQ.woff) format('woff'); }@font-face { font-family: 'Raleway'; font-style: normal; font-weight: 400; src: local('Raleway'), url(//fonts.gstatic.com/s/raleway/v9/IczWvq5y_Cwwv_rBjOtT0w.woff) format('woff'); }</style><script async="" src="./LSTM in Python_ Stock Market Predictions (article) - DataCamp_files/datacamp-light-latest.min.js"></script><script async="" src="./LSTM in Python_ Stock Market Predictions (article) - DataCamp_files/highlight.min.js"></script><script async="" src="./LSTM in Python_ Stock Market Predictions (article) - DataCamp_files/MathJax.js"></script><script async="" src="./LSTM in Python_ Stock Market Predictions (article) - DataCamp_files/r.min.js"></script><style type="text/css">.MathJax_Hover_Frame {border-radius: .25em; -webkit-border-radius: .25em; -moz-border-radius: .25em; -khtml-border-radius: .25em; box-shadow: 0px 0px 15px #83A; -webkit-box-shadow: 0px 0px 15px #83A; -moz-box-shadow: 0px 0px 15px #83A; -khtml-box-shadow: 0px 0px 15px #83A; border: 1px solid #A6D ! important; display: inline-block; position: absolute}
.MathJax_Menu_Button .MathJax_Hover_Arrow {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 4px; -webkit-border-radius: 4px; -moz-border-radius: 4px; -khtml-border-radius: 4px; font-family: 'Courier New',Courier; font-size: 9px; color: #F0F0F0}
.MathJax_Menu_Button .MathJax_Hover_Arrow span {display: block; background-color: #AAA; border: 1px solid; border-radius: 3px; line-height: 0; padding: 4px}
.MathJax_Hover_Arrow:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_Hover_Arrow:hover span {background-color: #CCC!important}
</style><style type="text/css">#MathJax_About {position: fixed; left: 50%; width: auto; text-align: center; border: 3px outset; padding: 1em 2em; background-color: #DDDDDD; color: black; cursor: default; font-family: message-box; font-size: 120%; font-style: normal; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 15px; -webkit-border-radius: 15px; -moz-border-radius: 15px; -khtml-border-radius: 15px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_About.MathJax_MousePost {outline: none}
.MathJax_Menu {position: absolute; background-color: white; color: black; width: auto; padding: 5px 0px; border: 1px solid #CCCCCC; margin: 0; cursor: default; font: menu; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 5px; -webkit-border-radius: 5px; -moz-border-radius: 5px; -khtml-border-radius: 5px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
.MathJax_MenuItem {padding: 1px 2em; background: transparent}
.MathJax_MenuArrow {position: absolute; right: .5em; padding-top: .25em; color: #666666; font-size: .75em}
.MathJax_MenuActive .MathJax_MenuArrow {color: white}
.MathJax_MenuArrow.RTL {left: .5em; right: auto}
.MathJax_MenuCheck {position: absolute; left: .7em}
.MathJax_MenuCheck.RTL {right: .7em; left: auto}
.MathJax_MenuRadioCheck {position: absolute; left: .7em}
.MathJax_MenuRadioCheck.RTL {right: .7em; left: auto}
.MathJax_MenuLabel {padding: 1px 2em 3px 1.33em; font-style: italic}
.MathJax_MenuRule {border-top: 1px solid #DDDDDD; margin: 4px 3px}
.MathJax_MenuDisabled {color: GrayText}
.MathJax_MenuActive {background-color: #606872; color: white}
.MathJax_MenuDisabled:focus, .MathJax_MenuLabel:focus {background-color: #E8E8E8}
.MathJax_ContextMenu:focus {outline: none}
.MathJax_ContextMenu .MathJax_MenuItem:focus {outline: none}
#MathJax_AboutClose {top: .2em; right: .2em}
.MathJax_Menu .MathJax_MenuClose {top: -10px; left: -10px}
.MathJax_MenuClose {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; font-family: 'Courier New',Courier; font-size: 24px; color: #F0F0F0}
.MathJax_MenuClose span {display: block; background-color: #AAA; border: 1.5px solid; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; line-height: 0; padding: 8px 0 6px}
.MathJax_MenuClose:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_MenuClose:hover span {background-color: #CCC!important}
.MathJax_MenuClose:hover:focus {outline: none}
</style><style type="text/css">.MathJax_Preview .MJXf-math {color: inherit!important}
</style><style type="text/css">.MJX_Assistive_MathML {position: absolute!important; top: 0; left: 0; clip: rect(1px, 1px, 1px, 1px); padding: 1px 0 0 0!important; border: 0!important; height: 1px!important; width: 1px!important; overflow: hidden!important; display: block!important; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none}
.MJX_Assistive_MathML.MJX_Assistive_MathML_Block {width: 100%!important}
</style><style type="text/css">#MathJax_Zoom {position: absolute; background-color: #F0F0F0; overflow: auto; display: block; z-index: 301; padding: .5em; border: 1px solid black; margin: 0; font-weight: normal; font-style: normal; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; -webkit-box-sizing: content-box; -moz-box-sizing: content-box; box-sizing: content-box; box-shadow: 5px 5px 15px #AAAAAA; -webkit-box-shadow: 5px 5px 15px #AAAAAA; -moz-box-shadow: 5px 5px 15px #AAAAAA; -khtml-box-shadow: 5px 5px 15px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_ZoomOverlay {position: absolute; left: 0; top: 0; z-index: 300; display: inline-block; width: 100%; height: 100%; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
#MathJax_ZoomFrame {position: relative; display: inline-block; height: 0; width: 0}
#MathJax_ZoomEventTrap {position: absolute; left: 0; top: 0; z-index: 302; display: inline-block; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
</style><style type="text/css">.MathJax_Preview {color: #888}
#MathJax_Message {position: fixed; left: 1em; bottom: 1.5em; background-color: #E6E6E6; border: 1px solid #959595; margin: 0px; padding: 2px 8px; z-index: 102; color: black; font-size: 80%; width: auto; white-space: nowrap}
#MathJax_MSIE_Frame {position: absolute; top: 0; left: 0; width: 0px; z-index: 101; border: 0px; margin: 0px; padding: 0px}
.MathJax_Error {color: #CC0000; font-style: italic}
</style><style type="text/css">div.datacamp-exercise {  margin: 0;  border: 1px solid #d5eaef;  background: none;  position: relative;  min-height: 300px;  color: black;  box-shadow: none;}div[data-datacamp-exercise] {  margin: 0;  border: 1px solid #d5eaef;  background: #fff url(https://cdn.datacamp.com/spinner.gif) no-repeat center center !important;  background-size: auto 80px !important;  position: relative;  min-height: 300px;  color: transparent;  box-shadow: none;}div[data-datacamp-exercise] > code,div[data-datacamp-exercise] > div,div[data-datacamp-exercise] > p {  display: none;}div.powered-by-datacamp {  margin: 5px 0;  display: block;}div.powered-by-datacamp a {@import "https://fonts.googleapis.com/css?family=Open+Sans";  font-family: "Open Sans", sans-serif;  text-decoration: none;  border: 0;  color: #3ac;  font-size: 20px;}div.powered-by-datacamp .logo {  vertical-align: sub;  display: inline-block;  background: url("https://cdn.datacamp.com/dcl/assets/images/logo_blue.svg") no-repeat center center;  background-size: contain;  height: 27px;  width: 23px;  margin-left: 4px;}</style><link type="text/css" rel="stylesheet" href="./LSTM in Python_ Stock Market Predictions (article) - DataCamp_files/style-8c2f2e17fe.css"><link type="text/css" rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css"><style type="text/css">.MJXp-script {font-size: .8em}
.MJXp-right {-webkit-transform-origin: right; -moz-transform-origin: right; -ms-transform-origin: right; -o-transform-origin: right; transform-origin: right}
.MJXp-bold {font-weight: bold}
.MJXp-italic {font-style: italic}
.MJXp-scr {font-family: MathJax_Script,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-frak {font-family: MathJax_Fraktur,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-sf {font-family: MathJax_SansSerif,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-cal {font-family: MathJax_Caligraphic,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-mono {font-family: MathJax_Typewriter,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-largeop {font-size: 150%}
.MJXp-largeop.MJXp-int {vertical-align: -.2em}
.MJXp-math {display: inline-block; line-height: 1.2; text-indent: 0; font-family: 'Times New Roman',Times,STIXGeneral,serif; white-space: nowrap; border-collapse: collapse}
.MJXp-display {display: block; text-align: center; margin: 1em 0}
.MJXp-math span {display: inline-block}
.MJXp-box {display: block!important; text-align: center}
.MJXp-box:after {content: " "}
.MJXp-rule {display: block!important; margin-top: .1em}
.MJXp-char {display: block!important}
.MJXp-mo {margin: 0 .15em}
.MJXp-mfrac {margin: 0 .125em; vertical-align: .25em}
.MJXp-denom {display: inline-table!important; width: 100%}
.MJXp-denom > * {display: table-row!important}
.MJXp-surd {vertical-align: top}
.MJXp-surd > * {display: block!important}
.MJXp-script-box > *  {display: table!important; height: 50%}
.MJXp-script-box > * > * {display: table-cell!important; vertical-align: top}
.MJXp-script-box > *:last-child > * {vertical-align: bottom}
.MJXp-script-box > * > * > * {display: block!important}
.MJXp-mphantom {visibility: hidden}
.MJXp-munderover {display: inline-table!important}
.MJXp-over {display: inline-block!important; text-align: center}
.MJXp-over > * {display: block!important}
.MJXp-munderover > * {display: table-row!important}
.MJXp-mtable {vertical-align: .25em; margin: 0 .125em}
.MJXp-mtable > * {display: inline-table!important; vertical-align: middle}
.MJXp-mtr {display: table-row!important}
.MJXp-mtd {display: table-cell!important; text-align: center; padding: .5em 0 0 .5em}
.MJXp-mtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-mlabeledtr {display: table-row!important}
.MJXp-mlabeledtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mlabeledtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
.MJXp-scale0 {-webkit-transform: scaleX(.0); -moz-transform: scaleX(.0); -ms-transform: scaleX(.0); -o-transform: scaleX(.0); transform: scaleX(.0)}
.MJXp-scale1 {-webkit-transform: scaleX(.1); -moz-transform: scaleX(.1); -ms-transform: scaleX(.1); -o-transform: scaleX(.1); transform: scaleX(.1)}
.MJXp-scale2 {-webkit-transform: scaleX(.2); -moz-transform: scaleX(.2); -ms-transform: scaleX(.2); -o-transform: scaleX(.2); transform: scaleX(.2)}
.MJXp-scale3 {-webkit-transform: scaleX(.3); -moz-transform: scaleX(.3); -ms-transform: scaleX(.3); -o-transform: scaleX(.3); transform: scaleX(.3)}
.MJXp-scale4 {-webkit-transform: scaleX(.4); -moz-transform: scaleX(.4); -ms-transform: scaleX(.4); -o-transform: scaleX(.4); transform: scaleX(.4)}
.MJXp-scale5 {-webkit-transform: scaleX(.5); -moz-transform: scaleX(.5); -ms-transform: scaleX(.5); -o-transform: scaleX(.5); transform: scaleX(.5)}
.MJXp-scale6 {-webkit-transform: scaleX(.6); -moz-transform: scaleX(.6); -ms-transform: scaleX(.6); -o-transform: scaleX(.6); transform: scaleX(.6)}
.MJXp-scale7 {-webkit-transform: scaleX(.7); -moz-transform: scaleX(.7); -ms-transform: scaleX(.7); -o-transform: scaleX(.7); transform: scaleX(.7)}
.MJXp-scale8 {-webkit-transform: scaleX(.8); -moz-transform: scaleX(.8); -ms-transform: scaleX(.8); -o-transform: scaleX(.8); transform: scaleX(.8)}
.MJXp-scale9 {-webkit-transform: scaleX(.9); -moz-transform: scaleX(.9); -ms-transform: scaleX(.9); -o-transform: scaleX(.9); transform: scaleX(.9)}
.MathJax_PHTML .noError {vertical-align: ; font-size: 90%; text-align: left; color: black; padding: 1px 3px; border: 1px solid}
</style><style id="ace_editor.css">.ace_editor {position: relative;overflow: hidden;font: 12px/normal 'Monaco', 'Menlo', 'Ubuntu Mono', 'Consolas', 'source-code-pro', monospace;direction: ltr;text-align: left;}.ace_scroller {position: absolute;overflow: hidden;top: 0;bottom: 0;background-color: inherit;-ms-user-select: none;-moz-user-select: none;-webkit-user-select: none;user-select: none;cursor: text;}.ace_content {position: absolute;-moz-box-sizing: border-box;-webkit-box-sizing: border-box;box-sizing: border-box;min-width: 100%;}.ace_dragging .ace_scroller:before{position: absolute;top: 0;left: 0;right: 0;bottom: 0;content: '';background: rgba(250, 250, 250, 0.01);z-index: 1000;}.ace_dragging.ace_dark .ace_scroller:before{background: rgba(0, 0, 0, 0.01);}.ace_selecting, .ace_selecting * {cursor: text !important;}.ace_gutter {position: absolute;overflow : hidden;width: auto;top: 0;bottom: 0;left: 0;cursor: default;z-index: 4;-ms-user-select: none;-moz-user-select: none;-webkit-user-select: none;user-select: none;}.ace_gutter-active-line {position: absolute;left: 0;right: 0;}.ace_scroller.ace_scroll-left {box-shadow: 17px 0 16px -16px rgba(0, 0, 0, 0.4) inset;}.ace_gutter-cell {padding-left: 19px;padding-right: 6px;background-repeat: no-repeat;}.ace_gutter-cell.ace_error {background-image: url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAMAAAAoLQ9TAAABOFBMVEX/////////QRswFAb/Ui4wFAYwFAYwFAaWGAfDRymzOSH/PxswFAb/SiUwFAYwFAbUPRvjQiDllog5HhHdRybsTi3/Tyv9Tir+Syj/UC3////XurebMBIwFAb/RSHbPx/gUzfdwL3kzMivKBAwFAbbvbnhPx66NhowFAYwFAaZJg8wFAaxKBDZurf/RB6mMxb/SCMwFAYwFAbxQB3+RB4wFAb/Qhy4Oh+4QifbNRcwFAYwFAYwFAb/QRzdNhgwFAYwFAbav7v/Uy7oaE68MBK5LxLewr/r2NXewLswFAaxJw4wFAbkPRy2PyYwFAaxKhLm1tMwFAazPiQwFAaUGAb/QBrfOx3bvrv/VC/maE4wFAbRPBq6MRO8Qynew8Dp2tjfwb0wFAbx6eju5+by6uns4uH9/f36+vr/GkHjAAAAYnRSTlMAGt+64rnWu/bo8eAA4InH3+DwoN7j4eLi4xP99Nfg4+b+/u9B/eDs1MD1mO7+4PHg2MXa347g7vDizMLN4eG+Pv7i5evs/v79yu7S3/DV7/498Yv24eH+4ufQ3Ozu/v7+y13sRqwAAADLSURBVHjaZc/XDsFgGIBhtDrshlitmk2IrbHFqL2pvXf/+78DPokj7+Fz9qpU/9UXJIlhmPaTaQ6QPaz0mm+5gwkgovcV6GZzd5JtCQwgsxoHOvJO15kleRLAnMgHFIESUEPmawB9ngmelTtipwwfASilxOLyiV5UVUyVAfbG0cCPHig+GBkzAENHS0AstVF6bacZIOzgLmxsHbt2OecNgJC83JERmePUYq8ARGkJx6XtFsdddBQgZE2nPR6CICZhawjA4Fb/chv+399kfR+MMMDGOQAAAABJRU5ErkJggg==");background-repeat: no-repeat;background-position: 2px center;}.ace_gutter-cell.ace_warning {background-image: url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAMAAAAoLQ9TAAAAmVBMVEX///8AAAD///8AAAAAAABPSzb/5sAAAAB/blH/73z/ulkAAAAAAAD85pkAAAAAAAACAgP/vGz/rkDerGbGrV7/pkQICAf////e0IsAAAD/oED/qTvhrnUAAAD/yHD/njcAAADuv2r/nz//oTj/p064oGf/zHAAAAA9Nir/tFIAAAD/tlTiuWf/tkIAAACynXEAAAAAAAAtIRW7zBpBAAAAM3RSTlMAABR1m7RXO8Ln31Z36zT+neXe5OzooRDfn+TZ4p3h2hTf4t3k3ucyrN1K5+Xaks52Sfs9CXgrAAAAjklEQVR42o3PbQ+CIBQFYEwboPhSYgoYunIqqLn6/z8uYdH8Vmdnu9vz4WwXgN/xTPRD2+sgOcZjsge/whXZgUaYYvT8QnuJaUrjrHUQreGczuEafQCO/SJTufTbroWsPgsllVhq3wJEk2jUSzX3CUEDJC84707djRc5MTAQxoLgupWRwW6UB5fS++NV8AbOZgnsC7BpEAAAAABJRU5ErkJggg==");background-position: 2px center;}.ace_gutter-cell.ace_info {background-image: url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAAAAAA6mKC9AAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAAJ0Uk5TAAB2k804AAAAPklEQVQY02NgIB68QuO3tiLznjAwpKTgNyDbMegwisCHZUETUZV0ZqOquBpXj2rtnpSJT1AEnnRmL2OgGgAAIKkRQap2htgAAAAASUVORK5CYII=");background-position: 2px center;}.ace_dark .ace_gutter-cell.ace_info {background-image: url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQBAMAAADt3eJSAAAAJFBMVEUAAAChoaGAgIAqKiq+vr6tra1ZWVmUlJSbm5s8PDxubm56enrdgzg3AAAAAXRSTlMAQObYZgAAAClJREFUeNpjYMAPdsMYHegyJZFQBlsUlMFVCWUYKkAZMxZAGdxlDMQBAG+TBP4B6RyJAAAAAElFTkSuQmCC");}.ace_scrollbar {position: absolute;right: 0;bottom: 0;z-index: 6;}.ace_scrollbar-inner {position: absolute;cursor: text;left: 0;top: 0;}.ace_scrollbar-v{overflow-x: hidden;overflow-y: scroll;top: 0;}.ace_scrollbar-h {overflow-x: scroll;overflow-y: hidden;left: 0;}.ace_print-margin {position: absolute;height: 100%;}.ace_text-input {position: absolute;z-index: 0;width: 0.5em;height: 1em;opacity: 0;background: transparent;-moz-appearance: none;appearance: none;border: none;resize: none;outline: none;overflow: hidden;font: inherit;padding: 0 1px;margin: 0 -1px;text-indent: -1em;-ms-user-select: text;-moz-user-select: text;-webkit-user-select: text;user-select: text;white-space: pre!important;}.ace_text-input.ace_composition {background: inherit;color: inherit;z-index: 1000;opacity: 1;text-indent: 0;}.ace_layer {z-index: 1;position: absolute;overflow: hidden;word-wrap: normal;white-space: pre;height: 100%;width: 100%;-moz-box-sizing: border-box;-webkit-box-sizing: border-box;box-sizing: border-box;pointer-events: none;}.ace_gutter-layer {position: relative;width: auto;text-align: right;pointer-events: auto;}.ace_text-layer {font: inherit !important;}.ace_cjk {display: inline-block;text-align: center;}.ace_cursor-layer {z-index: 4;}.ace_cursor {z-index: 4;position: absolute;-moz-box-sizing: border-box;-webkit-box-sizing: border-box;box-sizing: border-box;border-left: 2px solid;transform: translatez(0);}.ace_slim-cursors .ace_cursor {border-left-width: 1px;}.ace_overwrite-cursors .ace_cursor {border-left-width: 0;border-bottom: 1px solid;}.ace_hidden-cursors .ace_cursor {opacity: 0.2;}.ace_smooth-blinking .ace_cursor {-webkit-transition: opacity 0.18s;transition: opacity 0.18s;}.ace_editor.ace_multiselect .ace_cursor {border-left-width: 1px;}.ace_marker-layer .ace_step, .ace_marker-layer .ace_stack {position: absolute;z-index: 3;}.ace_marker-layer .ace_selection {position: absolute;z-index: 5;}.ace_marker-layer .ace_bracket {position: absolute;z-index: 6;}.ace_marker-layer .ace_active-line {position: absolute;z-index: 2;}.ace_marker-layer .ace_selected-word {position: absolute;z-index: 4;-moz-box-sizing: border-box;-webkit-box-sizing: border-box;box-sizing: border-box;}.ace_line .ace_fold {-moz-box-sizing: border-box;-webkit-box-sizing: border-box;box-sizing: border-box;display: inline-block;height: 11px;margin-top: -2px;vertical-align: middle;background-image:url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABEAAAAJCAYAAADU6McMAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAJpJREFUeNpi/P//PwOlgAXGYGRklAVSokD8GmjwY1wasKljQpYACtpCFeADcHVQfQyMQAwzwAZI3wJKvCLkfKBaMSClBlR7BOQikCFGQEErIH0VqkabiGCAqwUadAzZJRxQr/0gwiXIal8zQQPnNVTgJ1TdawL0T5gBIP1MUJNhBv2HKoQHHjqNrA4WO4zY0glyNKLT2KIfIMAAQsdgGiXvgnYAAAAASUVORK5CYII="),url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAA3CAYAAADNNiA5AAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAACJJREFUeNpi+P//fxgTAwPDBxDxD078RSX+YeEyDFMCIMAAI3INmXiwf2YAAAAASUVORK5CYII=");background-repeat: no-repeat, repeat-x;background-position: center center, top left;color: transparent;border: 1px solid black;border-radius: 2px;cursor: pointer;pointer-events: auto;}.ace_dark .ace_fold {}.ace_fold:hover{background-image:url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABEAAAAJCAYAAADU6McMAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAJpJREFUeNpi/P//PwOlgAXGYGRklAVSokD8GmjwY1wasKljQpYACtpCFeADcHVQfQyMQAwzwAZI3wJKvCLkfKBaMSClBlR7BOQikCFGQEErIH0VqkabiGCAqwUadAzZJRxQr/0gwiXIal8zQQPnNVTgJ1TdawL0T5gBIP1MUJNhBv2HKoQHHjqNrA4WO4zY0glyNKLT2KIfIMAAQsdgGiXvgnYAAAAASUVORK5CYII="),url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAA3CAYAAADNNiA5AAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAACBJREFUeNpi+P//fz4TAwPDZxDxD5X4i5fLMEwJgAADAEPVDbjNw87ZAAAAAElFTkSuQmCC");}.ace_tooltip {background-color: #FFF;background-image: -webkit-linear-gradient(top, transparent, rgba(0, 0, 0, 0.1));background-image: linear-gradient(to bottom, transparent, rgba(0, 0, 0, 0.1));border: 1px solid gray;border-radius: 1px;box-shadow: 0 1px 2px rgba(0, 0, 0, 0.3);color: black;max-width: 100%;padding: 3px 4px;position: fixed;z-index: 999999;-moz-box-sizing: border-box;-webkit-box-sizing: border-box;box-sizing: border-box;cursor: default;white-space: pre;word-wrap: break-word;line-height: normal;font-style: normal;font-weight: normal;letter-spacing: normal;pointer-events: none;}.ace_folding-enabled > .ace_gutter-cell {padding-right: 13px;}.ace_fold-widget {-moz-box-sizing: border-box;-webkit-box-sizing: border-box;box-sizing: border-box;margin: 0 -12px 0 1px;display: none;width: 11px;vertical-align: top;background-image: url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAUAAAAFCAYAAACNbyblAAAANElEQVR42mWKsQ0AMAzC8ixLlrzQjzmBiEjp0A6WwBCSPgKAXoLkqSot7nN3yMwR7pZ32NzpKkVoDBUxKAAAAABJRU5ErkJggg==");background-repeat: no-repeat;background-position: center;border-radius: 3px;border: 1px solid transparent;cursor: pointer;}.ace_folding-enabled .ace_fold-widget {display: inline-block;   }.ace_fold-widget.ace_end {background-image: url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAUAAAAFCAYAAACNbyblAAAANElEQVR42m3HwQkAMAhD0YzsRchFKI7sAikeWkrxwScEB0nh5e7KTPWimZki4tYfVbX+MNl4pyZXejUO1QAAAABJRU5ErkJggg==");}.ace_fold-widget.ace_closed {background-image: url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAMAAAAGCAYAAAAG5SQMAAAAOUlEQVR42jXKwQkAMAgDwKwqKD4EwQ26sSOkVWjgIIHAzPiCgaqiqnJHZnKICBERHN194O5b9vbLuAVRL+l0YWnZAAAAAElFTkSuQmCCXA==");}.ace_fold-widget:hover {border: 1px solid rgba(0, 0, 0, 0.3);background-color: rgba(255, 255, 255, 0.2);box-shadow: 0 1px 1px rgba(255, 255, 255, 0.7);}.ace_fold-widget:active {border: 1px solid rgba(0, 0, 0, 0.4);background-color: rgba(0, 0, 0, 0.05);box-shadow: 0 1px 1px rgba(255, 255, 255, 0.8);}.ace_dark .ace_fold-widget {background-image: url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAUAAAAFCAYAAACNbyblAAAAHklEQVQIW2P4//8/AzoGEQ7oGCaLLAhWiSwB146BAQCSTPYocqT0AAAAAElFTkSuQmCC");}.ace_dark .ace_fold-widget.ace_end {background-image: url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAUAAAAFCAYAAACNbyblAAAAH0lEQVQIW2P4//8/AxQ7wNjIAjDMgC4AxjCVKBirIAAF0kz2rlhxpAAAAABJRU5ErkJggg==");}.ace_dark .ace_fold-widget.ace_closed {background-image: url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAMAAAAFCAYAAACAcVaiAAAAHElEQVQIW2P4//+/AxAzgDADlOOAznHAKgPWAwARji8UIDTfQQAAAABJRU5ErkJggg==");}.ace_dark .ace_fold-widget:hover {box-shadow: 0 1px 1px rgba(255, 255, 255, 0.2);background-color: rgba(255, 255, 255, 0.1);}.ace_dark .ace_fold-widget:active {box-shadow: 0 1px 1px rgba(255, 255, 255, 0.2);}.ace_fold-widget.ace_invalid {background-color: #FFB4B4;border-color: #DE5555;}.ace_fade-fold-widgets .ace_fold-widget {-webkit-transition: opacity 0.4s ease 0.05s;transition: opacity 0.4s ease 0.05s;opacity: 0;}.ace_fade-fold-widgets:hover .ace_fold-widget {-webkit-transition: opacity 0.05s ease 0.05s;transition: opacity 0.05s ease 0.05s;opacity:1;}.ace_underline {text-decoration: underline;}.ace_bold {font-weight: bold;}.ace_nobold .ace_bold {font-weight: normal;}.ace_italic {font-style: italic;}.ace_error-marker {background-color: rgba(255, 0, 0,0.2);position: absolute;z-index: 9;}.ace_highlight-marker {background-color: rgba(255, 255, 0,0.2);position: absolute;z-index: 8;}.ace_br1 {border-top-left-radius    : 3px;}.ace_br2 {border-top-right-radius   : 3px;}.ace_br3 {border-top-left-radius    : 3px; border-top-right-radius:    3px;}.ace_br4 {border-bottom-right-radius: 3px;}.ace_br5 {border-top-left-radius    : 3px; border-bottom-right-radius: 3px;}.ace_br6 {border-top-right-radius   : 3px; border-bottom-right-radius: 3px;}.ace_br7 {border-top-left-radius    : 3px; border-top-right-radius:    3px; border-bottom-right-radius: 3px;}.ace_br8 {border-bottom-left-radius : 3px;}.ace_br9 {border-top-left-radius    : 3px; border-bottom-left-radius:  3px;}.ace_br10{border-top-right-radius   : 3px; border-bottom-left-radius:  3px;}.ace_br11{border-top-left-radius    : 3px; border-top-right-radius:    3px; border-bottom-left-radius:  3px;}.ace_br12{border-bottom-right-radius: 3px; border-bottom-left-radius:  3px;}.ace_br13{border-top-left-radius    : 3px; border-bottom-right-radius: 3px; border-bottom-left-radius:  3px;}.ace_br14{border-top-right-radius   : 3px; border-bottom-right-radius: 3px; border-bottom-left-radius:  3px;}.ace_br15{border-top-left-radius    : 3px; border-top-right-radius:    3px; border-bottom-right-radius: 3px; border-bottom-left-radius: 3px;}
/*# sourceURL=ace/css/ace_editor.css */</style><style id="ace-tm">.ace-tm .ace_gutter {background: #f0f0f0;color: #333;}.ace-tm .ace_print-margin {width: 1px;background: #e8e8e8;}.ace-tm .ace_fold {background-color: #6B72E6;}.ace-tm {background-color: #FFFFFF;color: black;}.ace-tm .ace_cursor {color: black;}.ace-tm .ace_invisible {color: rgb(191, 191, 191);}.ace-tm .ace_storage,.ace-tm .ace_keyword {color: blue;}.ace-tm .ace_constant {color: rgb(197, 6, 11);}.ace-tm .ace_constant.ace_buildin {color: rgb(88, 72, 246);}.ace-tm .ace_constant.ace_language {color: rgb(88, 92, 246);}.ace-tm .ace_constant.ace_library {color: rgb(6, 150, 14);}.ace-tm .ace_invalid {background-color: rgba(255, 0, 0, 0.1);color: red;}.ace-tm .ace_support.ace_function {color: rgb(60, 76, 114);}.ace-tm .ace_support.ace_constant {color: rgb(6, 150, 14);}.ace-tm .ace_support.ace_type,.ace-tm .ace_support.ace_class {color: rgb(109, 121, 222);}.ace-tm .ace_keyword.ace_operator {color: rgb(104, 118, 135);}.ace-tm .ace_string {color: rgb(3, 106, 7);}.ace-tm .ace_comment {color: rgb(76, 136, 107);}.ace-tm .ace_comment.ace_doc {color: rgb(0, 102, 255);}.ace-tm .ace_comment.ace_doc.ace_tag {color: rgb(128, 159, 191);}.ace-tm .ace_constant.ace_numeric {color: rgb(0, 0, 205);}.ace-tm .ace_variable {color: rgb(49, 132, 149);}.ace-tm .ace_xml-pe {color: rgb(104, 104, 91);}.ace-tm .ace_entity.ace_name.ace_function {color: #0000A2;}.ace-tm .ace_heading {color: rgb(12, 7, 255);}.ace-tm .ace_list {color:rgb(185, 6, 144);}.ace-tm .ace_meta.ace_tag {color:rgb(0, 22, 142);}.ace-tm .ace_string.ace_regex {color: rgb(255, 0, 0)}.ace-tm .ace_marker-layer .ace_selection {background: rgb(181, 213, 255);}.ace-tm.ace_multiselect .ace_selection.ace_start {box-shadow: 0 0 3px 0px white;}.ace-tm .ace_marker-layer .ace_step {background: rgb(252, 255, 0);}.ace-tm .ace_marker-layer .ace_stack {background: rgb(164, 229, 101);}.ace-tm .ace_marker-layer .ace_bracket {margin: -1px 0 0 -1px;border: 1px solid rgb(192, 192, 192);}.ace-tm .ace_marker-layer .ace_active-line {background: rgba(0, 0, 0, 0.07);}.ace-tm .ace_gutter-active-line {background-color : #dcdcdc;}.ace-tm .ace_marker-layer .ace_selected-word {background: rgb(250, 250, 255);border: 1px solid rgb(200, 200, 250);}.ace-tm .ace_indent-guide {background: url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAACCAYAAACZgbYnAAAAE0lEQVQImWP4////f4bLly//BwAmVgd1/w11/gAAAABJRU5ErkJggg==") right repeat-y;}
/*# sourceURL=ace/css/ace-tm */</style><style>    .error_widget_wrapper {        background: inherit;        color: inherit;        border:none    }    .error_widget {        border-top: solid 2px;        border-bottom: solid 2px;        margin: 5px 0;        padding: 10px 40px;        white-space: pre-wrap;    }    .error_widget.ace_error, .error_widget_arrow.ace_error{        border-color: #ff5a5a    }    .error_widget.ace_warning, .error_widget_arrow.ace_warning{        border-color: #F1D817    }    .error_widget.ace_info, .error_widget_arrow.ace_info{        border-color: #5a5a5a    }    .error_widget.ace_ok, .error_widget_arrow.ace_ok{        border-color: #5aaa5a    }    .error_widget_arrow {        position: absolute;        border: solid 5px;        border-top-color: transparent!important;        border-right-color: transparent!important;        border-left-color: transparent!important;        top: -5px;    }</style><style>.ace_snippet-marker {    -moz-box-sizing: border-box;    box-sizing: border-box;    background: rgba(194, 193, 208, 0.09);    border: 1px dotted rgba(211, 208, 235, 0.62);    position: absolute;}</style><style>.ace_editor.ace_autocomplete .ace_marker-layer .ace_active-line {    background-color: #CAD6FA;    z-index: 1;}.ace_editor.ace_autocomplete .ace_line-hover {    border: 1px solid #abbffe;    margin-top: -1px;    background: rgba(233,233,253,0.4);}.ace_editor.ace_autocomplete .ace_line-hover {    position: absolute;    z-index: 2;}.ace_editor.ace_autocomplete .ace_scroller {   background: none;   border: none;   box-shadow: none;}.ace_rightAlignedText {    color: gray;    display: inline-block;    position: absolute;    right: 4px;    text-align: right;    z-index: -1;}.ace_editor.ace_autocomplete .ace_completion-highlight{    color: #000;    text-shadow: 0 0 0.01em;}.ace_editor.ace_autocomplete {    width: 280px;    z-index: 200000;    background: #fbfbfb;    color: #444;    border: 1px lightgray solid;    position: fixed;    box-shadow: 2px 3px 5px rgba(0,0,0,.2);    line-height: 1.4;}</style><style type="text/css">.MathJax_Display {text-align: center; margin: 0; position: relative; display: block!important; text-indent: 0; max-width: none; max-height: none; min-width: 0; min-height: 0; width: 100%}
.MathJax .merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
.MathJax .MJX-monospace {font-family: monospace}
.MathJax .MJX-sans-serif {font-family: sans-serif}
#MathJax_Tooltip {background-color: InfoBackground; color: InfoText; border: 1px solid black; box-shadow: 2px 2px 5px #AAAAAA; -webkit-box-shadow: 2px 2px 5px #AAAAAA; -moz-box-shadow: 2px 2px 5px #AAAAAA; -khtml-box-shadow: 2px 2px 5px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true'); padding: 3px 4px; z-index: 401; position: absolute; left: 0; top: 0; width: auto; height: auto; display: none}
.MathJax {display: inline; font-style: normal; font-weight: normal; line-height: normal; font-size: 100%; font-size-adjust: none; text-indent: 0; text-align: left; text-transform: none; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; padding: 0; margin: 0}
.MathJax:focus, body :focus .MathJax {display: inline-table}
.MathJax.MathJax_FullWidth {text-align: center; display: table-cell!important; width: 10000em!important}
.MathJax img, .MathJax nobr, .MathJax a {border: 0; padding: 0; margin: 0; max-width: none; max-height: none; min-width: 0; min-height: 0; vertical-align: 0; line-height: normal; text-decoration: none}
img.MathJax_strut {border: 0!important; padding: 0!important; margin: 0!important; vertical-align: 0!important}
.MathJax span {display: inline; position: static; border: 0; padding: 0; margin: 0; vertical-align: 0; line-height: normal; text-decoration: none}
.MathJax nobr {white-space: nowrap!important}
.MathJax img {display: inline!important; float: none!important}
.MathJax * {transition: none; -webkit-transition: none; -moz-transition: none; -ms-transition: none; -o-transition: none}
.MathJax_Processing {visibility: hidden; position: fixed; width: 0; height: 0; overflow: hidden}
.MathJax_Processed {display: none!important}
.MathJax_ExBox {display: block!important; overflow: hidden; width: 1px; height: 60ex; min-height: 0; max-height: none}
.MathJax .MathJax_EmBox {display: block!important; overflow: hidden; width: 1px; height: 60em; min-height: 0; max-height: none}
.MathJax_LineBox {display: table!important}
.MathJax_LineBox span {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MathJax .MathJax_HitBox {cursor: text; background: white; opacity: 0; filter: alpha(opacity=0)}
.MathJax .MathJax_HitBox * {filter: none; opacity: 1; background: transparent}
#MathJax_Tooltip * {filter: none; opacity: 1; background: transparent}
@font-face {font-family: MathJax_Blank; src: url('about:blank')}
.MathJax .noError {vertical-align: ; font-size: 90%; text-align: left; color: black; padding: 1px 3px; border: 1px solid}
</style><meta property="og:image" content="https://s3.amazonaws.com/datacamp-community/social-share-tutorials.jpg" class="next-head"><meta name="twitter:image" content="https://s3.amazonaws.com/datacamp-community/social-share-tutorials.jpg" class="next-head"><meta name="keywords" content="LSTM python" class="next-head"><meta name="description" content="Discover Long Short-Term Memory (LSTM) networks in Python and how you can use them to make stock market predictions!" class="next-head"><meta property="og:title" content="LSTM in Python: Stock Market Predictions" class="next-head"><meta property="og:url" content="https://www.datacamp.com/community/tutorials/lstm-python-stock-market" class="next-head"><meta property="og:type" content="article" class="next-head"><meta property="og:published_time" content="2018-05-03T10:00:00.000Z" class="next-head"><meta property="og:author" content="Thushan Ganegedara" class="next-head"><meta property="og:description" content="Discover Long Short-Term Memory (LSTM) networks in Python and how you can use them to make stock market predictions!" class="next-head"><meta name="twitter:title" content="LSTM in Python: Stock Market Predictions" class="next-head"><meta name="twitter:description" content="Discover Long Short-Term Memory (LSTM) networks in Python and how you can use them to make stock market predictions!" class="next-head"><meta name="twitter:image:alt" content="LSTM in Python: Stock Market Predictions" class="next-head"><link rel="canonical" href="https://www.datacamp.com/community/tutorials/lstm-python-stock-market" class="next-head"></head><body><div style="visibility: hidden; overflow: hidden; position: absolute; top: 0px; height: 1px; width: auto; padding: 0px; border: 0px; margin: 0px; text-align: left; text-indent: 0px; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal;"><div id="MathJax_Hidden"></div></div><div id="MathJax_Message" style="display: none;"></div><div id="__next"><div><div class="Page content"><div class="jsx-1902599493 Layout bar"><div class="jsx-2803075824 SidebarMenu"><div class="jsx-2090414051 Logo"><a href="https://www.datacamp.com/" class="jsx-2090414051 Logo__image"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1367.47 306.77"><path d="M201.49 130.16c2.64-10.87 2.31-21.09-3.62-35.38 0 0 9.55 3.71 8.56-3.65S194.91 76 187 71.11c-3.48-2.17-12.89-6.79-25.52-9.6l2.36-5.32-.66-.32c-19.59-9.54-42.24-.89-42.47-.8l-.7.27 2.24 5.92a78 78 0 0 0-19 7.09C50 96.68 77 152 93.5 165.17s8.89 40 0 64.31H165c1-4.55.13 2.24 3.46-15.91s16.18-11.41 26.3-12 8.52-7.66 8.4-15.56c4.94-2.22 4.94-4.57 1.64-7.41 4.28-4 3.62-4 1.32-7.83s-.66-5.68-.66-5.68 6.92-1.35 7.9-5c.32-7.89-14.5-19.09-11.87-29.93zm-14.78-2.28l-10.59-3.6c-.56 1.45-6 14.9-13 17.27l-6.68-8.84c-3.21 2.51-10.54 4.72-14.07 3.69v-.32h-.19l.2 24.36c-14.05 1.45-30.84-7.06-38.88-18.77l-8.78 6.67c-10-12.07-11.51-26.62-11.62-35h11.77c0-9.27 3.62-21.34 8.72-28l9.23 6.52c.75-.93 7.72-9.27 17.05-12.28h.14l-6.67-17.64c14.09-4.06 24.44-4 35.7.19a3.87 3.87 0 0 1 1 .48l.18.13-1.99 5.26c.53.23 8 3.59 11.09 6.74l2.49-3.44a42.47 42.47 0 0 1 19 25.34L187 98v-.1a55.32 55.32 0 0 1-.28 29.98z"></path><path d="M141.69 95.69a11.77 11.77 0 1 0 11.76 11.77 11.78 11.78 0 0 0-11.76-11.77zM486.07 147.93a85.48 85.48 0 0 1-5.79 31.92 71.67 71.67 0 0 1-41.54 41.32 89 89 0 0 1-32.79 5.83h-60.24V68.9h60.23a88.33 88.33 0 0 1 32.79 5.85A74 74 0 0 1 464 91a72.76 72.76 0 0 1 16.29 25 85.49 85.49 0 0 1 5.78 31.93zm-30.17 0a73.61 73.61 0 0 0-3.44-23.34 48.4 48.4 0 0 0-9.95-17.49 43.45 43.45 0 0 0-15.74-11 54 54 0 0 0-20.82-3.83h-30.72v111.3h30.72a54 54 0 0 0 20.82-3.83 43.39 43.39 0 0 0 15.74-11 48.37 48.37 0 0 0 9.95-17.49 73.6 73.6 0 0 0 3.44-23.32zM505.36 130.44q19.35-17.71 46.57-17.71a45.54 45.54 0 0 1 17.6 3.22 37.21 37.21 0 0 1 13.12 9 38.4 38.4 0 0 1 8.14 13.72 52.72 52.72 0 0 1 2.79 17.49V227h-12.25a12.38 12.38 0 0 1-5.9-1.15q-2.08-1.15-3.28-4.65l-2.4-8.09a97.29 97.29 0 0 1-8.31 6.72 48.91 48.91 0 0 1-8.42 4.86 45.32 45.32 0 0 1-9.35 3 53.93 53.93 0 0 1-11 1 43.08 43.08 0 0 1-13.12-1.91 28.78 28.78 0 0 1-10.38-5.74 25.73 25.73 0 0 1-6.78-9.51 33.72 33.72 0 0 1-2.4-13.23 26.32 26.32 0 0 1 1.42-8.47 24.76 24.76 0 0 1 4.65-8 38.63 38.63 0 0 1 8.36-7.21 54.43 54.43 0 0 1 12.63-5.9 109.08 109.08 0 0 1 17.44-4.1 174.35 174.35 0 0 1 22.74-1.91v-6.56q0-11.26-4.81-16.67t-13.88-5.41a33 33 0 0 0-10.88 1.53 44.91 44.91 0 0 0-7.6 3.44q-3.28 1.91-6 3.44a11.78 11.78 0 0 1-6 1.53 7.79 7.79 0 0 1-4.81-1.48 12.33 12.33 0 0 1-3.17-3.44zm61.87 48.64a149.08 149.08 0 0 0-19.68 2 52.42 52.42 0 0 0-12.79 3.77 16.8 16.8 0 0 0-6.89 5.36 11.63 11.63 0 0 0-2.08 6.67q0 7.11 4.21 10.17t11 3.06a32 32 0 0 0 14.37-3 42.69 42.69 0 0 0 11.86-9.11zM657.79 228.72q-14.65 0-22.46-8.25t-7.82-22.79V135H616a5.26 5.26 0 0 1-3.72-1.42 5.53 5.53 0 0 1-1.53-4.26v-10.68l18-3 5.68-30.61a6 6 0 0 1 2.08-3.39 6.18 6.18 0 0 1 3.94-1.2h14v35.36h30V135h-30v60.78q0 5.25 2.57 8.2a8.85 8.85 0 0 0 7 3 12.7 12.7 0 0 0 4.21-.6 23 23 0 0 0 3-1.26q1.26-.66 2.24-1.26a3.75 3.75 0 0 1 2-.6 3.1 3.1 0 0 1 2 .6 9.23 9.23 0 0 1 1.64 1.8l8.09 13.12a40.87 40.87 0 0 1-13.55 7.43 50.47 50.47 0 0 1-15.86 2.51zM702.11 130.44q19.35-17.71 46.57-17.71a45.54 45.54 0 0 1 17.6 3.22 37.19 37.19 0 0 1 13.12 9 38.37 38.37 0 0 1 8.14 13.72 52.72 52.72 0 0 1 2.79 17.49V227h-12.25a12.37 12.37 0 0 1-5.9-1.15q-2.08-1.15-3.28-4.65l-2.4-8.09a97.21 97.21 0 0 1-8.31 6.72 49 49 0 0 1-8.42 4.86 45.33 45.33 0 0 1-9.35 3 53.92 53.92 0 0 1-11 1 43.08 43.08 0 0 1-13.12-1.91 28.78 28.78 0 0 1-10.38-5.74 25.74 25.74 0 0 1-6.78-9.51 33.72 33.72 0 0 1-2.4-13.23 26.31 26.31 0 0 1 1.42-8.47 24.76 24.76 0 0 1 4.65-8 38.66 38.66 0 0 1 8.36-7.21 54.45 54.45 0 0 1 12.63-5.9 109.07 109.07 0 0 1 17.44-4.1 174.32 174.32 0 0 1 22.76-1.93v-6.56q0-11.26-4.81-16.67t-13.88-5.41a33 33 0 0 0-10.88 1.53 44.89 44.89 0 0 0-7.6 3.44q-3.28 1.91-6 3.44a11.79 11.79 0 0 1-6 1.53 7.79 7.79 0 0 1-4.81-1.48 12.33 12.33 0 0 1-3.17-3.44zM764 179.09a149.06 149.06 0 0 0-19.68 2 52.43 52.43 0 0 0-12.79 3.77 16.81 16.81 0 0 0-6.89 5.36 11.63 11.63 0 0 0-2.08 6.67q0 7.11 4.21 10.17t11 3.06a32 32 0 0 0 14.37-3A42.68 42.68 0 0 0 764 198zM929.42 189.69a5.87 5.87 0 0 1 4.26 1.86l11.59 12.57a63.64 63.64 0 0 1-23.67 18.26q-14 6.34-33.72 6.34-17.6 0-31.65-6a69.71 69.71 0 0 1-24-16.73A73.19 73.19 0 0 1 817 180.4a96 96 0 0 1-5.3-32.47 90.36 90.36 0 0 1 5.68-32.63 75 75 0 0 1 16-25.52A72.5 72.5 0 0 1 858 73.11a81.77 81.77 0 0 1 31.7-6q17.27 0 30.66 5.68a73.08 73.08 0 0 1 22.83 14.91l-9.84 13.66a9 9 0 0 1-2.24 2.29 6.35 6.35 0 0 1-3.77 1 7.2 7.2 0 0 1-3.39-.93q-1.75-.93-3.83-2.29t-4.81-3a39.67 39.67 0 0 0-6.34-3 51.92 51.92 0 0 0-8.36-2.29 57.87 57.87 0 0 0-11-.93A48.74 48.74 0 0 0 870.23 96a42.16 42.16 0 0 0-15.14 10.93 50.38 50.38 0 0 0-9.84 17.49 73.27 73.27 0 0 0-3.5 23.56 69.25 69.25 0 0 0 3.77 23.72 52.12 52.12 0 0 0 10.22 17.49 43.61 43.61 0 0 0 15.2 10.81 47 47 0 0 0 18.8 3.77 81.89 81.89 0 0 0 10.88-.66 46.17 46.17 0 0 0 9-2.08 39.7 39.7 0 0 0 7.76-3.66 48.48 48.48 0 0 0 7.27-5.52 10.31 10.31 0 0 1 2.29-1.58 5.56 5.56 0 0 1 2.48-.58zM961.6 130.44q19.35-17.71 46.57-17.71a45.54 45.54 0 0 1 17.6 3.22 37.19 37.19 0 0 1 13.12 9 38.37 38.37 0 0 1 8.14 13.72 52.72 52.72 0 0 1 2.79 17.49V227h-12.24a12.37 12.37 0 0 1-5.9-1.15q-2.08-1.15-3.28-4.65l-2.4-8.09a97.21 97.21 0 0 1-8.31 6.72 49 49 0 0 1-8.42 4.86 45.33 45.33 0 0 1-9.35 3 53.92 53.92 0 0 1-11 1 43.08 43.08 0 0 1-13.12-1.91 28.78 28.78 0 0 1-10.38-5.74 25.74 25.74 0 0 1-6.78-9.51 33.73 33.73 0 0 1-2.4-13.23 26.31 26.31 0 0 1 1.42-8.47 24.76 24.76 0 0 1 4.65-8 38.66 38.66 0 0 1 8.36-7.21 54.45 54.45 0 0 1 12.63-5.9 109.07 109.07 0 0 1 17.44-4.1 174.32 174.32 0 0 1 22.74-1.91v-6.56q0-11.26-4.81-16.67t-13.88-5.41a33 33 0 0 0-10.88 1.53 44.89 44.89 0 0 0-7.6 3.44q-3.28 1.91-6 3.44a11.79 11.79 0 0 1-6 1.53 7.79 7.79 0 0 1-4.81-1.48 12.33 12.33 0 0 1-3.17-3.44zm61.87 48.64a149.06 149.06 0 0 0-19.68 2 52.43 52.43 0 0 0-12.79 3.8 16.81 16.81 0 0 0-6.89 5.36 11.63 11.63 0 0 0-2.08 6.67q0 7.11 4.21 10.17t11 3.06a32 32 0 0 0 14.37-3 42.68 42.68 0 0 0 11.86-9.13zM1078.18 227V114.81h16.51a6.63 6.63 0 0 1 6.89 4.92l1.75 8.31a63.82 63.82 0 0 1 6.18-6 39.66 39.66 0 0 1 6.89-4.7 37.29 37.29 0 0 1 7.87-3.12 35.05 35.05 0 0 1 9.24-1.15q10.6 0 17.43 5.74a34.56 34.56 0 0 1 10.22 15.25 34.23 34.23 0 0 1 6.56-9.57 35.9 35.9 0 0 1 8.63-6.5 39.77 39.77 0 0 1 10-3.72 48.07 48.07 0 0 1 10.66-1.2 44.82 44.82 0 0 1 16.51 2.84 31.69 31.69 0 0 1 12.13 8.31 36.63 36.63 0 0 1 7.49 13.34 58.1 58.1 0 0 1 2.57 18V227h-27v-71.41q0-10.71-4.7-16.12t-13.77-5.41a20.57 20.57 0 0 0-7.71 1.42 18.37 18.37 0 0 0-6.23 4.1 18.73 18.73 0 0 0-4.21 6.72 26.13 26.13 0 0 0-1.53 9.29V227h-27.11v-71.41q0-11.26-4.54-16.4t-13.28-5.14a21.83 21.83 0 0 0-11 2.9 36.66 36.66 0 0 0-9.46 7.92V227zM1289.85 130.12a58.51 58.51 0 0 1 15.63-12.57q8.74-4.81 20.55-4.81a36.79 36.79 0 0 1 16.78 3.83 37.68 37.68 0 0 1 13.12 11.09 53.26 53.26 0 0 1 8.53 17.93 90.21 90.21 0 0 1 3 24.43 76.84 76.84 0 0 1-3.39 23.28 57 57 0 0 1-9.67 18.58 44.72 44.72 0 0 1-15.19 12.3 44.22 44.22 0 0 1-19.95 4.43 40.23 40.23 0 0 1-16.07-2.9 39.23 39.23 0 0 1-11.92-8v45.91h-27V114.81h16.51a6.63 6.63 0 0 1 6.89 4.92zm1.42 67.77a26.57 26.57 0 0 0 10 7.87 29.76 29.76 0 0 0 11.75 2.3 25.79 25.79 0 0 0 11-2.3 21.63 21.63 0 0 0 8.36-7 34.62 34.62 0 0 0 5.3-11.86 67.79 67.79 0 0 0 1.86-16.89 75 75 0 0 0-1.58-16.67 32.22 32.22 0 0 0-4.54-11.09 17.92 17.92 0 0 0-7.16-6.23 22.34 22.34 0 0 0-9.57-2 27.28 27.28 0 0 0-14.32 3.55 43.46 43.46 0 0 0-11.15 10z"></path><path d="M144.06 306.77a9.83 9.83 0 0 1-4.72-1.21L23.79 242a9.82 9.82 0 0 1-5-7.56L.06 57.52a9.77 9.77 0 0 1 6.5-10.29L139.37.55a9.88 9.88 0 0 1 6.43 0L281.5 47.2a9.86 9.86 0 0 1 6.5 10.47L266.47 234.6a9.85 9.85 0 0 1-4.91 7.35l-112.68 63.56a9.84 9.84 0 0 1-4.82 1.26zm-110-77l110 60.49 107.22-60.48L271.89 60.5 142.64 16 16.15 60.5z"></path></svg></a></div><div class="jsx-2803075824 icon mobileOnly"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 80 70"><path d="M6 1a6 6 0 1 0 0 12h68a6 6 0 0 0 0-12H6zm0 28a6 6 0 1 0 0 12h68a6 6 0 0 0 0-12H6zm0 28a6 6 0 1 0 0 12h68a6 6 0 0 0 0-12H6z"></path></svg></div></div><div class="jsx-2919104997 Menu mobileOnlyHide"><div class="jsx-2919104997 section"><h5 class="jsx-2919104997">community</h5><nav class="jsx-2919104997"><div><a target="_self" class="jsx-2919104997 item" href="https://www.datacamp.com/community"><div class="jsx-2919104997 image"><svg height="14" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 23 23"><path id="a" d="M2 4.5h20a1.5 1.5 0 0 1 0 3H2a1.5 1.5 0 0 1 0-3zm0 6h14a1.5 1.5 0 0 1 0 3H2a1.5 1.5 0 0 1 0-3zm0 6h20a1.5 1.5 0 0 1 0 3H2a1.5 1.5 0 0 1 0-3z"></path></svg></div><div class="jsx-2919104997 text">News</div><div class="jsx-2919104997 statusIcon"><svg height="20" xmlns="http://www.w3.org/2000/svg" width="40" viewBox="0 0 40 20"><g fill="none" fill-rule="evenodd"><rect width="40" height="20" fill="#FFC844" rx="4"></rect><text fill="#3D4251" font-family="Lato-Bold, Lato" font-size="11" font-weight="bold" letter-spacing=".5"><tspan x="5" y="14">BETA</tspan></text></g></svg></div></a></div><div><a target="_self" class="jsx-2919104997 item active" href="https://www.datacamp.com/community/tutorials"><div class="jsx-2919104997 image"><svg height="14" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 24.22"><path d="M16.23 24.22a2 2 0 0 1-.73-.14L7 20.79a2 2 0 0 1-1.29-1.88v-4a1.5 1.5 0 0 1 3 0v3.36l7.54 2.92 7.54-2.92v-3.45a1.5 1.5 0 0 1 3 0v4.09a2 2 0 0 1-1.29 1.88L17 24.08a2 2 0 0 1-.77.14zm-.35-2.94zm.7 0z"></path><path d="M16.23 13.35a2 2 0 0 1-.62-.1C9.17 11.16 2.36 9 1.61 8.76a2 2 0 0 1-.25-3.87l14-4.78a2 2 0 0 1 1.3 0l14 4.78a2 2 0 0 1 0 3.81l-13.8 4.55a2 2 0 0 1-.63.1zm-.31-3zM5.21 6.74c3.49 1.11 9.07 2.92 11 3.56l10.68-3.53L16 3.05z"></path></svg></div><div class="jsx-2919104997 text">Tutorials</div></a></div><div><a target="_self" class="jsx-2919104997 item" href="https://www.datacamp.com/community/data-science-cheatsheets"><div class="jsx-2919104997 image"><svg height="14" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 26"><path d="M18.5 26h-13A5.51 5.51 0 0 1 0 20.5v-15A5.51 5.51 0 0 1 5.5 0h13A5.51 5.51 0 0 1 24 5.5v15a5.51 5.51 0 0 1-5.5 5.5zM5.5 3A2.5 2.5 0 0 0 3 5.5v15A2.5 2.5 0 0 0 5.5 23h13a2.5 2.5 0 0 0 2.5-2.5v-15A2.5 2.5 0 0 0 18.5 3z"></path><path d="M16 11H8a1.5 1.5 0 0 1 0-3h8a1.5 1.5 0 0 1 0 3zM16 18H8a1.5 1.5 0 0 1 0-3h8a1.5 1.5 0 0 1 0 3z"></path></svg></div><div class="jsx-2919104997 text">Cheat Sheets</div></a></div><div><a target="_self" class="jsx-2919104997 item" href="https://www.datacamp.com/community/open-courses"><div class="jsx-2919104997 image"><svg height="14" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 34 26"><path d="M28.5 26h-23A5.51 5.51 0 0 1 0 20.5v-15A5.51 5.51 0 0 1 5.5 0h23A5.51 5.51 0 0 1 34 5.5v15a5.51 5.51 0 0 1-5.5 5.5zM5.5 3A2.5 2.5 0 0 0 3 5.5v15A2.5 2.5 0 0 0 5.5 23h23a2.5 2.5 0 0 0 2.5-2.5v-15A2.5 2.5 0 0 0 28.5 3z"></path><path d="M13.5 26a1.5 1.5 0 0 1-1.5-1.5v-22a1.5 1.5 0 0 1 3 0v22a1.5 1.5 0 0 1-1.5 1.5zM27 11h-8a1.5 1.5 0 0 1 0-3h8a1.5 1.5 0 0 1 0 3zM27 18h-8a1.5 1.5 0 0 1 0-3h8a1.5 1.5 0 0 1 0 3z"></path></svg></div><div class="jsx-2919104997 text">Open Courses</div></a></div><div><a target="_self" class="jsx-2919104997 item" href="https://www.datacamp.com/community/podcast"><div class="jsx-2919104997 image"><svg height="14" xmlns="http://www.w3.org/2000/svg" width="18" viewBox="0 0 18 18"><path d="M9.415 11.077h-.369a2.777 2.777 0 0 1-2.769-2.77V2.77A2.777 2.777 0 0 1 9.047 0h.368a2.777 2.777 0 0 1 2.77 2.77v5.538a2.777 2.777 0 0 1-2.77 2.769zm5.008-7.615c.573 0 1.039.464 1.039 1.038v3.462c0 3.08-2.25 5.64-5.193 6.136v1.825h2.077a1.038 1.038 0 1 1 0 2.077h-6.23a1.038 1.038 0 1 1 0-2.077h2.076v-1.825C5.25 13.602 3 11.042 3 7.962V4.5a1.038 1.038 0 1 1 2.077 0v3.462a4.158 4.158 0 0 0 4.154 4.153 4.158 4.158 0 0 0 4.154-4.153V4.5c0-.574.465-1.038 1.038-1.038z"></path></svg></div><div class="jsx-2919104997 text">Podcast - DataFramed</div></a></div><div><a target="_self" class="jsx-2919104997 item" href="https://www.datacamp.com/community/chat"><div class="jsx-2919104997 image"><svg height="14" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 18 16"><g transform="translate(0 -1)"><path id="path-1" d="M12.595 13.364c.01-.111.02-.197.028-.251.058-.405.372-.702.74-.702h1.257c1.035-.002 1.875-.934 1.88-2.082V4.764c-.001-1.155-.842-2.092-1.878-2.094H3.38c-1.034.002-1.873.931-1.88 2.076v5.565c.001 1.156.842 2.092 1.878 2.094h6.626c.292 0 .557.189.68.484.408.977 1.07 1.576 1.94 1.85a6.004 6.004 0 0 1-.03-1.375h.001zm1.51 1.119c.048.314.136.521.235.606.566.487.258 1.497-.458 1.497-1.87 0-3.423-.785-4.33-2.51H3.376C1.513 14.07.004 12.39 0 10.311V4.74C.014 2.673 1.52 1.004 3.378 1h11.245c1.864.004 3.373 1.686 3.377 3.763v5.57c-.01 2.07-1.518 3.744-3.378 3.748h-.551c.004.138.016.273.035.402h-.001zm-8.423-5.81a1.115 1.115 0 1 0 0-2.229 1.115 1.115 0 0 0 0 2.229zm3.268 0a1.115 1.115 0 1 0 0-2.229 1.115 1.115 0 0 0 0 2.229zm3.318 0a1.114 1.114 0 1 0 0-2.229 1.114 1.114 0 0 0 0 2.229z"></path></g></svg></div><div class="jsx-2919104997 text">Chat</div><div class="jsx-2919104997 statusIcon"><svg height="20" xmlns="http://www.w3.org/2000/svg" width="40" viewBox="0 0 40 17"><g fill="none" fill-rule="evenodd"><rect width="40" height="17" fill="#36D57D" rx="4"></rect><text fill="#FFF" font-family="Lato-Bold, Lato" font-size="12" font-weight="bold" letter-spacing=".4"><tspan x="5" y="13">NEW</tspan></text></g></svg></div></a></div></nav></div><div class="jsx-2919104997 section"><h5 class="jsx-2919104997">datacamp</h5><nav class="jsx-2919104997"><div><a target="_self" class="jsx-2919104997 item" href="https://www.datacamp.com/community/blog"><div class="jsx-2919104997 image"><svg height="14" id="Rteg_1" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 17 18"><path id="path-1_1_" d="M12.3 9.8s-.1.1 0 .4c.1.2.2.2-.1.5.2.2.2.3-.1.5 0 .5.1.9-.5 1-.6 0-1.4-.4-1.7.8-.2 1.1-.2.7-.2 1H5.3c.6-1.5 1-3.2 0-4-1.1-1-2.7-4.4.6-6.2.4-.2.8-.3 1.2-.4L6.9 3s1.4-.5 2.7.1v.2c.8.2 1.4.5 1.6.6.5.3 1.2.8 1.2 1.3.1.5-.5.2-.5.2.4.9.4 1.5.2 2.2-.2.7.8 1.4.7 1.9-.1.3-.5.3-.5.3m4.2-7L8.6 0h-.4L.4 2.8c-.3.1-.4.3-.4.6l1.1 10.4c0 .2.1.4.3.4l6.8 3.7c.2.1.4.1.6 0l6.6-3.7c.2-.1.3-.3.3-.4L17 3.4c-.1-.3-.2-.5-.5-.6M8.3 7c-.4 0-.7-.4-.7-.8s.3-.7.7-.7c.4 0 .7.3.7.7 0 .4-.3.8-.7.8zm2.9-1.4l.2-.1c-.3-1-1.2-1.5-1.2-1.5l-.2.2c-.1-.2-.6-.4-.7-.5l.1-.3h-.1c-.6-.3-1.3-.3-2.1 0l.4 1.1c-.6.2-1.1.7-1.1.7l-.6-.4c-.3.5-.5 1.2-.5 1.8h-.8c0 .5.1 1.4.7 2.2l.6-.4c.5.7 1.6 1.3 2.4 1.2V8.1c.3 0 .7-.1.9-.3l.4.6c.4-.1.8-1 .8-1.1l.7.2c.2-.6.2-1.3.1-1.9z"></path></svg></div><div class="jsx-2919104997 text">Official Blog</div></a></div><div><a target="_self" class="jsx-2919104997 item" href="https://www.datacamp.com/community/tech"><div class="jsx-2919104997 image"><svg height="14" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 21.75 29.76"><path d="M15.56 22.57a1.5 1.5 0 0 1-1.5-1.5 7.66 7.66 0 0 1 2.47-5.29 7.38 7.38 0 0 0 2.21-5.31A7.48 7.48 0 0 0 11.28 3h-.82a7.47 7.47 0 0 0-5.2 12.83 7.63 7.63 0 0 1 2.42 5.23 1.5 1.5 0 0 1-3 0 4.65 4.65 0 0 0-1.45-3A10.47 10.47 0 0 1 10.47 0h.82a10.47 10.47 0 0 1 7.28 18 4.68 4.68 0 0 0-1.5 3.08 1.5 1.5 0 0 1-1.51 1.49zM16.5 24.26a5.5 5.5 0 0 1-11 0"></path><path d="M10.89 22.56a1.5 1.5 0 0 1-1.5-1.5v-8.84a1.5 1.5 0 0 1 3 0v8.84a1.5 1.5 0 0 1-1.5 1.5z"></path></svg></div><div class="jsx-2919104997 text">Tech Thoughts</div></a></div></nav></div></div><main class="jsx-1902599493 Main"><div class="jsx-702933904 ActionBar"><div><div class="jsx-3863678361 ActionBarSearch"><button class="jsx-322537325 Button extra noPadding" style="font-weight: normal;"><div class="jsx-322537325 icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20.03 23"><path d="M10.39 19.29A9.65 9.65 0 1 1 20 9.65a9.66 9.66 0 0 1-9.61 9.64zm0-17.06a7.42 7.42 0 1 0 7.42 7.42 7.43 7.43 0 0 0-7.42-7.42z"></path><path d="M1.11 23a1.11 1.11 0 0 1-.89-1.78l4.1-5.47a1.11 1.11 0 1 1 1.78 1.34L2 22.56a1.11 1.11 0 0 1-.89.44z"></path></svg></div><div class="jsx-322537325 desktopOnly">Search</div></button></div></div><div class="jsx-702933904 authBlock"><div></div><div class="jsx-3196442269 ActionBarAuth"><div class="jsx-3196442269"><button class="jsx-322537325 Button border minWidth"><div class="jsx-322537325 ">Log in</div></button><button class="jsx-322537325 Button primary"><div class="jsx-322537325 ">Create Account</div></button></div><div class="jsx-3666761727 SubmitAnArticleButton"><button class="jsx-322537325 Button desktopButton green noPadding"><div class="jsx-322537325 icon"><svg id="Layer_1" xmlns="http://www.w3.org/2000/svg" viewBox="-90 92 18 18"><path id="a" d="M-80.4 100.4V97c0-.3-.3-.6-.6-.6s-.6.3-.6.6v3.4H-85c-.3 0-.6.3-.6.6s.3.6.6.6h3.4v3.4c0 .3.3.6.6.6s.6-.3.6-.6v-3.4h3.4c.3 0 .6-.3.6-.6s-.3-.6-.6-.6h-3.4zM-81 92c5 0 9 4 9 9s-4 9-9 9-9-4-9-9 4-9 9-9z"></path></svg></div><div class="jsx-322537325 desktopOnly">Share an Article</div></button><div class="jsx-3666761727 mobileButton"><svg xmlns="http://www.w3.org/2000/svg" width="40" height="40" viewBox="0 0 40 40"><path d="M20.86 19.15v-4.822c0-.47-.385-.851-.86-.851s-.86.38-.86.85v4.822h-4.878c-.475 0-.86.381-.86.851s.385.85.86.85h4.877v4.822c0 .47.386.851.861.851s.86-.38.86-.85V20.85h4.878c.475 0 .86-.381.86-.851s-.385-.85-.86-.85h-4.877zM20 0c11.045 0 20 8.953 20 20 0 11.045-8.955 20-20 20C8.953 40 0 31.045 0 20 0 8.953 8.953 0 20 0z"></path></svg></div></div></div></div></div><div class="jsx-1374485364 TitleBar"><div class="jsx-1374485364 filter"><button class="jsx-322537325 Button iconButton noPadding"><div class="jsx-322537325 icon"><svg id="Rteg_1" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 7 12"><path id="path-1_1_" d="M5.9 0c.4 0 .9.3 1 .7s.1.9-.2 1.2L2.7 6l4 4.1c.3.5.3 1.1-.1 1.6s-1.1.4-1.5.1l-4.8-5c-.4-.4-.4-1.2 0-1.6L5.1.3c.2-.2.5-.3.8-.3z"></path></svg></div><div class="jsx-322537325 desktopOnly">Back to Tutorials</div></button></div><div class="jsx-1374485364 title"><div class="jsx-3889859319 Title"><div class="jsx-3889859319 icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 24.22"><path d="M16.23 24.22a2 2 0 0 1-.73-.14L7 20.79a2 2 0 0 1-1.29-1.88v-4a1.5 1.5 0 0 1 3 0v3.36l7.54 2.92 7.54-2.92v-3.45a1.5 1.5 0 0 1 3 0v4.09a2 2 0 0 1-1.29 1.88L17 24.08a2 2 0 0 1-.77.14zm-.35-2.94zm.7 0z"></path><path d="M16.23 13.35a2 2 0 0 1-.62-.1C9.17 11.16 2.36 9 1.61 8.76a2 2 0 0 1-.25-3.87l14-4.78a2 2 0 0 1 1.3 0l14 4.78a2 2 0 0 1 0 3.81l-13.8 4.55a2 2 0 0 1-.63.1zm-.31-3zM5.21 6.74c3.49 1.11 9.07 2.92 11 3.56l10.68-3.53L16 3.05z"></path></svg></div><div class="jsx-3889859319 h1">Tutorials</div></div></div><div class="jsx-1374485364 action"><button class="jsx-322537325 Button iconButton noPadding"><div class="jsx-322537325 icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20.06 20.39"><path d="M.53 13.94l-.04.04L0 20.39l6.08-.83.04-.03-5.59-5.59zM8.37 17.27L18.9 6.74a4 4 0 0 0 0-5.59 4 4 0 0 0-5.59 0L2.78 11.69z"></path></svg></div><div class="jsx-322537325 desktopOnly">Write a Tutorial. Earn $250</div></button></div></div><div class="jsx-1448759959 Tutorial"><div><div><div style="padding-bottom: 0px;"></div><div class="jsx-undefined social__top desktopOnly" style="transform: translateZ(0px); position: fixed; top: 0px; left: 321px; width: 858px;"><div class="jsx-undefined voteAndSocial"><div class="jsx-undefined"><a href="https://www.datacamp.com/community/tutorials/lstm-python-stock-market#comments" class="jsx-3293774837 CommentCounter"><span class="jsx-3293774837 icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 18 18"><path d="M12.595 13.364c.01-.111.02-.197.028-.251.058-.405.372-.702.74-.702h1.257c1.035-.002 1.875-.934 1.88-2.082V4.764c-.001-1.155-.842-2.092-1.878-2.094H3.38c-1.034.002-1.873.931-1.88 2.076v5.565c.001 1.156.842 2.092 1.878 2.094h6.626c.292 0 .557.189.68.484.408.977 1.07 1.576 1.94 1.85a6.004 6.004 0 0 1-.03-1.375zm1.51 1.119c.048.314.136.521.235.606.566.487.258 1.497-.458 1.497-1.87 0-3.423-.785-4.33-2.51H3.376C1.513 14.07.004 12.39 0 10.311V4.74C.014 2.673 1.52 1.004 3.378 1h11.245c1.864.004 3.373 1.686 3.377 3.763v5.57c-.01 2.07-1.518 3.744-3.378 3.748h-.551c.004.138.016.273.035.402zm-8.423-5.81a1.114 1.114 0 1 0 0-2.229 1.114 1.114 0 0 0 0 2.229zm3.268 0a1.114 1.114 0 1 0 0-2.229 1.114 1.114 0 0 0 0 2.229zm3.318 0a1.114 1.114 0 1 0 0-2.229 1.114 1.114 0 0 0 0 2.229z"></path></svg></span><span class="jsx-3293774837 count">25</span></a><div class="jsx-4192737526 Upvote"><div class="jsx-4192737526"><div class="jsx-4192737526 normal"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path d="M1 10L6 0l5 10z"></path></svg></span><span class="jsx-4192737526 count">45</span></div><div class="jsx-4192737526 voted"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path d="M1 10L6 0l5 10z"></path></svg></span><span class="jsx-4192737526 count">45</span></div></div></div></div><div class="jsx-1531915454 Social vertical"><div class="jsx-1531915454 icons"><a href="https://www.facebook.com/sharer.php?u=https://www.datacamp.com/community/tutorials/lstm-python-stock-market" target="_blank" rel="noopener noreferrer" class="jsx-1531915454 icon"><svg height="12" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 11.73 22.58"><path d="M7.61 22.58v-10.3h3.46l.52-4h-4V5.7c0-1.16.32-2 2-2h2.13V.16A28.47 28.47 0 0 0 8.63 0C5.56 0 3.47 1.87 3.47 5.31v3H0v4h3.47v10.3h4.14z"></path></svg></a><a href="https://twitter.com/intent/tweet?url=https://www.datacamp.com/community/tutorials/lstm-python-stock-market" target="_blank" rel="noopener noreferrer" class="jsx-1531915454 icon centerIcon"><svg height="10" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20.42 16.67"><path d="M10 5.18c0-.28-.06-.53-.07-.78a4 4 0 0 1 .73-2.57A4.08 4.08 0 0 1 13.93 0 4 4 0 0 1 17 1.15a.43.43 0 0 0 .46.12 8.68 8.68 0 0 0 2.2-.84l.2-.1a4.36 4.36 0 0 1-1.75 2.28A9 9 0 0 0 20.42 2l-.21.3a3.83 3.83 0 0 1-.23.3A8.45 8.45 0 0 1 18.5 4a.28.28 0 0 0-.13.27A12 12 0 0 1 17 10.18a11.8 11.8 0 0 1-3.37 4.11 11.17 11.17 0 0 1-4.39 2.06 12.53 12.53 0 0 1-4.44.22 11.87 11.87 0 0 1-4.74-1.73L0 14.79a8.6 8.6 0 0 0 6.16-1.74 4.28 4.28 0 0 1-3.91-2.91h.95a6.18 6.18 0 0 0 .89-.12A4.2 4.2 0 0 1 .8 5.88a4 4 0 0 0 1.81.49 4.23 4.23 0 0 1-1.78-3A4.07 4.07 0 0 1 1.38.79 12.06 12.06 0 0 0 10 5.18z" id="iOjKBC.tif"></path></svg></a><a href="https://www.linkedin.com/cws/share?url=https://www.datacamp.com/community/tutorials/lstm-python-stock-market" target="_blank" rel="noopener noreferrer" class="jsx-1531915454 icon"><svg height="10" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16.99 17"><path d="M3.85 17H.34V5.67h3.51zM2.07 4.18a2.09 2.09 0 1 1 2.08-2.09 2.08 2.08 0 0 1-2.08 2.09zM17 17h-3.5v-5.95c0-1.63-.62-2.54-1.91-2.54s-2.14.95-2.14 2.54V17H6.09V5.67h3.36v1.52a4 4 0 0 1 3.42-1.87c2.4 0 4.12 1.47 4.12 4.5V17z"></path></svg></a></div></div></div></div></div><div class="jsx-1448759959 preface"><div class="jsx-1448759959 author"><div class="jsx-566588255 Author"><a href="https://www.datacamp.com/profile/thushv" target="_blank" class="jsx-566588255"><div class="jsx-3208234818 Avatar" style="background-image: url(&quot;https://res.cloudinary.com/dyd911kmh/image/fetch/t_avatar_thumbnail/https://assets.datacamp.com/users/avatars/002/125/563/square/profile.jpeg?1518563443&quot;); border-radius: 20px; min-width: 40px; min-height: 40px;"></div><div class="jsx-566588255 info"><div class="jsx-566588255 name">Thushan Ganegedara</div><div class="jsx-566588255 date"><span>May 3rd, 2018</span></div></div></a></div></div><div class="jsx-1448759959 tags"><div class="jsx-2792531181 TagLine"><div class="jsx-1764811326 Tag"><span class="jsx-1764811326 title">deep learning</span></div><a class="jsx-1022557955 more">+2</a></div></div><h1 class="jsx-1448759959 pageTitle">Stock Market Predictions with LSTM in Python</h1><div class="jsx-1448759959 description pageDescription">Discover Long Short-Term Memory (LSTM) networks in Python and how you can use them to make stock market predictions!</div></div><div class="markdown"><div><p>In this tutorial, you will see how you can use a time-series model known as Long Short-Term Memory. LSTM models are powerful, especially for retaining a long-term memory, by design, as you will see later. You'll tackle the following topics in this tutorial:</p>
<p></p><nav></nav><p></p>
<ul>
<li>Understand <a href="https://www.datacamp.com/community/tutorials/lstm-python-stock-market#why">why</a> would you need to be able to predict stock price movements;</li>
<li><a href="https://www.datacamp.com/community/tutorials/lstm-python-stock-market#download">Download</a> the data - You will be using stock market data gathered from Yahoo finance;</li>
<li><a href="https://www.datacamp.com/community/tutorials/lstm-python-stock-market#split">Split train-test data</a> and also perform some data normalization;</li>
<li>Go over and apply a few <a href="https://www.datacamp.com/community/tutorials/lstm-python-stock-market#average">averaging techniques</a> that can be used for one-step ahead predictions;</li>
<li>Motivate and briefly discuss an <a href="https://www.datacamp.com/community/tutorials/lstm-python-stock-market#lstm">LSTM model</a> as it allows to predict more than one-step ahead; </li>
<li><a href="https://www.datacamp.com/community/tutorials/lstm-python-stock-market#predict">Predict</a> and visualize future stock market with current data

<div id="scoped-content"><style type="text/css">:target:before { content:""; display:block; height:150px; margin:-150px 0 0; } h3 {font-weight:normal; margin-top:.5em} h4 { font-weight:lighter }
</style>


</div></li>
</ul>
<p>If you're not familiar with deep learning or neural networks, you should take a look at our <a href="https://www.datacamp.com/courses/deep-learning-in-python">Deep Learning in Python course</a>. It covers the basics, as well as how to build a neural network on your own in Keras. This is a different package than TensorFlow, which will be used in this tutorial, but the idea is the same.</p>
<p><a id="why"></a></p>
<h2 id="why-do-you-need-time-series-models-">Why Do You Need Time Series Models?</h2>
<p>You would like to model stock prices correctly, so as a stock buyer you can reasonably decide when to buy stocks and when to sell them to make a profit. This is where time series modelling comes in. You need good machine learning models that can look at the history of a sequence of data and correctly predict what the future elements of the sequence are going to be.</p>
<p><strong>Warning</strong>: Stock market prices are highly unpredictable and volatile. This means that there are no consistent patterns in the data that allow you to model stock prices over time near-perfectly. Don't take it from me, take it from Princeton University economist Burton Malkiel, who argues in his 1973 book, "A Random Walk Down Wall Street," that if the market is truly efficient and a share price reflects all factors immediately as soon as they're made public, a blindfolded monkey throwing darts at a newspaper stock listing should do as well as any investment professional.</p>
<p>However, let's not go all the way believing that this is just a stochastic or random process and that there is no hope for machine learning. Let's see if you can at least model the data, so that the predictions you make correlate with the actual behavior of the data. In other words, you don't need the exact stock values of the future, but the stock price movements (that is, if it is going to rise of fall in the near future).</p>
<pre><code class="lang-python hljs"><span class="hljs-comment"># Make sure that you have all these libaries available to run the code successfully</span>
<span class="hljs-keyword">from</span> pandas_datareader <span class="hljs-keyword">import</span> data
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">import</span> datetime <span class="hljs-keyword">as</span> dt
<span class="hljs-keyword">import</span> urllib.request, json
<span class="hljs-keyword">import</span> os
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf <span class="hljs-comment"># This code has been tested with TensorFlow 1.6</span>
<span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> MinMaxScaler
</code></pre>
<p><a id="download"></a></p>
<h2 id="downloading-the-data">Downloading the Data</h2>
<p>You will be using data from the following sources:</p>
<ol>
<li><p>Alpha Vantage. Before you start, however, you will first need an API key, which you can obtain for free <a href="https://www.alphavantage.co/support/#api-key">here</a>. After that, you can assign that key to the <code>api_key</code> variable.</p>
</li>
<li><p>Use the data from <a href="https://www.kaggle.com/borismarjanovic/price-volume-data-for-all-us-stocks-etfs">this page</a>. You will need to copy the <em>Stocks</em> folder in the zip file to your project home folder.</p>
</li>
</ol>
<p>Stock prices come in several different flavours. They are,</p>
<ul>
<li>Open: Opening stock price of the day</li>
<li>Close: Closing stock price of the day</li>
<li>High: Highest stock price of the data</li>
<li>Low: Lowest stock price of the day</li>
</ul>
<h3 id="getting-data-from-alphavantage">Getting Data from Alphavantage</h3>
<p>You will first load in the data from Alpha Vantage. Since you're going to make use of the American Airlines Stock market prices to make your predictions, you set the ticker to <code>"AAL"</code>. Additionally, you also define a <code>url_string</code>, which will return a JSON file with all the stock market data for American Airlines within the last 20 years, and a <code>file_to_save</code>, which will be the file to which you save the data. You'll use the <code>ticker</code> variable that you defined beforehand to help name this file.</p>
<p>Next, you're going to specify a condition: if you haven't already saved data, you will go ahead and grab the data from the URL that you set in <code>url_string</code>; You'll store the date, low, high, volume, close, open values to a pandas DataFrame <code>df</code> and you'll save it to <code>file_to_save</code>. However, if the data is already there, you'll just load it from the CSV.</p>
<h3 id="getting-data-from-kaggle">Getting Data from Kaggle</h3>
<p>Data found on Kaggle is a collection of csv files and you don't have to do any preprocessing, so you can directly load the data into a Pandas DataFrame.</p>
<pre><code class="lang-python hljs">data_source = <span class="hljs-string">'kaggle'</span> <span class="hljs-comment"># alphavantage or kaggle</span>

<span class="hljs-keyword">if</span> data_source == <span class="hljs-string">'alphavantage'</span>:
    <span class="hljs-comment"># ====================== Loading Data from Alpha Vantage ==================================</span>

    api_key = <span class="hljs-string">'&lt;your API key&gt;'</span>

    <span class="hljs-comment"># American Airlines stock market prices</span>
    ticker = <span class="hljs-string">"AAL"</span>

    <span class="hljs-comment"># JSON file with all the stock market data for AAL from the last 20 years</span>
    url_string = <span class="hljs-string">"https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&amp;symbol=%s&amp;outputsize=full&amp;apikey=%s"</span>%(ticker,api_key)

    <span class="hljs-comment"># Save data to this file</span>
    file_to_save = <span class="hljs-string">'stock_market_data-%s.csv'</span>%ticker

    <span class="hljs-comment"># If you haven't already saved data,</span>
    <span class="hljs-comment"># Go ahead and grab the data from the url</span>
    <span class="hljs-comment"># And store date, low, high, volume, close, open values to a Pandas DataFrame</span>
    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> os.path.exists(file_to_save):
        <span class="hljs-keyword">with</span> urllib.request.urlopen(url_string) <span class="hljs-keyword">as</span> url:
            data = json.loads(url.read().decode())
            <span class="hljs-comment"># extract stock market data</span>
            data = data[<span class="hljs-string">'Time Series (Daily)'</span>]
            df = pd.DataFrame(columns=[<span class="hljs-string">'Date'</span>,<span class="hljs-string">'Low'</span>,<span class="hljs-string">'High'</span>,<span class="hljs-string">'Close'</span>,<span class="hljs-string">'Open'</span>])
            <span class="hljs-keyword">for</span> k,v <span class="hljs-keyword">in</span> data.items():
                date = dt.datetime.strptime(k, <span class="hljs-string">'%Y-%m-%d'</span>)
                data_row = [date.date(),float(v[<span class="hljs-string">'3. low'</span>]),float(v[<span class="hljs-string">'2. high'</span>]),
                            float(v[<span class="hljs-string">'4. close'</span>]),float(v[<span class="hljs-string">'1. open'</span>])]
                df.loc[<span class="hljs-number">-1</span>,:] = data_row
                df.index = df.index + <span class="hljs-number">1</span>
        print(<span class="hljs-string">'Data saved to : %s'</span>%file_to_save)        
        df.to_csv(file_to_save)

    <span class="hljs-comment"># If the data is already there, just load it from the CSV</span>
    <span class="hljs-keyword">else</span>:
        print(<span class="hljs-string">'File already exists. Loading data from CSV'</span>)
        df = pd.read_csv(file_to_save)

<span class="hljs-keyword">else</span>:

    <span class="hljs-comment"># ====================== Loading Data from Kaggle ==================================</span>
    <span class="hljs-comment"># You will be using HP's data. Feel free to experiment with other data.</span>
    <span class="hljs-comment"># But while doing so, be careful to have a large enough dataset and also pay attention to the data normalization</span>
    df = pd.read_csv(os.path.join(<span class="hljs-string">'Stocks'</span>,<span class="hljs-string">'hpq.us.txt'</span>),delimiter=<span class="hljs-string">','</span>,usecols=[<span class="hljs-string">'Date'</span>,<span class="hljs-string">'Open'</span>,<span class="hljs-string">'High'</span>,<span class="hljs-string">'Low'</span>,<span class="hljs-string">'Close'</span>])
    print(<span class="hljs-string">'Loaded data from the Kaggle repository'</span>)
</code></pre>
<pre><code>Data saved to : stock_market_data-AAL.csv
</code></pre><h3 id="data-exploration">Data Exploration</h3>
<p>Here you will print the data you collected in to the DataFrame. You should also make sure that the data is sorted by date, because the order of the data is crucial in time series modelling.</p>
<pre><code class="lang-python hljs"><span class="hljs-comment"># Sort DataFrame by date</span>
df = df.sort_values(<span class="hljs-string">'Date'</span>)

<span class="hljs-comment"># Double check the result</span>
df.head()
</code></pre>
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align:right;">
      <th></th>
      <th>Date</th>
      <th>Open</th>
      <th>High</th>
      <th>Low</th>
      <th>Close</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1970-01-02</td>
      <td>0.30627</td>
      <td>0.30627</td>
      <td>0.30627</td>
      <td>0.30627</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1970-01-05</td>
      <td>0.30627</td>
      <td>0.31768</td>
      <td>0.30627</td>
      <td>0.31385</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1970-01-06</td>
      <td>0.31385</td>
      <td>0.31385</td>
      <td>0.30996</td>
      <td>0.30996</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1970-01-07</td>
      <td>0.31385</td>
      <td>0.31385</td>
      <td>0.31385</td>
      <td>0.31385</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1970-01-08</td>
      <td>0.31385</td>
      <td>0.31768</td>
      <td>0.31385</td>
      <td>0.31385</td>
    </tr>
  </tbody>
</table>
</div>



<h4 id="data-visualization">Data Visualization</h4>
<p>Now let's see what sort of data you have. You want data with various patterns occurring over time.</p>
<pre><code class="lang-python hljs">plt.figure(figsize = (<span class="hljs-number">18</span>,<span class="hljs-number">9</span>))
plt.plot(range(df.shape[<span class="hljs-number">0</span>]),(df[<span class="hljs-string">'Low'</span>]+df[<span class="hljs-string">'High'</span>])/<span class="hljs-number">2.0</span>)
plt.xticks(range(<span class="hljs-number">0</span>,df.shape[<span class="hljs-number">0</span>],<span class="hljs-number">500</span>),df[<span class="hljs-string">'Date'</span>].loc[::<span class="hljs-number">500</span>],rotation=<span class="hljs-number">45</span>)
plt.xlabel(<span class="hljs-string">'Date'</span>,fontsize=<span class="hljs-number">18</span>)
plt.ylabel(<span class="hljs-string">'Mid Price'</span>,fontsize=<span class="hljs-number">18</span>)
plt.show()
</code></pre>
<p><img src="./LSTM in Python_ Stock Market Predictions (article) - DataCamp_files/output_7_0_ovatau.png"></p>
<p>This graph already says a lot of things. The specific reason I picked this company over others is that this graph is bursting with different behaviors of stock prices over time. This will make the learning more robust as well as give you a change to test how good the predictions are for a variety of situations.</p>
<p>Another thing to notice is that the values close to 2017 are much higher and fluctuate more than the values close to the 1970s. Therefore you need to make sure that the data behaves in similar value ranges throughout the time frame. You will take care of this during the <em>data normalization</em> phase.</p>
<p><a id="split"></a></p>
<h2 id="splitting-data-into-a-training-set-and-a-test-set">Splitting Data into a Training set and a Test set</h2>
<p>You will use the mid price calculated by taking the average of the highest and lowest recorded prices on a day.</p>
<pre><code class="lang-python hljs"><span class="hljs-comment"># First calculate the mid prices from the highest and lowest</span>
high_prices = df.loc[:,<span class="hljs-string">'High'</span>].as_matrix()
low_prices = df.loc[:,<span class="hljs-string">'Low'</span>].as_matrix()
mid_prices = (high_prices+low_prices)/<span class="hljs-number">2.0</span>
</code></pre>
<p>Now you can split the training data and test data. The training data will be the first 11,000 data points of the time series and rest will be test data.</p>
<pre><code class="lang-python hljs">train_data = mid_prices[:<span class="hljs-number">11000</span>]
test_data = mid_prices[<span class="hljs-number">11000</span>:]
</code></pre>
<h1 id="normalizing-the-data">Normalizing the Data</h1>
<p>Now you need to define a scaler to normalize the data. <code>MinMaxScalar</code> scales all the data to be in the region of 0 and 1. You can also reshape the training and test data to be in the shape <code>[data_size, num_features]</code>.</p>
<pre><code class="lang-python hljs"><span class="hljs-comment"># Scale the data to be between 0 and 1</span>
<span class="hljs-comment"># When scaling remember! You normalize both test and train data with respect to training data</span>
<span class="hljs-comment"># Because you are not supposed to have access to test data</span>
scaler = MinMaxScaler()
train_data = train_data.reshape(<span class="hljs-number">-1</span>,<span class="hljs-number">1</span>)
test_data = test_data.reshape(<span class="hljs-number">-1</span>,<span class="hljs-number">1</span>)
</code></pre>
<p>Due to the observation you made earlier, that is, different time periods of data have different value ranges, you normalize the data by splitting the full series into windows. If you don't do this, the earlier data will be close to 0 and will not add much value to the learning process. Here you choose a window size of 2500.</p>
<p><strong>Tip</strong>: when choosing the window size make sure it's not too small, because when  you perform windowed-normalization, it can introduce a break at the very end of each window, as each window is normalized independently.</p>
<p>In this example, 4 data points will be affected by this. But given you have 11,000 data points, 4 points will not cause any issue</p>
<pre><code class="lang-python hljs"><span class="hljs-comment"># Train the Scaler with training data and smooth data</span>
smoothing_window_size = <span class="hljs-number">2500</span>
<span class="hljs-keyword">for</span> di <span class="hljs-keyword">in</span> range(<span class="hljs-number">0</span>,<span class="hljs-number">10000</span>,smoothing_window_size):
    scaler.fit(train_data[di:di+smoothing_window_size,:])
    train_data[di:di+smoothing_window_size,:] = scaler.transform(train_data[di:di+smoothing_window_size,:])

<span class="hljs-comment"># You normalize the last bit of remaining data</span>
scaler.fit(train_data[di+smoothing_window_size:,:])
train_data[di+smoothing_window_size:,:] = scaler.transform(train_data[di+smoothing_window_size:,:])
</code></pre>
<p>Reshape the data back to the shape of <code>[data_size]</code></p>
<pre><code class="lang-python hljs"><span class="hljs-comment"># Reshape both train and test data</span>
train_data = train_data.reshape(<span class="hljs-number">-1</span>)

<span class="hljs-comment"># Normalize test data</span>
test_data = scaler.transform(test_data).reshape(<span class="hljs-number">-1</span>)
</code></pre>
<p>You can now smooth the data using the exponential moving average. This helps you to get rid of the inherent raggedness of the data in stock prices and produce a smoother curve.</p>
<p><strong>Note</strong> that you should only smooth training data.</p>
<pre><code class="lang-python hljs"><span class="hljs-comment"># Now perform exponential moving average smoothing</span>
<span class="hljs-comment"># So the data will have a smoother curve than the original ragged data</span>
EMA = <span class="hljs-number">0.0</span>
gamma = <span class="hljs-number">0.1</span>
<span class="hljs-keyword">for</span> ti <span class="hljs-keyword">in</span> range(<span class="hljs-number">11000</span>):
  EMA = gamma*train_data[ti] + (<span class="hljs-number">1</span>-gamma)*EMA
  train_data[ti] = EMA

<span class="hljs-comment"># Used for visualization and test purposes</span>
all_mid_data = np.concatenate([train_data,test_data],axis=<span class="hljs-number">0</span>)
</code></pre>
<p><a id="average"></a></p>
<h2 id="one-step-ahead-prediction-via-averaging">One-Step Ahead Prediction via Averaging</h2>
<p>Averaging mechanisms allow you to predict (often one time step ahead) by representing the future stock price as an average of the previously observed stock prices. Doing this for more than one time step can produce quite bad results. You will look at two averaging techniques below; standard averaging and exponential moving average. You will evaluate both qualitatively (visual inspection) and quantitatively (Mean Squared Error) the results produced by the two algorithms.</p>
<p>The Mean Squared Error (MSE) can be calculated by taking the Squared Error between the true value at one step ahead and the predicted value and averaging it over all the predictions.</p>
<h3 id="standard-average">Standard Average</h3>
<p>You can understand the difficulty of this problem by first trying to model this as an average calculation problem. First you will try to predict the future stock market prices (for example, x<sub>t+1</sub>) as an average of the previously observed stock market prices within a fixed size window (for example, x<sub>t-N</sub>, ..., x<sub>t</sub>) (say previous 100 days). Thereafter you will try a bit more fancier "exponential moving average" method and see how well that does. Then you will move on to the "holy-grail" of time-series prediction; Long Short-Term Memory models.</p>
<p>First you will see how normal averaging works. That is you say,</p>
<img src="./LSTM in Python_ Stock Market Predictions (article) - DataCamp_files/sum_formula.png">
<p>In other words, you say the prediction at <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-11-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-49" style="width: 2.33em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.985em; height: 0px; font-size: 116%;"><span style="position: absolute; clip: rect(1.683em, 1001.9em, 2.675em, -999.998em); top: -2.498em; left: 0em;"><span class="mrow" id="MathJax-Span-50"><span class="mi" id="MathJax-Span-51" style="font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span class="mo" id="MathJax-Span-52" style="font-family: STIXGeneral-Regular; padding-left: 0.261em;">+</span><span class="mn" id="MathJax-Span-53" style="font-family: STIXGeneral-Regular; padding-left: 0.261em;">1</span></span><span style="display: inline-block; width: 0px; height: 2.502em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.098em; border-left: 0px solid; width: 0px; height: 0.953em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>t</mi><mo>+</mo><mn>1</mn></math></span></span><script type="math/tex" id="MathJax-Element-11">t+1</script> is the average value of all the stock prices you observed within a window of <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-12-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-54" style="width: 0.304em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.261em; height: 0px; font-size: 116%;"><span style="position: absolute; clip: rect(1.813em, 1000.26em, 2.631em, -999.998em); top: -2.498em; left: 0em;"><span class="mrow" id="MathJax-Span-55"><span class="mi" id="MathJax-Span-56" style="font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.502em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.048em; border-left: 0px solid; width: 0px; height: 0.753em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>t</mi></math></span></span><script type="math/tex" id="MathJax-Element-12">t</script> to <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-13-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-57" style="width: 2.545em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.2em; height: 0px; font-size: 116%;"><span style="position: absolute; clip: rect(1.726em, 1002.2em, 2.761em, -999.998em); top: -2.498em; left: 0em;"><span class="mrow" id="MathJax-Span-58"><span class="mi" id="MathJax-Span-59" style="font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span class="mo" id="MathJax-Span-60" style="font-family: STIXGeneral-Regular; padding-left: 0.261em;"></span><span class="mi" id="MathJax-Span-61" style="font-family: STIXGeneral-Italic; padding-left: 0.261em;">N<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.045em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.502em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.198em; border-left: 0px solid; width: 0px; height: 1.002em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>t</mi><mo></mo><mi>N</mi></math></span></span><script type="math/tex" id="MathJax-Element-13">t-N</script>.</p>
<pre><code class="lang-python hljs">window_size = <span class="hljs-number">100</span>
N = train_data.size
std_avg_predictions = []
std_avg_x = []
mse_errors = []

<span class="hljs-keyword">for</span> pred_idx <span class="hljs-keyword">in</span> range(window_size,N):

    <span class="hljs-keyword">if</span> pred_idx &gt;= N:
        date = dt.datetime.strptime(k, <span class="hljs-string">'%Y-%m-%d'</span>).date() + dt.timedelta(days=<span class="hljs-number">1</span>)
    <span class="hljs-keyword">else</span>:
        date = df.loc[pred_idx,<span class="hljs-string">'Date'</span>]

    std_avg_predictions.append(np.mean(train_data[pred_idx-window_size:pred_idx]))
    mse_errors.append((std_avg_predictions[<span class="hljs-number">-1</span>]-train_data[pred_idx])**<span class="hljs-number">2</span>)
    std_avg_x.append(date)

print(<span class="hljs-string">'MSE error for standard averaging: %.5f'</span>%(<span class="hljs-number">0.5</span>*np.mean(mse_errors)))
</code></pre>
<pre><code>MSE error for standard averaging: 0.00418
</code></pre><p>Take a look at the averaged results below. It follows the actual behavior of stock quite closely. Next, you will look at a more accurate one-step prediction method.</p>
<pre><code class="lang-python hljs">
plt.figure(figsize = (<span class="hljs-number">18</span>,<span class="hljs-number">9</span>))
plt.plot(range(df.shape[<span class="hljs-number">0</span>]),all_mid_data,color=<span class="hljs-string">'b'</span>,label=<span class="hljs-string">'True'</span>)
plt.plot(range(window_size,N),std_avg_predictions,color=<span class="hljs-string">'orange'</span>,label=<span class="hljs-string">'Prediction'</span>)
<span class="hljs-comment">#plt.xticks(range(0,df.shape[0],50),df['Date'].loc[::50],rotation=45)</span>
plt.xlabel(<span class="hljs-string">'Date'</span>)
plt.ylabel(<span class="hljs-string">'Mid Price'</span>)
plt.legend(fontsize=<span class="hljs-number">18</span>)
plt.show()
</code></pre>
<p><img src="./LSTM in Python_ Stock Market Predictions (article) - DataCamp_files/output_24_0_nz8zxp.png"></p>
<p>So what do the above graphs (and the MSE) say?</p>
<p>It seems that it is not too bad of a model for very short predictions (one day ahead). Given that stock prices don't change from 0 to 100 overnight, this behavior is sensible. Next, you will look at a fancier averaging technique known as exponential moving average.</p>
<h3 id="exponential-moving-average">Exponential Moving Average</h3>
<p>You might have seen some articles on the internet using very complex models and predicting almost the exact behavior of the stock market. But <strong>beware!</strong> These are just optical illusions and not due to learning something useful. You will see below how you can replicate that behavior with a simple averaging method.</p>
<p>In the exponential moving average method, you calculate <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-14-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-62" style="width: 1.813em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.554em; height: 0px; font-size: 116%;"><span style="position: absolute; clip: rect(1.683em, 1001.55em, 2.545em, -999.998em); top: -2.239em; left: 0em;"><span class="mrow" id="MathJax-Span-63"><span class="msubsup" id="MathJax-Span-64"><span style="display: inline-block; position: relative; width: 1.554em; height: 0px;"><span style="position: absolute; clip: rect(3.45em, 1000.43em, 4.14em, -999.998em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-65" style="font-family: STIXGeneral-Italic;">x<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.877em; left: 0.433em;"><span class="texatom" id="MathJax-Span-66"><span class="mrow" id="MathJax-Span-67"><span class="mi" id="MathJax-Span-68" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span class="mo" id="MathJax-Span-69" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">+</span><span class="mn" id="MathJax-Span-70" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.244em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 0.802em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>x</mi><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub></math></span></span><script type="math/tex" id="MathJax-Element-14">x_{t+1}</script> as,</p>
<ul>
<li>x<sub>t+1</sub> = EMA<sub>t</sub> =   EMA<sub>t-1</sub> + (1-) x<sub>t</sub> where EMA<sub>0</sub> = 0 and EMA is the exponential moving average value you maintain over time.</li>
</ul>
<p>The above equation basically calculates the exponential moving average from <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-15-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-71" style="width: 2.33em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.985em; height: 0px; font-size: 116%;"><span style="position: absolute; clip: rect(1.683em, 1001.9em, 2.675em, -999.998em); top: -2.498em; left: 0em;"><span class="mrow" id="MathJax-Span-72"><span class="mi" id="MathJax-Span-73" style="font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span class="mo" id="MathJax-Span-74" style="font-family: STIXGeneral-Regular; padding-left: 0.261em;">+</span><span class="mn" id="MathJax-Span-75" style="font-family: STIXGeneral-Regular; padding-left: 0.261em;">1</span></span><span style="display: inline-block; width: 0px; height: 2.502em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.098em; border-left: 0px solid; width: 0px; height: 0.953em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>t</mi><mo>+</mo><mn>1</mn></math></span></span><script type="math/tex" id="MathJax-Element-15">t+1</script> time step and uses that as the one step ahead prediction. <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-16-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;&amp;#x03B3;&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-76" style="width: 0.563em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.476em; height: 0px; font-size: 116%;"><span style="position: absolute; clip: rect(1.942em, 1000.48em, 2.847em, -999.998em); top: -2.498em; left: 0em;"><span class="mrow" id="MathJax-Span-77"><span class="mi" id="MathJax-Span-78" style="font-family: STIXGeneral-Italic;"><span style="display: inline-block; overflow: hidden; height: 1px; width: 0.045em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.502em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.297em; border-left: 0px solid; width: 0px; height: 0.853em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi></mi></math></span></span><script type="math/tex" id="MathJax-Element-16">\gamma</script> decides what the contribution of the most recent prediction is to the EMA. For example, a <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-17-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;&amp;#x03B3;&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;0.1&lt;/mn&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-79" style="width: 3.45em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.976em; height: 0px; font-size: 116%;"><span style="position: absolute; clip: rect(1.683em, 1002.89em, 2.847em, -999.998em); top: -2.498em; left: 0em;"><span class="mrow" id="MathJax-Span-80"><span class="mi" id="MathJax-Span-81" style="font-family: STIXGeneral-Italic;"><span style="display: inline-block; overflow: hidden; height: 1px; width: 0.045em;"></span></span><span class="mo" id="MathJax-Span-82" style="font-family: STIXGeneral-Regular; padding-left: 0.304em;">=</span><span class="mn" id="MathJax-Span-83" style="font-family: STIXGeneral-Regular; padding-left: 0.304em;">0.1</span></span><span style="display: inline-block; width: 0px; height: 2.502em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.297em; border-left: 0px solid; width: 0px; height: 1.103em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi></mi><mo>=</mo><mn>0.1</mn></math></span></span><script type="math/tex" id="MathJax-Element-17">\gamma=0.1</script> gets only 10% of the current value into the EMA. Because you take only a very small fraction of the most recent, it allows to preserve much older values you saw very early in the average. See how good this looks when used to predict one-step ahead below.</p>
<pre><code class="lang-python hljs">window_size = <span class="hljs-number">100</span>
N = train_data.size

run_avg_predictions = []
run_avg_x = []

mse_errors = []

running_mean = <span class="hljs-number">0.0</span>
run_avg_predictions.append(running_mean)

decay = <span class="hljs-number">0.5</span>

<span class="hljs-keyword">for</span> pred_idx <span class="hljs-keyword">in</span> range(<span class="hljs-number">1</span>,N):

    running_mean = running_mean*decay + (<span class="hljs-number">1.0</span>-decay)*train_data[pred_idx<span class="hljs-number">-1</span>]
    run_avg_predictions.append(running_mean)
    mse_errors.append((run_avg_predictions[<span class="hljs-number">-1</span>]-train_data[pred_idx])**<span class="hljs-number">2</span>)
    run_avg_x.append(date)

print(<span class="hljs-string">'MSE error for EMA averaging: %.5f'</span>%(<span class="hljs-number">0.5</span>*np.mean(mse_errors)))
</code></pre>
<pre><code>MSE error for EMA averaging: 0.00003
</code></pre><pre><code class="lang-python hljs">
plt.figure(figsize = (<span class="hljs-number">18</span>,<span class="hljs-number">9</span>))
plt.plot(range(df.shape[<span class="hljs-number">0</span>]),all_mid_data,color=<span class="hljs-string">'b'</span>,label=<span class="hljs-string">'True'</span>)
plt.plot(range(<span class="hljs-number">0</span>,N),run_avg_predictions,color=<span class="hljs-string">'orange'</span>, label=<span class="hljs-string">'Prediction'</span>)
<span class="hljs-comment">#plt.xticks(range(0,df.shape[0],50),df['Date'].loc[::50],rotation=45)</span>
plt.xlabel(<span class="hljs-string">'Date'</span>)
plt.ylabel(<span class="hljs-string">'Mid Price'</span>)
plt.legend(fontsize=<span class="hljs-number">18</span>)
plt.show()
</code></pre>
<p><img src="./LSTM in Python_ Stock Market Predictions (article) - DataCamp_files/output_27_0_n4h76v.png"></p>
<h3 id="if-exponential-moving-average-is-this-good-why-do-you-need-better-models-">If Exponential Moving Average is this Good, Why do You Need Better Models?</h3>
<p>You see that it fits a perfect line that follows the <code>True</code> distribution (and justified by the very low MSE). Practically speaking, you can't do much with just the stock market value of the next day. Personally what I'd like is not the exact stock market price for the next day, but <em>would the stock market prices go up or down in the next 30 days</em>. Try to do this, and you will expose the incapability of the EMA method.</p>
<p>You will now try to make predictions in windows (say you predict the next 2 days window, instead of just the next day). Then you will realize how wrong EMA can go. Here is an example:</p>
<h3 id="predict-more-than-one-step-into-the-future">Predict More Than One Step into the Future</h3>
<p>To make things concrete, let's assume values, say <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-18-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;0.4&lt;/mn&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-84" style="width: 3.795em; display: inline-block;"><span style="display: inline-block; position: relative; width: 3.278em; height: 0px; font-size: 116%;"><span style="position: absolute; clip: rect(1.683em, 1003.24em, 2.804em, -999.998em); top: -2.498em; left: 0em;"><span class="mrow" id="MathJax-Span-85"><span class="msubsup" id="MathJax-Span-86"><span style="display: inline-block; position: relative; width: 0.735em; height: 0px;"><span style="position: absolute; clip: rect(3.45em, 1000.43em, 4.14em, -999.998em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-87" style="font-family: STIXGeneral-Italic;">x<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.877em; left: 0.433em;"><span class="mi" id="MathJax-Span-88" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-89" style="font-family: STIXGeneral-Regular; padding-left: 0.304em;">=</span><span class="mn" id="MathJax-Span-90" style="font-family: STIXGeneral-Regular; padding-left: 0.304em;">0.4</span></span><span style="display: inline-block; width: 0px; height: 2.502em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.052em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>x</mi><mi>t</mi></msub><mo>=</mo><mn>0.4</mn></math></span></span><script type="math/tex" id="MathJax-Element-18">x_t=0.4</script>, <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-19-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;mi&gt;M&lt;/mi&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;0.5&lt;/mn&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-91" style="width: 5.476em; display: inline-block;"><span style="display: inline-block; position: relative; width: 4.7em; height: 0px; font-size: 116%;"><span style="position: absolute; clip: rect(1.683em, 1004.66em, 2.631em, -999.998em); top: -2.498em; left: 0em;"><span class="mrow" id="MathJax-Span-92"><span class="mi" id="MathJax-Span-93" style="font-family: STIXGeneral-Italic;">E<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.045em;"></span></span><span class="mi" id="MathJax-Span-94" style="font-family: STIXGeneral-Italic;">M<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.045em;"></span></span><span class="mi" id="MathJax-Span-95" style="font-family: STIXGeneral-Italic;">A</span><span class="mo" id="MathJax-Span-96" style="font-family: STIXGeneral-Regular; padding-left: 0.304em;">=</span><span class="mn" id="MathJax-Span-97" style="font-family: STIXGeneral-Regular; padding-left: 0.304em;">0.5</span></span><span style="display: inline-block; width: 0px; height: 2.502em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.048em; border-left: 0px solid; width: 0px; height: 0.903em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>E</mi><mi>M</mi><mi>A</mi><mo>=</mo><mn>0.5</mn></math></span></span><script type="math/tex" id="MathJax-Element-19">EMA=0.5</script> and <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-20-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;&amp;#x03B3;&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;0.5&lt;/mn&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-98" style="width: 3.45em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.976em; height: 0px; font-size: 116%;"><span style="position: absolute; clip: rect(1.683em, 1002.93em, 2.847em, -999.998em); top: -2.498em; left: 0em;"><span class="mrow" id="MathJax-Span-99"><span class="mi" id="MathJax-Span-100" style="font-family: STIXGeneral-Italic;"><span style="display: inline-block; overflow: hidden; height: 1px; width: 0.045em;"></span></span><span class="mo" id="MathJax-Span-101" style="font-family: STIXGeneral-Regular; padding-left: 0.304em;">=</span><span class="mn" id="MathJax-Span-102" style="font-family: STIXGeneral-Regular; padding-left: 0.304em;">0.5</span></span><span style="display: inline-block; width: 0px; height: 2.502em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.297em; border-left: 0px solid; width: 0px; height: 1.153em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi></mi><mo>=</mo><mn>0.5</mn></math></span></span><script type="math/tex" id="MathJax-Element-20">\gamma = 0.5</script></p>
<ul>
<li>Say you get the output with the following equation<ul>
<li>X<sub>t+1</sub> = EMA<sub>t</sub> =   EMA<sub>t-1</sub> + (1 - )X<sub>t</sub></li>
<li>So you have <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-21-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;0.5&lt;/mn&gt;&lt;mo&gt;&amp;#x00D7;&lt;/mo&gt;&lt;mn&gt;0.5&lt;/mn&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mn&gt;0.5&lt;/mn&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;&amp;#x00D7;&lt;/mo&gt;&lt;mn&gt;0.4&lt;/mn&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;0.45&lt;/mn&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-103" style="width: 19.485em; display: inline-block;"><span style="display: inline-block; position: relative; width: 16.769em; height: 0px; font-size: 116%;"><span style="position: absolute; clip: rect(1.683em, 1016.73em, 2.804em, -999.998em); top: -2.498em; left: 0em;"><span class="mrow" id="MathJax-Span-104"><span class="msubsup" id="MathJax-Span-105"><span style="display: inline-block; position: relative; width: 1.554em; height: 0px;"><span style="position: absolute; clip: rect(3.45em, 1000.43em, 4.14em, -999.998em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-106" style="font-family: STIXGeneral-Italic;">x<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.877em; left: 0.433em;"><span class="texatom" id="MathJax-Span-107"><span class="mrow" id="MathJax-Span-108"><span class="mi" id="MathJax-Span-109" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span class="mo" id="MathJax-Span-110" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">+</span><span class="mn" id="MathJax-Span-111" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-112" style="font-family: STIXGeneral-Regular; padding-left: 0.304em;">=</span><span class="mn" id="MathJax-Span-113" style="font-family: STIXGeneral-Regular; padding-left: 0.304em;">0.5</span><span class="mo" id="MathJax-Span-114" style="font-family: STIXGeneral-Regular; padding-left: 0.261em;"></span><span class="mn" id="MathJax-Span-115" style="font-family: STIXGeneral-Regular; padding-left: 0.261em;">0.5</span><span class="mo" id="MathJax-Span-116" style="font-family: STIXGeneral-Regular; padding-left: 0.261em;">+</span><span class="mo" id="MathJax-Span-117" style="font-family: STIXGeneral-Regular; padding-left: 0.261em;">(</span><span class="mn" id="MathJax-Span-118" style="font-family: STIXGeneral-Regular;">1</span><span class="mo" id="MathJax-Span-119" style="font-family: STIXGeneral-Regular; padding-left: 0.261em;"></span><span class="mn" id="MathJax-Span-120" style="font-family: STIXGeneral-Regular; padding-left: 0.261em;">0.5</span><span class="mo" id="MathJax-Span-121" style="font-family: STIXGeneral-Regular;">)</span><span class="mo" id="MathJax-Span-122" style="font-family: STIXGeneral-Regular; padding-left: 0.261em;"></span><span class="mn" id="MathJax-Span-123" style="font-family: STIXGeneral-Regular; padding-left: 0.261em;">0.4</span><span class="mo" id="MathJax-Span-124" style="font-family: STIXGeneral-Regular; padding-left: 0.304em;">=</span><span class="mn" id="MathJax-Span-125" style="font-family: STIXGeneral-Regular; padding-left: 0.304em;">0.45</span></span><span style="display: inline-block; width: 0px; height: 2.502em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.103em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>x</mi><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><mn>0.5</mn><mo></mo><mn>0.5</mn><mo>+</mo><mo stretchy="false">(</mo><mn>1</mn><mo></mo><mn>0.5</mn><mo stretchy="false">)</mo><mo></mo><mn>0.4</mn><mo>=</mo><mn>0.45</mn></math></span></span><script type="math/tex" id="MathJax-Element-21">x_{t+1} = 0.5 \times 0.5 + (1-0.5) \times 0.4 = 0.45</script></li>
<li>So <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-22-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;mi&gt;M&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;0.45&lt;/mn&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-126" style="width: 9.657em; display: inline-block;"><span style="display: inline-block; position: relative; width: 8.321em; height: 0px; font-size: 116%;"><span style="position: absolute; clip: rect(1.683em, 1008.28em, 2.804em, -999.998em); top: -2.498em; left: 0em;"><span class="mrow" id="MathJax-Span-127"><span class="msubsup" id="MathJax-Span-128"><span style="display: inline-block; position: relative; width: 1.554em; height: 0px;"><span style="position: absolute; clip: rect(3.45em, 1000.43em, 4.14em, -999.998em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-129" style="font-family: STIXGeneral-Italic;">x<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.877em; left: 0.433em;"><span class="texatom" id="MathJax-Span-130"><span class="mrow" id="MathJax-Span-131"><span class="mi" id="MathJax-Span-132" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span class="mo" id="MathJax-Span-133" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">+</span><span class="mn" id="MathJax-Span-134" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-135" style="font-family: STIXGeneral-Regular; padding-left: 0.304em;">=</span><span class="mi" id="MathJax-Span-136" style="font-family: STIXGeneral-Italic; padding-left: 0.304em;">E<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.045em;"></span></span><span class="mi" id="MathJax-Span-137" style="font-family: STIXGeneral-Italic;">M<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.045em;"></span></span><span class="msubsup" id="MathJax-Span-138"><span style="display: inline-block; position: relative; width: 0.907em; height: 0px;"><span style="position: absolute; clip: rect(3.235em, 1000.56em, 4.14em, -999.998em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-139" style="font-family: STIXGeneral-Italic;">A</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.877em; left: 0.606em;"><span class="mi" id="MathJax-Span-140" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-141" style="font-family: STIXGeneral-Regular; padding-left: 0.304em;">=</span><span class="mn" id="MathJax-Span-142" style="font-family: STIXGeneral-Regular; padding-left: 0.304em;">0.45</span></span><span style="display: inline-block; width: 0px; height: 2.502em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.103em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>x</mi><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><mi>E</mi><mi>M</mi><msub><mi>A</mi><mi>t</mi></msub><mo>=</mo><mn>0.45</mn></math></span></span><script type="math/tex" id="MathJax-Element-22">x_{t+1} = EMA_t = 0.45</script></li>
</ul>
</li>
<li>So the next prediction <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-23-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-143" style="width: 1.813em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.554em; height: 0px; font-size: 116%;"><span style="position: absolute; clip: rect(1.683em, 1001.55em, 2.545em, -999.998em); top: -2.239em; left: 0em;"><span class="mrow" id="MathJax-Span-144"><span class="msubsup" id="MathJax-Span-145"><span style="display: inline-block; position: relative; width: 1.554em; height: 0px;"><span style="position: absolute; clip: rect(3.45em, 1000.43em, 4.14em, -999.998em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-146" style="font-family: STIXGeneral-Italic;">x<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.877em; left: 0.433em;"><span class="texatom" id="MathJax-Span-147"><span class="mrow" id="MathJax-Span-148"><span class="mi" id="MathJax-Span-149" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span class="mo" id="MathJax-Span-150" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">+</span><span class="mn" id="MathJax-Span-151" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.244em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 0.802em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>x</mi><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mo>+</mo><mn>2</mn></mrow></msub></math></span></span><script type="math/tex" id="MathJax-Element-23">x_{t+2}</script> becomes,<ul>
<li>X<sub>t+2</sub> =   EMA<sub>t</sub> + (1-)X<sub>t+1</sub></li>
<li>Which is <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-24-Frame" tabindex="0" style="position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;&amp;#x03B3;&lt;/mi&gt;&lt;mo&gt;&amp;#x00D7;&lt;/mo&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;mi&gt;M&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mi&gt;&amp;#x03B3;&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;mi&gt;M&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;mi&gt;M&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-152" style="width: 19.83em; display: inline-block;"><span style="display: inline-block; position: relative; width: 17.071em; height: 0px; font-size: 116%;"><span style="position: absolute; clip: rect(1.683em, 1017.07em, 2.847em, -999.998em); top: -2.498em; left: 0em;"><span class="mrow" id="MathJax-Span-153"><span class="msubsup" id="MathJax-Span-154"><span style="display: inline-block; position: relative; width: 1.554em; height: 0px;"><span style="position: absolute; clip: rect(3.45em, 1000.43em, 4.14em, -999.998em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-155" style="font-family: STIXGeneral-Italic;">x<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.877em; left: 0.433em;"><span class="texatom" id="MathJax-Span-156"><span class="mrow" id="MathJax-Span-157"><span class="mi" id="MathJax-Span-158" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span class="mo" id="MathJax-Span-159" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">+</span><span class="mn" id="MathJax-Span-160" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-161" style="font-family: STIXGeneral-Regular; padding-left: 0.304em;">=</span><span class="mi" id="MathJax-Span-162" style="font-family: STIXGeneral-Italic; padding-left: 0.304em;"><span style="display: inline-block; overflow: hidden; height: 1px; width: 0.045em;"></span></span><span class="mo" id="MathJax-Span-163" style="font-family: STIXGeneral-Regular; padding-left: 0.261em;"></span><span class="mi" id="MathJax-Span-164" style="font-family: STIXGeneral-Italic; padding-left: 0.261em;">E<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.045em;"></span></span><span class="mi" id="MathJax-Span-165" style="font-family: STIXGeneral-Italic;">M<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.045em;"></span></span><span class="msubsup" id="MathJax-Span-166"><span style="display: inline-block; position: relative; width: 0.907em; height: 0px;"><span style="position: absolute; clip: rect(3.235em, 1000.56em, 4.14em, -999.998em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-167" style="font-family: STIXGeneral-Italic;">A</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.877em; left: 0.606em;"><span class="mi" id="MathJax-Span-168" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-169" style="font-family: STIXGeneral-Regular; padding-left: 0.261em;">+</span><span class="mo" id="MathJax-Span-170" style="font-family: STIXGeneral-Regular; padding-left: 0.261em;">(</span><span class="mn" id="MathJax-Span-171" style="font-family: STIXGeneral-Regular;">1</span><span class="mo" id="MathJax-Span-172" style="font-family: STIXGeneral-Regular; padding-left: 0.261em;"></span><span class="mi" id="MathJax-Span-173" style="font-family: STIXGeneral-Italic; padding-left: 0.261em;"><span style="display: inline-block; overflow: hidden; height: 1px; width: 0.045em;"></span></span><span class="mo" id="MathJax-Span-174" style="font-family: STIXGeneral-Regular;">)</span><span class="mi" id="MathJax-Span-175" style="font-family: STIXGeneral-Italic;">E<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.045em;"></span></span><span class="mi" id="MathJax-Span-176" style="font-family: STIXGeneral-Italic;">M<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.045em;"></span></span><span class="msubsup" id="MathJax-Span-177"><span style="display: inline-block; position: relative; width: 0.907em; height: 0px;"><span style="position: absolute; clip: rect(3.235em, 1000.56em, 4.14em, -999.998em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-178" style="font-family: STIXGeneral-Italic;">A</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.877em; left: 0.606em;"><span class="mi" id="MathJax-Span-179" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-180" style="font-family: STIXGeneral-Regular; padding-left: 0.304em;">=</span><span class="mi" id="MathJax-Span-181" style="font-family: STIXGeneral-Italic; padding-left: 0.304em;">E<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.045em;"></span></span><span class="mi" id="MathJax-Span-182" style="font-family: STIXGeneral-Italic;">M<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.045em;"></span></span><span class="msubsup" id="MathJax-Span-183"><span style="display: inline-block; position: relative; width: 0.907em; height: 0px;"><span style="position: absolute; clip: rect(3.235em, 1000.56em, 4.14em, -999.998em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-184" style="font-family: STIXGeneral-Italic;">A</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.877em; left: 0.606em;"><span class="mi" id="MathJax-Span-185" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.502em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.297em; border-left: 0px solid; width: 0px; height: 1.103em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>x</mi><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mo>+</mo><mn>2</mn></mrow></msub><mo>=</mo><mi></mi><mo></mo><mi>E</mi><mi>M</mi><msub><mi>A</mi><mi>t</mi></msub><mo>+</mo><mo stretchy="false">(</mo><mn>1</mn><mo></mo><mi></mi><mo stretchy="false">)</mo><mi>E</mi><mi>M</mi><msub><mi>A</mi><mi>t</mi></msub><mo>=</mo><mi>E</mi><mi>M</mi><msub><mi>A</mi><mi>t</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-24">x_{t+2} = \gamma \times EMA_t + (1-\gamma) EMA_t = EMA_t</script></li>
<li>Or in this example, X<sub>t+2</sub> = X<sub>t+1</sub> = 0.45</li>
</ul>
</li>
</ul>
<p>So no matter how many steps you predict in to the future, you'll keep getting the same answer for all the future prediction steps.</p>
<p>One solution you have that will output useful information is to look at <strong>momentum-based algorithms</strong>. They make predictions based on whether the past recent values were going up or going down (not the exact values). For example, they will say the next day price is likely to be lower, if the prices have been dropping for the past days, which sounds reasonable. However, you will use a more complex model: an LSTM model.</p>
<p>These models have taken the realm of time series prediction by storm, because they are so good at modelling time series data. You will see if there actually are patterns hidden in the data that you can exploit.</p>
<p><a id="lstm"></a></p>
<h2 id="introduction-to-lstms-making-stock-movement-predictions-far-into-the-future">Introduction to LSTMs: Making Stock Movement Predictions Far into the Future</h2>
<p>Long Short-Term Memory models are extremely powerful time-series models. They can predict an arbitrary number of steps into the future. An LSTM module (or cell) has 5 essential components which allows it to model both long-term and short-term data.</p>
<ul>
<li>Cell state (<span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-25-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-186" style="width: 0.864em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.735em; height: 0px; font-size: 116%;"><span style="position: absolute; clip: rect(1.683em, 1000.74em, 2.545em, -999.998em); top: -2.239em; left: 0em;"><span class="mrow" id="MathJax-Span-187"><span class="msubsup" id="MathJax-Span-188"><span style="display: inline-block; position: relative; width: 0.735em; height: 0px;"><span style="position: absolute; clip: rect(3.45em, 1000.43em, 4.14em, -999.998em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-189" style="font-family: STIXGeneral-Italic;">c</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.877em; left: 0.433em;"><span class="mi" id="MathJax-Span-190" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.244em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 0.802em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>c</mi><mi>t</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-25">c_t</script>) - This represents the internal memory of the cell which stores both short term memory and long-term memories</li>
<li>Hidden state (<span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-26-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;h&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-191" style="width: 0.907em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.778em; height: 0px; font-size: 116%;"><span style="position: absolute; clip: rect(1.425em, 1000.78em, 2.545em, -999.998em); top: -2.239em; left: 0em;"><span class="mrow" id="MathJax-Span-192"><span class="msubsup" id="MathJax-Span-193"><span style="display: inline-block; position: relative; width: 0.778em; height: 0px;"><span style="position: absolute; clip: rect(3.192em, 1000.48em, 4.14em, -999.998em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-194" style="font-family: STIXGeneral-Italic;">h</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.877em; left: 0.519em;"><span class="mi" id="MathJax-Span-195" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.244em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.103em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>h</mi><mi>t</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-26">h_t</script>) - This is output state information calculated w.r.t. current input, previous hidden state and current cell input which you eventually use to predict the future stock market prices. Additionally, the hidden state can decide to only retrive the short or long-term or both types of memory stored in the cell state to make the next prediction.</li>
<li>Input gate (<span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-27-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-196" style="width: 0.649em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.563em; height: 0px; font-size: 116%;"><span style="position: absolute; clip: rect(1.468em, 1000.56em, 2.545em, -999.998em); top: -2.239em; left: 0em;"><span class="mrow" id="MathJax-Span-197"><span class="msubsup" id="MathJax-Span-198"><span style="display: inline-block; position: relative; width: 0.563em; height: 0px;"><span style="position: absolute; clip: rect(3.235em, 1000.26em, 4.14em, -999.998em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-199" style="font-family: STIXGeneral-Italic;">i</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.877em; left: 0.261em;"><span class="mi" id="MathJax-Span-200" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.244em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.052em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>i</mi><mi>t</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-27">i_t</script>) - Decides how much information from current input flows to the cell state</li>
<li>Forget gate (<span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-28-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-201" style="width: 0.649em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.563em; height: 0px; font-size: 116%;"><span style="position: absolute; clip: rect(1.425em, 1000.56em, 2.588em, -999.998em); top: -2.239em; left: 0em;"><span class="mrow" id="MathJax-Span-202"><span class="msubsup" id="MathJax-Span-203"><span style="display: inline-block; position: relative; width: 0.563em; height: 0px;"><span style="position: absolute; clip: rect(3.192em, 1000.43em, 4.356em, -999.998em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-204" style="font-family: STIXGeneral-Italic;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.131em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.877em; left: 0.261em;"><span class="mi" id="MathJax-Span-205" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.244em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.297em; border-left: 0px solid; width: 0px; height: 1.153em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>f</mi><mi>t</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-28">f_t</script>) - Decides how much information from the current input and the previous cell state flows into the current cell state</li>
<li>Output gate (<span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-29-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-206" style="width: 0.907em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.778em; height: 0px; font-size: 116%;"><span style="position: absolute; clip: rect(1.683em, 1000.78em, 2.545em, -999.998em); top: -2.239em; left: 0em;"><span class="mrow" id="MathJax-Span-207"><span class="msubsup" id="MathJax-Span-208"><span style="display: inline-block; position: relative; width: 0.778em; height: 0px;"><span style="position: absolute; clip: rect(3.45em, 1000.48em, 4.14em, -999.998em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-209" style="font-family: STIXGeneral-Italic;">o</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.877em; left: 0.519em;"><span class="mi" id="MathJax-Span-210" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.244em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 0.802em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>o</mi><mi>t</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-29">o_t</script>) - Decides how much information from the current cell state flows into the hidden state, so that if needed LSTM can only pick the long-term memories or short-term memories and long-term memories</li>
</ul>
<p>A cell is pictured below.</p>
<p><img src="./LSTM in Python_ Stock Market Predictions (article) - DataCamp_files/lstm_xszk4d.png" alt="Drawing" style="width:400px;"></p>
<p>And the equations for calculating each of these entities are as follows.</p>
<ul>
<li>$i<em>t = \sigma(W</em>{ix}x<em>t + W</em>{ih}h_{t-1}+b_i)$</li>
<li>$\tilde{c}<em>t = \sigma(W</em>{cx}x<em>t + W</em>{ch}h_{t-1} + b_c)$</li>
<li>$f<em>t = \sigma(W</em>{fx}x<em>t + W</em>{fh}h_{t-1}+b_f)$</li>
<li>$c_t = f<em>t c</em>{t-1} + i_t \tilde{c}_t$</li>
<li>$o<em>t = \sigma(W</em>{ox}x<em>t + W</em>{oh}h_{t-1}+b_o)$</li>
<li><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-30-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;h&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;h&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-211" style="width: 7.028em; display: inline-block;"><span style="display: inline-block; position: relative; width: 6.037em; height: 0px; font-size: 116%;"><span style="position: absolute; clip: rect(1.683em, 1005.99em, 2.804em, -999.998em); top: -2.498em; left: 0em;"><span class="mrow" id="MathJax-Span-212"><span class="msubsup" id="MathJax-Span-213"><span style="display: inline-block; position: relative; width: 0.778em; height: 0px;"><span style="position: absolute; clip: rect(3.192em, 1000.48em, 4.14em, -999.998em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-214" style="font-family: STIXGeneral-Italic;">h</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.877em; left: 0.519em;"><span class="mi" id="MathJax-Span-215" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-216" style="font-family: STIXGeneral-Regular; padding-left: 0.304em;">=</span><span class="msubsup" id="MathJax-Span-217" style="padding-left: 0.304em;"><span style="display: inline-block; position: relative; width: 0.778em; height: 0px;"><span style="position: absolute; clip: rect(3.45em, 1000.48em, 4.14em, -999.998em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-218" style="font-family: STIXGeneral-Italic;">o</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.877em; left: 0.519em;"><span class="mi" id="MathJax-Span-219" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mi" id="MathJax-Span-220" style="font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span class="mi" id="MathJax-Span-221" style="font-family: STIXGeneral-Italic;">a</span><span class="mi" id="MathJax-Span-222" style="font-family: STIXGeneral-Italic;">n</span><span class="mi" id="MathJax-Span-223" style="font-family: STIXGeneral-Italic;">h</span><span class="mo" id="MathJax-Span-224" style="font-family: STIXGeneral-Regular;">(</span><span class="msubsup" id="MathJax-Span-225"><span style="display: inline-block; position: relative; width: 0.735em; height: 0px;"><span style="position: absolute; clip: rect(3.45em, 1000.43em, 4.14em, -999.998em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-226" style="font-family: STIXGeneral-Italic;">c</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.877em; left: 0.433em;"><span class="mi" id="MathJax-Span-227" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-228" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.502em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.103em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>h</mi><mi>t</mi></msub><mo>=</mo><msub><mi>o</mi><mi>t</mi></msub><mi>t</mi><mi>a</mi><mi>n</mi><mi>h</mi><mo stretchy="false">(</mo><msub><mi>c</mi><mi>t</mi></msub><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-30">h_t = o_t tanh(c_t)</script></li>
</ul>
<p>For a better (more technical) understanding about LSTMs you can refer to <a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/">this article</a>.</p>
<p>TensorFlow provides a nice sub API (called RNN API) for implementing time series models. You will be using that for your implementations.</p>
<h3 id="data-generator">Data Generator</h3>
<p>You are first going to implement a data generator to train your model. This data generator will have a method called <code>.unroll_batches(...)</code> which will output a set of <em>num_unrollings</em> batches of input data obtained sequentially, where a batch of data is of size <code>[batch_size, 1]</code>. Then each batch of input data will have a corresponding output batch of data.</p>
<p>For example if <code>num_unrollings=3</code> and <code>batch_size=4</code> a set of unrolled batches it might look like,</p>
<ul>
<li>input data: <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-31-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;[&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;/msub&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo stretchy=&quot;false&quot;&gt;]&lt;/mo&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;[&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;/msub&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo stretchy=&quot;false&quot;&gt;]&lt;/mo&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;[&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;/msub&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mo stretchy=&quot;false&quot;&gt;]&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-229" style="width: 24.959em; display: inline-block;"><span style="display: inline-block; position: relative; width: 21.511em; height: 0px; font-size: 116%;"><span style="position: absolute; clip: rect(1.683em, 1021.42em, 2.804em, -999.998em); top: -2.498em; left: 0em;"><span class="mrow" id="MathJax-Span-230"><span class="mo" id="MathJax-Span-231" style="font-family: STIXGeneral-Regular;">[</span><span class="msubsup" id="MathJax-Span-232"><span style="display: inline-block; position: relative; width: 0.864em; height: 0px;"><span style="position: absolute; clip: rect(3.45em, 1000.43em, 4.14em, -999.998em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-233" style="font-family: STIXGeneral-Italic;">x<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.877em; left: 0.433em;"><span class="mn" id="MathJax-Span-234" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">0</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-235" style="font-family: STIXGeneral-Regular;">,</span><span class="msubsup" id="MathJax-Span-236" style="padding-left: 0.175em;"><span style="display: inline-block; position: relative; width: 0.864em; height: 0px;"><span style="position: absolute; clip: rect(3.45em, 1000.43em, 4.14em, -999.998em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-237" style="font-family: STIXGeneral-Italic;">x<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.877em; left: 0.433em;"><span class="mn" id="MathJax-Span-238" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mn" id="MathJax-Span-239" style="font-family: STIXGeneral-Regular;">0</span><span class="mo" id="MathJax-Span-240" style="font-family: STIXGeneral-Regular;">,</span><span class="msubsup" id="MathJax-Span-241" style="padding-left: 0.175em;"><span style="display: inline-block; position: relative; width: 0.864em; height: 0px;"><span style="position: absolute; clip: rect(3.45em, 1000.43em, 4.14em, -999.998em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-242" style="font-family: STIXGeneral-Italic;">x<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.877em; left: 0.433em;"><span class="mn" id="MathJax-Span-243" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mn" id="MathJax-Span-244" style="font-family: STIXGeneral-Regular;">0</span><span class="mo" id="MathJax-Span-245" style="font-family: STIXGeneral-Regular;">,</span><span class="msubsup" id="MathJax-Span-246" style="padding-left: 0.175em;"><span style="display: inline-block; position: relative; width: 0.864em; height: 0px;"><span style="position: absolute; clip: rect(3.45em, 1000.43em, 4.14em, -999.998em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-247" style="font-family: STIXGeneral-Italic;">x<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.877em; left: 0.433em;"><span class="mn" id="MathJax-Span-248" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">3</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mn" id="MathJax-Span-249" style="font-family: STIXGeneral-Regular;">0</span><span class="mo" id="MathJax-Span-250" style="font-family: STIXGeneral-Regular;">]</span><span class="mo" id="MathJax-Span-251" style="font-family: STIXGeneral-Regular;">,</span><span class="mo" id="MathJax-Span-252" style="font-family: STIXGeneral-Regular; padding-left: 0.175em;">[</span><span class="msubsup" id="MathJax-Span-253"><span style="display: inline-block; position: relative; width: 0.864em; height: 0px;"><span style="position: absolute; clip: rect(3.45em, 1000.43em, 4.14em, -999.998em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-254" style="font-family: STIXGeneral-Italic;">x<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.877em; left: 0.433em;"><span class="mn" id="MathJax-Span-255" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-256" style="font-family: STIXGeneral-Regular;">,</span><span class="msubsup" id="MathJax-Span-257" style="padding-left: 0.175em;"><span style="display: inline-block; position: relative; width: 0.864em; height: 0px;"><span style="position: absolute; clip: rect(3.45em, 1000.43em, 4.14em, -999.998em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-258" style="font-family: STIXGeneral-Italic;">x<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.877em; left: 0.433em;"><span class="mn" id="MathJax-Span-259" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mn" id="MathJax-Span-260" style="font-family: STIXGeneral-Regular;">1</span><span class="mo" id="MathJax-Span-261" style="font-family: STIXGeneral-Regular;">,</span><span class="msubsup" id="MathJax-Span-262" style="padding-left: 0.175em;"><span style="display: inline-block; position: relative; width: 0.864em; height: 0px;"><span style="position: absolute; clip: rect(3.45em, 1000.43em, 4.14em, -999.998em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-263" style="font-family: STIXGeneral-Italic;">x<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.877em; left: 0.433em;"><span class="mn" id="MathJax-Span-264" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mn" id="MathJax-Span-265" style="font-family: STIXGeneral-Regular;">1</span><span class="mo" id="MathJax-Span-266" style="font-family: STIXGeneral-Regular;">,</span><span class="msubsup" id="MathJax-Span-267" style="padding-left: 0.175em;"><span style="display: inline-block; position: relative; width: 0.864em; height: 0px;"><span style="position: absolute; clip: rect(3.45em, 1000.43em, 4.14em, -999.998em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-268" style="font-family: STIXGeneral-Italic;">x<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.877em; left: 0.433em;"><span class="mn" id="MathJax-Span-269" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">3</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mn" id="MathJax-Span-270" style="font-family: STIXGeneral-Regular;">1</span><span class="mo" id="MathJax-Span-271" style="font-family: STIXGeneral-Regular;">]</span><span class="mo" id="MathJax-Span-272" style="font-family: STIXGeneral-Regular;">,</span><span class="mo" id="MathJax-Span-273" style="font-family: STIXGeneral-Regular; padding-left: 0.175em;">[</span><span class="msubsup" id="MathJax-Span-274"><span style="display: inline-block; position: relative; width: 0.864em; height: 0px;"><span style="position: absolute; clip: rect(3.45em, 1000.43em, 4.14em, -999.998em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-275" style="font-family: STIXGeneral-Italic;">x<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.877em; left: 0.433em;"><span class="mn" id="MathJax-Span-276" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-277" style="font-family: STIXGeneral-Regular;">,</span><span class="msubsup" id="MathJax-Span-278" style="padding-left: 0.175em;"><span style="display: inline-block; position: relative; width: 0.864em; height: 0px;"><span style="position: absolute; clip: rect(3.45em, 1000.43em, 4.14em, -999.998em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-279" style="font-family: STIXGeneral-Italic;">x<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.877em; left: 0.433em;"><span class="mn" id="MathJax-Span-280" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mn" id="MathJax-Span-281" style="font-family: STIXGeneral-Regular;">2</span><span class="mo" id="MathJax-Span-282" style="font-family: STIXGeneral-Regular;">,</span><span class="msubsup" id="MathJax-Span-283" style="padding-left: 0.175em;"><span style="display: inline-block; position: relative; width: 0.864em; height: 0px;"><span style="position: absolute; clip: rect(3.45em, 1000.43em, 4.14em, -999.998em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-284" style="font-family: STIXGeneral-Italic;">x<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.877em; left: 0.433em;"><span class="mn" id="MathJax-Span-285" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mn" id="MathJax-Span-286" style="font-family: STIXGeneral-Regular;">2</span><span class="mo" id="MathJax-Span-287" style="font-family: STIXGeneral-Regular;">,</span><span class="msubsup" id="MathJax-Span-288" style="padding-left: 0.175em;"><span style="display: inline-block; position: relative; width: 0.864em; height: 0px;"><span style="position: absolute; clip: rect(3.45em, 1000.43em, 4.14em, -999.998em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-289" style="font-family: STIXGeneral-Italic;">x<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.877em; left: 0.433em;"><span class="mn" id="MathJax-Span-290" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">3</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mn" id="MathJax-Span-291" style="font-family: STIXGeneral-Regular;">2</span><span class="mo" id="MathJax-Span-292" style="font-family: STIXGeneral-Regular;">]</span></span><span style="display: inline-block; width: 0px; height: 2.502em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.052em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">[</mo><msub><mi>x</mi><mn>0</mn></msub><mo>,</mo><msub><mi>x</mi><mn>1</mn></msub><mn>0</mn><mo>,</mo><msub><mi>x</mi><mn>2</mn></msub><mn>0</mn><mo>,</mo><msub><mi>x</mi><mn>3</mn></msub><mn>0</mn><mo stretchy="false">]</mo><mo>,</mo><mo stretchy="false">[</mo><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><msub><mi>x</mi><mn>1</mn></msub><mn>1</mn><mo>,</mo><msub><mi>x</mi><mn>2</mn></msub><mn>1</mn><mo>,</mo><msub><mi>x</mi><mn>3</mn></msub><mn>1</mn><mo stretchy="false">]</mo><mo>,</mo><mo stretchy="false">[</mo><msub><mi>x</mi><mn>2</mn></msub><mo>,</mo><msub><mi>x</mi><mn>1</mn></msub><mn>2</mn><mo>,</mo><msub><mi>x</mi><mn>2</mn></msub><mn>2</mn><mo>,</mo><msub><mi>x</mi><mn>3</mn></msub><mn>2</mn><mo stretchy="false">]</mo></math></span></span><script type="math/tex" id="MathJax-Element-31">[x_0,x_10,x_20,x_30], [x_1,x_11,x_21,x_31], [x_2,x_12,x_22,x_32]</script></li>
<li>output data: <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-32-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;[&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;/msub&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo stretchy=&quot;false&quot;&gt;]&lt;/mo&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;[&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;/msub&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mo stretchy=&quot;false&quot;&gt;]&lt;/mo&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;[&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;/msub&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;mo stretchy=&quot;false&quot;&gt;]&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-293" style="width: 24.959em; display: inline-block;"><span style="display: inline-block; position: relative; width: 21.511em; height: 0px; font-size: 116%;"><span style="position: absolute; clip: rect(1.683em, 1021.42em, 2.804em, -999.998em); top: -2.498em; left: 0em;"><span class="mrow" id="MathJax-Span-294"><span class="mo" id="MathJax-Span-295" style="font-family: STIXGeneral-Regular;">[</span><span class="msubsup" id="MathJax-Span-296"><span style="display: inline-block; position: relative; width: 0.864em; height: 0px;"><span style="position: absolute; clip: rect(3.45em, 1000.43em, 4.14em, -999.998em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-297" style="font-family: STIXGeneral-Italic;">x<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.877em; left: 0.433em;"><span class="mn" id="MathJax-Span-298" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-299" style="font-family: STIXGeneral-Regular;">,</span><span class="msubsup" id="MathJax-Span-300" style="padding-left: 0.175em;"><span style="display: inline-block; position: relative; width: 0.864em; height: 0px;"><span style="position: absolute; clip: rect(3.45em, 1000.43em, 4.14em, -999.998em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-301" style="font-family: STIXGeneral-Italic;">x<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.877em; left: 0.433em;"><span class="mn" id="MathJax-Span-302" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mn" id="MathJax-Span-303" style="font-family: STIXGeneral-Regular;">1</span><span class="mo" id="MathJax-Span-304" style="font-family: STIXGeneral-Regular;">,</span><span class="msubsup" id="MathJax-Span-305" style="padding-left: 0.175em;"><span style="display: inline-block; position: relative; width: 0.864em; height: 0px;"><span style="position: absolute; clip: rect(3.45em, 1000.43em, 4.14em, -999.998em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-306" style="font-family: STIXGeneral-Italic;">x<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.877em; left: 0.433em;"><span class="mn" id="MathJax-Span-307" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mn" id="MathJax-Span-308" style="font-family: STIXGeneral-Regular;">1</span><span class="mo" id="MathJax-Span-309" style="font-family: STIXGeneral-Regular;">,</span><span class="msubsup" id="MathJax-Span-310" style="padding-left: 0.175em;"><span style="display: inline-block; position: relative; width: 0.864em; height: 0px;"><span style="position: absolute; clip: rect(3.45em, 1000.43em, 4.14em, -999.998em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-311" style="font-family: STIXGeneral-Italic;">x<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.877em; left: 0.433em;"><span class="mn" id="MathJax-Span-312" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">3</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mn" id="MathJax-Span-313" style="font-family: STIXGeneral-Regular;">1</span><span class="mo" id="MathJax-Span-314" style="font-family: STIXGeneral-Regular;">]</span><span class="mo" id="MathJax-Span-315" style="font-family: STIXGeneral-Regular;">,</span><span class="mo" id="MathJax-Span-316" style="font-family: STIXGeneral-Regular; padding-left: 0.175em;">[</span><span class="msubsup" id="MathJax-Span-317"><span style="display: inline-block; position: relative; width: 0.864em; height: 0px;"><span style="position: absolute; clip: rect(3.45em, 1000.43em, 4.14em, -999.998em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-318" style="font-family: STIXGeneral-Italic;">x<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.877em; left: 0.433em;"><span class="mn" id="MathJax-Span-319" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-320" style="font-family: STIXGeneral-Regular;">,</span><span class="msubsup" id="MathJax-Span-321" style="padding-left: 0.175em;"><span style="display: inline-block; position: relative; width: 0.864em; height: 0px;"><span style="position: absolute; clip: rect(3.45em, 1000.43em, 4.14em, -999.998em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-322" style="font-family: STIXGeneral-Italic;">x<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.877em; left: 0.433em;"><span class="mn" id="MathJax-Span-323" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mn" id="MathJax-Span-324" style="font-family: STIXGeneral-Regular;">2</span><span class="mo" id="MathJax-Span-325" style="font-family: STIXGeneral-Regular;">,</span><span class="msubsup" id="MathJax-Span-326" style="padding-left: 0.175em;"><span style="display: inline-block; position: relative; width: 0.864em; height: 0px;"><span style="position: absolute; clip: rect(3.45em, 1000.43em, 4.14em, -999.998em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-327" style="font-family: STIXGeneral-Italic;">x<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.877em; left: 0.433em;"><span class="mn" id="MathJax-Span-328" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mn" id="MathJax-Span-329" style="font-family: STIXGeneral-Regular;">2</span><span class="mo" id="MathJax-Span-330" style="font-family: STIXGeneral-Regular;">,</span><span class="msubsup" id="MathJax-Span-331" style="padding-left: 0.175em;"><span style="display: inline-block; position: relative; width: 0.864em; height: 0px;"><span style="position: absolute; clip: rect(3.45em, 1000.43em, 4.14em, -999.998em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-332" style="font-family: STIXGeneral-Italic;">x<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.877em; left: 0.433em;"><span class="mn" id="MathJax-Span-333" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">3</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mn" id="MathJax-Span-334" style="font-family: STIXGeneral-Regular;">2</span><span class="mo" id="MathJax-Span-335" style="font-family: STIXGeneral-Regular;">]</span><span class="mo" id="MathJax-Span-336" style="font-family: STIXGeneral-Regular;">,</span><span class="mo" id="MathJax-Span-337" style="font-family: STIXGeneral-Regular; padding-left: 0.175em;">[</span><span class="msubsup" id="MathJax-Span-338"><span style="display: inline-block; position: relative; width: 0.864em; height: 0px;"><span style="position: absolute; clip: rect(3.45em, 1000.43em, 4.14em, -999.998em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-339" style="font-family: STIXGeneral-Italic;">x<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.877em; left: 0.433em;"><span class="mn" id="MathJax-Span-340" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">3</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mo" id="MathJax-Span-341" style="font-family: STIXGeneral-Regular;">,</span><span class="msubsup" id="MathJax-Span-342" style="padding-left: 0.175em;"><span style="display: inline-block; position: relative; width: 0.864em; height: 0px;"><span style="position: absolute; clip: rect(3.45em, 1000.43em, 4.14em, -999.998em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-343" style="font-family: STIXGeneral-Italic;">x<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.877em; left: 0.433em;"><span class="mn" id="MathJax-Span-344" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mn" id="MathJax-Span-345" style="font-family: STIXGeneral-Regular;">3</span><span class="mo" id="MathJax-Span-346" style="font-family: STIXGeneral-Regular;">,</span><span class="msubsup" id="MathJax-Span-347" style="padding-left: 0.175em;"><span style="display: inline-block; position: relative; width: 0.864em; height: 0px;"><span style="position: absolute; clip: rect(3.45em, 1000.43em, 4.14em, -999.998em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-348" style="font-family: STIXGeneral-Italic;">x<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.877em; left: 0.433em;"><span class="mn" id="MathJax-Span-349" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mn" id="MathJax-Span-350" style="font-family: STIXGeneral-Regular;">3</span><span class="mo" id="MathJax-Span-351" style="font-family: STIXGeneral-Regular;">,</span><span class="msubsup" id="MathJax-Span-352" style="padding-left: 0.175em;"><span style="display: inline-block; position: relative; width: 0.864em; height: 0px;"><span style="position: absolute; clip: rect(3.45em, 1000.43em, 4.14em, -999.998em); top: -4.006em; left: 0em;"><span class="mi" id="MathJax-Span-353" style="font-family: STIXGeneral-Italic;">x<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span><span style="position: absolute; top: -3.877em; left: 0.433em;"><span class="mn" id="MathJax-Span-354" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">3</span><span style="display: inline-block; width: 0px; height: 4.011em;"></span></span></span></span><span class="mn" id="MathJax-Span-355" style="font-family: STIXGeneral-Regular;">3</span><span class="mo" id="MathJax-Span-356" style="font-family: STIXGeneral-Regular;">]</span></span><span style="display: inline-block; width: 0px; height: 2.502em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.052em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">[</mo><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><msub><mi>x</mi><mn>1</mn></msub><mn>1</mn><mo>,</mo><msub><mi>x</mi><mn>2</mn></msub><mn>1</mn><mo>,</mo><msub><mi>x</mi><mn>3</mn></msub><mn>1</mn><mo stretchy="false">]</mo><mo>,</mo><mo stretchy="false">[</mo><msub><mi>x</mi><mn>2</mn></msub><mo>,</mo><msub><mi>x</mi><mn>1</mn></msub><mn>2</mn><mo>,</mo><msub><mi>x</mi><mn>2</mn></msub><mn>2</mn><mo>,</mo><msub><mi>x</mi><mn>3</mn></msub><mn>2</mn><mo stretchy="false">]</mo><mo>,</mo><mo stretchy="false">[</mo><msub><mi>x</mi><mn>3</mn></msub><mo>,</mo><msub><mi>x</mi><mn>1</mn></msub><mn>3</mn><mo>,</mo><msub><mi>x</mi><mn>2</mn></msub><mn>3</mn><mo>,</mo><msub><mi>x</mi><mn>3</mn></msub><mn>3</mn><mo stretchy="false">]</mo></math></span></span><script type="math/tex" id="MathJax-Element-32">[x_1,x_11,x_21,x_31], [x_2,x_12,x_22,x_32], [x_3,x_13,x_23,x_33]</script></li>
</ul>
<h4 id="data-augmentation">Data Augmentation</h4>
<p>Also to make your model robust you will not make the output for $x<em>t<span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-33-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;w&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-357" style="width: 3.235em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.761em; height: 0px; font-size: 116%;"><span style="position: absolute; clip: rect(1.683em, 1002.72em, 2.847em, -999.998em); top: -2.498em; left: 0em;"><span class="mrow" id="MathJax-Span-358"><span class="mi" id="MathJax-Span-359" style="font-family: STIXGeneral-Italic;">a</span><span class="mi" id="MathJax-Span-360" style="font-family: STIXGeneral-Italic;">l<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span class="mi" id="MathJax-Span-361" style="font-family: STIXGeneral-Italic;">w</span><span class="mi" id="MathJax-Span-362" style="font-family: STIXGeneral-Italic;">a</span><span class="mi" id="MathJax-Span-363" style="font-family: STIXGeneral-Italic;">y</span><span class="mi" id="MathJax-Span-364" style="font-family: STIXGeneral-Italic;">s</span></span><span style="display: inline-block; width: 0px; height: 2.502em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.297em; border-left: 0px solid; width: 0px; height: 1.153em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>a</mi><mi>l</mi><mi>w</mi><mi>a</mi><mi>y</mi><mi>s</mi></math></span></span><script type="math/tex" id="MathJax-Element-33"> always </script>x</em>{t+1}<span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-34-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mo&gt;.&lt;/mo&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;h&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;u&lt;/mi&gt;&lt;mi&gt;w&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;u&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;u&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;h&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-365" style="width: 24.226em; display: inline-block;"><span style="display: inline-block; position: relative; width: 20.864em; height: 0px; font-size: 116%;"><span style="position: absolute; clip: rect(1.683em, 1020.86em, 2.847em, -999.998em); top: -2.498em; left: 0em;"><span class="mrow" id="MathJax-Span-366"><span class="mo" id="MathJax-Span-367" style="font-family: STIXGeneral-Regular;">.</span><span class="mi" id="MathJax-Span-368" style="font-family: STIXGeneral-Italic; padding-left: 0.175em;">R</span><span class="mi" id="MathJax-Span-369" style="font-family: STIXGeneral-Italic;">a</span><span class="mi" id="MathJax-Span-370" style="font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span class="mi" id="MathJax-Span-371" style="font-family: STIXGeneral-Italic;">h</span><span class="mi" id="MathJax-Span-372" style="font-family: STIXGeneral-Italic;">e</span><span class="mi" id="MathJax-Span-373" style="font-family: STIXGeneral-Italic;">r<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.045em;"></span></span><span class="mi" id="MathJax-Span-374" style="font-family: STIXGeneral-Italic;">y</span><span class="mi" id="MathJax-Span-375" style="font-family: STIXGeneral-Italic;">o</span><span class="mi" id="MathJax-Span-376" style="font-family: STIXGeneral-Italic;">u</span><span class="mi" id="MathJax-Span-377" style="font-family: STIXGeneral-Italic;">w</span><span class="mi" id="MathJax-Span-378" style="font-family: STIXGeneral-Italic;">i</span><span class="mi" id="MathJax-Span-379" style="font-family: STIXGeneral-Italic;">l<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span class="mi" id="MathJax-Span-380" style="font-family: STIXGeneral-Italic;">l<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span class="mi" id="MathJax-Span-381" style="font-family: STIXGeneral-Italic;">r<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.045em;"></span></span><span class="mi" id="MathJax-Span-382" style="font-family: STIXGeneral-Italic;">a</span><span class="mi" id="MathJax-Span-383" style="font-family: STIXGeneral-Italic;">n</span><span class="mi" id="MathJax-Span-384" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.045em;"></span></span><span class="mi" id="MathJax-Span-385" style="font-family: STIXGeneral-Italic;">o</span><span class="mi" id="MathJax-Span-386" style="font-family: STIXGeneral-Italic;">m</span><span class="mi" id="MathJax-Span-387" style="font-family: STIXGeneral-Italic;">l<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span class="mi" id="MathJax-Span-388" style="font-family: STIXGeneral-Italic;">y</span><span class="mi" id="MathJax-Span-389" style="font-family: STIXGeneral-Italic;">s</span><span class="mi" id="MathJax-Span-390" style="font-family: STIXGeneral-Italic;">a</span><span class="mi" id="MathJax-Span-391" style="font-family: STIXGeneral-Italic;">m</span><span class="mi" id="MathJax-Span-392" style="font-family: STIXGeneral-Italic;">p</span><span class="mi" id="MathJax-Span-393" style="font-family: STIXGeneral-Italic;">l<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span class="mi" id="MathJax-Span-394" style="font-family: STIXGeneral-Italic;">e</span><span class="mi" id="MathJax-Span-395" style="font-family: STIXGeneral-Italic;">a</span><span class="mi" id="MathJax-Span-396" style="font-family: STIXGeneral-Italic;">n</span><span class="mi" id="MathJax-Span-397" style="font-family: STIXGeneral-Italic;">o</span><span class="mi" id="MathJax-Span-398" style="font-family: STIXGeneral-Italic;">u</span><span class="mi" id="MathJax-Span-399" style="font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span class="mi" id="MathJax-Span-400" style="font-family: STIXGeneral-Italic;">p</span><span class="mi" id="MathJax-Span-401" style="font-family: STIXGeneral-Italic;">u</span><span class="mi" id="MathJax-Span-402" style="font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span class="mi" id="MathJax-Span-403" style="font-family: STIXGeneral-Italic;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.131em;"></span></span><span class="mi" id="MathJax-Span-404" style="font-family: STIXGeneral-Italic;">r<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.045em;"></span></span><span class="mi" id="MathJax-Span-405" style="font-family: STIXGeneral-Italic;">o</span><span class="mi" id="MathJax-Span-406" style="font-family: STIXGeneral-Italic;">m</span><span class="mi" id="MathJax-Span-407" style="font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span class="mi" id="MathJax-Span-408" style="font-family: STIXGeneral-Italic;">h</span><span class="mi" id="MathJax-Span-409" style="font-family: STIXGeneral-Italic;">e</span><span class="mi" id="MathJax-Span-410" style="font-family: STIXGeneral-Italic;">s</span><span class="mi" id="MathJax-Span-411" style="font-family: STIXGeneral-Italic;">e</span><span class="mi" id="MathJax-Span-412" style="font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.502em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.297em; border-left: 0px solid; width: 0px; height: 1.153em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>.</mo><mi>R</mi><mi>a</mi><mi>t</mi><mi>h</mi><mi>e</mi><mi>r</mi><mi>y</mi><mi>o</mi><mi>u</mi><mi>w</mi><mi>i</mi><mi>l</mi><mi>l</mi><mi>r</mi><mi>a</mi><mi>n</mi><mi>d</mi><mi>o</mi><mi>m</mi><mi>l</mi><mi>y</mi><mi>s</mi><mi>a</mi><mi>m</mi><mi>p</mi><mi>l</mi><mi>e</mi><mi>a</mi><mi>n</mi><mi>o</mi><mi>u</mi><mi>t</mi><mi>p</mi><mi>u</mi><mi>t</mi><mi>f</mi><mi>r</mi><mi>o</mi><mi>m</mi><mi>t</mi><mi>h</mi><mi>e</mi><mi>s</mi><mi>e</mi><mi>t</mi></math></span></span><script type="math/tex" id="MathJax-Element-34">. Rather you will randomly sample an output from the set </script>x<em>{t+1},x</em>{t+2},\ldots,x_{t+N}<span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-35-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;w&lt;/mi&gt;&lt;mi&gt;h&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-413" style="width: 2.933em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.502em; height: 0px; font-size: 116%;"><span style="position: absolute; clip: rect(1.683em, 1002.46em, 2.631em, -999.998em); top: -2.498em; left: 0em;"><span class="mrow" id="MathJax-Span-414"><span class="mi" id="MathJax-Span-415" style="font-family: STIXGeneral-Italic;">w</span><span class="mi" id="MathJax-Span-416" style="font-family: STIXGeneral-Italic;">h</span><span class="mi" id="MathJax-Span-417" style="font-family: STIXGeneral-Italic;">e</span><span class="mi" id="MathJax-Span-418" style="font-family: STIXGeneral-Italic;">r<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.045em;"></span></span><span class="mi" id="MathJax-Span-419" style="font-family: STIXGeneral-Italic;">e</span></span><span style="display: inline-block; width: 0px; height: 2.502em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.048em; border-left: 0px solid; width: 0px; height: 0.903em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>w</mi><mi>h</mi><mi>e</mi><mi>r</mi><mi>e</mi></math></span></span><script type="math/tex" id="MathJax-Element-35"> where </script>N$ is a small window size.</p>
<p>Here you are making the following assumption:</p>
<ul>
<li>$x<em>{t+1},x</em>{t+2},\ldots,x_{t+N}$ will not be very far from each other</li>
</ul>
<p>I personally think this is a reasonable assumption for stock movement predictions.</p>
<p>Below you illustrate how a batch of data is created visually.</p>
<p><img src="./LSTM in Python_ Stock Market Predictions (article) - DataCamp_files/batch_pno02e.png" alt="Drawing" style="width:600px;"></p>
<pre><code class="lang-python hljs">
<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">DataGeneratorSeq</span><span class="hljs-params">(object)</span>:</span>

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self,prices,batch_size,num_unroll)</span>:</span>
        self._prices = prices
        self._prices_length = len(self._prices) - num_unroll
        self._batch_size = batch_size
        self._num_unroll = num_unroll
        self._segments = self._prices_length //self._batch_size
        self._cursor = [offset * self._segments <span class="hljs-keyword">for</span> offset <span class="hljs-keyword">in</span> range(self._batch_size)]

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">next_batch</span><span class="hljs-params">(self)</span>:</span>

        batch_data = np.zeros((self._batch_size),dtype=np.float32)
        batch_labels = np.zeros((self._batch_size),dtype=np.float32)

        <span class="hljs-keyword">for</span> b <span class="hljs-keyword">in</span> range(self._batch_size):
            <span class="hljs-keyword">if</span> self._cursor[b]+<span class="hljs-number">1</span>&gt;=self._prices_length:
                <span class="hljs-comment">#self._cursor[b] = b * self._segments</span>
                self._cursor[b] = np.random.randint(<span class="hljs-number">0</span>,(b+<span class="hljs-number">1</span>)*self._segments)

            batch_data[b] = self._prices[self._cursor[b]]
            batch_labels[b]= self._prices[self._cursor[b]+np.random.randint(<span class="hljs-number">0</span>,<span class="hljs-number">5</span>)]

            self._cursor[b] = (self._cursor[b]+<span class="hljs-number">1</span>)%self._prices_length

        <span class="hljs-keyword">return</span> batch_data,batch_labels

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">unroll_batches</span><span class="hljs-params">(self)</span>:</span>

        unroll_data,unroll_labels = [],[]
        init_data, init_label = <span class="hljs-keyword">None</span>,<span class="hljs-keyword">None</span>
        <span class="hljs-keyword">for</span> ui <span class="hljs-keyword">in</span> range(self._num_unroll):

            data, labels = self.next_batch()    

            unroll_data.append(data)
            unroll_labels.append(labels)

        <span class="hljs-keyword">return</span> unroll_data, unroll_labels

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">reset_indices</span><span class="hljs-params">(self)</span>:</span>
        <span class="hljs-keyword">for</span> b <span class="hljs-keyword">in</span> range(self._batch_size):
            self._cursor[b] = np.random.randint(<span class="hljs-number">0</span>,min((b+<span class="hljs-number">1</span>)*self._segments,self._prices_length<span class="hljs-number">-1</span>))



dg = DataGeneratorSeq(train_data,<span class="hljs-number">5</span>,<span class="hljs-number">5</span>)
u_data, u_labels = dg.unroll_batches()

<span class="hljs-keyword">for</span> ui,(dat,lbl) <span class="hljs-keyword">in</span> enumerate(zip(u_data,u_labels)):   
    print(<span class="hljs-string">'\n\nUnrolled index %d'</span>%ui)
    dat_ind = dat
    lbl_ind = lbl
    print(<span class="hljs-string">'\tInputs: '</span>,dat )
    print(<span class="hljs-string">'\n\tOutput:'</span>,lbl)
</code></pre>
<pre><code>Unrolled index 0
    Inputs:  [0.03143791 0.6904868  0.82829314 0.32585657 0.11600105]

    Output: [0.08698314 0.68685144 0.8329321  0.33355275 0.11785509]


Unrolled index 1
    Inputs:  [0.06067836 0.6890754  0.8325337  0.32857886 0.11785509]

    Output: [0.15261841 0.68685144 0.8325337  0.33421066 0.12106793]


Unrolled index 2
    Inputs:  [0.08698314 0.68685144 0.8329321  0.33078218 0.11946969]

    Output: [0.11098009 0.6848606  0.83387965 0.33421066 0.12106793]


Unrolled index 3
    Inputs:  [0.11098009 0.6858036  0.83294916 0.33219692 0.12106793]

    Output: [0.132895   0.6836884  0.83294916 0.33219692 0.12288672]


Unrolled index 4
    Inputs:  [0.132895   0.6848606  0.833369   0.33355275 0.12158521]

    Output: [0.15261841 0.6836884  0.83383167 0.33355275 0.12230608]
</code></pre><h3 id="defining-hyperparameters">Defining Hyperparameters</h3>
<p>In this section, you'll define several hyperparameters. <code>D</code> is the dimensionality of the input. It's straightforward, as you take the previous stock price as the input and predict the next one, which should be <code>1</code>.</p>
<p>Then you have <code>num_unrollings</code>, this is a hyperparameter related to the backpropagation through time (BPTT) that is used to optimize the LSTM model. This denotes how many continuous time steps you consider for a single optimization step. You can think of this as, instead of optimizing the model by looking at a single time step, you optimize the network by looking at <code>num_unrollings</code> time steps. The larger the better.</p>
<p>Then you have the <code>batch_size</code>. Batch size is how many data samples you consider in a single time step.</p>
<p>Next you define <code>num_nodes</code> which represents the number of hidden neurons in each cell. You can see that there are three layers of LSTMs in this example.</p>
<pre><code class="lang-python hljs">D = <span class="hljs-number">1</span> <span class="hljs-comment"># Dimensionality of the data. Since your data is 1-D this would be 1</span>
num_unrollings = <span class="hljs-number">50</span> <span class="hljs-comment"># Number of time steps you look into the future.</span>
batch_size = <span class="hljs-number">500</span> <span class="hljs-comment"># Number of samples in a batch</span>
num_nodes = [<span class="hljs-number">200</span>,<span class="hljs-number">200</span>,<span class="hljs-number">150</span>] <span class="hljs-comment"># Number of hidden nodes in each layer of the deep LSTM stack we're using</span>
n_layers = len(num_nodes) <span class="hljs-comment"># number of layers</span>
dropout = <span class="hljs-number">0.2</span> <span class="hljs-comment"># dropout amount</span>

tf.reset_default_graph() <span class="hljs-comment"># This is important in case you run this multiple times</span>
</code></pre>
<h3 id="defining-inputs-and-outputs">Defining Inputs and Outputs</h3>
<p>Next you define placeholders for training inputs and labels. This is very straightforward as you have a list of input placeholders, where each placeholder contains a single batch of data. And the list has <code>num_unrollings</code> placeholders, that will be used at once for a single optimization step.</p>
<pre><code class="lang-python hljs"><span class="hljs-comment"># Input data.</span>
train_inputs, train_outputs = [],[]

<span class="hljs-comment"># You unroll the input over time defining placeholders for each time step</span>
<span class="hljs-keyword">for</span> ui <span class="hljs-keyword">in</span> range(num_unrollings):
    train_inputs.append(tf.placeholder(tf.float32, shape=[batch_size,D],name=<span class="hljs-string">'train_inputs_%d'</span>%ui))
    train_outputs.append(tf.placeholder(tf.float32, shape=[batch_size,<span class="hljs-number">1</span>], name = <span class="hljs-string">'train_outputs_%d'</span>%ui))
</code></pre>
<h3 id="defining-parameters-of-the-lstm-and-regression-layer">Defining Parameters of the LSTM and Regression layer</h3>
<p>You will have a three layers of LSTMs and a linear regression layer, denoted by <code>w</code> and <code>b</code>, that takes the output of the last Long Short-Term Memory cell and output the prediction for the next time step. You can use the <code>MultiRNNCell</code> in TensorFlow to encapsulate the three <code>LSTMCell</code> objects you created. Additionally, you can have the dropout implemented LSTM cells, as they improve performance and reduce overfitting.</p>
<pre><code class="lang-python hljs">lstm_cells = [
    tf.contrib.rnn.LSTMCell(num_units=num_nodes[li],
                            state_is_tuple=<span class="hljs-keyword">True</span>,
                            initializer= tf.contrib.layers.xavier_initializer()
                           )
 <span class="hljs-keyword">for</span> li <span class="hljs-keyword">in</span> range(n_layers)]

drop_lstm_cells = [tf.contrib.rnn.DropoutWrapper(
    lstm, input_keep_prob=<span class="hljs-number">1.0</span>,output_keep_prob=<span class="hljs-number">1.0</span>-dropout, state_keep_prob=<span class="hljs-number">1.0</span>-dropout
) <span class="hljs-keyword">for</span> lstm <span class="hljs-keyword">in</span> lstm_cells]
drop_multi_cell = tf.contrib.rnn.MultiRNNCell(drop_lstm_cells)
multi_cell = tf.contrib.rnn.MultiRNNCell(lstm_cells)

w = tf.get_variable(<span class="hljs-string">'w'</span>,shape=[num_nodes[<span class="hljs-number">-1</span>], <span class="hljs-number">1</span>], initializer=tf.contrib.layers.xavier_initializer())
b = tf.get_variable(<span class="hljs-string">'b'</span>,initializer=tf.random_uniform([<span class="hljs-number">1</span>],<span class="hljs-number">-0.1</span>,<span class="hljs-number">0.1</span>))
</code></pre>
<h3 id="calculating-lstm-output-and-feeding-it-to-the-regression-layer-to-get-final-prediction">Calculating LSTM output and Feeding it to the regression layer to get final prediction</h3>
<p>In this section, you first create TensorFlow variables (<code>c</code> and <code>h</code>) that will hold the cell state and the hidden state of the Long Short-Term Memory cell. Then you transform the list of <code>train_inputs</code> to have a shape of <code>[num_unrollings, batch_size, D]</code>, this is needed for calculating the outputs with the <code>tf.nn.dynamic_rnn</code> function.  You then calculate the LSTM outputs with the <code>tf.nn.dynamic_rnn</code> function and split the output back to a list of <code>num_unrolling</code> tensors. the loss between the predictions and true stock prices.</p>
<pre><code class="lang-python hljs"><span class="hljs-comment"># Create cell state and hidden state variables to maintain the state of the LSTM</span>
c, h = [],[]
initial_state = []
<span class="hljs-keyword">for</span> li <span class="hljs-keyword">in</span> range(n_layers):
  c.append(tf.Variable(tf.zeros([batch_size, num_nodes[li]]), trainable=<span class="hljs-keyword">False</span>))
  h.append(tf.Variable(tf.zeros([batch_size, num_nodes[li]]), trainable=<span class="hljs-keyword">False</span>))
  initial_state.append(tf.contrib.rnn.LSTMStateTuple(c[li], h[li]))

<span class="hljs-comment"># Do several tensor transofmations, because the function dynamic_rnn requires the output to be of</span>
<span class="hljs-comment"># a specific format. Read more at: https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn</span>
all_inputs = tf.concat([tf.expand_dims(t,<span class="hljs-number">0</span>) <span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> train_inputs],axis=<span class="hljs-number">0</span>)

<span class="hljs-comment"># all_outputs is [seq_length, batch_size, num_nodes]</span>
all_lstm_outputs, state = tf.nn.dynamic_rnn(
    drop_multi_cell, all_inputs, initial_state=tuple(initial_state),
    time_major = <span class="hljs-keyword">True</span>, dtype=tf.float32)

all_lstm_outputs = tf.reshape(all_lstm_outputs, [batch_size*num_unrollings,num_nodes[<span class="hljs-number">-1</span>]])

all_outputs = tf.nn.xw_plus_b(all_lstm_outputs,w,b)

split_outputs = tf.split(all_outputs,num_unrollings,axis=<span class="hljs-number">0</span>)
</code></pre>
<h3 id="loss-calculation-and-optimizer">Loss Calculation and Optimizer</h3>
<p>Now, you'll calculate the loss. However, you should note that there is a unique characteristic when calculating the loss. For each batch of predictions and true outputs, you calculate the Mean Squared Error. And you sum (not average) all these mean squared losses together. Finally, you define the optimizer you're going to use to optimize the neural network. In this case, you can use Adam, which is a very recent and well-performing optimizer.</p>
<pre><code class="lang-python hljs"><span class="hljs-comment"># When calculating the loss you need to be careful about the exact form, because you calculate</span>
<span class="hljs-comment"># loss of all the unrolled steps at the same time</span>
<span class="hljs-comment"># Therefore, take the mean error or each batch and get the sum of that over all the unrolled steps</span>

print(<span class="hljs-string">'Defining training Loss'</span>)
loss = <span class="hljs-number">0.0</span>
<span class="hljs-keyword">with</span> tf.control_dependencies([tf.assign(c[li], state[li][<span class="hljs-number">0</span>]) <span class="hljs-keyword">for</span> li <span class="hljs-keyword">in</span> range(n_layers)]+
                             [tf.assign(h[li], state[li][<span class="hljs-number">1</span>]) <span class="hljs-keyword">for</span> li <span class="hljs-keyword">in</span> range(n_layers)]):
  <span class="hljs-keyword">for</span> ui <span class="hljs-keyword">in</span> range(num_unrollings):
    loss += tf.reduce_mean(<span class="hljs-number">0.5</span>*(split_outputs[ui]-train_outputs[ui])**<span class="hljs-number">2</span>)

print(<span class="hljs-string">'Learning rate decay operations'</span>)
global_step = tf.Variable(<span class="hljs-number">0</span>, trainable=<span class="hljs-keyword">False</span>)
inc_gstep = tf.assign(global_step,global_step + <span class="hljs-number">1</span>)
tf_learning_rate = tf.placeholder(shape=<span class="hljs-keyword">None</span>,dtype=tf.float32)
tf_min_learning_rate = tf.placeholder(shape=<span class="hljs-keyword">None</span>,dtype=tf.float32)

learning_rate = tf.maximum(
    tf.train.exponential_decay(tf_learning_rate, global_step, decay_steps=<span class="hljs-number">1</span>, decay_rate=<span class="hljs-number">0.5</span>, staircase=<span class="hljs-keyword">True</span>),
    tf_min_learning_rate)

<span class="hljs-comment"># Optimizer.</span>
print(<span class="hljs-string">'TF Optimization operations'</span>)
optimizer = tf.train.AdamOptimizer(learning_rate)
gradients, v = zip(*optimizer.compute_gradients(loss))
gradients, _ = tf.clip_by_global_norm(gradients, <span class="hljs-number">5.0</span>)
optimizer = optimizer.apply_gradients(
    zip(gradients, v))

print(<span class="hljs-string">'\tAll done'</span>)
</code></pre>
<pre><code>Defining training Loss
Learning rate decay operations
TF Optimization operations
    All done
</code></pre><h3 id="prediction-related-calculations">Prediction Related Calculations</h3>
<p>Here you define the prediction related TensorFlow operations. First, define a placeholder for feeding in the input (<code>sample_inputs</code>), then similar to the training stage, you define state variables for prediction (<code>sample_c</code> and <code>sample_h</code>). Finally you calculate the prediction with the <code>tf.nn.dynamic_rnn</code> function and then sending the output through the regression layer (<code>w</code> and <code>b</code>). You also should define the <code>reset_sample_state</code> operation, which resets the cell state and the hidden state. You should execute this operation at the start, every time you make a sequence of predictions.</p>
<pre><code class="lang-python hljs">print(<span class="hljs-string">'Defining prediction related TF functions'</span>)

sample_inputs = tf.placeholder(tf.float32, shape=[<span class="hljs-number">1</span>,D])

<span class="hljs-comment"># Maintaining LSTM state for prediction stage</span>
sample_c, sample_h, initial_sample_state = [],[],[]
<span class="hljs-keyword">for</span> li <span class="hljs-keyword">in</span> range(n_layers):
  sample_c.append(tf.Variable(tf.zeros([<span class="hljs-number">1</span>, num_nodes[li]]), trainable=<span class="hljs-keyword">False</span>))
  sample_h.append(tf.Variable(tf.zeros([<span class="hljs-number">1</span>, num_nodes[li]]), trainable=<span class="hljs-keyword">False</span>))
  initial_sample_state.append(tf.contrib.rnn.LSTMStateTuple(sample_c[li],sample_h[li]))

reset_sample_states = tf.group(*[tf.assign(sample_c[li],tf.zeros([<span class="hljs-number">1</span>, num_nodes[li]])) <span class="hljs-keyword">for</span> li <span class="hljs-keyword">in</span> range(n_layers)],
                               *[tf.assign(sample_h[li],tf.zeros([<span class="hljs-number">1</span>, num_nodes[li]])) <span class="hljs-keyword">for</span> li <span class="hljs-keyword">in</span> range(n_layers)])

sample_outputs, sample_state = tf.nn.dynamic_rnn(multi_cell, tf.expand_dims(sample_inputs,<span class="hljs-number">0</span>),
                                   initial_state=tuple(initial_sample_state),
                                   time_major = <span class="hljs-keyword">True</span>,
                                   dtype=tf.float32)

<span class="hljs-keyword">with</span> tf.control_dependencies([tf.assign(sample_c[li],sample_state[li][<span class="hljs-number">0</span>]) <span class="hljs-keyword">for</span> li <span class="hljs-keyword">in</span> range(n_layers)]+
                              [tf.assign(sample_h[li],sample_state[li][<span class="hljs-number">1</span>]) <span class="hljs-keyword">for</span> li <span class="hljs-keyword">in</span> range(n_layers)]):  
  sample_prediction = tf.nn.xw_plus_b(tf.reshape(sample_outputs,[<span class="hljs-number">1</span>,<span class="hljs-number">-1</span>]), w, b)

print(<span class="hljs-string">'\tAll done'</span>)
</code></pre>
<pre><code>Defining prediction related TF functions
    All done
</code></pre><h3 id="running-the-lstm">Running the LSTM</h3>
<p>Here you will train and predict stock price movements for several epochs and see whether the predictions get better or worse over time. You follow the following procedure.</p>
<ul>
<li>Define a test set of starting points (<code>test_points_seq</code>) on the time series to evaluate the model on</li>
<li>For each epoch<ul>
<li>For full sequence length of training data<ul>
<li>Unroll a set of <code>num_unrollings</code> batches</li>
<li>Train the neural network with the unrolled batches</li>
</ul>
</li>
<li>Calculate the average training loss</li>
<li>For each starting point in the test set<ul>
<li>Update the LSTM state by iterating through the previous <code>num_unrollings</code> data points found before the test point</li>
<li>Make predictions for <code>n_predict_once</code> steps continuously, using the previous prediction as the current input</li>
<li>Calculate the MSE loss between the <code>n_predict_once</code> points predicted and the true stock prices at those time stamps</li>
</ul>
</li>
</ul>
</li>
</ul>
<pre><code class="lang-python hljs">epochs = <span class="hljs-number">30</span>
valid_summary = <span class="hljs-number">1</span> <span class="hljs-comment"># Interval you make test predictions</span>

n_predict_once = <span class="hljs-number">50</span> <span class="hljs-comment"># Number of steps you continously predict for</span>

train_seq_length = train_data.size <span class="hljs-comment"># Full length of the training data</span>

train_mse_ot = [] <span class="hljs-comment"># Accumulate Train losses</span>
test_mse_ot = [] <span class="hljs-comment"># Accumulate Test loss</span>
predictions_over_time = [] <span class="hljs-comment"># Accumulate predictions</span>

session = tf.InteractiveSession()

tf.global_variables_initializer().run()

<span class="hljs-comment"># Used for decaying learning rate</span>
loss_nondecrease_count = <span class="hljs-number">0</span>
loss_nondecrease_threshold = <span class="hljs-number">2</span> <span class="hljs-comment"># If the test error hasn't increased in this many steps, decrease learning rate</span>

print(<span class="hljs-string">'Initialized'</span>)
average_loss = <span class="hljs-number">0</span>

<span class="hljs-comment"># Define data generator</span>
data_gen = DataGeneratorSeq(train_data,batch_size,num_unrollings)

x_axis_seq = []

<span class="hljs-comment"># Points you start your test predictions from</span>
test_points_seq = np.arange(<span class="hljs-number">11000</span>,<span class="hljs-number">12000</span>,<span class="hljs-number">50</span>).tolist()

<span class="hljs-keyword">for</span> ep <span class="hljs-keyword">in</span> range(epochs):       

    <span class="hljs-comment"># ========================= Training =====================================</span>
    <span class="hljs-keyword">for</span> step <span class="hljs-keyword">in</span> range(train_seq_length//batch_size):

        u_data, u_labels = data_gen.unroll_batches()

        feed_dict = {}
        <span class="hljs-keyword">for</span> ui,(dat,lbl) <span class="hljs-keyword">in</span> enumerate(zip(u_data,u_labels)):            
            feed_dict[train_inputs[ui]] = dat.reshape(<span class="hljs-number">-1</span>,<span class="hljs-number">1</span>)
            feed_dict[train_outputs[ui]] = lbl.reshape(<span class="hljs-number">-1</span>,<span class="hljs-number">1</span>)

        feed_dict.update({tf_learning_rate: <span class="hljs-number">0.0001</span>, tf_min_learning_rate:<span class="hljs-number">0.000001</span>})

        _, l = session.run([optimizer, loss], feed_dict=feed_dict)

        average_loss += l

    <span class="hljs-comment"># ============================ Validation ==============================</span>
    <span class="hljs-keyword">if</span> (ep+<span class="hljs-number">1</span>) % valid_summary == <span class="hljs-number">0</span>:

      average_loss = average_loss/(valid_summary*(train_seq_length//batch_size))

      <span class="hljs-comment"># The average loss</span>
      <span class="hljs-keyword">if</span> (ep+<span class="hljs-number">1</span>)%valid_summary==<span class="hljs-number">0</span>:
        print(<span class="hljs-string">'Average loss at step %d: %f'</span> % (ep+<span class="hljs-number">1</span>, average_loss))

      train_mse_ot.append(average_loss)

      average_loss = <span class="hljs-number">0</span> <span class="hljs-comment"># reset loss</span>

      predictions_seq = []

      mse_test_loss_seq = []

      <span class="hljs-comment"># ===================== Updating State and Making Predicitons ========================</span>
      <span class="hljs-keyword">for</span> w_i <span class="hljs-keyword">in</span> test_points_seq:
        mse_test_loss = <span class="hljs-number">0.0</span>
        our_predictions = []

        <span class="hljs-keyword">if</span> (ep+<span class="hljs-number">1</span>)-valid_summary==<span class="hljs-number">0</span>:
          <span class="hljs-comment"># Only calculate x_axis values in the first validation epoch</span>
          x_axis=[]

        <span class="hljs-comment"># Feed in the recent past behavior of stock prices</span>
        <span class="hljs-comment"># to make predictions from that point onwards</span>
        <span class="hljs-keyword">for</span> tr_i <span class="hljs-keyword">in</span> range(w_i-num_unrollings+<span class="hljs-number">1</span>,w_i<span class="hljs-number">-1</span>):
          current_price = all_mid_data[tr_i]
          feed_dict[sample_inputs] = np.array(current_price).reshape(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)    
          _ = session.run(sample_prediction,feed_dict=feed_dict)

        feed_dict = {}

        current_price = all_mid_data[w_i<span class="hljs-number">-1</span>]

        feed_dict[sample_inputs] = np.array(current_price).reshape(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)

        <span class="hljs-comment"># Make predictions for this many steps</span>
        <span class="hljs-comment"># Each prediction uses previous prediciton as it's current input</span>
        <span class="hljs-keyword">for</span> pred_i <span class="hljs-keyword">in</span> range(n_predict_once):

          pred = session.run(sample_prediction,feed_dict=feed_dict)

          our_predictions.append(np.asscalar(pred))

          feed_dict[sample_inputs] = np.asarray(pred).reshape(<span class="hljs-number">-1</span>,<span class="hljs-number">1</span>)

          <span class="hljs-keyword">if</span> (ep+<span class="hljs-number">1</span>)-valid_summary==<span class="hljs-number">0</span>:
            <span class="hljs-comment"># Only calculate x_axis values in the first validation epoch</span>
            x_axis.append(w_i+pred_i)

          mse_test_loss += <span class="hljs-number">0.5</span>*(pred-all_mid_data[w_i+pred_i])**<span class="hljs-number">2</span>

        session.run(reset_sample_states)

        predictions_seq.append(np.array(our_predictions))

        mse_test_loss /= n_predict_once
        mse_test_loss_seq.append(mse_test_loss)

        <span class="hljs-keyword">if</span> (ep+<span class="hljs-number">1</span>)-valid_summary==<span class="hljs-number">0</span>:
          x_axis_seq.append(x_axis)

      current_test_mse = np.mean(mse_test_loss_seq)

      <span class="hljs-comment"># Learning rate decay logic</span>
      <span class="hljs-keyword">if</span> len(test_mse_ot)&gt;<span class="hljs-number">0</span> <span class="hljs-keyword">and</span> current_test_mse &gt; min(test_mse_ot):
          loss_nondecrease_count += <span class="hljs-number">1</span>
      <span class="hljs-keyword">else</span>:
          loss_nondecrease_count = <span class="hljs-number">0</span>

      <span class="hljs-keyword">if</span> loss_nondecrease_count &gt; loss_nondecrease_threshold :
            session.run(inc_gstep)
            loss_nondecrease_count = <span class="hljs-number">0</span>
            print(<span class="hljs-string">'\tDecreasing learning rate by 0.5'</span>)

      test_mse_ot.append(current_test_mse)
      print(<span class="hljs-string">'\tTest MSE: %.5f'</span>%np.mean(mse_test_loss_seq))
      predictions_over_time.append(predictions_seq)
      print(<span class="hljs-string">'\tFinished Predictions'</span>)
</code></pre>
<pre><code>Initialized
Average loss at step 1: 1.703350
    Test MSE: 0.00318
    Finished Predictions
  ...
  ...
  ...
Average loss at step 30: 0.033753
    Test MSE: 0.00243
    Finished Predictions
</code></pre><p><a id="predict"></a></p>
<h2 id="visualizing-the-predictions">Visualizing the Predictions</h2>
<p>You can see how the MSE loss is going down with the amount of training. This is good sign that the model is learning something useful. To quantify your findings, you can compare the network's MSE loss to the MSE loss you obtained when doing the standard averaging (0.004). You can see that the LSTM is doing better than the standard averaging. And you know that standard averaging (though not perfect) followed the true stock prices movements reasonably.</p>
<pre><code class="lang-python hljs">best_prediction_epoch = <span class="hljs-number">28</span> <span class="hljs-comment"># replace this with the epoch that you got the best results when running the plotting code</span>

plt.figure(figsize = (<span class="hljs-number">18</span>,<span class="hljs-number">18</span>))
plt.subplot(<span class="hljs-number">2</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)
plt.plot(range(df.shape[<span class="hljs-number">0</span>]),all_mid_data,color=<span class="hljs-string">'b'</span>)

<span class="hljs-comment"># Plotting how the predictions change over time</span>
<span class="hljs-comment"># Plot older predictions with low alpha and newer predictions with high alpha</span>
start_alpha = <span class="hljs-number">0.25</span>
alpha  = np.arange(start_alpha,<span class="hljs-number">1.1</span>,(<span class="hljs-number">1.0</span>-start_alpha)/len(predictions_over_time[::<span class="hljs-number">3</span>]))
<span class="hljs-keyword">for</span> p_i,p <span class="hljs-keyword">in</span> enumerate(predictions_over_time[::<span class="hljs-number">3</span>]):
    <span class="hljs-keyword">for</span> xval,yval <span class="hljs-keyword">in</span> zip(x_axis_seq,p):
        plt.plot(xval,yval,color=<span class="hljs-string">'r'</span>,alpha=alpha[p_i])

plt.title(<span class="hljs-string">'Evolution of Test Predictions Over Time'</span>,fontsize=<span class="hljs-number">18</span>)
plt.xlabel(<span class="hljs-string">'Date'</span>,fontsize=<span class="hljs-number">18</span>)
plt.ylabel(<span class="hljs-string">'Mid Price'</span>,fontsize=<span class="hljs-number">18</span>)
plt.xlim(<span class="hljs-number">11000</span>,<span class="hljs-number">12500</span>)

plt.subplot(<span class="hljs-number">2</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>)

<span class="hljs-comment"># Predicting the best test prediction you got</span>
plt.plot(range(df.shape[<span class="hljs-number">0</span>]),all_mid_data,color=<span class="hljs-string">'b'</span>)
<span class="hljs-keyword">for</span> xval,yval <span class="hljs-keyword">in</span> zip(x_axis_seq,predictions_over_time[best_prediction_epoch]):
    plt.plot(xval,yval,color=<span class="hljs-string">'r'</span>)

plt.title(<span class="hljs-string">'Best Test Predictions Over Time'</span>,fontsize=<span class="hljs-number">18</span>)
plt.xlabel(<span class="hljs-string">'Date'</span>,fontsize=<span class="hljs-number">18</span>)
plt.ylabel(<span class="hljs-string">'Mid Price'</span>,fontsize=<span class="hljs-number">18</span>)
plt.xlim(<span class="hljs-number">11000</span>,<span class="hljs-number">12500</span>)
plt.show()
</code></pre>
<p><img src="./LSTM in Python_ Stock Market Predictions (article) - DataCamp_files/output_47_0_gmxsj3.png"></p>
<p>Though not perfect, LSTMs seem to be able to predict stock price behavior correctly most of the time. Note that you are making predictions roughly in the range of 0 and 1.0 (that is, not the true stock prices). This is okay, because you're predicting the stock price movement, not the prices themselves.</p>
<p><a id="remarks"></a></p>
<h2 id="final-remarks">Final Remarks</h2>
<p>I'm hoping that you found this tutorial useful. I should mention that this was a rewarding experience for me. In this tutorial, I learnt how difficult it can be to device a model that is able to correctly predict stock price movements. You started with a motivation for why you need to model stock prices. This was followed by an explanation and code for downloading data. Then you looked at two averaging techniques that allow you to make predictions one step into the future. You next saw that these methods are futile when you need to predict more than one step into the future. Thereafter you discussed how you can use LSTMs to make predictions many steps into the future. Finally you visualized the results and saw that your model (though not perfect) is quite good at correctly predicting stock price movements.</p>
<p>If you would like to learn more about deep learning, be sure to take a look at our <a href="https://www.datacamp.com/courses/deep-learning-in-python">Deep Learning in Python course</a>. It covers the basics, as well as how to build a neural network on your own in Keras. This is a different package than TensorFlow, which will be used in this tutorial, but the idea is the same.</p>
<p>Here, I'm stating several takeaways of this tutorial.</p>
<ol>
<li><p>Stock price/movement prediction is an extremely difficult task. Personally I don't think any of the stock prediction models out there shouldn't be taken for granted and blindly rely on them. However models might be able to predict stock price movement correctly most of the time, but not always.</p>
</li>
<li><p>Do not be fooled by articles out there that shows predictions curves that perfectly overlaps the true stock prices. This can be replicated with a simple averaging technique and in practice it's useless. A more sensible thing to do is predicting the stock price movements.</p>
</li>
<li><p>The model's hyperparameters are extremely sensitive to the results you obtain. So a very good thing to do would be to run some hyperparameter optimization technique (for example, Grid search / Random search) on the hyperparameters. Below I listed some of the most critical hyperparameters</p>
<ul>
<li>The learning rate of the optimizer</li>
<li>Number of layers and the number of hidden units in each layer</li>
<li>The optimizer. I found Adam to perform the best</li>
<li>Type of the model. You can try GRU/ Standard LSTM/ LSTM with Peepholes and evaluation performance difference</li>
</ul>
</li>
<li><p>In this tutorial you did something faulty (due to the small size of data)! That is you used the test loss to decay the learning rate. This indirectly leaks information about test set into the training procedure. A better way of handling this is to have a separate validation set (apart from the test set) and decay learning rate with respect to performance of the validation set.</p>
</li>
</ol>
<p>If you'd like to get in touch with me, you can drop me an e-mail at thushv@gmail.com or connect with me via <a href="https://www.linkedin.com/in/thushanganegedara/">LinkedIn</a>.</p>
<h2 id="references">References</h2>
<p>I referred to <a href="https://github.com/jaungiers/LSTM-Neural-Network-for-Time-Series-Prediction">this repository</a> to get an understanding about how to use LSTMs for stock predictions. But details can be vastly different from the implementation found in the reference.</p>
</div><link href="./LSTM in Python_ Stock Market Predictions (article) - DataCamp_files/solarized-dark.min.css" rel="stylesheet"><link href="./LSTM in Python_ Stock Market Predictions (article) - DataCamp_files/css" rel="stylesheet"><link href="./LSTM in Python_ Stock Market Predictions (article) - DataCamp_files/css(1)" rel="stylesheet"></div><div class="jsx-1448759959 social__bottom mobileOnly"><div class="jsx-1448759959 voteAndSocial"><div class="jsx-1448759959"><div class="jsx-4192737526 Upvote"><div class="jsx-4192737526"><div class="jsx-4192737526 normal"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path d="M1 10L6 0l5 10z"></path></svg></span><span class="jsx-4192737526 count">45</span></div><div class="jsx-4192737526 voted"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path d="M1 10L6 0l5 10z"></path></svg></span><span class="jsx-4192737526 count">45</span></div></div></div><a href="https://www.datacamp.com/community/tutorials/lstm-python-stock-market#comments" class="jsx-3293774837 CommentCounter"><span class="jsx-3293774837 icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 18 18"><path d="M12.595 13.364c.01-.111.02-.197.028-.251.058-.405.372-.702.74-.702h1.257c1.035-.002 1.875-.934 1.88-2.082V4.764c-.001-1.155-.842-2.092-1.878-2.094H3.38c-1.034.002-1.873.931-1.88 2.076v5.565c.001 1.156.842 2.092 1.878 2.094h6.626c.292 0 .557.189.68.484.408.977 1.07 1.576 1.94 1.85a6.004 6.004 0 0 1-.03-1.375zm1.51 1.119c.048.314.136.521.235.606.566.487.258 1.497-.458 1.497-1.87 0-3.423-.785-4.33-2.51H3.376C1.513 14.07.004 12.39 0 10.311V4.74C.014 2.673 1.52 1.004 3.378 1h11.245c1.864.004 3.373 1.686 3.377 3.763v5.57c-.01 2.07-1.518 3.744-3.378 3.748h-.551c.004.138.016.273.035.402zm-8.423-5.81a1.114 1.114 0 1 0 0-2.229 1.114 1.114 0 0 0 0 2.229zm3.268 0a1.114 1.114 0 1 0 0-2.229 1.114 1.114 0 0 0 0 2.229zm3.318 0a1.114 1.114 0 1 0 0-2.229 1.114 1.114 0 0 0 0 2.229z"></path></svg></span><span class="jsx-3293774837 count">25</span></a></div><div class="jsx-1531915454 Social"><div class="jsx-1531915454 icons"><a href="https://www.facebook.com/sharer.php?u=https://www.datacamp.com/community/tutorials/lstm-python-stock-market" target="_blank" rel="noopener noreferrer" class="jsx-1531915454 icon"><svg height="12" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 11.73 22.58"><path d="M7.61 22.58v-10.3h3.46l.52-4h-4V5.7c0-1.16.32-2 2-2h2.13V.16A28.47 28.47 0 0 0 8.63 0C5.56 0 3.47 1.87 3.47 5.31v3H0v4h3.47v10.3h4.14z"></path></svg></a><a href="https://twitter.com/intent/tweet?url=https://www.datacamp.com/community/tutorials/lstm-python-stock-market" target="_blank" rel="noopener noreferrer" class="jsx-1531915454 icon centerIcon"><svg height="10" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20.42 16.67"><path d="M10 5.18c0-.28-.06-.53-.07-.78a4 4 0 0 1 .73-2.57A4.08 4.08 0 0 1 13.93 0 4 4 0 0 1 17 1.15a.43.43 0 0 0 .46.12 8.68 8.68 0 0 0 2.2-.84l.2-.1a4.36 4.36 0 0 1-1.75 2.28A9 9 0 0 0 20.42 2l-.21.3a3.83 3.83 0 0 1-.23.3A8.45 8.45 0 0 1 18.5 4a.28.28 0 0 0-.13.27A12 12 0 0 1 17 10.18a11.8 11.8 0 0 1-3.37 4.11 11.17 11.17 0 0 1-4.39 2.06 12.53 12.53 0 0 1-4.44.22 11.87 11.87 0 0 1-4.74-1.73L0 14.79a8.6 8.6 0 0 0 6.16-1.74 4.28 4.28 0 0 1-3.91-2.91h.95a6.18 6.18 0 0 0 .89-.12A4.2 4.2 0 0 1 .8 5.88a4 4 0 0 0 1.81.49 4.23 4.23 0 0 1-1.78-3A4.07 4.07 0 0 1 1.38.79 12.06 12.06 0 0 0 10 5.18z" id="iOjKBC.tif"></path></svg></a><a href="https://www.linkedin.com/cws/share?url=https://www.datacamp.com/community/tutorials/lstm-python-stock-market" target="_blank" rel="noopener noreferrer" class="jsx-1531915454 icon"><svg height="10" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16.99 17"><path d="M3.85 17H.34V5.67h3.51zM2.07 4.18a2.09 2.09 0 1 1 2.08-2.09 2.08 2.08 0 0 1-2.08 2.09zM17 17h-3.5v-5.95c0-1.63-.62-2.54-1.91-2.54s-2.14.95-2.14 2.54V17H6.09V5.67h3.36v1.52a4 4 0 0 1 3.42-1.87c2.4 0 4.12 1.47 4.12 4.5V17z"></path></svg></a></div></div></div></div></div></div><div id="comments" class="jsx-3070642063 Comments"><div class="jsx-3070642063 title">Comments</div><div class="jsx-3070642063 wrapper"><div class="jsx-2482332697 CommentLevel top"><div class="jsx-487597203 Comment"><div id="comment-798" class="jsx-487597203 anchor"></div><div class="jsx-487597203"><a href="https://www.datacamp.com/profile/maysamkhorsand" target="_blank" class="jsx-487597203"><div class="jsx-3208234818 Avatar" style="background-image: url(&quot;https://res.cloudinary.com/dyd911kmh/image/fetch/t_avatar_thumbnail/https://cdn.datacamp.com/community/assets/placeholder_avatar-7f673b5d40e159404a56b5931250cc73.png&quot;); border-radius: 20px; min-width: 40px; min-height: 40px;"></div></a></div><div class="jsx-487597203 right"><div class="jsx-487597203 top"><div class="jsx-487597203"><a href="https://www.datacamp.com/profile/maysamkhorsand" target="_blank" class="jsx-487597203 username">maysamkhorsand</a></div><div class="jsx-487597203 more"></div></div><span class="date mobileOnly">04/05/2018 09:07 PM</span><div class="jsx-487597203 message"><p>Hello awesome tutorial thank you!</p>
<p>Anywhere we can download the full code by any chance?</p>
<p><br></p>
<p>Thanks in advance!</p>
<p><br></p>
<p>Sam</p></div><div class="jsx-487597203 bottom"><div class="jsx-487597203 left"><div class="jsx-4192737526 Upvote comment"><div class="jsx-4192737526"><div class="jsx-4192737526 normal"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path d="M1 10L6 0l5 10z"></path></svg></span><span class="jsx-4192737526 count">1</span></div><div class="jsx-4192737526 voted"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path id="a" d="M9.769.435a1.255 1.255 0 0 1 1.81-.094 1.35 1.35 0 0 1 .09 1.865l-6.457 7.36a1.257 1.257 0 0 1-1.934-.04l-2.98-3.68a1.348 1.348 0 0 1 .162-1.86 1.255 1.255 0 0 1 1.805.168L4.3 6.667 9.77.435z"></path></svg></span><span class="jsx-4192737526 count">1</span></div></div></div><a class="jsx-487597203 replyIcon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="9" viewBox="0 0 12 9"><path d="M.234 3.663L5.032.065a.375.375 0 0 1 .585.293v1.895c5.23 0 6.221 3.633 6.383 5.57a.375.375 0 0 1-.654.27C9.028 5.388 5.617 6.008 5.617 6.008v1.895a.375.375 0 0 1-.585.293L.234 4.598a.584.584 0 0 1 0-.935z"></path></svg> <span class="jsx-487597203 replyText">Reply</span></a><span class="jsx-487597203 divider desktopOnly"></span><a href="https://www.datacamp.com/community/tutorials/lstm-python-stock-market#comment-798" class="jsx-487597203"><span class="date desktopOnly">04/05/2018 09:07 PM</span></a></div><div class="jsx-487597203 spam"><svg title="Flag as spam" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 10 12"><path d="M9.708.265A.441.441 0 0 0 9.304 0H.441A.441.441 0 0 0 0 .441v11.118a.441.441 0 1 0 .882 0V6.532h8.422a.441.441 0 0 0 .322-.735L7.274 3.27 9.626.742a.441.441 0 0 0 .082-.477z"></path></svg></div></div></div></div><div class="jsx-2482332697 CommentLevel"><div class="jsx-487597203 Comment"><div id="comment-799" class="jsx-487597203 anchor"></div><div class="jsx-487597203"><a href="https://www.datacamp.com/profile/thushv" target="_blank" class="jsx-487597203"><div class="jsx-3208234818 Avatar" style="background-image: url(&quot;https://res.cloudinary.com/dyd911kmh/image/fetch/t_avatar_thumbnail/https://assets.datacamp.com/users/avatars/002/125/563/square/profile.jpeg?1518563443&quot;); border-radius: 20px; min-width: 40px; min-height: 40px;"></div></a></div><div class="jsx-487597203 right"><div class="jsx-487597203 top"><div class="jsx-487597203"><a href="https://www.datacamp.com/profile/thushv" target="_blank" class="jsx-487597203 username">Thushan Ganegedara</a></div><div class="jsx-487597203 more"></div></div><span class="date mobileOnly">04/05/2018 09:23 PM</span><div class="jsx-487597203 message"><p>I have uploaded the code at: https://github.com/thushv89/datacamp_tutorials</p></div><div class="jsx-487597203 bottom"><div class="jsx-487597203 left"><div class="jsx-4192737526 Upvote comment"><div class="jsx-4192737526"><div class="jsx-4192737526 normal"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path d="M1 10L6 0l5 10z"></path></svg></span><span class="jsx-4192737526 count">2</span></div><div class="jsx-4192737526 voted"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path id="a" d="M9.769.435a1.255 1.255 0 0 1 1.81-.094 1.35 1.35 0 0 1 .09 1.865l-6.457 7.36a1.257 1.257 0 0 1-1.934-.04l-2.98-3.68a1.348 1.348 0 0 1 .162-1.86 1.255 1.255 0 0 1 1.805.168L4.3 6.667 9.77.435z"></path></svg></span><span class="jsx-4192737526 count">2</span></div></div></div><a class="jsx-487597203 replyIcon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="9" viewBox="0 0 12 9"><path d="M.234 3.663L5.032.065a.375.375 0 0 1 .585.293v1.895c5.23 0 6.221 3.633 6.383 5.57a.375.375 0 0 1-.654.27C9.028 5.388 5.617 6.008 5.617 6.008v1.895a.375.375 0 0 1-.585.293L.234 4.598a.584.584 0 0 1 0-.935z"></path></svg> <span class="jsx-487597203 replyText">Reply</span></a><span class="jsx-487597203 divider desktopOnly"></span><a href="https://www.datacamp.com/community/tutorials/lstm-python-stock-market#comment-799" class="jsx-487597203"><span class="date desktopOnly">04/05/2018 09:23 PM</span></a></div><div class="jsx-487597203 spam"><svg title="Flag as spam" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 10 12"><path d="M9.708.265A.441.441 0 0 0 9.304 0H.441A.441.441 0 0 0 0 .441v11.118a.441.441 0 1 0 .882 0V6.532h8.422a.441.441 0 0 0 .322-.735L7.274 3.27 9.626.742a.441.441 0 0 0 .082-.477z"></path></svg></div></div></div></div></div></div><div class="jsx-2482332697 CommentLevel top"><div class="jsx-487597203 Comment"><div id="comment-800" class="jsx-487597203 anchor"></div><div class="jsx-487597203"><a href="https://www.datacamp.com/profile/satnampahwa85" target="_blank" class="jsx-487597203"><div class="jsx-3208234818 Avatar" style="background-image: url(&quot;https://res.cloudinary.com/dyd911kmh/image/fetch/t_avatar_thumbnail/https://cdn.datacamp.com/community/assets/placeholder_avatar-7f673b5d40e159404a56b5931250cc73.png&quot;); border-radius: 20px; min-width: 40px; min-height: 40px;"></div></a></div><div class="jsx-487597203 right"><div class="jsx-487597203 top"><div class="jsx-487597203"><a href="https://www.datacamp.com/profile/satnampahwa85" target="_blank" class="jsx-487597203 username">satnampahwa85</a></div><div class="jsx-487597203 more"></div></div><span class="date mobileOnly">05/05/2018 11:31 AM</span><div class="jsx-487597203 message"><p>Will something similar work for crypto market?</p></div><div class="jsx-487597203 bottom"><div class="jsx-487597203 left"><div class="jsx-4192737526 Upvote comment"><div class="jsx-4192737526"><div class="jsx-4192737526 normal"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path d="M1 10L6 0l5 10z"></path></svg></span><span class="jsx-4192737526 count">1</span></div><div class="jsx-4192737526 voted"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path id="a" d="M9.769.435a1.255 1.255 0 0 1 1.81-.094 1.35 1.35 0 0 1 .09 1.865l-6.457 7.36a1.257 1.257 0 0 1-1.934-.04l-2.98-3.68a1.348 1.348 0 0 1 .162-1.86 1.255 1.255 0 0 1 1.805.168L4.3 6.667 9.77.435z"></path></svg></span><span class="jsx-4192737526 count">1</span></div></div></div><a class="jsx-487597203 replyIcon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="9" viewBox="0 0 12 9"><path d="M.234 3.663L5.032.065a.375.375 0 0 1 .585.293v1.895c5.23 0 6.221 3.633 6.383 5.57a.375.375 0 0 1-.654.27C9.028 5.388 5.617 6.008 5.617 6.008v1.895a.375.375 0 0 1-.585.293L.234 4.598a.584.584 0 0 1 0-.935z"></path></svg> <span class="jsx-487597203 replyText">Reply</span></a><span class="jsx-487597203 divider desktopOnly"></span><a href="https://www.datacamp.com/community/tutorials/lstm-python-stock-market#comment-800" class="jsx-487597203"><span class="date desktopOnly">05/05/2018 11:31 AM</span></a></div><div class="jsx-487597203 spam"><svg title="Flag as spam" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 10 12"><path d="M9.708.265A.441.441 0 0 0 9.304 0H.441A.441.441 0 0 0 0 .441v11.118a.441.441 0 1 0 .882 0V6.532h8.422a.441.441 0 0 0 .322-.735L7.274 3.27 9.626.742a.441.441 0 0 0 .082-.477z"></path></svg></div></div></div></div><div class="jsx-2482332697 CommentLevel"><div class="jsx-487597203 Comment"><div id="comment-801" class="jsx-487597203 anchor"></div><div class="jsx-487597203"><a href="https://www.datacamp.com/profile/thushv" target="_blank" class="jsx-487597203"><div class="jsx-3208234818 Avatar" style="background-image: url(&quot;https://res.cloudinary.com/dyd911kmh/image/fetch/t_avatar_thumbnail/https://assets.datacamp.com/users/avatars/002/125/563/square/profile.jpeg?1518563443&quot;); border-radius: 20px; min-width: 40px; min-height: 40px;"></div></a></div><div class="jsx-487597203 right"><div class="jsx-487597203 top"><div class="jsx-487597203"><a href="https://www.datacamp.com/profile/thushv" target="_blank" class="jsx-487597203 username">Thushan Ganegedara</a></div><div class="jsx-487597203 more"></div></div><span class="date mobileOnly">05/05/2018 01:41 PM</span><div class="jsx-487597203 message"><p>I haven't studied crypto. I have seen people trying to predict stock price movements with ML and that's what inspired me to give a try. On the other hand, given that crypto is relatively new (thus less data) I probably wouldn't trust a machine learning algorithm (especially deep learning) to forecast a promising output.&nbsp;</p></div><div class="jsx-487597203 bottom"><div class="jsx-487597203 left"><div class="jsx-4192737526 Upvote comment"><div class="jsx-4192737526"><div class="jsx-4192737526 normal"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path d="M1 10L6 0l5 10z"></path></svg></span><span class="jsx-4192737526 count">1</span></div><div class="jsx-4192737526 voted"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path id="a" d="M9.769.435a1.255 1.255 0 0 1 1.81-.094 1.35 1.35 0 0 1 .09 1.865l-6.457 7.36a1.257 1.257 0 0 1-1.934-.04l-2.98-3.68a1.348 1.348 0 0 1 .162-1.86 1.255 1.255 0 0 1 1.805.168L4.3 6.667 9.77.435z"></path></svg></span><span class="jsx-4192737526 count">1</span></div></div></div><a class="jsx-487597203 replyIcon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="9" viewBox="0 0 12 9"><path d="M.234 3.663L5.032.065a.375.375 0 0 1 .585.293v1.895c5.23 0 6.221 3.633 6.383 5.57a.375.375 0 0 1-.654.27C9.028 5.388 5.617 6.008 5.617 6.008v1.895a.375.375 0 0 1-.585.293L.234 4.598a.584.584 0 0 1 0-.935z"></path></svg> <span class="jsx-487597203 replyText">Reply</span></a><span class="jsx-487597203 divider desktopOnly"></span><a href="https://www.datacamp.com/community/tutorials/lstm-python-stock-market#comment-801" class="jsx-487597203"><span class="date desktopOnly">05/05/2018 01:41 PM</span></a></div><div class="jsx-487597203 spam"><svg title="Flag as spam" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 10 12"><path d="M9.708.265A.441.441 0 0 0 9.304 0H.441A.441.441 0 0 0 0 .441v11.118a.441.441 0 1 0 .882 0V6.532h8.422a.441.441 0 0 0 .322-.735L7.274 3.27 9.626.742a.441.441 0 0 0 .082-.477z"></path></svg></div></div></div></div></div></div><div class="jsx-2482332697 CommentLevel top"><div class="jsx-487597203 Comment"><div id="comment-803" class="jsx-487597203 anchor"></div><div class="jsx-487597203"><a href="https://www.datacamp.com/profile/carlgoodier" target="_blank" class="jsx-487597203"><div class="jsx-3208234818 Avatar" style="background-image: url(&quot;https://res.cloudinary.com/dyd911kmh/image/fetch/t_avatar_thumbnail/https://cdn.datacamp.com/community/assets/placeholder_avatar-7f673b5d40e159404a56b5931250cc73.png&quot;); border-radius: 20px; min-width: 40px; min-height: 40px;"></div></a></div><div class="jsx-487597203 right"><div class="jsx-487597203 top"><div class="jsx-487597203"><a href="https://www.datacamp.com/profile/carlgoodier" target="_blank" class="jsx-487597203 username">carlgoodier</a></div><div class="jsx-487597203 more"></div></div><span class="date mobileOnly">05/05/2018 04:31 PM</span><div class="jsx-487597203 message"><p>Name df not defined</p>
<p>sorry if super noob, but can't figure it out&nbsp;</p></div><div class="jsx-487597203 bottom"><div class="jsx-487597203 left"><div class="jsx-4192737526 Upvote comment"><div class="jsx-4192737526"><div class="jsx-4192737526 normal"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path d="M1 10L6 0l5 10z"></path></svg></span><span class="jsx-4192737526 count">2</span></div><div class="jsx-4192737526 voted"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path id="a" d="M9.769.435a1.255 1.255 0 0 1 1.81-.094 1.35 1.35 0 0 1 .09 1.865l-6.457 7.36a1.257 1.257 0 0 1-1.934-.04l-2.98-3.68a1.348 1.348 0 0 1 .162-1.86 1.255 1.255 0 0 1 1.805.168L4.3 6.667 9.77.435z"></path></svg></span><span class="jsx-4192737526 count">2</span></div></div></div><a class="jsx-487597203 replyIcon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="9" viewBox="0 0 12 9"><path d="M.234 3.663L5.032.065a.375.375 0 0 1 .585.293v1.895c5.23 0 6.221 3.633 6.383 5.57a.375.375 0 0 1-.654.27C9.028 5.388 5.617 6.008 5.617 6.008v1.895a.375.375 0 0 1-.585.293L.234 4.598a.584.584 0 0 1 0-.935z"></path></svg> <span class="jsx-487597203 replyText">Reply</span></a><span class="jsx-487597203 divider desktopOnly"></span><a href="https://www.datacamp.com/community/tutorials/lstm-python-stock-market#comment-803" class="jsx-487597203"><span class="date desktopOnly">05/05/2018 04:31 PM</span></a></div><div class="jsx-487597203 spam"><svg title="Flag as spam" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 10 12"><path d="M9.708.265A.441.441 0 0 0 9.304 0H.441A.441.441 0 0 0 0 .441v11.118a.441.441 0 1 0 .882 0V6.532h8.422a.441.441 0 0 0 .322-.735L7.274 3.27 9.626.742a.441.441 0 0 0 .082-.477z"></path></svg></div></div></div></div><div class="jsx-2482332697 CommentLevel"><div class="jsx-487597203 Comment"><div id="comment-809" class="jsx-487597203 anchor"></div><div class="jsx-487597203"><a href="https://www.datacamp.com/profile/thushv" target="_blank" class="jsx-487597203"><div class="jsx-3208234818 Avatar" style="background-image: url(&quot;https://res.cloudinary.com/dyd911kmh/image/fetch/t_avatar_thumbnail/https://assets.datacamp.com/users/avatars/002/125/563/square/profile.jpeg?1518563443&quot;); border-radius: 20px; min-width: 40px; min-height: 40px;"></div></a></div><div class="jsx-487597203 right"><div class="jsx-487597203 top"><div class="jsx-487597203"><a href="https://www.datacamp.com/profile/thushv" target="_blank" class="jsx-487597203 username">Thushan Ganegedara</a></div><div class="jsx-487597203 more"></div></div><span class="date mobileOnly">06/05/2018 01:39 AM</span><div class="jsx-487597203 message"><p>Can you tell me which line your having trouble with? I'm suspecting something to do with panda library. Have you installed it?</p></div><div class="jsx-487597203 bottom"><div class="jsx-487597203 left"><div class="jsx-4192737526 Upvote comment"><div class="jsx-4192737526"><div class="jsx-4192737526 normal"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path d="M1 10L6 0l5 10z"></path></svg></span><span class="jsx-4192737526 count">1</span></div><div class="jsx-4192737526 voted"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path id="a" d="M9.769.435a1.255 1.255 0 0 1 1.81-.094 1.35 1.35 0 0 1 .09 1.865l-6.457 7.36a1.257 1.257 0 0 1-1.934-.04l-2.98-3.68a1.348 1.348 0 0 1 .162-1.86 1.255 1.255 0 0 1 1.805.168L4.3 6.667 9.77.435z"></path></svg></span><span class="jsx-4192737526 count">1</span></div></div></div><a class="jsx-487597203 replyIcon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="9" viewBox="0 0 12 9"><path d="M.234 3.663L5.032.065a.375.375 0 0 1 .585.293v1.895c5.23 0 6.221 3.633 6.383 5.57a.375.375 0 0 1-.654.27C9.028 5.388 5.617 6.008 5.617 6.008v1.895a.375.375 0 0 1-.585.293L.234 4.598a.584.584 0 0 1 0-.935z"></path></svg> <span class="jsx-487597203 replyText">Reply</span></a><span class="jsx-487597203 divider desktopOnly"></span><a href="https://www.datacamp.com/community/tutorials/lstm-python-stock-market#comment-809" class="jsx-487597203"><span class="date desktopOnly">06/05/2018 01:39 AM</span></a></div><div class="jsx-487597203 spam"><svg title="Flag as spam" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 10 12"><path d="M9.708.265A.441.441 0 0 0 9.304 0H.441A.441.441 0 0 0 0 .441v11.118a.441.441 0 1 0 .882 0V6.532h8.422a.441.441 0 0 0 .322-.735L7.274 3.27 9.626.742a.441.441 0 0 0 .082-.477z"></path></svg></div></div></div></div></div></div><div class="jsx-2482332697 CommentLevel top"><div class="jsx-487597203 Comment"><div id="comment-810" class="jsx-487597203 anchor"></div><div class="jsx-487597203"><a href="https://www.datacamp.com/profile/gabemocan" target="_blank" class="jsx-487597203"><div class="jsx-3208234818 Avatar" style="background-image: url(&quot;https://res.cloudinary.com/dyd911kmh/image/fetch/t_avatar_thumbnail/https://cdn.datacamp.com/community/assets/placeholder_avatar-7f673b5d40e159404a56b5931250cc73.png&quot;); border-radius: 20px; min-width: 40px; min-height: 40px;"></div></a></div><div class="jsx-487597203 right"><div class="jsx-487597203 top"><div class="jsx-487597203"><a href="https://www.datacamp.com/profile/gabemocan" target="_blank" class="jsx-487597203 username">Gabriel Mocan</a></div><div class="jsx-487597203 more"></div></div><span class="date mobileOnly">06/05/2018 05:34 AM</span><div class="jsx-487597203 message"><p>Do you think that is possible to apply these techniques to Forex market? Feeding the system with real time data from let's say five minutes candles from the last month or so trying to predict the direction of the market for the next hours or so... Reducing the time frame a little bit but still having lots of data to feed the learning process.</p></div><div class="jsx-487597203 bottom"><div class="jsx-487597203 left"><div class="jsx-4192737526 Upvote comment"><div class="jsx-4192737526"><div class="jsx-4192737526 normal"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path d="M1 10L6 0l5 10z"></path></svg></span><span class="jsx-4192737526 count">1</span></div><div class="jsx-4192737526 voted"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path id="a" d="M9.769.435a1.255 1.255 0 0 1 1.81-.094 1.35 1.35 0 0 1 .09 1.865l-6.457 7.36a1.257 1.257 0 0 1-1.934-.04l-2.98-3.68a1.348 1.348 0 0 1 .162-1.86 1.255 1.255 0 0 1 1.805.168L4.3 6.667 9.77.435z"></path></svg></span><span class="jsx-4192737526 count">1</span></div></div></div><a class="jsx-487597203 replyIcon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="9" viewBox="0 0 12 9"><path d="M.234 3.663L5.032.065a.375.375 0 0 1 .585.293v1.895c5.23 0 6.221 3.633 6.383 5.57a.375.375 0 0 1-.654.27C9.028 5.388 5.617 6.008 5.617 6.008v1.895a.375.375 0 0 1-.585.293L.234 4.598a.584.584 0 0 1 0-.935z"></path></svg> <span class="jsx-487597203 replyText">Reply</span></a><span class="jsx-487597203 divider desktopOnly"></span><a href="https://www.datacamp.com/community/tutorials/lstm-python-stock-market#comment-810" class="jsx-487597203"><span class="date desktopOnly">06/05/2018 05:34 AM</span></a></div><div class="jsx-487597203 spam"><svg title="Flag as spam" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 10 12"><path d="M9.708.265A.441.441 0 0 0 9.304 0H.441A.441.441 0 0 0 0 .441v11.118a.441.441 0 1 0 .882 0V6.532h8.422a.441.441 0 0 0 .322-.735L7.274 3.27 9.626.742a.441.441 0 0 0 .082-.477z"></path></svg></div></div></div></div><div class="jsx-2482332697 CommentLevel"><div class="jsx-487597203 Comment"><div id="comment-811" class="jsx-487597203 anchor"></div><div class="jsx-487597203"><a href="https://www.datacamp.com/profile/thushv" target="_blank" class="jsx-487597203"><div class="jsx-3208234818 Avatar" style="background-image: url(&quot;https://res.cloudinary.com/dyd911kmh/image/fetch/t_avatar_thumbnail/https://assets.datacamp.com/users/avatars/002/125/563/square/profile.jpeg?1518563443&quot;); border-radius: 20px; min-width: 40px; min-height: 40px;"></div></a></div><div class="jsx-487597203 right"><div class="jsx-487597203 top"><div class="jsx-487597203"><a href="https://www.datacamp.com/profile/thushv" target="_blank" class="jsx-487597203 username">Thushan Ganegedara</a></div><div class="jsx-487597203 more"></div></div><span class="date mobileOnly">06/05/2018 11:49 PM</span><div class="jsx-487597203 message"><p>Hi,<br>
<br>
First of all I'm not really familiar with Forex market, neither have I looked at any tutorial specifically that deals with Forex. However, the problem formulation + objective is quite similar. So technically, it is possible to extend this method to Forex. But one point I'd like to stress is that, I wouldn't really recommend to make decisions just based on a simple framework that consist of one machine learning model. Because as you know, the markets are quite volatile. However machine learning definitely has potential for being used. If I'm to actually use machine learning for something like this, I'd go with a probabilistic model (I've seen people proposing probabilistic time-series models emerging recently). Then as we have the uncertainty metric, the predictions will be more reliable.<br>
</p></div><div class="jsx-487597203 bottom"><div class="jsx-487597203 left"><div class="jsx-4192737526 Upvote comment"><div class="jsx-4192737526"><div class="jsx-4192737526 normal"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path d="M1 10L6 0l5 10z"></path></svg></span><span class="jsx-4192737526 count">1</span></div><div class="jsx-4192737526 voted"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path id="a" d="M9.769.435a1.255 1.255 0 0 1 1.81-.094 1.35 1.35 0 0 1 .09 1.865l-6.457 7.36a1.257 1.257 0 0 1-1.934-.04l-2.98-3.68a1.348 1.348 0 0 1 .162-1.86 1.255 1.255 0 0 1 1.805.168L4.3 6.667 9.77.435z"></path></svg></span><span class="jsx-4192737526 count">1</span></div></div></div><a class="jsx-487597203 replyIcon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="9" viewBox="0 0 12 9"><path d="M.234 3.663L5.032.065a.375.375 0 0 1 .585.293v1.895c5.23 0 6.221 3.633 6.383 5.57a.375.375 0 0 1-.654.27C9.028 5.388 5.617 6.008 5.617 6.008v1.895a.375.375 0 0 1-.585.293L.234 4.598a.584.584 0 0 1 0-.935z"></path></svg> <span class="jsx-487597203 replyText">Reply</span></a><span class="jsx-487597203 divider desktopOnly"></span><a href="https://www.datacamp.com/community/tutorials/lstm-python-stock-market#comment-811" class="jsx-487597203"><span class="date desktopOnly">06/05/2018 11:49 PM</span></a></div><div class="jsx-487597203 spam"><svg title="Flag as spam" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 10 12"><path d="M9.708.265A.441.441 0 0 0 9.304 0H.441A.441.441 0 0 0 0 .441v11.118a.441.441 0 1 0 .882 0V6.532h8.422a.441.441 0 0 0 .322-.735L7.274 3.27 9.626.742a.441.441 0 0 0 .082-.477z"></path></svg></div></div></div></div><div class="jsx-2482332697 CommentLevel"><div class="jsx-487597203 Comment"><div id="comment-845" class="jsx-487597203 anchor"></div><div class="jsx-487597203"><a href="https://www.datacamp.com/profile/gabemocan" target="_blank" class="jsx-487597203"><div class="jsx-3208234818 Avatar" style="background-image: url(&quot;https://res.cloudinary.com/dyd911kmh/image/fetch/t_avatar_thumbnail/https://cdn.datacamp.com/community/assets/placeholder_avatar-7f673b5d40e159404a56b5931250cc73.png&quot;); border-radius: 20px; min-width: 40px; min-height: 40px;"></div></a></div><div class="jsx-487597203 right"><div class="jsx-487597203 top"><div class="jsx-487597203"><a href="https://www.datacamp.com/profile/gabemocan" target="_blank" class="jsx-487597203 username">Gabriel Mocan</a></div><div class="jsx-487597203 more"></div></div><span class="date mobileOnly">10/05/2018 04:57 AM</span><div class="jsx-487597203 message"><p>Thanks for the reply,</p>
<p>I'm a Python developer but don't have too much machine learn coding experience. It is too different from your tutorial to implement a probabilistic model as you mentioned? And, also, do you have any source that I could look at in order to achieve that? If you want to team-up, I have a certain level of market knowledge that would help in this project.</p>
<p>Thanks!</p></div><div class="jsx-487597203 bottom"><div class="jsx-487597203 left"><div class="jsx-4192737526 Upvote comment"><div class="jsx-4192737526"><div class="jsx-4192737526 normal"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path d="M1 10L6 0l5 10z"></path></svg></span><span class="jsx-4192737526 count">1</span></div><div class="jsx-4192737526 voted"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path id="a" d="M9.769.435a1.255 1.255 0 0 1 1.81-.094 1.35 1.35 0 0 1 .09 1.865l-6.457 7.36a1.257 1.257 0 0 1-1.934-.04l-2.98-3.68a1.348 1.348 0 0 1 .162-1.86 1.255 1.255 0 0 1 1.805.168L4.3 6.667 9.77.435z"></path></svg></span><span class="jsx-4192737526 count">1</span></div></div></div><span class="jsx-487597203 divider desktopOnly"></span><a href="https://www.datacamp.com/community/tutorials/lstm-python-stock-market#comment-845" class="jsx-487597203"><span class="date desktopOnly">10/05/2018 04:57 AM</span></a></div><div class="jsx-487597203 spam"><svg title="Flag as spam" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 10 12"><path d="M9.708.265A.441.441 0 0 0 9.304 0H.441A.441.441 0 0 0 0 .441v11.118a.441.441 0 1 0 .882 0V6.532h8.422a.441.441 0 0 0 .322-.735L7.274 3.27 9.626.742a.441.441 0 0 0 .082-.477z"></path></svg></div></div></div></div></div><div class="jsx-2482332697 CommentLevel"><div class="jsx-487597203 Comment"><div id="comment-852" class="jsx-487597203 anchor"></div><div class="jsx-487597203"><a href="https://www.datacamp.com/profile/thushv" target="_blank" class="jsx-487597203"><div class="jsx-3208234818 Avatar" style="background-image: url(&quot;https://res.cloudinary.com/dyd911kmh/image/fetch/t_avatar_thumbnail/https://assets.datacamp.com/users/avatars/002/125/563/square/profile.jpeg?1518563443&quot;); border-radius: 20px; min-width: 40px; min-height: 40px;"></div></a></div><div class="jsx-487597203 right"><div class="jsx-487597203 top"><div class="jsx-487597203"><a href="https://www.datacamp.com/profile/thushv" target="_blank" class="jsx-487597203 username">Thushan Ganegedara</a></div><div class="jsx-487597203 more"></div></div><span class="date mobileOnly">11/05/2018 12:48 AM</span><div class="jsx-487597203 message"><p>So regarding the probabilistic model, it can vary. For example there was a recent paper, https://arxiv.org/pdf/1804.07351.pdf which tries to address this. I'm not sure how much work is that. <br>
<br>
About actually getting into the stock market, well I'm not a big fan of actively participating in the stock market. I put up this tutorial, in pure machine learning interest, of whether there is any possibility for these models in stock market. But feel free to contact me on LinkedIn if you get your feet into implementing something and hit an obstacle.&nbsp;</p></div><div class="jsx-487597203 bottom"><div class="jsx-487597203 left"><div class="jsx-4192737526 Upvote comment"><div class="jsx-4192737526"><div class="jsx-4192737526 normal"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path d="M1 10L6 0l5 10z"></path></svg></span><span class="jsx-4192737526 count">1</span></div><div class="jsx-4192737526 voted"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path id="a" d="M9.769.435a1.255 1.255 0 0 1 1.81-.094 1.35 1.35 0 0 1 .09 1.865l-6.457 7.36a1.257 1.257 0 0 1-1.934-.04l-2.98-3.68a1.348 1.348 0 0 1 .162-1.86 1.255 1.255 0 0 1 1.805.168L4.3 6.667 9.77.435z"></path></svg></span><span class="jsx-4192737526 count">1</span></div></div></div><span class="jsx-487597203 divider desktopOnly"></span><a href="https://www.datacamp.com/community/tutorials/lstm-python-stock-market#comment-852" class="jsx-487597203"><span class="date desktopOnly">11/05/2018 12:48 AM</span></a></div><div class="jsx-487597203 spam"><svg title="Flag as spam" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 10 12"><path d="M9.708.265A.441.441 0 0 0 9.304 0H.441A.441.441 0 0 0 0 .441v11.118a.441.441 0 1 0 .882 0V6.532h8.422a.441.441 0 0 0 .322-.735L7.274 3.27 9.626.742a.441.441 0 0 0 .082-.477z"></path></svg></div></div></div></div></div></div></div><div class="jsx-2482332697 CommentLevel top"><div class="jsx-487597203 Comment"><div id="comment-812" class="jsx-487597203 anchor"></div><div class="jsx-487597203"><a href="https://www.datacamp.com/profile/yaserabdelaziz" target="_blank" class="jsx-487597203"><div class="jsx-3208234818 Avatar" style="background-image: url(&quot;https://res.cloudinary.com/dyd911kmh/image/fetch/t_avatar_thumbnail/https://graph.facebook.com/10209055654803915/picture?width=150&amp;height=150&quot;); border-radius: 20px; min-width: 40px; min-height: 40px;"></div></a></div><div class="jsx-487597203 right"><div class="jsx-487597203 top"><div class="jsx-487597203"><a href="https://www.datacamp.com/profile/yaserabdelaziz" target="_blank" class="jsx-487597203 username">Yaser Abdelaziz</a></div><div class="jsx-487597203 more"></div></div><span class="date mobileOnly">07/05/2018 09:28 AM</span><div class="jsx-487597203 message"><p>Hello Thushan Ganegedara,</p>
<p>First, thanks so much for this great tutorial, the other thing, could you recheck this part?</p>
<p>batch_labels[b]= self._prices[self._cursor[b]+np.random.randint(0,5)]</p>
<p>looks like it should use np.random.randint(1,5), as equations stated before (in this case N = 6).</p>
<p>Also I don't think this could be used for a real trading, it seems just predicting stock price going up if it was going up in the recent period, and vise-versa, is this observation right? are there an interesting observation about this I can't notice?</p></div><div class="jsx-487597203 bottom"><div class="jsx-487597203 left"><div class="jsx-4192737526 Upvote comment"><div class="jsx-4192737526"><div class="jsx-4192737526 normal"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path d="M1 10L6 0l5 10z"></path></svg></span><span class="jsx-4192737526 count">1</span></div><div class="jsx-4192737526 voted"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path id="a" d="M9.769.435a1.255 1.255 0 0 1 1.81-.094 1.35 1.35 0 0 1 .09 1.865l-6.457 7.36a1.257 1.257 0 0 1-1.934-.04l-2.98-3.68a1.348 1.348 0 0 1 .162-1.86 1.255 1.255 0 0 1 1.805.168L4.3 6.667 9.77.435z"></path></svg></span><span class="jsx-4192737526 count">1</span></div></div></div><a class="jsx-487597203 replyIcon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="9" viewBox="0 0 12 9"><path d="M.234 3.663L5.032.065a.375.375 0 0 1 .585.293v1.895c5.23 0 6.221 3.633 6.383 5.57a.375.375 0 0 1-.654.27C9.028 5.388 5.617 6.008 5.617 6.008v1.895a.375.375 0 0 1-.585.293L.234 4.598a.584.584 0 0 1 0-.935z"></path></svg> <span class="jsx-487597203 replyText">Reply</span></a><span class="jsx-487597203 divider desktopOnly"></span><a href="https://www.datacamp.com/community/tutorials/lstm-python-stock-market#comment-812" class="jsx-487597203"><span class="date desktopOnly">07/05/2018 09:28 AM</span></a></div><div class="jsx-487597203 spam"><svg title="Flag as spam" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 10 12"><path d="M9.708.265A.441.441 0 0 0 9.304 0H.441A.441.441 0 0 0 0 .441v11.118a.441.441 0 1 0 .882 0V6.532h8.422a.441.441 0 0 0 .322-.735L7.274 3.27 9.626.742a.441.441 0 0 0 .082-.477z"></path></svg></div></div></div></div><div class="jsx-2482332697 CommentLevel"><div class="jsx-487597203 Comment"><div id="comment-819" class="jsx-487597203 anchor"></div><div class="jsx-487597203"><a href="https://www.datacamp.com/profile/thushv" target="_blank" class="jsx-487597203"><div class="jsx-3208234818 Avatar" style="background-image: url(&quot;https://res.cloudinary.com/dyd911kmh/image/fetch/t_avatar_thumbnail/https://assets.datacamp.com/users/avatars/002/125/563/square/profile.jpeg?1518563443&quot;); border-radius: 20px; min-width: 40px; min-height: 40px;"></div></a></div><div class="jsx-487597203 right"><div class="jsx-487597203 top"><div class="jsx-487597203"><a href="https://www.datacamp.com/profile/thushv" target="_blank" class="jsx-487597203 username">Thushan Ganegedara</a></div><div class="jsx-487597203 more"></div></div><span class="date mobileOnly">07/05/2018 08:42 PM</span><div class="jsx-487597203 message"><p>Hi Yaser,</p>
<p>Good catch, yes it should be 1. I'll fix that in my code and try to get that fixed here as well.</p>
<p>About using the for real trading.</p>
<p>Well that's a risk you're taking. Even if you're the trading expert in the world there is no guarantee that you'll get it always right. So when an algorithm can predict things correctly after being trained for 30 minutes, compared to a person that learnt his whole life, I see some potential there. One thing you could do to make this model more reliable is to get a probabilistic output instead of a deterministic one. How you do that is upto you (e.g. get several models and calculate variance using their predictions).</p></div><div class="jsx-487597203 bottom"><div class="jsx-487597203 left"><div class="jsx-4192737526 Upvote comment"><div class="jsx-4192737526"><div class="jsx-4192737526 normal"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path d="M1 10L6 0l5 10z"></path></svg></span><span class="jsx-4192737526 count">2</span></div><div class="jsx-4192737526 voted"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path id="a" d="M9.769.435a1.255 1.255 0 0 1 1.81-.094 1.35 1.35 0 0 1 .09 1.865l-6.457 7.36a1.257 1.257 0 0 1-1.934-.04l-2.98-3.68a1.348 1.348 0 0 1 .162-1.86 1.255 1.255 0 0 1 1.805.168L4.3 6.667 9.77.435z"></path></svg></span><span class="jsx-4192737526 count">2</span></div></div></div><a class="jsx-487597203 replyIcon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="9" viewBox="0 0 12 9"><path d="M.234 3.663L5.032.065a.375.375 0 0 1 .585.293v1.895c5.23 0 6.221 3.633 6.383 5.57a.375.375 0 0 1-.654.27C9.028 5.388 5.617 6.008 5.617 6.008v1.895a.375.375 0 0 1-.585.293L.234 4.598a.584.584 0 0 1 0-.935z"></path></svg> <span class="jsx-487597203 replyText">Reply</span></a><span class="jsx-487597203 divider desktopOnly"></span><a href="https://www.datacamp.com/community/tutorials/lstm-python-stock-market#comment-819" class="jsx-487597203"><span class="date desktopOnly">07/05/2018 08:42 PM</span></a></div><div class="jsx-487597203 spam"><svg title="Flag as spam" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 10 12"><path d="M9.708.265A.441.441 0 0 0 9.304 0H.441A.441.441 0 0 0 0 .441v11.118a.441.441 0 1 0 .882 0V6.532h8.422a.441.441 0 0 0 .322-.735L7.274 3.27 9.626.742a.441.441 0 0 0 .082-.477z"></path></svg></div></div></div></div></div></div><div class="jsx-2482332697 CommentLevel top"><div class="jsx-487597203 Comment"><div id="comment-827" class="jsx-487597203 anchor"></div><div class="jsx-487597203"><a href="https://www.datacamp.com/profile/annabee97" target="_blank" class="jsx-487597203"><div class="jsx-3208234818 Avatar" style="background-image: url(&quot;https://res.cloudinary.com/dyd911kmh/image/fetch/t_avatar_thumbnail/https://cdn.datacamp.com/community/assets/placeholder_avatar-7f673b5d40e159404a56b5931250cc73.png&quot;); border-radius: 20px; min-width: 40px; min-height: 40px;"></div></a></div><div class="jsx-487597203 right"><div class="jsx-487597203 top"><div class="jsx-487597203"><a href="https://www.datacamp.com/profile/annabee97" target="_blank" class="jsx-487597203 username">annabee97</a></div><div class="jsx-487597203 more"></div></div><span class="date mobileOnly">08/05/2018 06:24 PM</span><div class="jsx-487597203 message"><p>Hello,&nbsp;</p>
<p>First of all, thank you! This post is a perfect combination of what I have been looking for! That being said, I am somewhat new to python (I have been using it for the past 5 months or so but sometimes the same things still stump me). For example, just trying to run the beginning/import the libraries I am getting errors with matplotlib.pyplot and pandas_reader. Any idea why? I really want to go through this tutorial but I can't even get past the first part!</p></div><div class="jsx-487597203 bottom"><div class="jsx-487597203 left"><div class="jsx-4192737526 Upvote comment"><div class="jsx-4192737526"><div class="jsx-4192737526 normal"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path d="M1 10L6 0l5 10z"></path></svg></span><span class="jsx-4192737526 count">0</span></div><div class="jsx-4192737526 voted"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path id="a" d="M9.769.435a1.255 1.255 0 0 1 1.81-.094 1.35 1.35 0 0 1 .09 1.865l-6.457 7.36a1.257 1.257 0 0 1-1.934-.04l-2.98-3.68a1.348 1.348 0 0 1 .162-1.86 1.255 1.255 0 0 1 1.805.168L4.3 6.667 9.77.435z"></path></svg></span><span class="jsx-4192737526 count">0</span></div></div></div><a class="jsx-487597203 replyIcon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="9" viewBox="0 0 12 9"><path d="M.234 3.663L5.032.065a.375.375 0 0 1 .585.293v1.895c5.23 0 6.221 3.633 6.383 5.57a.375.375 0 0 1-.654.27C9.028 5.388 5.617 6.008 5.617 6.008v1.895a.375.375 0 0 1-.585.293L.234 4.598a.584.584 0 0 1 0-.935z"></path></svg> <span class="jsx-487597203 replyText">Reply</span></a><span class="jsx-487597203 divider desktopOnly"></span><a href="https://www.datacamp.com/community/tutorials/lstm-python-stock-market#comment-827" class="jsx-487597203"><span class="date desktopOnly">08/05/2018 06:24 PM</span></a></div><div class="jsx-487597203 spam"><svg title="Flag as spam" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 10 12"><path d="M9.708.265A.441.441 0 0 0 9.304 0H.441A.441.441 0 0 0 0 .441v11.118a.441.441 0 1 0 .882 0V6.532h8.422a.441.441 0 0 0 .322-.735L7.274 3.27 9.626.742a.441.441 0 0 0 .082-.477z"></path></svg></div></div></div></div><div class="jsx-2482332697 CommentLevel"><div class="jsx-487597203 Comment"><div id="comment-830" class="jsx-487597203 anchor"></div><div class="jsx-487597203"><a href="https://www.datacamp.com/profile/thushv" target="_blank" class="jsx-487597203"><div class="jsx-3208234818 Avatar" style="background-image: url(&quot;https://res.cloudinary.com/dyd911kmh/image/fetch/t_avatar_thumbnail/https://assets.datacamp.com/users/avatars/002/125/563/square/profile.jpeg?1518563443&quot;); border-radius: 20px; min-width: 40px; min-height: 40px;"></div></a></div><div class="jsx-487597203 right"><div class="jsx-487597203 top"><div class="jsx-487597203"><a href="https://www.datacamp.com/profile/thushv" target="_blank" class="jsx-487597203 username">Thushan Ganegedara</a></div><div class="jsx-487597203 more"></div></div><span class="date mobileOnly">08/05/2018 08:41 PM</span><div class="jsx-487597203 message"><p>Do you have all the libraries installed? Tensorflow, pandas, matplotlib, ...</p>
<p>Also, I might be able to help better if you can post the error you're getting.</p></div><div class="jsx-487597203 bottom"><div class="jsx-487597203 left"><div class="jsx-4192737526 Upvote comment"><div class="jsx-4192737526"><div class="jsx-4192737526 normal"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path d="M1 10L6 0l5 10z"></path></svg></span><span class="jsx-4192737526 count">1</span></div><div class="jsx-4192737526 voted"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path id="a" d="M9.769.435a1.255 1.255 0 0 1 1.81-.094 1.35 1.35 0 0 1 .09 1.865l-6.457 7.36a1.257 1.257 0 0 1-1.934-.04l-2.98-3.68a1.348 1.348 0 0 1 .162-1.86 1.255 1.255 0 0 1 1.805.168L4.3 6.667 9.77.435z"></path></svg></span><span class="jsx-4192737526 count">1</span></div></div></div><a class="jsx-487597203 replyIcon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="9" viewBox="0 0 12 9"><path d="M.234 3.663L5.032.065a.375.375 0 0 1 .585.293v1.895c5.23 0 6.221 3.633 6.383 5.57a.375.375 0 0 1-.654.27C9.028 5.388 5.617 6.008 5.617 6.008v1.895a.375.375 0 0 1-.585.293L.234 4.598a.584.584 0 0 1 0-.935z"></path></svg> <span class="jsx-487597203 replyText">Reply</span></a><span class="jsx-487597203 divider desktopOnly"></span><a href="https://www.datacamp.com/community/tutorials/lstm-python-stock-market#comment-830" class="jsx-487597203"><span class="date desktopOnly">08/05/2018 08:41 PM</span></a></div><div class="jsx-487597203 spam"><svg title="Flag as spam" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 10 12"><path d="M9.708.265A.441.441 0 0 0 9.304 0H.441A.441.441 0 0 0 0 .441v11.118a.441.441 0 1 0 .882 0V6.532h8.422a.441.441 0 0 0 .322-.735L7.274 3.27 9.626.742a.441.441 0 0 0 .082-.477z"></path></svg></div></div></div></div><div class="jsx-2482332697 CommentLevel"><div class="jsx-487597203 Comment"><div id="comment-831" class="jsx-487597203 anchor"></div><div class="jsx-487597203"><a href="https://www.datacamp.com/profile/annabee97" target="_blank" class="jsx-487597203"><div class="jsx-3208234818 Avatar" style="background-image: url(&quot;https://res.cloudinary.com/dyd911kmh/image/fetch/t_avatar_thumbnail/https://cdn.datacamp.com/community/assets/placeholder_avatar-7f673b5d40e159404a56b5931250cc73.png&quot;); border-radius: 20px; min-width: 40px; min-height: 40px;"></div></a></div><div class="jsx-487597203 right"><div class="jsx-487597203 top"><div class="jsx-487597203"><a href="https://www.datacamp.com/profile/annabee97" target="_blank" class="jsx-487597203 username">annabee97</a></div><div class="jsx-487597203 more"></div></div><span class="date mobileOnly">09/05/2018 01:48 AM</span><div class="jsx-487597203 message"><p>I am getting the errors while trying to install the libraries. So really it's not directly related to your post so I understand if you don't know of the issue. It probably is a personal thing. Here is the error:</p>
<p><br></p>
<p>annas-mbp-2:~ annakoretchko$ pip3 install matplotlib.pyplot</p>
<p>Collecting matplotlib.pyplot</p>
<p>Could not find a version that satisfies the requirement matplotlib.pyplot (from versions: )</p>
<p>No matching distribution found for matplotlib.pyplot</p>
<p>annas-mbp-2:~ annakoretchko$&nbsp;</p></div><div class="jsx-487597203 bottom"><div class="jsx-487597203 left"><div class="jsx-4192737526 Upvote comment"><div class="jsx-4192737526"><div class="jsx-4192737526 normal"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path d="M1 10L6 0l5 10z"></path></svg></span><span class="jsx-4192737526 count">1</span></div><div class="jsx-4192737526 voted"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path id="a" d="M9.769.435a1.255 1.255 0 0 1 1.81-.094 1.35 1.35 0 0 1 .09 1.865l-6.457 7.36a1.257 1.257 0 0 1-1.934-.04l-2.98-3.68a1.348 1.348 0 0 1 .162-1.86 1.255 1.255 0 0 1 1.805.168L4.3 6.667 9.77.435z"></path></svg></span><span class="jsx-4192737526 count">1</span></div></div></div><span class="jsx-487597203 divider desktopOnly"></span><a href="https://www.datacamp.com/community/tutorials/lstm-python-stock-market#comment-831" class="jsx-487597203"><span class="date desktopOnly">09/05/2018 01:48 AM</span></a></div><div class="jsx-487597203 spam"><svg title="Flag as spam" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 10 12"><path d="M9.708.265A.441.441 0 0 0 9.304 0H.441A.441.441 0 0 0 0 .441v11.118a.441.441 0 1 0 .882 0V6.532h8.422a.441.441 0 0 0 .322-.735L7.274 3.27 9.626.742a.441.441 0 0 0 .082-.477z"></path></svg></div></div></div></div></div><div class="jsx-2482332697 CommentLevel"><div class="jsx-487597203 Comment"><div id="comment-833" class="jsx-487597203 anchor"></div><div class="jsx-487597203"><a href="https://www.datacamp.com/profile/annabee97" target="_blank" class="jsx-487597203"><div class="jsx-3208234818 Avatar" style="background-image: url(&quot;https://res.cloudinary.com/dyd911kmh/image/fetch/t_avatar_thumbnail/https://cdn.datacamp.com/community/assets/placeholder_avatar-7f673b5d40e159404a56b5931250cc73.png&quot;); border-radius: 20px; min-width: 40px; min-height: 40px;"></div></a></div><div class="jsx-487597203 right"><div class="jsx-487597203 top"><div class="jsx-487597203"><a href="https://www.datacamp.com/profile/annabee97" target="_blank" class="jsx-487597203 username">annabee97</a></div><div class="jsx-487597203 more"></div></div><span class="date mobileOnly">09/05/2018 04:45 AM</span><div class="jsx-487597203 message"><p>I actually was able to figure that out. &nbsp;Some weird thing on my computer. But now I can start with the rest of the tutorial which I am excited for! Thanks</p>
<p><br></p></div><div class="jsx-487597203 bottom"><div class="jsx-487597203 left"><div class="jsx-4192737526 Upvote comment"><div class="jsx-4192737526"><div class="jsx-4192737526 normal"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path d="M1 10L6 0l5 10z"></path></svg></span><span class="jsx-4192737526 count">2</span></div><div class="jsx-4192737526 voted"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path id="a" d="M9.769.435a1.255 1.255 0 0 1 1.81-.094 1.35 1.35 0 0 1 .09 1.865l-6.457 7.36a1.257 1.257 0 0 1-1.934-.04l-2.98-3.68a1.348 1.348 0 0 1 .162-1.86 1.255 1.255 0 0 1 1.805.168L4.3 6.667 9.77.435z"></path></svg></span><span class="jsx-4192737526 count">2</span></div></div></div><span class="jsx-487597203 divider desktopOnly"></span><a href="https://www.datacamp.com/community/tutorials/lstm-python-stock-market#comment-833" class="jsx-487597203"><span class="date desktopOnly">09/05/2018 04:45 AM</span></a></div><div class="jsx-487597203 spam"><svg title="Flag as spam" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 10 12"><path d="M9.708.265A.441.441 0 0 0 9.304 0H.441A.441.441 0 0 0 0 .441v11.118a.441.441 0 1 0 .882 0V6.532h8.422a.441.441 0 0 0 .322-.735L7.274 3.27 9.626.742a.441.441 0 0 0 .082-.477z"></path></svg></div></div></div></div></div></div></div><div class="jsx-2482332697 CommentLevel top"><div class="jsx-487597203 Comment"><div id="comment-834" class="jsx-487597203 anchor"></div><div class="jsx-487597203"><a href="https://www.datacamp.com/profile/hanimounla" target="_blank" class="jsx-487597203"><div class="jsx-3208234818 Avatar" style="background-image: url(&quot;https://res.cloudinary.com/dyd911kmh/image/fetch/t_avatar_thumbnail/https://assets.datacamp.com/users/avatars/000/834/790/square/HaniPic.jpg?1515879246&quot;); border-radius: 20px; min-width: 40px; min-height: 40px;"></div></a></div><div class="jsx-487597203 right"><div class="jsx-487597203 top"><div class="jsx-487597203"><a href="https://www.datacamp.com/profile/hanimounla" target="_blank" class="jsx-487597203 username">Hani  Mounla</a></div><div class="jsx-487597203 more"></div></div><span class="date mobileOnly">09/05/2018 05:30 AM</span><div class="jsx-487597203 message"><p>Awesome one !</p></div><div class="jsx-487597203 bottom"><div class="jsx-487597203 left"><div class="jsx-4192737526 Upvote comment"><div class="jsx-4192737526"><div class="jsx-4192737526 normal"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path d="M1 10L6 0l5 10z"></path></svg></span><span class="jsx-4192737526 count">1</span></div><div class="jsx-4192737526 voted"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path id="a" d="M9.769.435a1.255 1.255 0 0 1 1.81-.094 1.35 1.35 0 0 1 .09 1.865l-6.457 7.36a1.257 1.257 0 0 1-1.934-.04l-2.98-3.68a1.348 1.348 0 0 1 .162-1.86 1.255 1.255 0 0 1 1.805.168L4.3 6.667 9.77.435z"></path></svg></span><span class="jsx-4192737526 count">1</span></div></div></div><a class="jsx-487597203 replyIcon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="9" viewBox="0 0 12 9"><path d="M.234 3.663L5.032.065a.375.375 0 0 1 .585.293v1.895c5.23 0 6.221 3.633 6.383 5.57a.375.375 0 0 1-.654.27C9.028 5.388 5.617 6.008 5.617 6.008v1.895a.375.375 0 0 1-.585.293L.234 4.598a.584.584 0 0 1 0-.935z"></path></svg> <span class="jsx-487597203 replyText">Reply</span></a><span class="jsx-487597203 divider desktopOnly"></span><a href="https://www.datacamp.com/community/tutorials/lstm-python-stock-market#comment-834" class="jsx-487597203"><span class="date desktopOnly">09/05/2018 05:30 AM</span></a></div><div class="jsx-487597203 spam"><svg title="Flag as spam" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 10 12"><path d="M9.708.265A.441.441 0 0 0 9.304 0H.441A.441.441 0 0 0 0 .441v11.118a.441.441 0 1 0 .882 0V6.532h8.422a.441.441 0 0 0 .322-.735L7.274 3.27 9.626.742a.441.441 0 0 0 .082-.477z"></path></svg></div></div></div></div><div class="jsx-2482332697 CommentLevel"><div class="jsx-487597203 Comment"><div id="comment-837" class="jsx-487597203 anchor"></div><div class="jsx-487597203"><a href="https://www.datacamp.com/profile/thushv" target="_blank" class="jsx-487597203"><div class="jsx-3208234818 Avatar" style="background-image: url(&quot;https://res.cloudinary.com/dyd911kmh/image/fetch/t_avatar_thumbnail/https://assets.datacamp.com/users/avatars/002/125/563/square/profile.jpeg?1518563443&quot;); border-radius: 20px; min-width: 40px; min-height: 40px;"></div></a></div><div class="jsx-487597203 right"><div class="jsx-487597203 top"><div class="jsx-487597203"><a href="https://www.datacamp.com/profile/thushv" target="_blank" class="jsx-487597203 username">Thushan Ganegedara</a></div><div class="jsx-487597203 more"></div></div><span class="date mobileOnly">09/05/2018 08:48 AM</span><div class="jsx-487597203 message"><p>Thank you :)</p></div><div class="jsx-487597203 bottom"><div class="jsx-487597203 left"><div class="jsx-4192737526 Upvote comment"><div class="jsx-4192737526"><div class="jsx-4192737526 normal"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path d="M1 10L6 0l5 10z"></path></svg></span><span class="jsx-4192737526 count">2</span></div><div class="jsx-4192737526 voted"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path id="a" d="M9.769.435a1.255 1.255 0 0 1 1.81-.094 1.35 1.35 0 0 1 .09 1.865l-6.457 7.36a1.257 1.257 0 0 1-1.934-.04l-2.98-3.68a1.348 1.348 0 0 1 .162-1.86 1.255 1.255 0 0 1 1.805.168L4.3 6.667 9.77.435z"></path></svg></span><span class="jsx-4192737526 count">2</span></div></div></div><a class="jsx-487597203 replyIcon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="9" viewBox="0 0 12 9"><path d="M.234 3.663L5.032.065a.375.375 0 0 1 .585.293v1.895c5.23 0 6.221 3.633 6.383 5.57a.375.375 0 0 1-.654.27C9.028 5.388 5.617 6.008 5.617 6.008v1.895a.375.375 0 0 1-.585.293L.234 4.598a.584.584 0 0 1 0-.935z"></path></svg> <span class="jsx-487597203 replyText">Reply</span></a><span class="jsx-487597203 divider desktopOnly"></span><a href="https://www.datacamp.com/community/tutorials/lstm-python-stock-market#comment-837" class="jsx-487597203"><span class="date desktopOnly">09/05/2018 08:48 AM</span></a></div><div class="jsx-487597203 spam"><svg title="Flag as spam" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 10 12"><path d="M9.708.265A.441.441 0 0 0 9.304 0H.441A.441.441 0 0 0 0 .441v11.118a.441.441 0 1 0 .882 0V6.532h8.422a.441.441 0 0 0 .322-.735L7.274 3.27 9.626.742a.441.441 0 0 0 .082-.477z"></path></svg></div></div></div></div></div></div><div class="jsx-2482332697 CommentLevel top"><div class="jsx-487597203 Comment"><div id="comment-996" class="jsx-487597203 anchor"></div><div class="jsx-487597203"><a href="https://www.datacamp.com/profile/jaedukseo" target="_blank" class="jsx-487597203"><div class="jsx-3208234818 Avatar" style="background-image: url(&quot;https://res.cloudinary.com/dyd911kmh/image/fetch/t_avatar_thumbnail/https://assets.datacamp.com/users/avatars/002/129/563/square/Webp.net-resizeimage.png?1518640340&quot;); border-radius: 20px; min-width: 40px; min-height: 40px;"></div></a></div><div class="jsx-487597203 right"><div class="jsx-487597203 top"><div class="jsx-487597203"><a href="https://www.datacamp.com/profile/jaedukseo" target="_blank" class="jsx-487597203 username">Jae Duk  Seo</a></div><div class="jsx-487597203 more"></div></div><span class="date mobileOnly">30/05/2018 10:18 PM</span><div class="jsx-487597203 message"><p>One of the most informative tutorials I ever saw</p></div><div class="jsx-487597203 bottom"><div class="jsx-487597203 left"><div class="jsx-4192737526 Upvote comment"><div class="jsx-4192737526"><div class="jsx-4192737526 normal"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path d="M1 10L6 0l5 10z"></path></svg></span><span class="jsx-4192737526 count">2</span></div><div class="jsx-4192737526 voted"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path id="a" d="M9.769.435a1.255 1.255 0 0 1 1.81-.094 1.35 1.35 0 0 1 .09 1.865l-6.457 7.36a1.257 1.257 0 0 1-1.934-.04l-2.98-3.68a1.348 1.348 0 0 1 .162-1.86 1.255 1.255 0 0 1 1.805.168L4.3 6.667 9.77.435z"></path></svg></span><span class="jsx-4192737526 count">2</span></div></div></div><a class="jsx-487597203 replyIcon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="9" viewBox="0 0 12 9"><path d="M.234 3.663L5.032.065a.375.375 0 0 1 .585.293v1.895c5.23 0 6.221 3.633 6.383 5.57a.375.375 0 0 1-.654.27C9.028 5.388 5.617 6.008 5.617 6.008v1.895a.375.375 0 0 1-.585.293L.234 4.598a.584.584 0 0 1 0-.935z"></path></svg> <span class="jsx-487597203 replyText">Reply</span></a><span class="jsx-487597203 divider desktopOnly"></span><a href="https://www.datacamp.com/community/tutorials/lstm-python-stock-market#comment-996" class="jsx-487597203"><span class="date desktopOnly">30/05/2018 10:18 PM</span></a></div><div class="jsx-487597203 spam"><svg title="Flag as spam" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 10 12"><path d="M9.708.265A.441.441 0 0 0 9.304 0H.441A.441.441 0 0 0 0 .441v11.118a.441.441 0 1 0 .882 0V6.532h8.422a.441.441 0 0 0 .322-.735L7.274 3.27 9.626.742a.441.441 0 0 0 .082-.477z"></path></svg></div></div></div></div><div class="jsx-2482332697 CommentLevel"><div class="jsx-487597203 Comment"><div id="comment-997" class="jsx-487597203 anchor"></div><div class="jsx-487597203"><a href="https://www.datacamp.com/profile/thushv" target="_blank" class="jsx-487597203"><div class="jsx-3208234818 Avatar" style="background-image: url(&quot;https://res.cloudinary.com/dyd911kmh/image/fetch/t_avatar_thumbnail/https://assets.datacamp.com/users/avatars/002/125/563/square/profile.jpeg?1518563443&quot;); border-radius: 20px; min-width: 40px; min-height: 40px;"></div></a></div><div class="jsx-487597203 right"><div class="jsx-487597203 top"><div class="jsx-487597203"><a href="https://www.datacamp.com/profile/thushv" target="_blank" class="jsx-487597203 username">Thushan Ganegedara</a></div><div class="jsx-487597203 more"></div></div><span class="date mobileOnly">31/05/2018 03:49 AM</span><div class="jsx-487597203 message"><p>Thank you Jae</p></div><div class="jsx-487597203 bottom"><div class="jsx-487597203 left"><div class="jsx-4192737526 Upvote comment"><div class="jsx-4192737526"><div class="jsx-4192737526 normal"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path d="M1 10L6 0l5 10z"></path></svg></span><span class="jsx-4192737526 count">1</span></div><div class="jsx-4192737526 voted"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path id="a" d="M9.769.435a1.255 1.255 0 0 1 1.81-.094 1.35 1.35 0 0 1 .09 1.865l-6.457 7.36a1.257 1.257 0 0 1-1.934-.04l-2.98-3.68a1.348 1.348 0 0 1 .162-1.86 1.255 1.255 0 0 1 1.805.168L4.3 6.667 9.77.435z"></path></svg></span><span class="jsx-4192737526 count">1</span></div></div></div><a class="jsx-487597203 replyIcon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="9" viewBox="0 0 12 9"><path d="M.234 3.663L5.032.065a.375.375 0 0 1 .585.293v1.895c5.23 0 6.221 3.633 6.383 5.57a.375.375 0 0 1-.654.27C9.028 5.388 5.617 6.008 5.617 6.008v1.895a.375.375 0 0 1-.585.293L.234 4.598a.584.584 0 0 1 0-.935z"></path></svg> <span class="jsx-487597203 replyText">Reply</span></a><span class="jsx-487597203 divider desktopOnly"></span><a href="https://www.datacamp.com/community/tutorials/lstm-python-stock-market#comment-997" class="jsx-487597203"><span class="date desktopOnly">31/05/2018 03:49 AM</span></a></div><div class="jsx-487597203 spam"><svg title="Flag as spam" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 10 12"><path d="M9.708.265A.441.441 0 0 0 9.304 0H.441A.441.441 0 0 0 0 .441v11.118a.441.441 0 1 0 .882 0V6.532h8.422a.441.441 0 0 0 .322-.735L7.274 3.27 9.626.742a.441.441 0 0 0 .082-.477z"></path></svg></div></div></div></div></div></div><div class="jsx-2482332697 CommentLevel top"><div class="jsx-487597203 Comment"><div id="comment-1019" class="jsx-487597203 anchor"></div><div class="jsx-487597203"><a href="https://www.datacamp.com/profile/dcvhouten" target="_blank" class="jsx-487597203"><div class="jsx-3208234818 Avatar" style="background-image: url(&quot;https://res.cloudinary.com/dyd911kmh/image/fetch/t_avatar_thumbnail/https://graph.facebook.com/10155236467932186/picture?width=150&amp;height=150&quot;); border-radius: 20px; min-width: 40px; min-height: 40px;"></div></a></div><div class="jsx-487597203 right"><div class="jsx-487597203 top"><div class="jsx-487597203"><a href="https://www.datacamp.com/profile/dcvhouten" target="_blank" class="jsx-487597203 username">Diederik Van Houten</a></div><div class="jsx-487597203 more"></div></div><span class="date mobileOnly">02/06/2018 08:35 PM</span><div class="jsx-487597203 message"><p>Really nice tutorial - However I am having issues running this right from the beginning: Getting Import errors (i.e. ImportError: cannot import name 'is_list_like'</p>
<p>) when trying to import pandas - datareader. I understand that this is a bug and the development version of datareader has fixed this. However being quite new to Python I have not figured out a way to fix this.&nbsp; pip install will not fix this. Appreciate any help.</p></div><div class="jsx-487597203 bottom"><div class="jsx-487597203 left"><div class="jsx-4192737526 Upvote comment"><div class="jsx-4192737526"><div class="jsx-4192737526 normal"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path d="M1 10L6 0l5 10z"></path></svg></span><span class="jsx-4192737526 count">2</span></div><div class="jsx-4192737526 voted"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path id="a" d="M9.769.435a1.255 1.255 0 0 1 1.81-.094 1.35 1.35 0 0 1 .09 1.865l-6.457 7.36a1.257 1.257 0 0 1-1.934-.04l-2.98-3.68a1.348 1.348 0 0 1 .162-1.86 1.255 1.255 0 0 1 1.805.168L4.3 6.667 9.77.435z"></path></svg></span><span class="jsx-4192737526 count">2</span></div></div></div><a class="jsx-487597203 replyIcon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="9" viewBox="0 0 12 9"><path d="M.234 3.663L5.032.065a.375.375 0 0 1 .585.293v1.895c5.23 0 6.221 3.633 6.383 5.57a.375.375 0 0 1-.654.27C9.028 5.388 5.617 6.008 5.617 6.008v1.895a.375.375 0 0 1-.585.293L.234 4.598a.584.584 0 0 1 0-.935z"></path></svg> <span class="jsx-487597203 replyText">Reply</span></a><span class="jsx-487597203 divider desktopOnly"></span><a href="https://www.datacamp.com/community/tutorials/lstm-python-stock-market#comment-1019" class="jsx-487597203"><span class="date desktopOnly">02/06/2018 08:35 PM</span></a></div><div class="jsx-487597203 spam"><svg title="Flag as spam" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 10 12"><path d="M9.708.265A.441.441 0 0 0 9.304 0H.441A.441.441 0 0 0 0 .441v11.118a.441.441 0 1 0 .882 0V6.532h8.422a.441.441 0 0 0 .322-.735L7.274 3.27 9.626.742a.441.441 0 0 0 .082-.477z"></path></svg></div></div></div></div><div class="jsx-2482332697 CommentLevel"><div class="jsx-487597203 Comment"><div id="comment-1021" class="jsx-487597203 anchor"></div><div class="jsx-487597203"><a href="https://www.datacamp.com/profile/dcvhouten" target="_blank" class="jsx-487597203"><div class="jsx-3208234818 Avatar" style="background-image: url(&quot;https://res.cloudinary.com/dyd911kmh/image/fetch/t_avatar_thumbnail/https://graph.facebook.com/10155236467932186/picture?width=150&amp;height=150&quot;); border-radius: 20px; min-width: 40px; min-height: 40px;"></div></a></div><div class="jsx-487597203 right"><div class="jsx-487597203 top"><div class="jsx-487597203"><a href="https://www.datacamp.com/profile/dcvhouten" target="_blank" class="jsx-487597203 username">Diederik Van Houten</a></div><div class="jsx-487597203 more"></div></div><span class="date mobileOnly">02/06/2018 08:45 PM</span><div class="jsx-487597203 message"><p>Found a fix - see https://github.com/pydata/pandas-datareader/pull/520</p></div><div class="jsx-487597203 bottom"><div class="jsx-487597203 left"><div class="jsx-4192737526 Upvote comment"><div class="jsx-4192737526"><div class="jsx-4192737526 normal"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path d="M1 10L6 0l5 10z"></path></svg></span><span class="jsx-4192737526 count">1</span></div><div class="jsx-4192737526 voted"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path id="a" d="M9.769.435a1.255 1.255 0 0 1 1.81-.094 1.35 1.35 0 0 1 .09 1.865l-6.457 7.36a1.257 1.257 0 0 1-1.934-.04l-2.98-3.68a1.348 1.348 0 0 1 .162-1.86 1.255 1.255 0 0 1 1.805.168L4.3 6.667 9.77.435z"></path></svg></span><span class="jsx-4192737526 count">1</span></div></div></div><a class="jsx-487597203 replyIcon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="9" viewBox="0 0 12 9"><path d="M.234 3.663L5.032.065a.375.375 0 0 1 .585.293v1.895c5.23 0 6.221 3.633 6.383 5.57a.375.375 0 0 1-.654.27C9.028 5.388 5.617 6.008 5.617 6.008v1.895a.375.375 0 0 1-.585.293L.234 4.598a.584.584 0 0 1 0-.935z"></path></svg> <span class="jsx-487597203 replyText">Reply</span></a><span class="jsx-487597203 divider desktopOnly"></span><a href="https://www.datacamp.com/community/tutorials/lstm-python-stock-market#comment-1021" class="jsx-487597203"><span class="date desktopOnly">02/06/2018 08:45 PM</span></a></div><div class="jsx-487597203 spam"><svg title="Flag as spam" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 10 12"><path d="M9.708.265A.441.441 0 0 0 9.304 0H.441A.441.441 0 0 0 0 .441v11.118a.441.441 0 1 0 .882 0V6.532h8.422a.441.441 0 0 0 .322-.735L7.274 3.27 9.626.742a.441.441 0 0 0 .082-.477z"></path></svg></div></div></div></div></div><div class="jsx-2482332697 CommentLevel"><div class="jsx-487597203 Comment"><div id="comment-1028" class="jsx-487597203 anchor"></div><div class="jsx-487597203"><a href="https://www.datacamp.com/profile/thushv" target="_blank" class="jsx-487597203"><div class="jsx-3208234818 Avatar" style="background-image: url(&quot;https://res.cloudinary.com/dyd911kmh/image/fetch/t_avatar_thumbnail/https://assets.datacamp.com/users/avatars/002/125/563/square/profile.jpeg?1518563443&quot;); border-radius: 20px; min-width: 40px; min-height: 40px;"></div></a></div><div class="jsx-487597203 right"><div class="jsx-487597203 top"><div class="jsx-487597203"><a href="https://www.datacamp.com/profile/thushv" target="_blank" class="jsx-487597203 username">Thushan Ganegedara</a></div><div class="jsx-487597203 more"></div></div><span class="date mobileOnly">03/06/2018 10:37 PM</span><div class="jsx-487597203 message"><p>Hi Diederik,<br>
</p>
<p>Sorry I couldn't reply to you in time. But glad you found the solution.</p></div><div class="jsx-487597203 bottom"><div class="jsx-487597203 left"><div class="jsx-4192737526 Upvote comment"><div class="jsx-4192737526"><div class="jsx-4192737526 normal"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path d="M1 10L6 0l5 10z"></path></svg></span><span class="jsx-4192737526 count">1</span></div><div class="jsx-4192737526 voted"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path id="a" d="M9.769.435a1.255 1.255 0 0 1 1.81-.094 1.35 1.35 0 0 1 .09 1.865l-6.457 7.36a1.257 1.257 0 0 1-1.934-.04l-2.98-3.68a1.348 1.348 0 0 1 .162-1.86 1.255 1.255 0 0 1 1.805.168L4.3 6.667 9.77.435z"></path></svg></span><span class="jsx-4192737526 count">1</span></div></div></div><a class="jsx-487597203 replyIcon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="9" viewBox="0 0 12 9"><path d="M.234 3.663L5.032.065a.375.375 0 0 1 .585.293v1.895c5.23 0 6.221 3.633 6.383 5.57a.375.375 0 0 1-.654.27C9.028 5.388 5.617 6.008 5.617 6.008v1.895a.375.375 0 0 1-.585.293L.234 4.598a.584.584 0 0 1 0-.935z"></path></svg> <span class="jsx-487597203 replyText">Reply</span></a><span class="jsx-487597203 divider desktopOnly"></span><a href="https://www.datacamp.com/community/tutorials/lstm-python-stock-market#comment-1028" class="jsx-487597203"><span class="date desktopOnly">03/06/2018 10:37 PM</span></a></div><div class="jsx-487597203 spam"><svg title="Flag as spam" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 10 12"><path d="M9.708.265A.441.441 0 0 0 9.304 0H.441A.441.441 0 0 0 0 .441v11.118a.441.441 0 1 0 .882 0V6.532h8.422a.441.441 0 0 0 .322-.735L7.274 3.27 9.626.742a.441.441 0 0 0 .082-.477z"></path></svg></div></div></div></div></div></div><div class="jsx-2482332697 CommentLevel top"><div class="jsx-487597203 Comment"><div id="comment-1054" class="jsx-487597203 anchor"></div><div class="jsx-487597203"><a href="https://www.datacamp.com/profile/dhanunjayalakshmi60" target="_blank" class="jsx-487597203"><div class="jsx-3208234818 Avatar" style="background-image: url(&quot;https://res.cloudinary.com/dyd911kmh/image/fetch/t_avatar_thumbnail/https://cdn.datacamp.com/community/assets/placeholder_avatar-7f673b5d40e159404a56b5931250cc73.png&quot;); border-radius: 20px; min-width: 40px; min-height: 40px;"></div></a></div><div class="jsx-487597203 right"><div class="jsx-487597203 top"><div class="jsx-487597203"><a href="https://www.datacamp.com/profile/dhanunjayalakshmi60" target="_blank" class="jsx-487597203 username">Dhanunjaya Lakshmi</a></div><div class="jsx-487597203 more"></div></div><span class="date mobileOnly">07/06/2018 06:05 AM</span><div class="jsx-487597203 message"><p>I observed that the alphavantage is returning only 3195 data points now. Not sure if they have updated their API after this tutorial got published. So, we may need to modify the test and train data sets split accordingly.</p></div><div class="jsx-487597203 bottom"><div class="jsx-487597203 left"><div class="jsx-4192737526 Upvote comment"><div class="jsx-4192737526"><div class="jsx-4192737526 normal"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path d="M1 10L6 0l5 10z"></path></svg></span><span class="jsx-4192737526 count">1</span></div><div class="jsx-4192737526 voted"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path id="a" d="M9.769.435a1.255 1.255 0 0 1 1.81-.094 1.35 1.35 0 0 1 .09 1.865l-6.457 7.36a1.257 1.257 0 0 1-1.934-.04l-2.98-3.68a1.348 1.348 0 0 1 .162-1.86 1.255 1.255 0 0 1 1.805.168L4.3 6.667 9.77.435z"></path></svg></span><span class="jsx-4192737526 count">1</span></div></div></div><a class="jsx-487597203 replyIcon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="9" viewBox="0 0 12 9"><path d="M.234 3.663L5.032.065a.375.375 0 0 1 .585.293v1.895c5.23 0 6.221 3.633 6.383 5.57a.375.375 0 0 1-.654.27C9.028 5.388 5.617 6.008 5.617 6.008v1.895a.375.375 0 0 1-.585.293L.234 4.598a.584.584 0 0 1 0-.935z"></path></svg> <span class="jsx-487597203 replyText">Reply</span></a><span class="jsx-487597203 divider desktopOnly"></span><a href="https://www.datacamp.com/community/tutorials/lstm-python-stock-market#comment-1054" class="jsx-487597203"><span class="date desktopOnly">07/06/2018 06:05 AM</span></a></div><div class="jsx-487597203 spam"><svg title="Flag as spam" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 10 12"><path d="M9.708.265A.441.441 0 0 0 9.304 0H.441A.441.441 0 0 0 0 .441v11.118a.441.441 0 1 0 .882 0V6.532h8.422a.441.441 0 0 0 .322-.735L7.274 3.27 9.626.742a.441.441 0 0 0 .082-.477z"></path></svg></div></div></div></div><div class="jsx-2482332697 CommentLevel"><div class="jsx-487597203 Comment"><div id="comment-1056" class="jsx-487597203 anchor"></div><div class="jsx-487597203"><a href="https://www.datacamp.com/profile/thushv" target="_blank" class="jsx-487597203"><div class="jsx-3208234818 Avatar" style="background-image: url(&quot;https://res.cloudinary.com/dyd911kmh/image/fetch/t_avatar_thumbnail/https://assets.datacamp.com/users/avatars/002/125/563/square/profile.jpeg?1518563443&quot;); border-radius: 20px; min-width: 40px; min-height: 40px;"></div></a></div><div class="jsx-487597203 right"><div class="jsx-487597203 top"><div class="jsx-487597203"><a href="https://www.datacamp.com/profile/thushv" target="_blank" class="jsx-487597203 username">Thushan Ganegedara</a></div><div class="jsx-487597203 more"></div></div><span class="date mobileOnly">07/06/2018 07:21 AM</span><div class="jsx-487597203 message"><p>That's right. And also make sure the data normalization stage normalizes "all" the data to a reasonably varying range as well.</p></div><div class="jsx-487597203 bottom"><div class="jsx-487597203 left"><div class="jsx-4192737526 Upvote comment"><div class="jsx-4192737526"><div class="jsx-4192737526 normal"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path d="M1 10L6 0l5 10z"></path></svg></span><span class="jsx-4192737526 count">1</span></div><div class="jsx-4192737526 voted"><span class="jsx-4192737526 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path id="a" d="M9.769.435a1.255 1.255 0 0 1 1.81-.094 1.35 1.35 0 0 1 .09 1.865l-6.457 7.36a1.257 1.257 0 0 1-1.934-.04l-2.98-3.68a1.348 1.348 0 0 1 .162-1.86 1.255 1.255 0 0 1 1.805.168L4.3 6.667 9.77.435z"></path></svg></span><span class="jsx-4192737526 count">1</span></div></div></div><a class="jsx-487597203 replyIcon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="9" viewBox="0 0 12 9"><path d="M.234 3.663L5.032.065a.375.375 0 0 1 .585.293v1.895c5.23 0 6.221 3.633 6.383 5.57a.375.375 0 0 1-.654.27C9.028 5.388 5.617 6.008 5.617 6.008v1.895a.375.375 0 0 1-.585.293L.234 4.598a.584.584 0 0 1 0-.935z"></path></svg> <span class="jsx-487597203 replyText">Reply</span></a><span class="jsx-487597203 divider desktopOnly"></span><a href="https://www.datacamp.com/community/tutorials/lstm-python-stock-market#comment-1056" class="jsx-487597203"><span class="date desktopOnly">07/06/2018 07:21 AM</span></a></div><div class="jsx-487597203 spam"><svg title="Flag as spam" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 10 12"><path d="M9.708.265A.441.441 0 0 0 9.304 0H.441A.441.441 0 0 0 0 .441v11.118a.441.441 0 1 0 .882 0V6.532h8.422a.441.441 0 0 0 .322-.735L7.274 3.27 9.626.742a.441.441 0 0 0 .082-.477z"></path></svg></div></div></div></div></div></div></div></div></main><div class="jsx-3269835606 SidebarSocial"><div class="jsx-3269835606 rss"><a href="https://www.datacamp.com/community/rss.xml" class="jsx-3269835606"><svg height="13" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 18 18"><circle cx="3.08" cy="14.92" r="3.08"></circle><path d="M16.46 18a1.54 1.54 0 0 1-1.54-1.54c0-8.25-5.13-13.38-13.38-13.38A1.59 1.59 0 0 1 .46 1.15 1.72 1.72 0 0 1 1.54 0a16.45 16.45 0 0 1 12 4.51c3 2.95 4.51 7.08 4.51 12A1.54 1.54 0 0 1 16.46 18z"></path><path d="M10.63 18a1.54 1.54 0 0 1-1.54-1.54c0-5-2.54-7.54-7.54-7.54a1.54 1.54 0 0 1 0-3.08c6.75 0 10.63 3.87 10.63 10.62A1.54 1.54 0 0 1 10.63 18z"></path></svg>Subscribe to RSS</a></div><div class="jsx-3269835606 icons"><a href="https://www.facebook.com/pages/DataCamp/726282547396228" target="_blank" rel="noopener noreferrer" class="jsx-3269835606 icon"><svg height="16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 11.73 22.58"><path d="M7.61 22.58v-10.3h3.46l.52-4h-4V5.7c0-1.16.32-2 2-2h2.13V.16A28.47 28.47 0 0 0 8.63 0C5.56 0 3.47 1.87 3.47 5.31v3H0v4h3.47v10.3h4.14z"></path></svg></a><a href="https://twitter.com/datacamp" target="_blank" rel="noopener noreferrer" class="jsx-3269835606 icon"><svg height="13" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20.42 16.67"><path d="M10 5.18c0-.28-.06-.53-.07-.78a4 4 0 0 1 .73-2.57A4.08 4.08 0 0 1 13.93 0 4 4 0 0 1 17 1.15a.43.43 0 0 0 .46.12 8.68 8.68 0 0 0 2.2-.84l.2-.1a4.36 4.36 0 0 1-1.75 2.28A9 9 0 0 0 20.42 2l-.21.3a3.83 3.83 0 0 1-.23.3A8.45 8.45 0 0 1 18.5 4a.28.28 0 0 0-.13.27A12 12 0 0 1 17 10.18a11.8 11.8 0 0 1-3.37 4.11 11.17 11.17 0 0 1-4.39 2.06 12.53 12.53 0 0 1-4.44.22 11.87 11.87 0 0 1-4.74-1.73L0 14.79a8.6 8.6 0 0 0 6.16-1.74 4.28 4.28 0 0 1-3.91-2.91h.95a6.18 6.18 0 0 0 .89-.12A4.2 4.2 0 0 1 .8 5.88a4 4 0 0 0 1.81.49 4.23 4.23 0 0 1-1.78-3A4.07 4.07 0 0 1 1.38.79 12.06 12.06 0 0 0 10 5.18z" id="iOjKBC.tif"></path></svg></a><a href="https://www.linkedin.com/company/datamind-org" target="_blank" rel="noopener noreferrer" class="jsx-3269835606 icon"><svg height="12" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16.99 17"><path d="M3.85 17H.34V5.67h3.51zM2.07 4.18a2.09 2.09 0 1 1 2.08-2.09 2.08 2.08 0 0 1-2.08 2.09zM17 17h-3.5v-5.95c0-1.63-.62-2.54-1.91-2.54s-2.14.95-2.14 2.54V17H6.09V5.67h3.36v1.52a4 4 0 0 1 3.42-1.87c2.4 0 4.12 1.47 4.12 4.5V17z"></path></svg></a><a href="https://www.youtube.com/channel/UC79Gv3mYp6zKiSwYemEik9A" target="_blank" rel="noopener noreferrer" class="jsx-3269835606 icon"><svg height="12" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 25.19 17.73"><path d="M24.21 1.52C23.3.44 21.62 0 18.42 0H6.78C3.5 0 1.79.47.88 1.62S0 4.4 0 6.68V11c0 4.43 1 6.68 6.78 6.68h11.64c2.78 0 4.32-.39 5.32-1.34S25.2 13.76 25.2 11V6.68c-.01-2.41-.08-4.07-.99-5.16zm-8 7.94l-5.29 2.76a.81.81 0 0 1-1.19-.72V6a.81.81 0 0 1 1.19-.72L16.17 8a.81.81 0 0 1 0 1.44z"></path></svg></a></div><div class="jsx-3269835606 menu"><a href="https://www.datacamp.com/about" class="jsx-3269835606 menuItem">About</a><a href="https://www.datacamp.com/terms-of-use" class="jsx-3269835606 menuItem">Terms</a><a href="https://www.datacamp.com/privacy-policy" class="jsx-3269835606 menuItem">Privacy</a></div></div><div class="jsx-3994298077 BottomBar bar"><div class="jsx-3994298077 barView"><div class="jsx-3208234818 Avatar" style="background-image: url(&quot;https://res.cloudinary.com/dyd911kmh/image/fetch/t_avatar_thumbnail/https://cdn.datacamp.com/community/assets/placeholder_avatar-7f673b5d40e159404a56b5931250cc73.png&quot;); border-radius: 20px; min-width: 40px; min-height: 40px;"></div><div class="jsx-3994298077 blueBar">Want to leave a comment?</div></div></div></div><link href="./LSTM in Python_ Stock Market Predictions (article) - DataCamp_files/css(2)" rel="stylesheet"><div class="Analytics"><script>
      ;(function(p,l,o,w,i,n,g){if(!p[i]){p.GlobalSnowplowNamespace=p.GlobalSnowplowNamespace||[];
        p.GlobalSnowplowNamespace.push(i);p[i]=function(){(p[i].q=p[i].q||[]).push(arguments)
        };p[i].q=p[i].q||[];n=l.createElement(o);g=l.getElementsByTagName(o)[0];n.async=1;
        n.src=w;g.parentNode.insertBefore(n,g)}}(window,document,"script","//d36fqcuygdrd4y.cloudfront.net/BuKMCyKUvvyXZkMi44LjI.js","snowplow"));

      window.snowplow('newTracker', 'co', 'track.datacamp.com', {
        platform: 'web',
        post: true,
        discoverRootDomain: true,
        contexts: {
          webPage: true,
          performanceTiming: true
        }
      });
      window.snowplow('enableActivityTracking', 10, 10);
      window.snowplow('enableLinkClickTracking');
    </script><script data-cfasync="false">(function(W,i,s,e,P,o,p){W['WisePopsObject']=P;W[P]=W[P]||function(){
      (W[P].q=W[P].q||[]).push(arguments)},W[P].l=1*new Date();o=i.createElement(s),
      p=i.getElementsByTagName(s)[0];o.async=1;o.src=e;p.parentNode.insertBefore(o,p)
    })(window,document,'script','//loader.wisepops.com/get-loader.js?v=1&site=VswVJn7o4J','wisepops');</script></div></div></div></div><div id="__next-error"></div><script>
          __NEXT_DATA__ = {"props":{"isServer":true,"store":{},"initialState":{"adminContent":{"isFetching":false,"isFetched":false,"statusMessage":"","content":{},"form":{"isSaving":false,"isSucceeded":false,"statusMessage":"","isAdminFormModalOpen":false,"previewSlug":""},"delete":{"isDeleting":false,"isSucceeded":false,"statusMessage":"","isDeleteAdminContentModalOpen":false},"update":{"isApprovingArticle":false,"isSucceeded":false,"statusMessage":"","isApproveArticleModalOpen":false}},"adminList":{"isFetched":false,"isFetching":false,"statusMessage":""},"auth":{"isAuthModalOpen":false,"isLogin":false,"isAuthorized":false,"isSubscriber":false,"user":{},"loginTitle":"","signUpTitle":""},"clientConfig":{"isDevelopment":false,"absoluteUrl":"https://www.datacamp.com","isNewsActive":true,"ALGOLIA_APP_ID":"7H5IORUQLD","ALGOLIA_API_KEY":"ae6cc3c278ce31c9e334adc652020c2a","ALGOLIA_API_INDEX":"community_prod","DC_COMMUNITY_AUTHOR_APP_URL":"http://datacamp-community-author.us-east-1.elasticbeanstalk.com/","DC_LIGHT_URL":"https://cdn.datacamp.com/datacamp-light-latest.min.js","ANALYTICS_GOOGLE_TAG_MANAGER":"GTM-TGGWB2P","ANALYTICS_SNOWPLOW_ENDPOINT":"track.datacamp.com","WISEPOPS":"VswVJn7o4J","CHAT_SUBSCRIBER_REDIRECT":"https://www.datacamp.com/slack/join","CHAT_NONSUBSCRIBER_LINK":"https://www.datacamp.com/subscribe?from_communitychat=true","CHAT_SUBSCRIBE_TEAM":"https://www.datacamp.com/groups/business"},"comment":{"isFetching":false,"isFetched":false,"statusMessage":"","comments":[],"commentsTotal":0,"form":{"isSaving":false,"isSucceeded":false,"statusMessage":"","id":"new","parentId":null,"commentText":""},"delete":{"isDeleting":false,"isSucceeded":false,"statusMessage":"","isDeleteCommentModalOpen":false},"isBottomBarOpen":false,"bottomBarView":"bar"},"content":{"content":{"tags":[],"author":{}},"isFetched":false,"isFetching":false,"statusMessage":""},"countdownBanner":{"banner":{"showBanner":false,"title":"","text":"","startDate":"","endDate":"","link":""},"isBannerOpen":false},"form":{},"list":{"isFetched":true,"isFetching":false,"statusMessage":"","Tutorial":[{"id":10112,"externalId":null,"type":"Tutorial","status":"published","authorId":"tommyjee","title":"Converting Strings to Dates as datetime Objects","slug":"converting-strings-datetime-objects","previewSlug":null,"description":"Learn how to convert strings to datetime objects in Python and why doing so has become standard practice for working data scientists today.","articles":[],"courses":[],"redirectSlug":null,"contentHtml":"\u003cp\u003eAnalyzing datasets with dates and times is often very cumbersome. Months of different lengths, different distributions of weekdays and weekends, leap years, and the dreaded timezones are just a few things you may have to consider depending on your context. For this reason, Python has a data type specifically designed for dates and times called \u003ccode\u003edatetime\u003c/code\u003e.\u003c/p\u003e\r\n\u003cp\u003eHowever, in many datasets, you\u0026#39;ll find that dates are represented as strings. So, in this tutorial, you\u0026#39;ll learn how to convert date strings to the \u003ccode\u003edatetime\u003c/code\u003e format and see how you can use its powerful set of tools to work effectively with complicated time series data.\u003c/p\u003e\r\n\u003ch3 id=\"dealing-with-different-representations-of-dates\"\u003eDealing with different representations of dates\u003c/h3\u003e\r\n\u003cp\u003eThe main challenge is often specifying how date strings are expressed. For example, \u003ccode\u003e\u0026#39;Wednesday, June 6, 2018\u0026#39;\u003c/code\u003e can be represented as \u003ccode\u003e\u0026#39;6/6/18\u0026#39;\u003c/code\u003e and \u003ccode\u003e\u0026#39;06-06-2018\u0026#39;\u003c/code\u003e too. These all inform you of the same date, but you can probably imagine that the code to convert each of these is slightly different. Take a moment to examine the function calls below:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003efrom datetime import datetime\r\n\r\n# Define dates as strings\r\ndate_str1 = \u0026#39;Wednesday, June 6, 2018\u0026#39;\r\ndate_str2 = \u0026#39;6/6/18\u0026#39;\r\ndate_str3 = \u0026#39;06-06-2018\u0026#39;\r\n\r\n# Define dates as datetime objects\r\ndate_dt1 = datetime.strptime(date_str1, \u0026#39;%A, %B %d, %Y\u0026#39;)\r\ndate_dt2 = datetime.strptime(date_str2, \u0026#39;%m/%d/%y\u0026#39;)\r\ndate_dt3 = datetime.strptime(date_str3, \u0026#39;%m-%d-%Y\u0026#39;)\r\n\r\n# Print converted dates\r\nprint(date_dt1)\r\nprint(date_dt2)\r\nprint(date_dt3)\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e2018-06-06 00:00:00\r\n2018-06-06 00:00:00\r\n2018-06-06 00:00:00\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eFirst, the \u003ccode\u003edatetime\u003c/code\u003e type is imported from the \u003ccode\u003edatetime\u003c/code\u003e module. Then, the date string is passed to the \u003ccode\u003e.strptime()\u003c/code\u003e method, followed by what\u0026#39;s called Python\u0026#39;s \u003ccode\u003estrptime\u003c/code\u003e directives. You can combine directives, special characters (e.g.  \u003ccode\u003e,\u003c/code\u003e, \u003ccode\u003e/\u003c/code\u003e, or \u003ccode\u003e-\u003c/code\u003e as in the cases above), and spaces to match the date string you are trying to parse. As you can see, the resulting \u003ccode\u003edatetime\u003c/code\u003e objects are identical because all three date strings represent the same date.\u003c/p\u003e\r\n\u003cp\u003eYou can find the full list of directives in the \u003ca href=\"http://strftime.org/\"\u003ePython Documentation\u003c/a\u003e, but below is a table most relevant to what you saw above:\u003c/p\u003e\r\n\u003ctable\u003e\r\n\u003cthead\u003e\r\n\u003ctr\u003e\r\n\u003cth\u003eCode\u003c/th\u003e\r\n\u003cth\u003eMeaning\u003c/th\u003e\r\n\u003cth\u003eExample\u003c/th\u003e\r\n\u003c/tr\u003e\r\n\u003c/thead\u003e\r\n\u003ctbody\u003e\r\n\u003ctr\u003e\r\n\u003ctd\u003e%A\u003c/td\u003e\r\n\u003ctd\u003eWeekday as locales full name.\u003c/td\u003e\r\n\u003ctd\u003eWednesday\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd\u003e%a\u003c/td\u003e\r\n\u003ctd\u003eWeekday as locales abbreviated name.\u003c/td\u003e\r\n\u003ctd\u003eWed\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd\u003e%B\u003c/td\u003e\r\n\u003ctd\u003eMonth as locales full name.\u003c/td\u003e\r\n\u003ctd\u003eJune\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd\u003e%d\u003c/td\u003e\r\n\u003ctd\u003eDay of the month.\u003c/td\u003e\r\n\u003ctd\u003e06\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd\u003e%m\u003c/td\u003e\r\n\u003ctd\u003eMonth as a number.\u003c/td\u003e\r\n\u003ctd\u003e6\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd\u003e%Y\u003c/td\u003e\r\n\u003ctd\u003eFour-digit year.\u003c/td\u003e\r\n\u003ctd\u003e2018\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd\u003e%y\u003c/td\u003e\r\n\u003ctd\u003eTwo-digit year.\u003c/td\u003e\r\n\u003ctd\u003e18\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003ch3 id=\"converting-the-date-string-column\"\u003eConverting the date string column\u003c/h3\u003e\r\n\u003cp\u003eNow that you\u0026#39;re familiar with Python\u0026#39;s \u003ccode\u003estrptime\u003c/code\u003e directives, let\u0026#39;s learn how to convert a whole column of date strings in a dataset to the \u003ccode\u003edatetime\u003c/code\u003e format.\u003c/p\u003e\r\n\u003cp\u003eFrom now on, you\u0026#39;ll be working with a DataFrame called \u003ccode\u003eeth\u003c/code\u003e that contains some \u003ca href=\"https://coinmetrics.io/data-downloads/\"\u003ehistorical data\u003c/a\u003e on ether, a cryptocurrency whose blockchain is generated by the Ethereum platform. Your dataset has the following columns:\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli\u003e\u003ccode\u003edate\u003c/code\u003e: Date, daily at 00:00 UTC.\u003c/li\u003e\r\n\u003cli\u003e\u003ccode\u003etxVolume\u003c/code\u003e: Unadjusted measure of the total value, in US dollars, of outputs on the blockchain.\u003c/li\u003e\r\n\u003cli\u003e\u003ccode\u003etxCount\u003c/code\u003e: Number of transactions happening on the public blockchain.\u003c/li\u003e\r\n\u003cli\u003e\u003ccode\u003emarketCap\u003c/code\u003e: Unit price in US dollars multiplied by the number of units in circulation.\u003c/li\u003e\r\n\u003cli\u003e\u003ccode\u003eprice\u003c/code\u003e: Opening price in US dollars at 00:00 UTC.\u003c/li\u003e\r\n\u003cli\u003e\u003ccode\u003egeneratedCoins\u003c/code\u003e: Number of new coins that have been mined into existence.\u003c/li\u003e\r\n\u003cli\u003e\u003ccode\u003eexchangeVolume\u003c/code\u003e: The volume, measured by US dollars, at exchanges like GDAX and Bitfinex.\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003eHere are the first few rows of your dataset. Note how the dates are represented so you can use the right directives later:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003eprint(eth.head())\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e         date  txVolume(USD)  txCount  marketcap(USD)  price(USD)  \\\r\n0  2015-08-10   1.193012e+06     2037      43130000.0    0.713989   \r\n1  2015-08-11   1.052027e+06     4963      42796500.0    0.708087   \r\n2  2015-08-12   7.923370e+05     2036      64018400.0    1.060000   \r\n3  2015-08-13   2.181182e+06     2842      73935400.0    1.220000   \r\n4  2015-08-14   4.154763e+06     3174     109594000.0    1.810000   \r\n\r\n   generatedCoins  exchangeVolume(USD)  \r\n0     27817.34375             405283.0  \r\n1     28027.81250            1463100.0  \r\n2     27370.93750            2150620.0  \r\n3     28268.12500            4068680.0  \r\n4     31106.71875            4637030.0\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eAnd let\u0026#39;s confirm that the \u003ccode\u003edate\u003c/code\u003e column needs to be converted:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# Confirm the date column is a string\r\nprint(eth.info())\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e\u0026lt;class \u0026#39;pandas.core.frame.DataFrame\u0026#39;\u0026gt;\r\nRangeIndex: 1014 entries, 0 to 1013\r\nData columns (total 7 columns):\r\ndate                   1014 non-null object\r\ntxVolume(USD)          1014 non-null float64\r\ntxCount                1014 non-null int64\r\nmarketcap(USD)         1014 non-null float64\r\nprice(USD)             1014 non-null float64\r\ngeneratedCoins         1014 non-null float64\r\nexchangeVolume(USD)    1014 non-null float64\r\ndtypes: float64(5), int64(1), object(1)\r\nmemory usage: 55.5+ KB\r\nNone\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eThe \u003ccode\u003edate\u003c/code\u003e column is indeed a string, whichrememberis denoted as an \u003ccode\u003eobject\u003c/code\u003e type in Python. You can convert it to the \u003ccode\u003edatetime\u003c/code\u003e type with the \u003ccode\u003e.to_datetime()\u003c/code\u003e method in \u003ccode\u003epandas\u003c/code\u003e. The console below contains the call to convert the column. Can you complete it by specifying the directives according to how dates are expressed in your dataset?\u003c/p\u003e\r\n\u003cdiv data-datacamp-exercise=\"\" data-height=\"300\" data-encoded=\"true\"\u003e\r\neyJsYW5ndWFnZSI6InB5dGhvbiIsInByZV9leGVyY2lzZV9jb2RlIjoiaW1wb3J0IHBhbmRhcyBhcyBwZFxuZXRoID0gcGQucmVhZF9jc3YoXCJodHRwczovL3Jhdy5naXRodWJ1c2VyY29udGVudC5jb20vdG9tbXlqZWUvYXJ0aWNsZXMvbWFzdGVyL3BhbmRhcy9kYXRldGltZS9kYXRhL2V0aF9maW4uY3N2XCIpIiwic2FtcGxlIjoiIyBDb21wbGV0ZSB0aGUgY2FsbCB0byBjb252ZXJ0IHRoZSBkYXRlIGNvbHVtblxuZXRoWydkYXRlJ10gPSAgcGQudG9fZGF0ZXRpbWUoZXRoWydkYXRlJ10sXG4gICAgICAgICAgICAgICAgICAgICAgICAgICAgICBmb3JtYXQ9J19fXycpXG5cbiMgQ29uZmlybSB0aGUgZGF0ZSBjb2x1bW4gaXMgaW4gZGF0ZXRpbWUgZm9ybWF0XG5wcmludChldGguaW5mbygpKSJ9\r\n\u003c/div\u003e\r\n\r\n\u003cp\u003eDid you complete it using \u003ccode\u003e\u0026#39;%Y-%m-%d\u0026#39;\u003c/code\u003e? Great!\u003c/p\u003e\r\n\u003ch3 id=\"components-of-datetime-objects\"\u003eComponents of \u003ccode\u003edatetime\u003c/code\u003e objects\u003c/h3\u003e\r\n\u003cp\u003eNow that you have \u003ccode\u003edatetime\u003c/code\u003e objects as your date column, you can extract specific components of the date such as the month, day, or year, all of which are available as the object\u0026#39;s attributes:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# Print datetime attributes\r\nprint(eth[\u0026#39;date\u0026#39;][0].month)\r\nprint(eth[\u0026#39;date\u0026#39;][0].day)\r\nprint(eth[\u0026#39;date\u0026#39;][0].year)\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e8\r\n10\r\n2015\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eDate attributes are frequently used to group data by a particular time frame. For example, you can see how many ethers were generated on a yearly basis:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003efrom collections import defaultdict\r\nimport matplotlib.pyplot as plt\r\n\r\n# Initialize defaultdict of type float\r\nyearly_total_coins = defaultdict(float)\r\n\r\n# Loop over the rows of eth\r\nfor day in eth.iterrows():\r\n    # Get the date\r\n    dates = day[1][0]\r\n\r\n    # Get the number of coins generated\r\n    num_coins = day[1][5]\r\n\r\n    # Add the total number of coins to the current value for the year\r\n    yearly_total_coins[dates.year] += num_coins\r\n\r\n# Print yearly_total_coins\r\nprint(yearly_total_coins)\r\n\r\n# Visualize aggregated data\r\nplt.bar(range(len(yearly_total_coins)), list(yearly_total_coins.values()), align=\u0026#39;center\u0026#39;)\r\nplt.xticks(range(len(yearly_total_coins)), list(yearly_total_coins.keys()))\r\nplt.title(\u0026#39;# of ethers generated by year\u0026#39;)\r\nplt.show()\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003edefaultdict(\u0026lt;class \u0026#39;float\u0026#39;\u0026gt;, {2015: 3805167.8125, 2016: 11321892.96875, 2017: 9230132.65625, 2018: 2849975.625})\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1528209945/year_ethers_heabkw.png\" /\u003e\u003c/p\u003e\r\n\u003ch3 id=\"adding-and-subtracting-time\"\u003eAdding and subtracting time\u003c/h3\u003e\r\n\u003cp\u003eAnother common case when working with dates is to get a date 30, 60, or 90 days in the past from some date. In Python, the \u003ccode\u003etimedelta\u003c/code\u003e object from the \u003ccode\u003edatetime\u003c/code\u003e module is used to represent differences in \u003ccode\u003edatetime\u003c/code\u003e objects. You can create a \u003ccode\u003etimedelta\u003c/code\u003e by passing any number of keyword arguments such as \u003ccode\u003edays\u003c/code\u003e, \u003ccode\u003eseconds\u003c/code\u003e, \u003ccode\u003emicroseconds\u003c/code\u003e, \u003ccode\u003emilliseconds\u003c/code\u003e, \u003ccode\u003eminutes\u003c/code\u003e, \u003ccode\u003ehours\u003c/code\u003e, and \u003ccode\u003eweeks\u003c/code\u003e to it.\u003c/p\u003e\r\n\u003cp\u003eOnce you have a \u003ccode\u003etimedelta\u003c/code\u003e object, you can add or subtract it from a \u003ccode\u003edatetime\u003c/code\u003e object to get another \u003ccode\u003edatetime\u003c/code\u003e object. Try it in the console below:\u003c/p\u003e\r\n\u003cdiv data-datacamp-exercise=\"\" data-height=\"300\" data-encoded=\"true\"\u003e\r\neyJsYW5ndWFnZSI6InB5dGhvbiIsInByZV9leGVyY2lzZV9jb2RlIjoiZnJvbSBkYXRldGltZSBpbXBvcnQgZGF0ZXRpbWUiLCJzYW1wbGUiOiIjIEltcG9ydCB0aW1lZGVsdGEgZnJvbSBkYXRldGltZSBtb2R1bGVcbmZyb20gZGF0ZXRpbWUgaW1wb3J0IHRpbWVkZWx0YVxuXG4jIERlZmluZSB0aW1lZGVsdGEgb2YgNTkgZGF5cywgNCBob3VycywgNDIgbWludXRlc1xuZ2xhbmNlYmFjayA9IHRpbWVkZWx0YShkYXlzPTU5LFxuICAgICAgICAgICAgICAgICAgICAgICBob3Vycz00LFxuICAgICAgICAgICAgICAgICAgICAgICBtaW51dGVzPTQyKVxuXG4jIEdldCBjdXJyZW50IGRhdGUgYW5kIHRpbWVcbnJpZ2h0X25vdyA9IGRhdGV0aW1lLm5vdygpXG5wcmludChyaWdodF9ub3cpXG5cbiMgV2hlbiB3YXMgNTkgZGF5cywgNCBob3VycywgNDIgbWludXRlcyBhZ28/XG5wcmludChyaWdodF9ub3cgLSBnbGFuY2ViYWNrKSJ9\r\n\u003c/div\u003e\r\n\r\n\u003ch3 id=\"indexing-pandas-dataframes-with-datetimeindex\"\u003eIndexing pandas DataFrames with DatetimeIndex\u003c/h3\u003e\r\n\u003cp\u003eAfter you\u0026#39;ve converted the \u003ccode\u003edate\u003c/code\u003e column to the \u003ccode\u003edatetime\u003c/code\u003e format, it is usually a good idea to index your DataFrame by the date, creating the \u003ccode\u003eDatetimeIndex\u003c/code\u003e. Like the \u003ccode\u003edatetime\u003c/code\u003e type, the \u003ccode\u003eDatetimeIndex\u003c/code\u003e is a special index type designed to work with dates and times. By using the \u003ccode\u003e.set_index()\u003c/code\u003e method with the \u003ccode\u003einplace\u003c/code\u003e argument set equal to \u003ccode\u003eTrue\u003c/code\u003e, you can remove the \u003ccode\u003edate\u003c/code\u003e column from your dataset and append it as the index of your DataFrame:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# Set index\r\neth.set_index(\u0026#39;date\u0026#39;, inplace=True)\r\nprint(eth.head(5))\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e                txVolume  txCount    marketCap     price  generatedCoins  \\\r\ndate                                                                       \r\n2015-08-10  1.193012e+06     2037   43130000.0  0.713989     27817.34375   \r\n2015-08-11  1.052027e+06     4963   42796500.0  0.708087     28027.81250   \r\n2015-08-12  7.923370e+05     2036   64018400.0  1.060000     27370.93750   \r\n2015-08-13  2.181182e+06     2842   73935400.0  1.220000     28268.12500   \r\n2015-08-14  4.154763e+06     3174  109594000.0  1.810000     31106.71875   \r\n\r\n            exchangeVolume  \r\ndate                        \r\n2015-08-10        405283.0  \r\n2015-08-11       1463100.0  \r\n2015-08-12       2150620.0  \r\n2015-08-13       4068680.0  \r\n2015-08-14       4637030.0\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eSetting the \u003ccode\u003eDatetimeIndex\u003c/code\u003e in your DataFrame unlocks a whole set of useful functionalities. For example, when visualizing your time series data, \u003ccode\u003epandas\u003c/code\u003e automatically creates reasonably spaced date labels for the x-axis:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003eeth.txCount.plot(title=\u0026#39;# of transactions\u0026#39;)\r\nplt.show()\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1528209945/number_transactions_r9xich.png\" /\u003e\u003c/p\u003e\r\n\u003cp\u003ePretty neat, right?\u003c/p\u003e\r\n\u003ch3 id=\"partial-string-indexing-and-slicing\"\u003ePartial string indexing and slicing\u003c/h3\u003e\r\n\u003cp\u003ePerhaps the most useful functionalities are partial string indexing and slicing, which allow you to easily subset your data. Let\u0026#39;s say you wanted to take a closer look at the peak around January 2018 as seen in the graph above. The following code uses partial string indexing and slicing to observe the number of transactions between December 2017 and February 2018.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# Subset data around peak\r\npeak_eth = eth[\u0026#39;2017-12\u0026#39;: \u0026#39;2018-2\u0026#39;]\r\npeak_eth.txCount.plot(title=\u0026#39;# of transactions around peak\u0026#39;)\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1528209945/txns_peak_ihtb3e.png\" /\u003e\u003c/p\u003e\r\n\u003cp\u003eWell, that was easy! Did you notice that the boundaries are inclusive for partial string indexing unlike for typical Python indexing?\u003c/p\u003e\r\n\u003ch3 id=\"recap\"\u003eRecap\u003c/h3\u003e\r\n\u003cp\u003eFrom stock prices to flight timings, data containing dates and times are abudant in a wide variety of domains. Being able to effectively work with such data is essential for answering questions that start with when, how long, or how often.\u003c/p\u003e\r\n\u003cp\u003eIn this tutorial, you:\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli\u003eLearned about Python\u0026#39;s directives to deal with the various ways dates can be represented.\u003c/li\u003e\r\n\u003cli\u003eLearned how to convert strings to dates with the \u003ccode\u003e.strptime()\u003c/code\u003e method in the \u003ccode\u003edatetime\u003c/code\u003e module.\u003c/li\u003e\r\n\u003cli\u003eLearned how to convert date string columns in DataFrames with the \u003ccode\u003e.to_datetime()\u003c/code\u003e method in \u003ccode\u003epandas\u003c/code\u003e.\u003c/li\u003e\r\n\u003cli\u003eLearned about the components of the \u003ccode\u003edatetime\u003c/code\u003e object and how to access them as the object\u0026#39;s attributes.\u003c/li\u003e\r\n\u003cli\u003eLearned how to do date arithmetic with the \u003ccode\u003etimedelta\u003c/code\u003e object.\u003c/li\u003e\r\n\u003cli\u003eLearned to index DataFrames with \u003ccode\u003eDatetimeIndex\u003c/code\u003e and explored some examples of its usefulness.\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003eThe \u003ccode\u003edatetime\u003c/code\u003e and \u003ccode\u003eDatetimeIndex\u003c/code\u003e objects in Python offer a much more manageable and intuitive way to deal with dates and times. If you\u0026#39;re curious about learning more advanced techniques and eager to get some hands-on practice manipulating, analyzing, and visualizing time series data, check out the \u003ca href=\"https://www.datacamp.com/courses/manipulating-time-series-data-in-python\"\u003eManipulating Time Series Data in Python\u003c/a\u003e, \u003ca href=\"https://www.datacamp.com/courses/introduction-to-time-series-analysis-in-python\"\u003eIntroduction to Time Series Analysis in Python\u003c/a\u003e, and \u003ca href=\"https://www.datacamp.com/courses/visualizing-time-series-data-in-python\"\u003eVisualizing Time Series Data in Python\u003c/a\u003e courses on DataCamp.\u003c/p\u003e\r\n\u003cp\u003eHappy learning!\u003c/p\u003e\r\n","contentUrl":"https://www.datacamp.com/community/tutorials/converting-strings-datetime-objects","userContentUrl":null,"illustrationUrl":null,"seoTitle":"Converting Strings to datetime Objects","seoMetaDescription":"Learn how to convert strings to datetime objects in Python and why doing so has become standard practice for working data scientists today.","seoKeyword":"Convert strings date as datetime objects","mustRead":false,"programmingLanguage":null,"submissionDate":"2018-06-05T14:22:29.604Z","publishDate":"2018-06-08T16:00:00.000Z","episode":null,"isLatest":null,"externalUrl":null,"transcriptUrl":null,"guests":[],"links":null,"isSpam":false,"xp":0,"flaggingUsers":[],"isDisabled":false,"connectedInternalContentId":null,"createdAt":"2018-06-05T14:22:29.601Z","updatedAt":"2018-06-08T16:52:46.438Z","upvoting":{"voteCount":7,"voted":false},"tags":["python","pandas"],"author":{"id":329323,"slug":"tommyjee","avatarUrlSquare":"https://assets.datacamp.com/users/avatars/000/329/323/square/tom.jpg?1465645479","fullName":"Tom Jeon","nameFromEmail":"tom","isAdmin":false}},{"id":9948,"externalId":null,"type":"Tutorial","status":"published","authorId":"thushv","title":"TensorBoard Tutorial","slug":"tensorboard-tutorial","previewSlug":null,"description":"Visualize the training parameters, metrics, hyperparameters or any statistics of your neural network with TensorBoard!","articles":[],"courses":[],"redirectSlug":null,"contentHtml":"\u003cp\u003eThis tutorial will guide you on how to use TensorBoard, which is an amazing utility that allows you to visualize data and how it behaves. You will see for what sort of purposes you can use it when training a neural network.\u003c/p\u003e\r\n\u003cp\u003e\u003cnav\u003e\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli\u003eFirst, you will learn \u003ca href=\"#start\"\u003ehow to start TensorBoard\u003c/a\u003e, followed by an overview of \u003ca href=\"#views\"\u003ethe different views\u003c/a\u003e offered. \u003c/li\u003e\r\n\u003cli\u003eNext, you will see how you can \u003ca href=\"#visualizing\"\u003evisualize scalar values\u003c/a\u003e produced during computations. You will also learn how to \u003ca href=\"#insights\"\u003eget insights from the model\u003c/a\u003e to fix any potential errors in the learning. \u003c/li\u003e\r\n\u003cli\u003eThereafter, you will investigate how you can \u003ca href=\"#histograms\"\u003evisualize vectors or collections of data as histograms\u003c/a\u003e. \u003c/li\u003e\r\n\u003cli\u003eWith this view you will compare how \u003ca href=\"#weights\"\u003eweight initialization\u003c/a\u003e of the neural network affects the weight update of the neural network during the learning.\r\n\u003c/nav\u003e\r\n\u003cdiv id=\"scoped-content\"\u003e\u003cstyle type=\"text/css\"\u003e:target:before { content:\"\"; display:block; height:150px; margin:-150px 0 0; } h3 {font-weight:normal; margin-top:.5em} h4 { font-weight:lighter }\r\n\u003c/style\u003e\r\n\r\n\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003e\u003cstrong\u003eTip\u003c/strong\u003e: check out DataCamp\u0026#39;s Deep Learning course with Keras \u003ca href=\"https://www.datacamp.com/courses/deep-learning-in-python\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\r\n\u003cp\u003eBefore you get started, make sure to import the following libraries to run the code successfully:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003efrom pandas_datareader import data\r\nimport matplotlib.pyplot as plt\r\nimport pandas as pd\r\nimport datetime as dt\r\nimport urllib.request, json\r\nimport os\r\nimport numpy as np\r\n\r\n# This code has been tested with TensorFlow 1.6\r\nimport tensorflow as tf\r\nfrom tensorflow.examples.tutorials.mnist import input_data\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003e\u003ca id=\"start\"\u003e\u003c/a\u003e\u003c/p\u003e\r\n\u003ch2 id=\"starting-tensorboard\"\u003eStarting TensorBoard\u003c/h2\u003e\r\n\u003cp\u003eTo visualize things via TensorBoard, you first need to start its service. For that,\u003c/p\u003e\r\n\u003col\u003e\r\n\u003cli\u003eOpen up the command prompt (Windows) or terminal (Ubuntu/Mac)\u003c/li\u003e\r\n\u003cli\u003eGo into the project home directory\u003c/li\u003e\r\n\u003cli\u003eIf you are using Python virtuanenv, activate the virtual environment you have installed TensorFlow in\u003c/li\u003e\r\n\u003cli\u003eMake sure that you can see the TensorFlow library through Python. For that,\u003cul\u003e\r\n\u003cli\u003eType in \u003ccode\u003epython3\u003c/code\u003e, you will get a \u003ccode\u003e\u0026gt;\u0026gt;\u0026gt;\u003c/code\u003e looking prompt\u003c/li\u003e\r\n\u003cli\u003eTry \u003ccode\u003eimport tensorflow as tf\u003c/code\u003e\u003c/li\u003e\r\n\u003cli\u003eIf you can run this successfully you are fine\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003c/li\u003e\r\n\u003cli\u003eExit the Python prompt (that is, \u003ccode\u003e\u0026gt;\u0026gt;\u0026gt;\u003c/code\u003e) by typing \u003ccode\u003eexit()\u003c/code\u003e and type in the following command\u003cul\u003e\r\n\u003cli\u003e\u003ccode\u003etensorboard --logdir=summaries\u003c/code\u003e\u003c/li\u003e\r\n\u003cli\u003e\u003ccode\u003e--logdir\u003c/code\u003e is the directory you will create data to visualize\u003c/li\u003e\r\n\u003cli\u003eFiles that TensorBoard saves data into are called \u003cem\u003eevent files\u003c/em\u003e\u003c/li\u003e\r\n\u003cli\u003eType of data saved into the event files is called \u003cem\u003esummary data\u003c/em\u003e\u003c/li\u003e\r\n\u003cli\u003eOptionally you can use \u003ccode\u003e--port=\u0026lt;port_you_like\u0026gt;\u003c/code\u003e to change the port TensorBoard runs on\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003c/li\u003e\r\n\u003cli\u003eYou should now get the following message\u003cul\u003e\r\n\u003cli\u003e\u003ccode\u003eTensorBoard 1.6.0 at \u0026amp;lt;url\u0026amp;gt;:6006 (Press CTRL+C to quit)\u003c/code\u003e\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003c/li\u003e\r\n\u003cli\u003eEnter the \u0026lt;url\u0026gt;:6006 in to the web browser\u003cul\u003e\r\n\u003cli\u003eYou should be able to see a orange dashboard at this point. You won\u0026#39;t have anything to display because you haven\u0026#39;t generated data.\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003c/li\u003e\r\n\u003c/ol\u003e\r\n\u003cp\u003e\u003cstrong\u003eNote\u003c/strong\u003e: TensorBoard does not like to see multiple event files in the same directory. This can lead to you getting very gruesome curves on the display. So you should create a separate folder for each different example (for example, summaries/first, summaries/second, ...) to save data. Another thing to keep in mind is that, if you want to re-run an experiment (that is, saving an event file to an already populated folder), you have to make sure to first delete the existing event files.\u003c/p\u003e\r\n\u003cp\u003e\u003ca id=\"views\"\u003e\u003c/a\u003e\u003c/p\u003e\r\n\u003ch2 id=\"different-views-of-tensorboard\"\u003eDifferent Views of TensorBoard\u003c/h2\u003e\r\n\u003cp\u003eDifferent views take inputs of different formats and display them differently. You can change them on the orange top bar.\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli\u003e\u003cstrong\u003eScalars\u003c/strong\u003e - Visualize scalar values, such as classification accuracy.\u003c/li\u003e\r\n\u003cli\u003e\u003cstrong\u003eGraph\u003c/strong\u003e - Visualize the computational graph of your model, such as the neural network model.\u003c/li\u003e\r\n\u003cli\u003e\u003cstrong\u003eDistributions\u003c/strong\u003e - Visualize how data changes over time, such as the weights of a neural network.\u003c/li\u003e\r\n\u003cli\u003e\u003cstrong\u003eHistograms\u003c/strong\u003e - A fancier view of the distribution that shows distributions in a 3-dimensional perspective\u003c/li\u003e\r\n\u003cli\u003eProjector - Can be used to visualize word embeddings (that is, word embeddings are numerical representations of words that capture their semantic relationships)\u003c/li\u003e\r\n\u003cli\u003eImage - Visualizing image data\u003c/li\u003e\r\n\u003cli\u003eAudio - Visualizing audio data\u003c/li\u003e\r\n\u003cli\u003eText - Visualizing text (string) data\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003eIn this tutorial, you will cover the views shown in bold.\u003c/p\u003e\r\n\u003ch2 id=\"understanding-the-benefits-of-scalar-visualization\"\u003eUnderstanding the Benefits of Scalar Visualization\u003c/h2\u003e\r\n\u003cp\u003eIn this section, you will first understand why visualizing certain metrics (for example loss or accuracy) is beneficial. When training deep neural networks, one of the crucial issues that strikes the beginners is the lack of understanding the effects of various design choices and hyperparameters.\u003c/p\u003e\r\n\u003cp\u003eFor example, if you carelessly initialize weights of a deep neural network to have a very large variance between weights, your model will quickly diverge and collapse. On the other hand, things can go wrong even when you are quite competent in taming neural networks to make use of them. For example, not paying attention to the learning rate can lead to either the divergence of the model or pre-maturely saturating to sub-optimal performance.\u003c/p\u003e\r\n\u003cp\u003eOne way to quickly detect problems with your model is to have a graphical visualization of what\u0026#39;s going on in your model in real time (for example, every 100 iterations). So if your model is behaving oddly, it will be clearly visible. That is exactly what TensorBoard provides you with. You can decide which values need to be displayed and it will maintain a real time visualization of those values during learning.\u003c/p\u003e\r\n\u003cp\u003eYou start by first creating a five-layer neural network that you will use to classify hand-written digit images. For that you will use the famous MNIST dataset. TensorFlow provides a simple API to load MNIST data, so you don\u0026#39;t have to manually download it. Before that you define a simple method (that is, \u003ccode\u003eaccuracy()\u003c/code\u003e), which calculates the accuracy of some predictions with respect to the true labels.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003edef accuracy(predictions,labels):\r\n    \u0026#39;\u0026#39;\u0026#39;\r\n    Accuracy of a given set of predictions of size (N x n_classes) and\r\n    labels of size (N x n_classes)\r\n    \u0026#39;\u0026#39;\u0026#39;\r\n    return np.sum(np.argmax(predictions,axis=1)==np.argmax(labels,axis=1))*100.0/labels.shape[0]\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003ch3 id=\"define-inputs-outputs-weights-and-biases\"\u003eDefine Inputs, Outputs, Weights and Biases\u003c/h3\u003e\r\n\u003cp\u003eFirst, define a \u003ccode\u003ebatch_size\u003c/code\u003e denoting the amount of data you sample at a single optimization/validation or testing step. Then you define the \u003ccode\u003elayer_ids\u003c/code\u003e, which gives an identifier for each of the layers of the neural network you will be defining. You then can define \u003ccode\u003elayer_sizes\u003c/code\u003e.\u003c/p\u003e\r\n\u003cp\u003eNote that \u003ccode\u003elen(layer_sizes)\u003c/code\u003e should be \u003ccode\u003elen(layer_ids)+1\u003c/code\u003e, because \u003ccode\u003elayer_sizes\u003c/code\u003e includes the size of the input at the beginning.\u003c/p\u003e\r\n\u003cp\u003eMNIST has images of size 28x28, which will be 784 when unwrapped to a single dimension. Then you can define the input and label placeholders, that you will later use to train the model. Finally, you define two TensorFlow variables for each layer (that is, \u003ccode\u003eweights\u003c/code\u003e and \u003ccode\u003ebias\u003c/code\u003e).\u003c/p\u003e\r\n\u003cp\u003eYou can use variable scoping (more information \u003ca href=\"https://www.tensorflow.org/programmers_guide/variables\"\u003ehere\u003c/a\u003e) so that the variables will be nicely named and will be much easier to access later.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003ebatch_size = 100\r\nlayer_ids = [\u0026#39;hidden1\u0026#39;,\u0026#39;hidden2\u0026#39;,\u0026#39;hidden3\u0026#39;,\u0026#39;hidden4\u0026#39;,\u0026#39;hidden5\u0026#39;,\u0026#39;out\u0026#39;]\r\nlayer_sizes = [784, 500, 400, 300, 200, 100, 10]\r\n\r\ntf.reset_default_graph()\r\n\r\n# Inputs and Labels\r\ntrain_inputs = tf.placeholder(tf.float32, shape=[batch_size, layer_sizes[0]], name=\u0026#39;train_inputs\u0026#39;)\r\ntrain_labels = tf.placeholder(tf.float32, shape=[batch_size, layer_sizes[-1]], name=\u0026#39;train_labels\u0026#39;)\r\n\r\n# Weight and Bias definitions\r\nfor idx, lid in enumerate(layer_ids):\r\n\r\n    with tf.variable_scope(lid):\r\n        w = tf.get_variable(\u0026#39;weights\u0026#39;,shape=[layer_sizes[idx], layer_sizes[idx+1]],\r\n                            initializer=tf.truncated_normal_initializer(stddev=0.05))\r\n        b = tf.get_variable(\u0026#39;bias\u0026#39;,shape= [layer_sizes[idx+1]],\r\n                            initializer=tf.random_uniform_initializer(-0.1,0.1))\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003ch3 id=\"calculating-logits-predictions-loss-and-optimization\"\u003eCalculating Logits, Predictions, Loss and Optimization\u003c/h3\u003e\r\n\u003cp\u003eWith the input/output placeholders, weights and biases of each layer defined, you now can define the calculations to calculate the logits of the neural network. Logits are the unnormalized values produced in the last layer of the neural network. When normalized, you call them predictions. This involves iterating through each layer in the neural network and computing \u003ccode\u003etf.matmul(h,w) +b\u003c/code\u003e. You also need to apply an activation function like \u003ccode\u003etf.nn.relu(tf.matmul(h,w) +b)\u003c/code\u003e for all layers except for the last one.\u003c/p\u003e\r\n\u003cp\u003eNext, you define the loss function that is used to optimize the neural network. In this example, you can use the cross entropy loss, which often delivers better results in classification problems than the mean squared error.\u003c/p\u003e\r\n\u003cp\u003eFinally, you will need to define an optimizer that takes in the loss and updates the weights of the neural network in the direction that minimizes the loss.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# Calculating Logits\r\nh = train_inputs\r\nfor lid in layer_ids:\r\n    with tf.variable_scope(lid,reuse=True):\r\n        w, b = tf.get_variable(\u0026#39;weights\u0026#39;), tf.get_variable(\u0026#39;bias\u0026#39;)\r\n        if lid != \u0026#39;out\u0026#39;:\r\n          h = tf.nn.relu(tf.matmul(h,w)+b,name=lid+\u0026#39;_output\u0026#39;)\r\n        else:\r\n          h = tf.nn.xw_plus_b(h,w,b,name=lid+\u0026#39;_output\u0026#39;)\r\n\r\ntf_predictions = tf.nn.softmax(h, name=\u0026#39;predictions\u0026#39;)\r\n# Calculating Loss\r\ntf_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=train_labels, logits=h),name=\u0026#39;loss\u0026#39;)\r\n\r\n# Optimizer\r\ntf_learning_rate = tf.placeholder(tf.float32, shape=None, name=\u0026#39;learning_rate\u0026#39;)\r\noptimizer = tf.train.MomentumOptimizer(tf_learning_rate,momentum=0.9)\r\ngrads_and_vars = optimizer.compute_gradients(tf_loss)\r\ntf_loss_minimize = optimizer.minimize(tf_loss)\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003ch3 id=\"defining-summaries\"\u003eDefining Summaries\u003c/h3\u003e\r\n\u003cp\u003eHere you can define the \u003ccode\u003etf.summary\u003c/code\u003e objects. These objects are the type of entities understood by TensorBoard. This means that whatever value you\u0026#39;d like to be displayed, you should encapsulate as a \u003ccode\u003etf.summary\u003c/code\u003e object.\u003c/p\u003e\r\n\u003cp\u003eThere are several different types of summaries. Here, as you are visualizing only scalars, you can define \u003ccode\u003etf.summary.scalar\u003c/code\u003e objects. Furthermore, you can use \u003ccode\u003etf.name_scope\u003c/code\u003e to group scalars on the board. That is, scalars having the same name scope will be displayed on the same row. Here you define three different summaries.\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli\u003e\u003ccode\u003etf_loss_summary\u003c/code\u003e : you feed in a value by means of a placeholder, whenever you need to publish this to the board\u003c/li\u003e\r\n\u003cli\u003e\u003ccode\u003etf_accuracy_summary\u003c/code\u003e : you feed in a value by means of a placeholder, whenever you need to publish this to the board\u003c/li\u003e\r\n\u003cli\u003e\u003ccode\u003etf_gradnorm_summary\u003c/code\u003e : this calculates the l2 norm of the gradients of the last layer of your neural network. Gradient norm is a good indicator of whether the weights of the neural network are being properly updated. A too small gradient norm can indicate \u003cem\u003evanishing gradient\u003c/em\u003e or a too large gradient can imply \u003cem\u003eexploding gradient\u003c/em\u003e phenomenon.\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# Name scope allows you to group various summaries together\r\n# Summaries having the same name_scope will be displayed on the same row\r\nwith tf.name_scope(\u0026#39;performance\u0026#39;):\r\n    # Summaries need to be displayed\r\n    # Whenever you need to record the loss, feed the mean loss to this placeholder\r\n    tf_loss_ph = tf.placeholder(tf.float32,shape=None,name=\u0026#39;loss_summary\u0026#39;)\r\n    # Create a scalar summary object for the loss so it can be displayed\r\n    tf_loss_summary = tf.summary.scalar(\u0026#39;loss\u0026#39;, tf_loss_ph)\r\n\r\n    # Whenever you need to record the loss, feed the mean test accuracy to this placeholder\r\n    tf_accuracy_ph = tf.placeholder(tf.float32,shape=None, name=\u0026#39;accuracy_summary\u0026#39;)\r\n    # Create a scalar summary object for the accuracy so it can be displayed\r\n    tf_accuracy_summary = tf.summary.scalar(\u0026#39;accuracy\u0026#39;, tf_accuracy_ph)\r\n\r\n# Gradient norm summary\r\nfor g,v in grads_and_vars:\r\n    if \u0026#39;hidden5\u0026#39; in v.name and \u0026#39;weights\u0026#39; in v.name:\r\n        with tf.name_scope(\u0026#39;gradients\u0026#39;):\r\n            tf_last_grad_norm = tf.sqrt(tf.reduce_mean(g**2))\r\n            tf_gradnorm_summary = tf.summary.scalar(\u0026#39;grad_norm\u0026#39;, tf_last_grad_norm)\r\n            break\r\n# Merge all summaries together\r\nperformance_summaries = tf.summary.merge([tf_loss_summary,tf_accuracy_summary])\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003ch3 id=\"executing-the-neural-network-loading-data-training-validation-and-testing\"\u003eExecuting the neural network: Loading Data, Training, Validation and Testing\u003c/h3\u003e\r\n\u003cp\u003eIn the code below you do the following. First, you create a session, in which you execute the operations you defined above. Then, you create a folder for saving summary data. Next, you create a summary writer \u003ccode\u003esumm_writer\u003c/code\u003e. You can now initialize all variables. This will be followed by loading the MNIST dataset.\u003c/p\u003e\r\n\u003cp\u003eThen, for each epoch, and each batch in the training data (that is, each iteration), execute \u003ccode\u003egradnorm_summary\u003c/code\u003e if it is the first iteration and write \u003ccode\u003egradnorm_summary\u003c/code\u003e to the event file with the summary writer. You now execute the model optimization and loss calculation. After you go through the full training dataset for a single epoch, calculate the average training loss.\u003c/p\u003e\r\n\u003cp\u003eYou follow a similar treatment for the validation dataset as well. Specifically, for each batch in the validation data, you calculate the validation accuracy. Thereafter, calculate the average validation accuracy for full validation set.\u003c/p\u003e\r\n\u003cp\u003eFinally, the testing phase is executed. In this, for each batch in the test data, you calculate test accuracy for each batch. With that, you calculate the average test accuracy for the full test set. At the very end you execute \u003ccode\u003eperformance_summaries\u003c/code\u003e and write them to the event file with the summary writer.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e\r\nimage_size = 28\r\nn_channels = 1\r\nn_classes = 10\r\nn_train = 55000\r\nn_valid = 5000\r\nn_test = 10000\r\nn_epochs = 25\r\n\r\nconfig = tf.ConfigProto(allow_soft_placement=True)\r\nconfig.gpu_options.allow_growth = True\r\nconfig.gpu_options.per_process_gpu_memory_fraction = 0.9 # making sure Tensorflow doesn\u0026#39;t overflow the GPU\r\n\r\nsession = tf.InteractiveSession(config=config)\r\n\r\nif not os.path.exists(\u0026#39;summaries\u0026#39;):\r\n    os.mkdir(\u0026#39;summaries\u0026#39;)\r\nif not os.path.exists(os.path.join(\u0026#39;summaries\u0026#39;,\u0026#39;first\u0026#39;)):\r\n    os.mkdir(os.path.join(\u0026#39;summaries\u0026#39;,\u0026#39;first\u0026#39;))\r\n\r\nsumm_writer = tf.summary.FileWriter(os.path.join(\u0026#39;summaries\u0026#39;,\u0026#39;first\u0026#39;), session.graph)\r\n\r\ntf.global_variables_initializer().run()\r\n\r\naccuracy_per_epoch = []\r\nmnist_data = input_data.read_data_sets(\u0026#39;MNIST_data\u0026#39;, one_hot=True)\r\n\r\n\r\nfor epoch in range(n_epochs):\r\n    loss_per_epoch = []\r\n    for i in range(n_train//batch_size):\r\n\r\n        # =================================== Training for one step ========================================\r\n        batch = mnist_data.train.next_batch(batch_size)    # Get one batch of training data\r\n        if i == 0:\r\n            # Only for the first epoch, get the summary data\r\n            # Otherwise, it can clutter the visualization\r\n            l,_,gn_summ = session.run([tf_loss,tf_loss_minimize,tf_gradnorm_summary],\r\n                                      feed_dict={train_inputs: batch[0].reshape(batch_size,image_size*image_size),\r\n                                                 train_labels: batch[1],\r\n                                                tf_learning_rate: 0.0001})\r\n            summ_writer.add_summary(gn_summ, epoch)\r\n        else:\r\n            # Optimize with training data\r\n            l,_ = session.run([tf_loss,tf_loss_minimize],\r\n                              feed_dict={train_inputs: batch[0].reshape(batch_size,image_size*image_size),\r\n                                         train_labels: batch[1],\r\n                                         tf_learning_rate: 0.0001})\r\n        loss_per_epoch.append(l)\r\n\r\n    print(\u0026#39;Average loss in epoch %d: %.5f\u0026#39;%(epoch,np.mean(loss_per_epoch)))    \r\n    avg_loss = np.mean(loss_per_epoch)\r\n\r\n    # ====================== Calculate the Validation Accuracy ==========================\r\n    valid_accuracy_per_epoch = []\r\n    for i in range(n_valid//batch_size):\r\n        valid_images,valid_labels = mnist_data.validation.next_batch(batch_size)\r\n        valid_batch_predictions = session.run(\r\n            tf_predictions,feed_dict={train_inputs: valid_images.reshape(batch_size,image_size*image_size)})\r\n        valid_accuracy_per_epoch.append(accuracy(valid_batch_predictions,valid_labels))\r\n\r\n    mean_v_acc = np.mean(valid_accuracy_per_epoch)\r\n    print(\u0026#39;\\tAverage Valid Accuracy in epoch %d: %.5f\u0026#39;%(epoch,np.mean(valid_accuracy_per_epoch)))\r\n\r\n    # ===================== Calculate the Test Accuracy ===============================\r\n    accuracy_per_epoch = []\r\n    for i in range(n_test//batch_size):\r\n        test_images, test_labels = mnist_data.test.next_batch(batch_size)\r\n        test_batch_predictions = session.run(\r\n            tf_predictions,feed_dict={train_inputs: test_images.reshape(batch_size,image_size*image_size)}\r\n        )\r\n        accuracy_per_epoch.append(accuracy(test_batch_predictions,test_labels))\r\n\r\n    print(\u0026#39;\\tAverage Test Accuracy in epoch %d: %.5f\\n\u0026#39;%(epoch,np.mean(accuracy_per_epoch)))\r\n    avg_test_accuracy = np.mean(accuracy_per_epoch)\r\n\r\n    # Execute the summaries defined above\r\n    summ = session.run(performance_summaries, feed_dict={tf_loss_ph:avg_loss, tf_accuracy_ph:avg_test_accuracy})\r\n\r\n    # Write the obtained summaries to the file, so it can be displayed in the TensorBoard\r\n    summ_writer.add_summary(summ, epoch)\r\n\r\nsession.close()\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003eSuccessfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\r\nExtracting MNIST_data/train-images-idx3-ubyte.gz\r\nSuccessfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\r\nExtracting MNIST_data/train-labels-idx1-ubyte.gz\r\nSuccessfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\r\nExtracting MNIST_data/t10k-images-idx3-ubyte.gz\r\nSuccessfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\r\nExtracting MNIST_data/t10k-labels-idx1-ubyte.gz\r\nAverage loss in epoch 0: 2.30252\r\n    Average Valid Accuracy in epoch 0: 10.02000\r\n    Average Test Accuracy in epoch 0: 9.76000\r\n\r\nAverage loss in epoch 1: 2.30016\r\n    Average Valid Accuracy in epoch 1: 12.56000\r\n    Average Test Accuracy in epoch 1: 12.64000\r\n\r\n  ...\r\n  ...\r\n  ...\r\n\r\nAverage loss in epoch 24: 1.03386\r\n    Average Valid Accuracy in epoch 24: 71.88000\r\n    Average Test Accuracy in epoch 24: 71.23000\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003ca id=\"visualizing\"\u003e\u003c/a\u003e\u003c/p\u003e\r\n\u003ch3 id=\"visualize-the-computational-graph\"\u003eVisualize the Computational Graph\u003c/h3\u003e\r\n\u003cp\u003eFirst, you will see what the computational graph of your model looks like. You can access this view by clicking on the \u003cstrong\u003eGraphs\u003c/strong\u003e view on in TensorBoard. It should look like the image below. You can see that you have a nice flow from \u003ccode\u003etrain_inputs\u003c/code\u003e to \u003ccode\u003eloss\u003c/code\u003e and \u003ccode\u003epredictions\u003c/code\u003e flowing through the \u003cstrong\u003ehidden layers\u003c/strong\u003e \u003cstrong\u003e1\u003c/strong\u003e to \u003cstrong\u003e5\u003c/strong\u003e.\u003c/p\u003e\r\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1524647200/tensorboard_graph_jvkmtq.png\"/\u003e\u003c/p\u003e\r\n\u003ch3 id=\"visualize-the-summary-data\"\u003eVisualize the Summary Data\u003c/h3\u003e\r\n\u003cp\u003eMNIST classification is one of the simplest examples, and it still cannot be solved with a 5 layer neural network. For MNIST, it\u0026#39;s not difficult to achieve an accuracy of more than 90% in less than 5 epochs.\u003c/p\u003e\r\n\u003cp\u003eSo what is going on here?\u003c/p\u003e\r\n\u003cp\u003eLet\u0026#39;s take a look at TensorBoard:\u003c/p\u003e\r\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1524647199/tensorboard_1_tctal1.png\"/\u003e\u003c/p\u003e\r\n\u003ch3 id=\"observations-and-conclusions\"\u003eObservations and Conclusions\u003c/h3\u003e\r\n\u003cp\u003eYou can see that the accuracy is going up, but very slowly, and that the gradient updates are increasing over time. This is an odd behavior. If you\u0026#39;re reaching towards convergence, you should see the gradients diminishing (approaching zero), not increasing.  But because the accuracy is going up, you\u0026#39;re on the right path. You probably need a higher learning rate.\u003c/p\u003e\r\n\u003cp\u003eYou can now try a learning rate of \u003ccode\u003e0.01\u003c/code\u003e. This is almost identical to the previous execution of the neural network, except that you will be using \u003ccode\u003e0.01\u003c/code\u003e instead of \u003ccode\u003e0.0001\u003c/code\u003e. Instead of \u003ccode\u003etf_learning_rate: 0.0001\u003c/code\u003e, use \u003ccode\u003etf_learning_rate: 0.01\u003c/code\u003e. Beware that there are two instances in which you will need to replace the argument.\u003c/p\u003e\r\n\u003cp\u003e\u003ca id=\"insights\"\u003e\u003c/a\u003e\u003c/p\u003e\r\n\u003ch3 id=\"second-look-at-tensorboard-looks-much-better-now\"\u003eSecond Look at TensorBoard: Looks Much Better Now\u003c/h3\u003e\r\n\u003cp\u003eYou can now see that the accuracy starts close to 100 and continues to go up. And you can see that the gradient updates are also diminishing over time and approaching zero. Things seems much better with the learning rate of \u003ccode\u003e0.01\u003c/code\u003e.\u003c/p\u003e\r\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1524647199/tensorboard_2_oogqq3.png\"/\u003e\u003c/p\u003e\r\n\u003cp\u003eNext, let\u0026#39;s move beyond scalars. You will see how you can analyze vectors of scalars and collections of scalars.\u003c/p\u003e\r\n\u003cp\u003e\u003ca id=\"histograms\"\u003e\u003c/a\u003e\u003c/p\u003e\r\n\u003ch2 id=\"beyond-scalars-visualizing-histograms-distributions\"\u003eBeyond Scalars: Visualizing Histograms/Distributions\u003c/h2\u003e\r\n\u003cp\u003eYou saw the benefit of visualizing scalars through TensorBoard, which allowed you to see how the model behaves and fix any potential issues with the model. Moreover, visualizing the graph allowed you to see that there is an uninterrupted link from the inputs to the predictions, which is necessary for gradient calculations.\u003c/p\u003e\r\n\u003cp\u003eNow, you\u0026#39;re going to see another useful view in TensorBoard; histograms or distributions.\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eRemember\u003c/strong\u003e that a histogram is a collection of values represented by the frequency/density that the value has in the collection. You can use histograms to visualize the network weight values over time. Visualizing network weights is important, because if the weights are wildly jumping here and there during learning, it indicates something is wrong with the weight initialization or the learning rate.\u003c/p\u003e\r\n\u003cp\u003eYou will see how weights change in the example. If you look at the code, it uses a \u003ccode\u003etruncated_normal_initializer()\u003c/code\u003e to initialize weights.\u003c/p\u003e\r\n\u003ch3 id=\"defining-histogram-summaries-to-visualize-weights-and-biases\"\u003eDefining Histogram Summaries to Visualize Weights and Biases\u003c/h3\u003e\r\n\u003cp\u003eHere you again define the \u003ccode\u003etf.summary\u003c/code\u003e objects. However, now you are visualizing vectors of scalars so you need to define \u003ccode\u003etf.summary.histogram\u003c/code\u003e objects.\u003c/p\u003e\r\n\u003cp\u003eIn this case, you define two histogram objects (namely, \u003ccode\u003etf_w_hist\u003c/code\u003e and \u003ccode\u003etf_b_hist\u003c/code\u003e) that contain weights and biases of a given layer. You will define such histogram objects for all the layers and each layer will have its own name scope.\u003c/p\u003e\r\n\u003cp\u003eFinally, you can use the \u003ccode\u003etf.summary.merge\u003c/code\u003e operation to create a grouped operation that executes all these summaries at once.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# Summaries need to be displayed\r\n# Create a summary for each weight bias in each layer\r\nall_summaries = []\r\nfor lid in layer_ids:\r\n    with tf.name_scope(lid+\u0026#39;_hist\u0026#39;):\r\n        with tf.variable_scope(lid,reuse=True):\r\n            w,b = tf.get_variable(\u0026#39;weights\u0026#39;), tf.get_variable(\u0026#39;bias\u0026#39;)\r\n\r\n            # Create a scalar summary object for the loss so it can be displayed\r\n            tf_w_hist = tf.summary.histogram(\u0026#39;weights_hist\u0026#39;, tf.reshape(w,[-1]))\r\n            tf_b_hist = tf.summary.histogram(\u0026#39;bias_hist\u0026#39;, b)\r\n            all_summaries.extend([tf_w_hist, tf_b_hist])\r\n\r\n# Merge all parameter histogram summaries together\r\ntf_param_summaries = tf.summary.merge(all_summaries)\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003ch3 id=\"executing-the-neural-network-with-histogram-summaries-\"\u003eExecuting the neural network (with Histogram Summaries)\u003c/h3\u003e\r\n\u003cp\u003eThis step is almost the same as what you did before, but here you have few additional lines to compute the histogram summaries (that is, \u003ccode\u003etf_param_summaries\u003c/code\u003e).  \u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eNote\u003c/strong\u003e that the learning rates have also changed again.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003eimage_size = 28\r\nn_channels = 1\r\nn_classes = 10\r\nn_train = 55000\r\nn_valid = 5000\r\nn_test = 10000\r\nn_epochs = 25\r\n\r\nconfig = tf.ConfigProto(allow_soft_placement=True)\r\nconfig.gpu_options.allow_growth = True\r\nconfig.gpu_options.per_process_gpu_memory_fraction = 0.9 # making sure Tensorflow doesn\u0026#39;t overflow the GPU\r\n\r\nsession = tf.InteractiveSession(config=config)\r\n\r\nif not os.path.exists(\u0026#39;summaries\u0026#39;):\r\n    os.mkdir(\u0026#39;summaries\u0026#39;)\r\nif not os.path.exists(os.path.join(\u0026#39;summaries\u0026#39;,\u0026#39;third\u0026#39;)):\r\n    os.mkdir(os.path.join(\u0026#39;summaries\u0026#39;,\u0026#39;third\u0026#39;))\r\n\r\nsumm_writer_3 = tf.summary.FileWriter(os.path.join(\u0026#39;summaries\u0026#39;,\u0026#39;third\u0026#39;), session.graph)\r\n\r\ntf.global_variables_initializer().run()\r\n\r\naccuracy_per_epoch = []\r\nmnist_data = input_data.read_data_sets(\u0026#39;MNIST_data\u0026#39;, one_hot=True)\r\n\r\n\r\nfor epoch in range(n_epochs):\r\n    loss_per_epoch = []\r\n    for i in range(n_train//batch_size):\r\n\r\n        # =================================== Training for one step ========================================\r\n        batch = mnist_data.train.next_batch(batch_size)    # Get one batch of training data\r\n        if i == 0:\r\n            # Only for the first epoch, get the summary data\r\n            # Otherwise, it can clutter the visualization\r\n            l,_,gn_summ, wb_summ = session.run([tf_loss,tf_loss_minimize,tf_gradnorm_summary, tf_param_summaries],\r\n                                      feed_dict={train_inputs: batch[0].reshape(batch_size,image_size*image_size),\r\n                                                 train_labels: batch[1],\r\n                                                tf_learning_rate: 0.00001})\r\n            summ_writer_3.add_summary(gn_summ, epoch)\r\n            summ_writer_3.add_summary(wb_summ, epoch)\r\n        else:\r\n            # Optimize with training data\r\n            l,_ = session.run([tf_loss,tf_loss_minimize],\r\n                              feed_dict={train_inputs: batch[0].reshape(batch_size,image_size*image_size),\r\n                                         train_labels: batch[1],\r\n                                         tf_learning_rate: 0.01})\r\n        loss_per_epoch.append(l)\r\n\r\n    print(\u0026#39;Average loss in epoch %d: %.5f\u0026#39;%(epoch,np.mean(loss_per_epoch)))    \r\n    avg_loss = np.mean(loss_per_epoch)\r\n\r\n    # ====================== Calculate the Validation Accuracy ==========================\r\n    valid_accuracy_per_epoch = []\r\n    for i in range(n_valid//batch_size):\r\n        valid_images,valid_labels = mnist_data.validation.next_batch(batch_size)\r\n        valid_batch_predictions = session.run(\r\n            tf_predictions,feed_dict={train_inputs: valid_images.reshape(batch_size,image_size*image_size)})\r\n        valid_accuracy_per_epoch.append(accuracy(valid_batch_predictions,valid_labels))\r\n\r\n    mean_v_acc = np.mean(valid_accuracy_per_epoch)\r\n    print(\u0026#39;\\tAverage Valid Accuracy in epoch %d: %.5f\u0026#39;%(epoch,np.mean(valid_accuracy_per_epoch)))\r\n\r\n    # ===================== Calculate the Test Accuracy ===============================\r\n    accuracy_per_epoch = []\r\n    for i in range(n_test//batch_size):\r\n        test_images, test_labels = mnist_data.test.next_batch(batch_size)\r\n        test_batch_predictions = session.run(\r\n            tf_predictions,feed_dict={train_inputs: test_images.reshape(batch_size,image_size*image_size)}\r\n        )\r\n        accuracy_per_epoch.append(accuracy(test_batch_predictions,test_labels))\r\n\r\n    print(\u0026#39;\\tAverage Test Accuracy in epoch %d: %.5f\\n\u0026#39;%(epoch,np.mean(accuracy_per_epoch)))\r\n    avg_test_accuracy = np.mean(accuracy_per_epoch)\r\n\r\n    # Execute the summaries defined above\r\n    summ = session.run(performance_summaries, feed_dict={tf_loss_ph:avg_loss, tf_accuracy_ph:avg_test_accuracy})\r\n\r\n    # Write the obtained summaries to the file, so they can be displayed\r\n    summ_writer_3.add_summary(summ, epoch)\r\n\r\nsession.close()\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003eExtracting MNIST_data/train-images-idx3-ubyte.gz\r\nExtracting MNIST_data/train-labels-idx1-ubyte.gz\r\nExtracting MNIST_data/t10k-images-idx3-ubyte.gz\r\nExtracting MNIST_data/t10k-labels-idx1-ubyte.gz\r\nAverage loss in epoch 0: 1.02625\r\n    Average Valid Accuracy in epoch 0: 92.76000\r\n    Average Test Accuracy in epoch 0: 92.65000\r\n\r\nAverage loss in epoch 1: 0.19110\r\n    Average Valid Accuracy in epoch 1: 95.80000\r\n    Average Test Accuracy in epoch 1: 95.48000\r\n\r\n  ...\r\n  ...\r\n  ...\r\n\r\nAverage loss in epoch 24: 0.00009\r\n    Average Valid Accuracy in epoch 24: 98.28000\r\n    Average Test Accuracy in epoch 24: 98.09000\r\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"visualizing-histogram-data-of-weights-and-biases\"\u003eVisualizing Histogram Data of Weights and Biases\u003c/h3\u003e\r\n\u003cp\u003eHere\u0026#39;s what your weights and biases look like. First, you have 3 axes; time (x-axis), value (y-axis) and frequency/density of values (z-axis). Darker histograms represent older data and lighter histograms represent newer data. A higher value on the z axis means that the vector contains more values near that specific value.\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eNote\u003c/strong\u003e: you also have an \u0026quot;overlay\u0026quot; view of the histograms over time as well. You can change the type of display on the left side option panel.\u003c/p\u003e\r\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1524647199/tensorboard_3_1_twfnqm.png\"/\u003e\r\n\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1524647199/tensorboard_3_2_re94rh.png\"/\u003e\r\n\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1524647199/tensorboard_3_3_q2l6bt.png\"/\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003ca id=\"weights\"\u003e\u003c/a\u003e\u003c/p\u003e\r\n\u003ch3 id=\"the-effect-of-different-initializers\"\u003eThe Effect of Different Initializers\u003c/h3\u003e\r\n\u003cp\u003eNow, instead of using \u003ccode\u003etruncated_normal_initializer()\u003c/code\u003e, you will use the \u003ccode\u003exavier_initializer()\u003c/code\u003e to initialize weights. Xavier initialization is a much better initialization technique, especially for deep neural networks.\u003c/p\u003e\r\n\u003cp\u003eThis is because  instead of using a user defined standard deviation (as you did when using the \u003ccode\u003etruncated_normal_initializer()\u003c/code\u003e), Xavier initialization automatically decides the standard deviation based on the number of input and output connections to a layer. This helps to flow gradients from top to bottom without issues like \u003cem\u003evanishing gradient\u003c/em\u003e. You then define the model again.\u003c/p\u003e\r\n\u003cp\u003eFirst, you define a \u003ccode\u003ebatch_size\u003c/code\u003e denoting the amount of data you sample at a single optimization/validation or testing step. You can then define the \u003ccode\u003elayer_ids\u003c/code\u003e, which give an identifier for each of the layers of the neural network you will be defining.\u003c/p\u003e\r\n\u003cp\u003eYou can then define \u003ccode\u003elayer_sizes\u003c/code\u003e. Note that \u003ccode\u003elen(layer_sizes)\u003c/code\u003e should be \u003ccode\u003elen(layer_ids)+1\u003c/code\u003e, because \u003ccode\u003elayer_sizes\u003c/code\u003e includes the size of the input at the beginning. MNIST has images of size 28x28, which will be 784 when unwrapped to a single dimension.\u003c/p\u003e\r\n\u003cp\u003eThen, you can define the input and label placeholders, which you will later use to train the model. Finally, you define two TensorFlow variables for each layer (that is, \u003ccode\u003eweights\u003c/code\u003e and \u003ccode\u003ebias\u003c/code\u003e).\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eNote\u003c/strong\u003e: This is identical to the code you used first time, except for the initialization technique used for the weights\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003ebatch_size = 100\r\nlayer_ids = [\u0026#39;hidden1\u0026#39;,\u0026#39;hidden2\u0026#39;,\u0026#39;hidden3\u0026#39;,\u0026#39;hidden4\u0026#39;,\u0026#39;hidden5\u0026#39;,\u0026#39;out\u0026#39;]\r\nlayer_sizes = [784, 500, 400, 300, 200, 100, 10]\r\n\r\ntf.reset_default_graph()\r\n\r\n# Inputs and Labels\r\ntrain_inputs = tf.placeholder(tf.float32, shape=[batch_size, layer_sizes[0]], name=\u0026#39;train_inputs\u0026#39;)\r\ntrain_labels = tf.placeholder(tf.float32, shape=[batch_size, layer_sizes[-1]], name=\u0026#39;train_labels\u0026#39;)\r\n\r\n# Weight and Bias definitions\r\nfor idx, lid in enumerate(layer_ids):\r\n\r\n    with tf.variable_scope(lid):\r\n        w = tf.get_variable(\u0026#39;weights\u0026#39;,shape=[layer_sizes[idx], layer_sizes[idx+1]],\r\n                            initializer=tf.contrib.layers.xavier_initializer())\r\n        b = tf.get_variable(\u0026#39;bias\u0026#39;,shape= [layer_sizes[idx+1]],\r\n                            initializer=tf.random_uniform_initializer(-0.1,0.1))\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003ch3 id=\"calculating-logits-predictions-loss-and-optimization\"\u003eCalculating Logits, Predictions, Loss and Optimization\u003c/h3\u003e\r\n\u003cp\u003eWith the input/output placeholders, weights and biases of each layer defined, you now can define the calculations to calculate the logits of the neural network again.\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eNote\u003c/strong\u003e: This part is identical to the code you used the first time you defined these operations and tensors.\u003c/p\u003e\r\n\u003ch3 id=\"define-summaries\"\u003eDefine Summaries\u003c/h3\u003e\r\n\u003cp\u003eHere you can define the \u003ccode\u003etf.summary\u003c/code\u003e objects again. This is also identical to the code you used the first time you defined these operations and tensors.\u003c/p\u003e\r\n\u003ch3 id=\"histogram-summaries-visualizing-weights-and-biases\"\u003eHistogram Summaries: Visualizing Weights and Biases\u003c/h3\u003e\r\n\u003cp\u003eHere you again define the \u003ccode\u003etf.summary\u003c/code\u003e objects. However, you now are visualizing vectors of scalars so you need to define \u003ccode\u003etf.summary.histogram\u003c/code\u003e objects.\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eNote\u003c/strong\u003e that this is identical to the code you used the first time you defined these operations and tensors.\u003c/p\u003e\r\n\u003ch3 id=\"execute-the-neural-network\"\u003eExecute the neural network\u003c/h3\u003e\r\n\u003cp\u003e\u003cstrong\u003eNote\u003c/strong\u003e that this is the same as what you did before in the previous section!\u003c/p\u003e\r\n\u003cp\u003eThere are only a few bits of code that you need to change: the three occurrences of \u003ccode\u003eos.path.join(\u0026#39;summaries\u0026#39;,\u0026#39;third\u0026#39;)\u003c/code\u003e to \u003ccode\u003eos.path.join(\u0026#39;summaries\u0026#39;,\u0026#39;fourth\u0026#39;)\u003c/code\u003e, \u003ccode\u003esumm_writer_3\u003c/code\u003e to \u003ccode\u003esumm_writer_4\u003c/code\u003e (this appears 4 times) and the \u003ccode\u003etf_learning_rate\u003c/code\u003e of \u003ccode\u003e0.00001\u003c/code\u003e has to be set to \u003ccode\u003e0.01\u003c/code\u003e.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e\r\nimage_size = 28\r\nn_channels = 1\r\nn_classes = 10\r\nn_train = 55000\r\nn_valid = 5000\r\nn_test = 10000\r\nn_epochs = 25\r\n\r\nconfig = tf.ConfigProto(allow_soft_placement=True)\r\nconfig.gpu_options.allow_growth = True\r\nconfig.gpu_options.per_process_gpu_memory_fraction = 0.9 # making sure TensorFlow doesn\u0026#39;t overflow the GPU\r\n\r\nsession = tf.InteractiveSession(config=config)\r\n\r\nif not os.path.exists(\u0026#39;summaries\u0026#39;):\r\n    os.mkdir(\u0026#39;summaries\u0026#39;)\r\nif not os.path.exists(os.path.join(\u0026#39;summaries\u0026#39;,\u0026#39;fourth\u0026#39;)):\r\n    os.mkdir(os.path.join(\u0026#39;summaries\u0026#39;,\u0026#39;fourth\u0026#39;))\r\n\r\nsumm_writer_4 = tf.summary.FileWriter(os.path.join(\u0026#39;summaries\u0026#39;,\u0026#39;fourth\u0026#39;), session.graph)\r\n\r\ntf.global_variables_initializer().run()\r\n\r\naccuracy_per_epoch = []\r\nmnist_data = input_data.read_data_sets(\u0026#39;MNIST_data\u0026#39;, one_hot=True)\r\n\r\n\r\nfor epoch in range(n_epochs):\r\n    loss_per_epoch = []\r\n    for i in range(n_train//batch_size):\r\n\r\n        # =================================== Training for one step ========================================\r\n        batch = mnist_data.train.next_batch(batch_size)    # Get one batch of training data\r\n        if i == 0:\r\n            # Only for the first epoch, get the summary data\r\n            # Otherwise, it can clutter the visualization\r\n            l,_,gn_summ, wb_summ = session.run([tf_loss,tf_loss_minimize,tf_gradnorm_summary, tf_param_summaries],\r\n                                      feed_dict={train_inputs: batch[0].reshape(batch_size,image_size*image_size),\r\n                                                 train_labels: batch[1],\r\n                                                tf_learning_rate: 0.01})\r\n            summ_writer_4.add_summary(gn_summ, epoch)\r\n            summ_writer_4.add_summary(wb_summ, epoch)\r\n        else:\r\n            # Optimize with training data\r\n            l,_ = session.run([tf_loss,tf_loss_minimize],\r\n                              feed_dict={train_inputs: batch[0].reshape(batch_size,image_size*image_size),\r\n                                         train_labels: batch[1],\r\n                                         tf_learning_rate: 0.01})\r\n        loss_per_epoch.append(l)\r\n\r\n    print(\u0026#39;Average loss in epoch %d: %.5f\u0026#39;%(epoch,np.mean(loss_per_epoch)))    \r\n    avg_loss = np.mean(loss_per_epoch)\r\n\r\n    # ====================== Calculate the Validation Accuracy ==========================\r\n    valid_accuracy_per_epoch = []\r\n    for i in range(n_valid//batch_size):\r\n        valid_images,valid_labels = mnist_data.validation.next_batch(batch_size)\r\n        valid_batch_predictions = session.run(\r\n            tf_predictions,feed_dict={train_inputs: valid_images.reshape(batch_size,image_size*image_size)})\r\n        valid_accuracy_per_epoch.append(accuracy(valid_batch_predictions,valid_labels))\r\n\r\n    mean_v_acc = np.mean(valid_accuracy_per_epoch)\r\n    print(\u0026#39;\\tAverage Valid Accuracy in epoch %d: %.5f\u0026#39;%(epoch,np.mean(valid_accuracy_per_epoch)))\r\n\r\n    # ===================== Calculate the Test Accuracy ===============================\r\n    accuracy_per_epoch = []\r\n    for i in range(n_test//batch_size):\r\n        test_images, test_labels = mnist_data.test.next_batch(batch_size)\r\n        test_batch_predictions = session.run(\r\n            tf_predictions,feed_dict={train_inputs: test_images.reshape(batch_size,image_size*image_size)}\r\n        )\r\n        accuracy_per_epoch.append(accuracy(test_batch_predictions,test_labels))\r\n\r\n    print(\u0026#39;\\tAverage Test Accuracy in epoch %d: %.5f\\n\u0026#39;%(epoch,np.mean(accuracy_per_epoch)))\r\n    avg_test_accuracy = np.mean(accuracy_per_epoch)\r\n\r\n    # Execute the summaries defined above\r\n    summ = session.run(performance_summaries, feed_dict={tf_loss_ph:avg_loss, tf_accuracy_ph:avg_test_accuracy})\r\n\r\n    # Write the obtained summaries to the file, so they can be displayed\r\n    summ_writer_4.add_summary(summ, epoch)\r\n\r\nsession.close()\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003eExtracting MNIST_data/train-images-idx3-ubyte.gz\r\nExtracting MNIST_data/train-labels-idx1-ubyte.gz\r\nExtracting MNIST_data/t10k-images-idx3-ubyte.gz\r\nExtracting MNIST_data/t10k-labels-idx1-ubyte.gz\r\nAverage loss in epoch 0: 0.43618\r\n    Average Valid Accuracy in epoch 0: 95.70000\r\n    Average Test Accuracy in epoch 0: 95.22000\r\n\r\nAverage loss in epoch 1: 0.12872\r\n    Average Valid Accuracy in epoch 1: 96.86000\r\n    Average Test Accuracy in epoch 1: 96.71000\r\n\r\n  ...\r\n  ...\r\n  ...\r\n\r\nAverage loss in epoch 24: 0.00009\r\n    Average Valid Accuracy in epoch 24: 98.42000\r\n    Average Test Accuracy in epoch 24: 98.21000\r\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"how-to-compare-different-initialization-techniques\"\u003eHow To Compare Different Initialization Techniques\u003c/h3\u003e\r\n\u003cp\u003eHere you can compare how weights evolve over time for the two different initalizations; \u003ccode\u003etruncated_normal_initializer\u003c/code\u003e (red) and \u003ccode\u003exavier_initializer\u003c/code\u003e (blue). You can see that \u003ccode\u003exavier_initializer\u003c/code\u003e keeps more weights away from zero than the normal initializer, which is a better thing to do. This is potentially allowing the Xavier initialized neural networks to converge faster, as evident by the loss/accuracy curves.\u003c/p\u003e\r\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1524647200/tensorboard_3_and_4_uc5jqf.jpg\"/\u003e\u003c/p\u003e\r\n\u003ch2 id=\"distribution-view-of-histograms\"\u003eDistribution View of Histograms\u003c/h2\u003e\r\n\u003cp\u003eYou now can compare the difference between the two views; histogram view and the distribution view. Distribution view is essentially a different way of looking at the histograms. If you look at the image below, you can easily see that the distribution view is a top view of the histogram view. Note that the histogram graphs are rotated in this case to easily see the resemblance.\u003c/p\u003e\r\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1524647200/tensorboard_histogram_vs_distribution_views_xhqe8e.png\"/\u003e\u003c/p\u003e\r\n\u003ch2 id=\"conclusion\"\u003eConclusion\u003c/h2\u003e\r\n\u003cp\u003eIn this tutorial, you saw how to use TensorBoard. First, you learned how to start its service through the command prompt (Windows) or terminal (Ubuntu/Mac). Next, you looked at different views of data provided by TensorBoard. You then looked at code that visualizes scalar values (for example loss / accuracy) and used a feed-forward neural network model to concretely understand the use of the scalar value visualization.\u003c/p\u003e\r\n\u003cp\u003eThereafter, you explored how you can visualize collections/vectors of scalars using the histogram view. This was followed by a comparison highlighting the differences between neural network weight initialization techniques using the histogram view.\u003c/p\u003e\r\n\u003cp\u003eFinally, you discussed the similarities between the distribution view and the histogram view.\u003c/p\u003e\r\n\u003cp\u003eIf you would like to learn more about deep learning, be sure to take a look at our \u003ca href=\"https://www.datacamp.com/courses/deep-learning-in-python\"\u003eDeep Learning in Keras\u003c/a\u003e course.\u003c/p\u003e\r\n\u003cp\u003eIf you\u0026#39;d like to get in touch with me, you can drop me an e-mail at thushv@gmail.com or connect with me via \u003ca href=\"https://www.linkedin.com/in/thushanganegedara/\"\u003eLinkedIn\u003c/a\u003e.\u003c/p\u003e\r\n","contentUrl":"https://www.datacamp.com/community/tutorials/tensorboard-tutorial","userContentUrl":null,"illustrationUrl":null,"seoTitle":"TensorBoard Tutorial For Beginners","seoMetaDescription":"In this TensorBoard tutorial, you'll learn how to visualize the training parameters, metrics, hyperparameters or any statistics of your neural network!","seoKeyword":"TensorBoard Tutorial","mustRead":false,"programmingLanguage":null,"submissionDate":"2018-04-24T09:09:22.671Z","publishDate":"2018-06-06T10:00:00.000Z","episode":null,"isLatest":null,"externalUrl":null,"transcriptUrl":null,"guests":[],"links":null,"isSpam":false,"xp":0,"flaggingUsers":[],"isDisabled":false,"connectedInternalContentId":10117,"createdAt":"2018-04-24T09:09:22.658Z","updatedAt":"2018-06-06T20:57:04.374Z","upvoting":{"voteCount":7,"voted":false},"tags":["neural networks","deep learning","tensorflow"],"author":{"id":2125563,"slug":"thushv","avatarUrlSquare":"https://assets.datacamp.com/users/avatars/002/125/563/square/profile.jpeg?1518563443","fullName":"Thushan Ganegedara","nameFromEmail":"thushv","isAdmin":false}},{"id":10071,"externalId":null,"type":"Tutorial","status":"published","authorId":"mgalarny-9d736b5c-bc15-4424-b6e2-2171c0af2e4a","title":"Installing Anaconda on Mac OS X","slug":"installing-anaconda-mac-os-x","previewSlug":null,"description":"This tutorial will demonstrate how you can install Anaconda, a powerful package manager, on your Mac.","articles":[],"courses":[],"redirectSlug":null,"contentHtml":"\u003cp\u003eAnaconda is a package manager, an environment manager, and Python distribution that contains a collection of many open source packages. An installation of Anaconda comes with many packages such as numpy, scikit-learn, scipy, and pandas preinstalled and is also the \u003ca href=\"http://jupyter.org/install.html\"\u003erecommended way to install Jupyter Notebooks\u003c/a\u003e. This tutorial will include:\u003c/p\u003e\n\u003cp\u003e\u003cnav\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#gui\"\u003eHow to Install Anaconda by using a graphical installer\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#test\"\u003eHow to test your installation and fix common installation issues\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#after\"\u003eWhat to do after installing Anaconda.\u003c/a\u003e\n\u003c/nav\u003e\n\u003cdiv id=\"scoped-content\"\u003e\u003cstyle type=\"text/css\"\u003e:target:before { content:\"\"; display:block; height:150px; margin:-150px 0 0; } h3 {font-weight:normal; margin-top:.5em} h4 { font-weight:lighter }\n\u003c/style\u003e\n\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWith that, lets get started\u003c/p\u003e\n\u003cp\u003e\u003ca id=\"gui\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"graphical-installation-of-anaconda\"\u003eGraphical Installation of Anaconda\u003c/h2\u003e\n\u003cp\u003eInstalling Anaconda using a graphical installer is probably the easiest way to install Anaconda.\u003c/p\u003e\n\u003cp\u003e1  Go to the \u003ca href=\"https://www.anaconda.com/download/#macos\"\u003eAnaconda Website\u003c/a\u003e and choose a Python 3.x graphical installer (A) or a Python 2.x graphical installer (B). If you arent sure which Python version you want to install, choose Python 3. \u003cstrong\u003eDo not choose both\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1524574895/1_t80NtO9yzEmR-780X-VqyQ_knhqai.png\"/\u003e\u003c/p\u003e\n\u003cp\u003e2 - Locate your download and double click it.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1524574894/1_jn5uWfWFRo59d-SdmtVLYg_qdydof.png\"/\u003e\u003c/p\u003e\n\u003cp\u003e3 - Click on Continue\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1524574894/1_s3ExKfXaWZTxCZwsp5zHIQ_jkurlq.png\"/\u003e\u003c/p\u003e\n\u003cp\u003e4 - Click on Continue\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1524574895/1_U0VDYn3MyrMLuT9MywHEpg_t1dbkk.png\"/\u003e\u003c/p\u003e\n\u003cp\u003e5 - Note that when you install Anaconda, it modifies your bash profile with either anaconda3 or anaconda2 depending on what Python version you choose. \u003cstrong\u003eThis can important for later\u003c/strong\u003e. Click on Continue.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1524574894/1_MP1JnekC9Rt3pcx_iI_oXQ_sbyoao.png\"/\u003e\u003c/p\u003e\n\u003cp\u003e6 - Click on Continue to get the License Agreement to appear.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1524574896/1_yJi9zxuECYsH2z3pVerjDw_m2rkz3.png\"/\u003e\u003c/p\u003e\n\u003cp\u003eYou will need to read and click Agree to the license agreement before clicking on Continue again.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1524574896/1_YPcf2ryBVKTszXlcIyA5oQ_f3harg.png\"/\u003e\u003c/p\u003e\n\u003cp\u003e7 - Click on Install\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1524574893/1_-6PruLPlIcDPGcO6J6uWIA_uarmcv.png\"/\u003e\u003c/p\u003e\n\u003cp\u003e8 - Youll be prompted to give your password, which is usually the one that you also use to unlock your Mac when you start it up. After you enter your password, click on Install Software.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1524574895/1_W2jgSCmoWO9-aieiyvWrGA_b0xhis.png\"/\u003e\u003c/p\u003e\n\u003cp\u003e9 - Click on Continue. You can install Microsoft Visual Studio Code if you like, but it is not required. It is an Integrated Development Environment. You can learn about Python Integrated Development Environments \u003ca href=\"https://www.datacamp.com/community/tutorials/data-science-python-ide\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1524574893/1_-SF1N3YH5KjhRq5gYSaFzA_joyk3z.png\"/\u003e\u003c/p\u003e\n\u003cp\u003e10 - You should get a screen saying the installation has completed. Close the installer and move it to the trash.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1524574893/1_DE-uFn3xEiCxqktB2ryf_Q_pe438o.png\"/\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca id=\"test\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"test-your-installation\"\u003eTest your Installation\u003c/h2\u003e\n\u003cp\u003e1 - Open a \u003cstrong\u003enew terminal\u003c/strong\u003e on your Mac. You can do this by clicking on the Spotlight magnifying glass at the top right of the screen, type terminal then click on the terminal icon. Now, type the following command into your terminal\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003epython --version\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1524574893/1_cTOOkqZCYWfwSEFhAI1nCQ_jeu48m.gif\"/\u003e\u003c/p\u003e\n\u003cp\u003eIf you had chosen a Python 3 version of Anaconda (like the one in the image above), you will get an output similar to above.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1524575537/1_w5tXcnOlXX3p1v_4RsxBlw_sesmxd.png\"/\u003e\u003c/p\u003e\n\u003cp\u003eIf you had chosen a Python 2 version of Anaconda, you should get a similar output to the one below.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003epython --version\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1524575537/1_YmtxeDXmki4ml5U33i5Q1w_uufbmi.png\"/\u003e\u003c/p\u003e\n\u003cp\u003e2 - Another good way to test your installation is to try and open a Jupyter Notebook. You can type the command below in your terminal to open a Jupyter Notebook. If the command fails, chances are that Anaconda isnt in your path. See the next section on Common Issues.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003ejupyter notebook\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe image below shows a Jupyter Notebook in action. Jupyter notebooks contain both code and rich text elements, such as figures, links, and equations. You can learn more about Jupyter Notebooks \u003ca href=\"https://www.datacamp.com/community/tutorials/tutorial-jupyter-notebook\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1524574893/1_1IijNUMn_tQ3InlN0ADQWQ_zdnnh7.gif\"/\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca id=\"after\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"common-issues\"\u003eCommon Issues\u003c/h2\u003e\n\u003cp\u003eThe image below shows step 5 of the Graphical Installation of Anaconda from earlier in this tutorial. Notice that when you install Anaconda, it modifies your .bash_profile to put Anaconda in your path.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1524574894/1_MP1JnekC9Rt3pcx_iI_oXQ_sbyoao.png\"/\u003e\u003c/p\u003e\n\u003cp\u003eThe problem is that sometimes people have installed multiple different versions of Anaconda and consequently they have multiple versions of Anaconda in their path. For example, say a person needs Python 2 and they install a Python 2 version of Anaconda, That same person then finds that they need Python 3, so they install a Python 3 version of Anaconda. The problem is that you really \u003cstrong\u003eonly need 1 version of Anaconda\u003c/strong\u003e. A lot of people think that is that if you install a Python 2 version of Anaconda, you are stuck with Python 2. Anaconda is also an environment manager and makes it very easy to go back and forth between Python 2 and 3 on a single installation of Anaconda (learn more \u003ca href=\"https://medium.com/r/?url=https%3A%2F%2Ftowardsdatascience.com%2Fenvironment-management-with-conda-python-2-3-b9961a8a5097\"\u003ehere\u003c/a\u003e).\u003c/p\u003e\n\u003cp\u003eTo see if you have more than 1 version of anaconda installed and to fix it if you do, lets first look at your .bash_profile.\u003c/p\u003e\n\u003cp\u003e1 - Open a new terminal and go to your home directory. You can do this by using the command below.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-bash\"\u003ecd ~\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e2 - Use the \u003ccode\u003ecat\u003c/code\u003e command to see the contents of the hidden file .bash_profile. Type the following command into your terminal.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-bash\"\u003ecat .bash_profile\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eYou should only see one anaconda version added to your path as you see below, this isnt a problem for you. Move to the conclusion of the tutorial.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1524574894/1_GhpTPeunftfa8w_n4kO_Ag_yvuaj7.png\"/\u003e\u003c/p\u003e\n\u003cp\u003eIf you see more than one Anaconda version, proceed to step 3.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1524574895/1_t5nVJ8CJ2x1DHNEqwOyeoA_sa9dcw.png\"/\u003e\u003c/p\u003e\n\u003cp\u003e3 - To remove the old version of Anaconda from your .bash_profile use the command below to edit the file using the nano editor.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-bash\"\u003enano .bash_profile\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1524574894/1_oSNFz4rJgxDTYLJTJGVxkg_hpw2ta.png\"/\u003e\u003c/p\u003e\n\u003cp\u003eFrom the image above, notice there is a newer Version of Anaconda. Simply remove the older version of Anaconda. Type control + X to exit out of nano.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1524574894/1_IgJOoh2Gi1hraum4oSNpQw_ke4itf.png\"/\u003e\u003c/p\u003e\n\u003cp\u003eSave changes by typing Y.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1524574894/1_exp7Y8_BNY_MAHcDphfgGA_fycy7e.png\"/\u003e\u003c/p\u003e\n\u003cp\u003eClose that terminal and open a new one. You should be okay now. Keep in mind that this isnt the only issue you can have when installing Anaconda, but it is a very common issue.\u003c/p\u003e\n\u003ch2 id=\"conclusion\"\u003eConclusion\u003c/h2\u003e\n\u003cp\u003eThis tutorial provided a quick guide to install Anaconda on Mac as well as dealing with a common installation issue. A graphical install of Anaconda isnt the only way to install Anaconda as you can \u003ca href=\"https://medium.com/@GalarnykMichael/install-python-on-mac-anaconda-ccd9f2014072\"\u003eInstall Anaconda by a Command Line Installer\u003c/a\u003e, but it is the easiest. If you arent sure what to do after installing Anaconda, here are a few things you can do:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eIf you would like to learn more about Anaconda, you can learn about more \u003ca href=\"https://towardsdatascience.com/environment-management-with-conda-python-2-3-b9961a8a5097\"\u003ehere\u003c/a\u003e.\u003c/li\u003e\n\u003cli\u003eIf you want to start coding on your local computer, you can check out the the \u003ca href=\"https://www.datacamp.com/community/tutorials/tutorial-jupyter-notebook\"\u003eJupyter Notebook Definitive Guide\u003c/a\u003e to learn how to code in Jupyter Notebooks.\u003c/li\u003e\n\u003cli\u003eIf you want to learn Python, you can check out the free DataCamp course \u003ca href=\"https://www.datacamp.com/courses/intro-to-python-for-data-science\"\u003eIntro to Python for Data Science\u003c/a\u003e.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eIf you any questions or thoughts on the tutorial, feel free to reach out in the comments below or through \u003ca href=\"https://twitter.com/GalarnykMichael\"\u003eTwitter\u003c/a\u003e.\u003c/p\u003e\n","contentUrl":"https://www.datacamp.com/community/tutorials/installing-anaconda-mac-os-x","userContentUrl":null,"illustrationUrl":null,"seoTitle":"How to Install Anaconda on Mac OS X","seoMetaDescription":"This tutorial will demonstrate how you can install Anaconda, a powerful package manager, on your Mac.","seoKeyword":"Installing Anaconda Mac OS X","mustRead":false,"programmingLanguage":null,"submissionDate":"2018-05-28T16:54:55.235Z","publishDate":"2018-06-05T10:00:00.000Z","episode":null,"isLatest":null,"externalUrl":null,"transcriptUrl":null,"guests":[],"links":null,"isSpam":false,"xp":0,"flaggingUsers":[],"isDisabled":false,"connectedInternalContentId":null,"createdAt":"2018-05-28T16:54:55.233Z","updatedAt":"2018-06-08T20:41:49.413Z","upvoting":{"voteCount":6,"voted":false},"tags":["python"],"author":{"id":1782418,"slug":"mgalarny-9d736b5c-bc15-4424-b6e2-2171c0af2e4a","avatarUrlSquare":"https://assets.datacamp.com/users/avatars/001/782/418/square/0_PGUE8F8TgCL-M4md.jpg?1512569472","fullName":"Michael Galarnyk","nameFromEmail":"mgalarny","isAdmin":false}},{"id":9995,"externalId":null,"type":"Tutorial","status":"published","authorId":"stephaniehowson","title":"Custom Templates for Jupyter Notebooks with Jinja2","slug":"jinja2-custom-export-templates-jupyter","previewSlug":null,"description":"Learn how to create custom export templates for your Jupyter Notebooks using Jinja2.","articles":[],"courses":[],"redirectSlug":null,"contentHtml":"\u003cp\u003eIn data science, you will often need to create reports of your work to show to decision makers or other non-technical personnel. Converting your Jupyter Notebook into a stable PDF or HTML document is more transferable to colleagues who do not have Python or Jupyter installed. Python uses a library called \u003ccode\u003enbconvert\u003c/code\u003e and a templating language called \u003ccode\u003eJinja2\u003c/code\u003e for converting documents. Templates define how a document will be displayed on a webpage or another output format. Understanding how to customize templates is beneficial to making beautified reports of your Notebooks.\u003c/p\u003e\r\n\u003cp\u003eJupyter notebooks are a way to run Python code in your browser. If you\u0026#39;d like to learn more about Python, be sure tot take a look at our free \u003ca href=\"https://www.datacamp.com/courses/intro-to-python-for-data-science\"\u003eIntro to Python for Data Science\r\n\u003c/a\u003e course.\u003c/p\u003e\r\n\u003cp\u003eIn this tutorial, you\u0026#39;ll cover the following topics:\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli\u003e\u003ca href=\"#what\"\u003eTemplates and the \u003ccode\u003eJinja2\u003c/code\u003e template designer.\u003c/a\u003e\u003c/li\u003e\r\n\u003cli\u003e\u003ca href=\"#render\"\u003eRendering templates and inheritance.\u003c/a\u003e\u003c/li\u003e\r\n\u003cli\u003e\u003ca href=\"#nbconvert\"\u003eHow to use \u003ccode\u003enbconvert\u003c/code\u003e for exporting your Notebooks.\u003c/a\u003e\u003c/li\u003e\r\n\u003cli\u003e\u003ca href=\"#syntax\"\u003eThe syntax and structure for extending the Jupyter default templates for HTML export.\u003c/a\u003e\u003c/li\u003e\r\n\u003cli\u003e\u003ca href=\"#export\"\u003eThe differences for exporting to LaTeX and PDF formats.\u003c/a\u003e\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003e\u003ca id=\"what\"\u003e\u003c/a\u003e\u003c/p\u003e\r\n\u003ch2 id=\"what-are-templates-\"\u003eWhat are templates?\u003c/h2\u003e\r\n\u003cp\u003eFrom the Python wiki:\r\n\u0026quot;Templating, and in particular web templating, is a way to represent data in different forms... Frequently, templating solutions involve a document (the template) and data. Templates usually look much like the final output, with placeholders instead of actual data\u0026quot;\u003c/p\u003e\r\n\u003cp\u003eThe Jupyter Notebook can be exported easily by using \u003ccode\u003eFile\u003c/code\u003e -\u0026gt; \u003ccode\u003eDownload As\u003c/code\u003e (In Jupyter Lab, you will see \u003ccode\u003eExport Notebook As\u003c/code\u003e). This option uses the default templates held in the main Jupyter environment. \u003ccode\u003eJinja2\u003c/code\u003e is a powerful templating language for Python to define blocking and typesetting. Templates have sections, defined by \u003cem\u003etags\u003c/em\u003e, which tell the template how to render the input data. The data replaces the \u003cem\u003evariables\u003c/em\u003e, or \u003cem\u003eexpressions\u003c/em\u003e, when the template is rendered.\u003c/p\u003e\r\n\u003cp\u003eThe delimiters for the different sections of a template are:\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli\u003e\u003ccode\u003e{% ... %}\u003c/code\u003e for Statements\u003c/li\u003e\r\n\u003cli\u003e\u003ccode\u003e{{ ... }}\u003c/code\u003e for Expressions to print to the template output\u003c/li\u003e\r\n\u003cli\u003e\u003ccode\u003e{# ... #}\u003c/code\u003e for Comments not included in the template output\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003eTake a look at this short example of a \u003ccode\u003eJinja\u003c/code\u003e template (courtesy of \u003ccode\u003eJinja2\u003c/code\u003e documentation):\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-html\"\u003e\u0026lt;!DOCTYPE html\u0026gt;\r\n\r\n\u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt;\r\n\r\n\u0026lt;head\u0026gt;\r\n\r\n    {% block head %}\r\n    \u0026lt;link rel=\u0026quot;stylesheet\u0026quot; href=\u0026quot;style.css\u0026quot; /\u0026gt;\r\n    \u0026lt;title\u0026gt;{% block title %}{% endblock %} - My Webpage \u0026lt;/title\u0026gt;\r\n    {% endblock %}\r\n\u0026lt;/head\u0026gt;\r\n\r\n\u0026lt;body\u0026gt;\r\n\r\n    \u0026lt;div id=\u0026quot;content\u0026quot;\u0026gt;{% block content %}{% endblock %}\u0026lt;/div\u0026gt;\r\n    \u0026lt;div id=\u0026quot;footer\u0026quot;\u0026gt;\r\n        {% block footer %}\r\n        \u0026amp;copy; Copyright 2008 by \u0026lt;a href=\u0026quot;http://domain.invalid/\u0026quot;\u0026gt;you \u0026lt;/a\u0026gt;.\r\n        {% endblock %}\r\n    \u0026lt;/div\u0026gt;\r\n\u0026lt;/body\u0026gt;\r\n\r\n\u0026lt;/html\u0026gt;\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eYou can see above that much of the template resembles a normal HTML document. \u003ccode\u003eJinja\u003c/code\u003e needs a few extra lines to interpret the code as a template. The \u003ccode\u003e{% block head %}\u003c/code\u003e defines the head section of the HTML document and how this template will extend its formatting. The \u003ccode\u003e{% block title %}\u003c/code\u003e section describes where the input title will be displayed. And the \u003ccode\u003e{% endblock %}\u003c/code\u003e appears in multiple places because that ends any corresponding template block.\u003c/p\u003e\r\n\u003cp\u003eNow you are ready to learn how to use \u003ccode\u003eJinja\u003c/code\u003e to create custom templates of your own!\u003c/p\u003e\r\n\u003ch2 id=\"introduction-to-jinja\"\u003eIntroduction to Jinja\u003c/h2\u003e\r\n\u003cp\u003e\u003ccode\u003eJinja\u003c/code\u003e is a templating engine that allows you to define how your documents will be displayed. Specifically, for this tutorial, you will focus on how to export your Jupyter Notebook with the help of \u003ccode\u003eJinja\u003c/code\u003e templates.\u003c/p\u003e\r\n\u003cp\u003eFirst, from \u003ccode\u003eJinja2\u003c/code\u003e import \u003ccode\u003eTemplate\u003c/code\u003e:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003efrom jinja2 import Template\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003e\u003ca id=\"render\"\u003e\u003c/a\u003e\u003c/p\u003e\r\n\u003ch2 id=\"understanding-basic-rendering-with-templates\"\u003eUnderstanding Basic Rendering with Templates\u003c/h2\u003e\r\n\u003cp\u003eRendering data in \u003ccode\u003eJinja\u003c/code\u003e templates is pretty straightforward. Using brackets and variable names, you can display your data in the template:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003emyTemplate = Template(\u0026quot;My template is {{ something }}!\u0026quot;)\r\nmyTemplate.render(something=\u0026quot;awesome\u0026quot;)\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e\u0026#39;My template is awesome!\u0026#39;\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eCalling \u003ccode\u003e.render(input)\u003c/code\u003e allows you to display the template in your Notebook with your input replacing the generic \u003ccode\u003e{{ something }}\u003c/code\u003e from the template. This is an example of \u003ccode\u003eexpression\u003c/code\u003e usage in \u003ccode\u003eJinja\u003c/code\u003e.\u003c/p\u003e\r\n\u003cp\u003eYou can use a template more dynamically by defining a Python \u003ccode\u003estatement\u003c/code\u003e, which \u003ccode\u003eJinja\u003c/code\u003e will interpret.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003emyFancyTemplate = Template(\u0026quot;Let\u0026#39;s count to 10: {% for i in range(11) %}{{i}} \u0026quot; \u0026quot;{% endfor %}\u0026quot;)\r\nmyFancyTemplate.render()\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e\u0026quot;Let\u0026#39;s count to 10: 0 1 2 3 4 5 6 7 8 9 10 \u0026quot;\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cstrong\u003eNotice\u003c/strong\u003e you defined a \u003cem\u003efor\u003c/em\u003e loop and the template rendered the numbers from 0 to 10 with spaces between. The \u003ccode\u003estatement\u003c/code\u003e syntax of \u003ccode\u003e{% expression %}\u003c/code\u003e provides a lot of flexibility for making a custom template.\u003c/p\u003e\r\n\u003ch2 id=\"template-inheritance\"\u003eTemplate Inheritance\u003c/h2\u003e\r\n\u003cp\u003eIn order to make templates that extend the default Jupyter exports, you can use \u003cem\u003etemplate inheritance\u003c/em\u003e. \u003cem\u003eInheritance\u003c/em\u003e is the concept in programming that you can implement something in a child object that can utilize the parent\u0026#39;s defined functionality. A simple example is if you have a \u003ccode\u003eDog\u003c/code\u003e object that can \u003cem\u003ebark\u003c/em\u003e, \u003cem\u003eeat\u003c/em\u003e, and \u003cem\u003ewalk\u003c/em\u003e, you can use inheritance to create a \u003ccode\u003eDalmatian\u003c/code\u003e object that can inherit all those attributes and add others, like \u003cem\u003ehas spots\u003c/em\u003e. You will see in this tutorial how inheritance is very useful for templating, because typically only small changes are needed to customize the output. Like other inheritance languages, \u003ccode\u003eJinja\u003c/code\u003e uses keywords like \u003ccode\u003eextends\u003c/code\u003e and \u003ccode\u003esuper\u003c/code\u003e to access parent definitions.\u003c/p\u003e\r\n\u003cp\u003eTake a look at the example parent template from above, called \u003cem\u003ebase.html\u003c/em\u003e:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-html\"\u003e\u0026lt;!DOCTYPE html\u0026gt;\r\n\u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt;\r\n\r\n\u0026lt;head\u0026gt;\r\n    {% block head %}\r\n    \u0026lt;link rel=\u0026quot;stylesheet\u0026quot; href=\u0026quot;style.css\u0026quot; /\u0026gt;\r\n    \u0026lt;title\u0026gt;{% block title %}{% endblock %} - My Webpage \u0026lt;/title\u0026gt;\r\n    {% endblock %}\r\n\u0026lt;/head\u0026gt;\r\n\r\n\u0026lt;body\u0026gt;\r\n    \u0026lt;div id=\u0026quot;content\u0026quot;\u0026gt;{% block content %}{% endblock %}\u0026lt;/div\u0026gt;\r\n    \u0026lt;div id=\u0026quot;footer\u0026quot;\u0026gt;\r\n        {% block footer %}\r\n        \u0026amp;copy; Copyright 2008 by \u0026lt;a href=\u0026quot;http://domain.invalid/\u0026quot;\u0026gt;you \u0026lt;/a\u0026gt;.\r\n        {% endblock %}\r\n    \u0026lt;/div\u0026gt;\r\n\u0026lt;/body\u0026gt;\r\n\r\n\u0026lt;/html\u0026gt;\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eA child template might look like this (courtesy of Jinja2 documentation):\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-django\"\u003e{% extends \u0026quot;base.html\u0026quot; %}\r\n\r\n{% block title %}Index{% endblock %}\r\n\r\n{% block head %}\r\n    {{ super() }}\r\n    \u0026lt;style type=\u0026quot;text/css\u0026quot;\u0026gt;\r\n        .important { color: #336699; }\r\n    \u0026lt;/style\u0026gt;\r\n{% endblock %}\r\n\r\n{% block content %}\r\n    \u0026lt;h1\u0026gt;Index\u0026lt;/h1\u0026gt;\r\n    \u0026lt;p class=\u0026quot;important\u0026quot;\u0026gt;\r\n      Welcome to my awesome homepage.\r\n    \u0026lt;/p\u0026gt;\r\n{% endblock %}\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eNotice how the child template begin with \u003ccode\u003e{% extends \u0026quot;base.html\u0026quot; %}\u003c/code\u003e. This declaration tells the \u003ccode\u003eJinja\u003c/code\u003e templating engine how to treat this document (as an HTML with inheritance from \u003cem\u003ebase.html\u003c/em\u003e). Using this child template allows for specifying different attributes for the homepage (like a specific CSS color). Also, you can see in the \u003cem\u003ehead block\u003c/em\u003e that the child template inherits the parent\u0026#39;s style with the call to \u003ccode\u003esuper()\u003c/code\u003e.\u003c/p\u003e\r\n\u003cp\u003e\u003ca id=\"nbconvert\"\u003e\u003c/a\u003e\u003c/p\u003e\r\n\u003ch2 id=\"using-nbconvert-for-exporting-jupyter-notebooks\"\u003eUsing nbconvert for Exporting Jupyter Notebooks\u003c/h2\u003e\r\n\u003cp\u003eNow that you understand the basic syntax and inheritance of templates, you can learn how to export your Jupter Notebook with \u003ccode\u003enbconvert\u003c/code\u003e and define templates to customize the output.\u003c/p\u003e\r\n\u003cp\u003eFirst import \u003ccode\u003enbconvert\u003c/code\u003e:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003eimport nbconvert\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003e\u003ccode\u003enbconvert\u003c/code\u003e can create output to a variety of formats. This tutorial will focus on HTML and LaTeX/PDF output. To view the output in the notebook, use the \u003ccode\u003eIPython\u003c/code\u003e display function and the \u003ccode\u003e--stdout\u003c/code\u003e in your call to nbconvert.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003eexample = !jupyter nbconvert --to html \u0026#39;Example.ipynb\u0026#39; --stdout\r\nfrom IPython.display import HTML, display\r\ndisplay(HTML(\u0026#39;\\n\u0026#39;.join(example)))\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003e[NbConvertApp] Converting notebook Example.ipynb to html\u003c/p\u003e\r\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1526406715/example_svmwcn.png\" /\u003e\u003c/p\u003e\r\n\u003cp\u003eThis snippet of a Notebook looks very similar to the original \u003cem\u003e.ipynb\u003c/em\u003e file. The output displays as a standalone document with headings and text the way it typically displays in a Notebook. The code cell blocks are displayed as gray boxes (known as \u0026quot;Notebook style\u0026quot;). The main difference you can see is that the Jupyter default HTML template does not display \u0026quot;Out:\u0026quot; prompts, like active Notebooks do.\u003c/p\u003e\r\n\u003cp\u003e\u003ca id=\"nbconvert\"\u003e\u003c/a\u003e\u003c/p\u003e\r\n\u003ch3 id=\"using-nbconvert-and-a-custom-child-template-to-export-jupyter-notebooks\"\u003eUsing nbconvert and a Custom Child Template to Export Jupyter Notebooks\u003c/h3\u003e\r\n\u003cp\u003eTypically, you\u0026#39;ll want to extend the Jupyter Notebook\u0026#39;s default export templates and make small design changes to your output.\u003c/p\u003e\r\n\u003cp\u003eFor example, look at this simple template that removes Markdown cells from the output (called \u003cem\u003ermMkdwn.tpl\u003c/em\u003e):\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-django\"\u003e{% extends \u0026#39;basic.tpl\u0026#39;%}\r\n\r\n{% block markdowncell -%}\r\n{% endblock markdowncell %}\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eApplying a template to \u003ccode\u003enbconvert\u003c/code\u003e is done with the \u003ccode\u003e--template=\u003c/code\u003e option:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003eexample = !jupyter nbconvert --to html \u0026#39;Example.ipynb\u0026#39; --template=\u0026#39;rmMkdwn.tpl\u0026#39; --stdout\r\ndisplay(HTML(\u0026#39;\\n\u0026#39;.join(example)))\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003e[NbConvertApp] Converting notebook Example.ipynb to html\r\n\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1526406906/example2_h2henk.png\" /\u003e\r\nEven a very simple template, like \u003cem\u003ermMkdwn.tpl\u003c/em\u003e , can help you customize your output tremendously.\u003c/p\u003e\r\n\u003cp\u003eLook at this more complicated template, which boxes cells in red (called \u003cem\u003eboxRed.tpl\u003c/em\u003e):\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-django\"\u003e{% extends \u0026#39;full.tpl\u0026#39;%}\r\n\r\n{% block any_cell %}\r\n    \u0026lt;div style=\u0026quot;border:thin solid red\u0026quot;\u0026gt;\r\n        {{ super() }}\r\n    \u0026lt;/div\u0026gt;\r\n{% endblock any_cell %}\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003eexample = !jupyter nbconvert --to html \u0026#39;Example.ipynb\u0026#39; --template=\u0026#39;boxRed.tpl\u0026#39; --stdout\r\ndisplay(HTML(\u0026#39;\\n\u0026#39;.join(example)))\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003e[NbConvertApp] Converting notebook Example.ipynb to html\r\n\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1526407115/example3_wteqqe.png\" /\u003e\u003c/p\u003e\r\n\u003cp\u003eAbove, you can see that the only style change is the red boxes around each cell. \u003ccode\u003esuper()\u003c/code\u003e is used to make sure that each cell maintains its individual styling from the parent template \u003cem\u003efull.tpl\u003c/em\u003e.\u003c/p\u003e\r\n\u003cp\u003e\u003ca id=\"export\"\u003e\u003c/a\u003e\u003c/p\u003e\r\n\u003ch3 id=\"differences-in-templates-for-exporting-to-latex-and-pdf\"\u003eDifferences in Templates for Exporting to LaTeX and PDF\u003c/h3\u003e\r\n\u003cp\u003eSince { } and % are special characters in LaTeX, you have to use (( )) and *. Also the default LaTeX templates are \u003cem\u003ebase.tplx\u003c/em\u003e, \u003cem\u003earticle.tplx\u003c/em\u003e, and \u003cem\u003ereport.tplx\u003c/em\u003e, which correspond to LaTeX document classes.\u003c/p\u003e\r\n\u003cp\u003eLook at removing Markdown cells with a LaTeX child template:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003e((* extends \u0026#39;article.tplx\u0026#39; *))\r\n\r\n((* block markdowncell -*))\r\n((* endblock markdowncell *))\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003ccode\u003enbconvert\u003c/code\u003e can make LaTeX or PDF output - the PDF output is compiled from the LaTeX templates. For ease of viewing in this tutorial, look at what happens when you export to PDF using \u003cem\u003ermMkdwn.tplx\u003c/em\u003e.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e!jupyter nbconvert --to pdf \u0026#39;Example.ipynb\u0026#39; --template=\u0026#39;rmMkdwn.tplx\u0026#39;\r\nfrom IPython.display import IFrame\r\nIFrame(\u0026#39;Example.pdf\u0026#39;, width=800, height=500)\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e[NbConvertApp] Converting notebook Example.ipynb to pdf\r\n[NbConvertApp] Support files will be in Example_files/\r\n[NbConvertApp] Making directory Example_files\r\n[NbConvertApp] Writing 16047 bytes to notebook.tex\r\n[NbConvertApp] Building PDF\r\n[NbConvertApp] Running xelatex 3 times: [\u0026#39;xelatex\u0026#39;, \u0026#39;notebook.tex\u0026#39;]\r\n[NbConvertApp] Running bibtex 1 time: [\u0026#39;bibtex\u0026#39;, \u0026#39;notebook\u0026#39;]\r\n[NbConvertApp] WARNING | bibtex had problems, most likely because there were no citations\r\n[NbConvertApp] PDF successfully created\r\n[NbConvertApp] Writing 16102 bytes to Example.pdf\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1526407257/example4_d9pwud.png\" /\u003e\u003c/p\u003e\r\n\u003cp\u003eNotice, this output turned out very differently than the HTML version. LaTeX feeds the first Markdown cell into the article title, so it still displays in the output. The template did correctly remove the subtitle (so it regarded that Markdown cell as true Markdown). The article document class updates with today\u0026#39;s date - which is not something in the original Notebook. The font and spacing is different than the HTML version. Lastly, by default the output uses the classic IPython display, not the \u0026quot;Notebook style\u0026quot; display.\u003c/p\u003e\r\n\u003cp\u003eIf you choose to extend a LaTeX document class that lives in Jupyter, make sure you understand what formatting it will use.\u003c/p\u003e\r\n\u003ch2 id=\"conclusion\"\u003eConclusion\u003c/h2\u003e\r\n\u003cp\u003eThere are some key things to remember about templates, \u003ccode\u003eJinja2\u003c/code\u003e and \u003ccode\u003enbconvert\u003c/code\u003e.\u003c/p\u003e\r\n\u003cp\u003eTemplates define how a document will be displayed on a webpage or another output format. Jupyter Notebooks implement \u003ccode\u003eJinja\u003c/code\u003e templates to display different export formats. Templates have inheritance rules that allow you to define parent and child templates for similar pages, with slightly different formatting.\u003c/p\u003e\r\n\u003cp\u003e\u003ccode\u003eJinja\u003c/code\u003e templates have \u003ccode\u003estatements\u003c/code\u003e, \u003ccode\u003eexpressions\u003c/code\u003e, and (optionally) \u003ccode\u003ecomments\u003c/code\u003e. \u003ccode\u003eStatements\u003c/code\u003e, defined by \u003ccode\u003e{% statement %}\u003c/code\u003e, define the template structure. \u003ccode\u003eExpressions\u003c/code\u003e, defined by \u003ccode\u003e{{ expression }}\u003c/code\u003e, fill the template with your data. And \u003ccode\u003ecomments\u003c/code\u003e, defined by \u003ccode\u003e{# comment #}\u003c/code\u003e, do not get displayed in the output - they are internal to the template only.\u003c/p\u003e\r\n\u003cp\u003e\u003ccode\u003enbconvert\u003c/code\u003e is a Python library that allows you to convert your Jupyter Notebook into other formats, like HTML, LaTeX and PDF. \u003ccode\u003enbconvert\u003c/code\u003e uses \u003ccode\u003eJinja\u003c/code\u003e templates to define how Jupyter Notebooks will be displayed in these formats. You can define custom templates or extend the default Jupyter templates using inheritance.\u003c/p\u003e\r\n\u003cp\u003eNow you are ready to start making your own templates and exporting beautiful Jupyter Notebook documents!\u003c/p\u003e\r\n\u003cp\u003e\u003cem\u003eReferences:\u003c/em\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003ca href=\"http://jinja.pocoo.org/docs/2.10/\"\u003eJinja2 documentation\u003c/a\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003ca href=\"https://wiki.python.org/moin/Templating\"\u003ePython templating documentation\u003c/a\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003ca href=\"http://nbconvert.readthedocs.io/en/latest/customizing.html\"\u003enbconvert documentation\u003c/a\u003e\u003c/p\u003e\r\n","contentUrl":"https://www.datacamp.com/community/tutorials/jinja2-custom-export-templates-jupyter","userContentUrl":null,"illustrationUrl":null,"seoTitle":"Jinja2 Templates for Jupyter Notebooks","seoMetaDescription":"Learn how to create custom export templates for your Jupyter Notebooks using Jinja2.","seoKeyword":"Jinja2 Custom Export Templates for Jupyter Notebooks","mustRead":false,"programmingLanguage":null,"submissionDate":"2018-05-08T15:28:40.278Z","publishDate":"2018-05-30T10:00:00.000Z","episode":null,"isLatest":null,"externalUrl":null,"transcriptUrl":null,"guests":[],"links":null,"isSpam":false,"xp":0,"flaggingUsers":[],"isDisabled":false,"connectedInternalContentId":null,"createdAt":"2018-05-08T15:28:40.252Z","updatedAt":"2018-05-30T12:23:20.263Z","upvoting":{"voteCount":8,"voted":false},"tags":["jupyter"],"author":{"id":1764233,"slug":"stephaniehowson","avatarUrlSquare":"https://assets.datacamp.com/users/avatars/001/764/233/square/AAEAAQAAAAAAAAemAAAAJDI5ZWNlYmVhLWMxYmUtNDExMy1hNTNlLWZkZTU5NTI2YTY5ZA.jpg?1519759627","fullName":"Steph Howson","nameFromEmail":"stephaniehowson","isAdmin":false}},{"id":10042,"externalId":null,"type":"Tutorial","status":"published","authorId":"mgalarny-9d736b5c-bc15-4424-b6e2-2171c0af2e4a","title":"Python Sets and Set Theory","slug":"sets-in-python","previewSlug":null,"description":"Learn about Python sets: what they are, how to create them, when to use them, built-in functions, and their relationship to set theory operations.","articles":[],"courses":[],"redirectSlug":null,"contentHtml":"\u003ch2 id=\"sets-vs-lists-and-tuples\"\u003eSets vs Lists and Tuples\u003c/h2\u003e\n\u003cp\u003eLists and tuples are standard Python data types that store values in a sequence. Sets are another standard Python data type that also store values. The major difference is that sets, unlike lists or tuples, cannot have multiple occurrences of the same element and store  unordered values.\u003c/p\u003e\n\u003ch2 id=\"advantages-of-python-sets\"\u003eAdvantages of Python Sets\u003c/h2\u003e\n\u003cp\u003eBecause sets cannot have multiple occurrences of the same element, it makes sets highly useful to efficiently remove duplicate values from a list or tuple and to perform common math operations like unions and intersections.\u003c/p\u003e\n\u003cp\u003eIf you\u0026#39;d like to sharpen your Python skills, or you\u0026#39;re just a beginner, be sure to take a look at our \u003ca href=\"https://www.datacamp.com/tracks/python-programmer\"\u003ePython Programmer career track\u003c/a\u003e on DataCamp.\u003c/p\u003e\n\u003cp\u003eThis tutorial will introduce you a few topics about Python sets and set theory:\u003c/p\u003e\n\u003cp\u003e\u003cnav\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cp\u003e\u003ca href=\"#init\"\u003eHow to initialize empty sets and sets with values.\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003ca href=\"#add\"\u003eHow to add and remove values from sets\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003ca href=\"#use\"\u003eHow to use efficiently use sets for tasks such as membership tests and removing duplicate values from a list. \u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003ca href=\"#operations\"\u003eHow to perform common set operations like unions, intersections, difference, and symmetric difference. \u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003ca href=\"#frozenset\"\u003eThe difference between a set and a frozenset\u003c/a\u003e\n\u003c/nav\u003e\n\u003cdiv id=\"scoped-content\"\u003e\u003c/p\u003e\n\u003cstyle type=\"text/css\"\u003e:target:before { content:\"\"; display:block; height:150px; margin:-150px 0 0; } h3 {font-weight:normal; margin-top:.5em} h4 { font-weight:lighter }\n\u003c/style\u003e\n\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWith that, let\u0026#39;s get started.\u003c/p\u003e\n\u003cp\u003e\u003ca id=\"init\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"initialize-a-set\"\u003eInitialize a Set\u003c/h2\u003e\n\u003cp\u003eSets are a mutable collection of distinct (unique) immutable values that are unordered.\u003c/p\u003e\n\u003cp\u003eYou can initialize an empty set by using \u003ccode\u003eset()\u003c/code\u003e.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003eemptySet = set()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eTo intialize a set with values, you can pass in a list to \u003ccode\u003eset()\u003c/code\u003e.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003edataScientist = set([\u0026#39;Python\u0026#39;, \u0026#39;R\u0026#39;, \u0026#39;SQL\u0026#39;, \u0026#39;Git\u0026#39;, \u0026#39;Tableau\u0026#39;, \u0026#39;SAS\u0026#39;])\ndataEngineer = set([\u0026#39;Python\u0026#39;, \u0026#39;Java\u0026#39;, \u0026#39;Scala\u0026#39;, \u0026#39;Git\u0026#39;, \u0026#39;SQL\u0026#39;, \u0026#39;Hadoop\u0026#39;])\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1526998740/1_set_values.png\"/\u003e\u003c/p\u003e\n\u003cp\u003eIf you look at the output of dataScientist and dataEngineer variables above, notice that the values in the set are not in the order added in. This is because sets are unordered.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eSets containing values\u003c/strong\u003e can also be initialized by using curly braces.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003edataScientist = {\u0026#39;Python\u0026#39;, \u0026#39;R\u0026#39;, \u0026#39;SQL\u0026#39;, \u0026#39;Git\u0026#39;, \u0026#39;Tableau\u0026#39;, \u0026#39;SAS\u0026#39;}\ndataEngineer = {\u0026#39;Python\u0026#39;, \u0026#39;Java\u0026#39;, \u0026#39;Scala\u0026#39;, \u0026#39;Git\u0026#39;, \u0026#39;SQL\u0026#39;, \u0026#39;Hadoop\u0026#39;}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1526998740/2_sets_values_curly.png\"/\u003e\u003c/p\u003e\n\u003cp\u003eKeep in mind that curly braces can only be used to initialize a set containing values. The image below shows that using curly braces without values is one of the ways to initialize a dictionary and not a set.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1526998740/3_emptySet_vs_Dict.png\"/\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca id=\"add\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"add-and-remove-values-from-sets\"\u003eAdd and Remove Values from Sets\u003c/h2\u003e\n\u003cp\u003eTo add or remove values from a set, you first have to initialize a set.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# Initialize set with values\ngraphicDesigner = {\u0026#39;InDesign\u0026#39;, \u0026#39;Photoshop\u0026#39;, \u0026#39;Acrobat\u0026#39;, \u0026#39;Premiere\u0026#39;, \u0026#39;Bridge\u0026#39;}\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id=\"add-values-to-a-set\"\u003eAdd Values to a Set\u003c/h3\u003e\n\u003cp\u003eYou can use the method \u003ccode\u003eadd\u003c/code\u003e to add a value to a set.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003egraphicDesigner.add(\u0026#39;Illustrator\u0026#39;)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1526998740/4_add_value.png\"/\u003e\u003c/p\u003e\n\u003cp\u003eIn is important to note that you can only add a value that is immutable (like a string or a tuple) to a set. For example, you would get a TypeError if you try to add a list to a set.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003egraphicDesigner.add([\u0026#39;Powerpoint\u0026#39;, \u0026#39;Blender\u0026#39;])\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1526998740/5_add_unhashable.png\"/\u003e\u003c/p\u003e\n\u003ch2 id=\"remove-values-from-a-set\"\u003eRemove Values from a Set\u003c/h2\u003e\n\u003cp\u003eThere are a couple ways to remove a value from a set.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eOption 1:\u003c/strong\u003e You can use the \u003ccode\u003eremove\u003c/code\u003e method to remove a value from a set.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003egraphicDesigner.remove(\u0026#39;Illustrator\u0026#39;)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1526998740/6_remove_value.png\"/\u003e\u003c/p\u003e\n\u003cp\u003eThe drawback of this method is that if you try to remove a value that is not in your set, you will get a KeyError.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1526998740/7_remove_value_k_error.png\"/\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eOption 2:\u003c/strong\u003e You can use the \u003ccode\u003ediscard\u003c/code\u003e method to remove a value from a set.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003egraphicDesigner.discard(\u0026#39;Premiere\u0026#39;)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1526998740/8_discard_value.png\"/\u003e\u003c/p\u003e\n\u003cp\u003eThe benefit of this approach over the \u003ccode\u003eremove\u003c/code\u003e method is if you try to remove a value that is not part of the set, you will not get a KeyError. If you are familiar with dictionaries, you might find that this works similarly to the \u003ca href=\"https://hackernoon.com/python-basics-10-dictionaries-and-dictionary-methods-4e9efa70f5b9\"\u003edictionary method get\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eOption 3:\u003c/strong\u003e You can also use the \u003ccode\u003epop\u003c/code\u003e method to \u003cstrong\u003eremove and return\u003c/strong\u003e an arbitrary value from a set.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003egraphicDesigner.pop()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1526998740/9_pop_remove_return.png\"/\u003e\u003c/p\u003e\n\u003cp\u003eIt is important to note that the method raises a KeyError if the set is empty.\u003c/p\u003e\n\u003ch2 id=\"remove-all-values-from-a-set\"\u003eRemove All Values from a Set\u003c/h2\u003e\n\u003cp\u003eYou can use the \u003ccode\u003eclear\u003c/code\u003e method to remove all values from a set.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003egraphicDesigner.clear()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1526998740/10_clear.png\"/\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca id=\"use\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"iterate-through-a-set\"\u003eIterate through a Set\u003c/h2\u003e\n\u003cp\u003eLike many standard python data types, it is possible to iterate through a set.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# Initialize a set\ndataScientist = {\u0026#39;Python\u0026#39;, \u0026#39;R\u0026#39;, \u0026#39;SQL\u0026#39;, \u0026#39;Git\u0026#39;, \u0026#39;Tableau\u0026#39;, \u0026#39;SAS\u0026#39;}\n\nfor skill in dataScientist:\n    print(skill)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1526998740/11_iterate.png\"/\u003e\u003c/p\u003e\n\u003cp\u003eIf you look at the output of printing each of the values in dataScientist, notice that the values printed in the set are not in the order they were added in. This is because sets are unordered.\u003c/p\u003e\n\u003ch2 id=\"transform-set-into-ordered-values\"\u003eTransform Set into Ordered Values\u003c/h2\u003e\n\u003cp\u003eThis tutorial has emphasized that sets are unordered. If you find that you need to get the values from your set in an ordered form, you can use the \u003ccode\u003esorted\u003c/code\u003e function which outputs a list that is ordered.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003etype(sorted(dataScientist))\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1526998740/12_type_sorted.png\"/\u003e\u003c/p\u003e\n\u003cp\u003eThe code below outputs the values in the set dataScientist in descending alphabetical order (Z-A in this case).\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003esorted(dataScientist, reverse = True)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1526998740/13_sort_reverse.png\"/\u003e\u003c/p\u003e\n\u003ch2 id=\"remove-duplicates-from-a-list\"\u003eRemove Duplicates from a List\u003c/h2\u003e\n\u003cp\u003ePart of the content in this section was previously explored in the tutorial \u003ca href=\"https://www.datacamp.com/community/tutorials/18-most-common-python-list-questions-learn-python#question15\"\u003e18 Most Common Python List Questions\u003c/a\u003e, but it is important to emphasize that sets are the \u003ca href=\"https://www.peterbe.com/plog/fastest-way-to-uniquify-a-list-in-python-3.6\"\u003efastest way\u003c/a\u003e to remove duplicates from a list. To show this, let\u0026#39;s study the performance difference between two approaches.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eApproach 1:\u003c/strong\u003e Use a set to remove duplicates from a list.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003eprint(list(set([1, 2, 3, 1, 7])))\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eApproach 2:\u003c/strong\u003e Use a list comprehension to remove duplicates from a list (If you would like a refresher on list comprehensions, see this \u003ca href=\"https://www.datacamp.com/community/tutorials/python-list-comprehension\"\u003etutorial\u003c/a\u003e).\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003edef remove_duplicates(original):\n    unique = []\n    [unique.append(n) for n in original if n not in unique]\n    return(unique)\n\nprint(remove_duplicates([1, 2, 3, 1, 7]))\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe performance difference can be measured using the the \u003ccode\u003etimeit\u003c/code\u003e library which allows you to time your Python code. The code below runs the code for each approach 10000 times and outputs the overall time it took in seconds.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003eimport timeit\n\n# Approach 1: Execution time\nprint(timeit.timeit(\u0026#39;list(set([1, 2, 3, 1, 7]))\u0026#39;, number=10000))\n\n# Approach 2: Execution time\nprint(timeit.timeit(\u0026#39;remove_duplicates([1, 2, 3, 1, 7])\u0026#39;, globals=globals(), number=10000))\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1526998740/14_remove_duplicates.png\"/\u003e\u003c/p\u003e\n\u003cp\u003eComparing these two approaches shows that using sets to remove duplicates is more efficient. While it may seem like a small difference in time, it can save you a lot of time if you have very large lists.\u003c/p\u003e\n\u003cp\u003e\u003ca id=\"operations\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"set-operation-methods\"\u003eSet Operation Methods\u003c/h2\u003e\n\u003cp\u003eA common use of sets in Python is computing standard math operations such as union, intersection, difference, and symmetric difference. The image below shows a couple standard math operations on two sets A and B. The red part of each Venn diagram is the resulting set of a given set operation.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1526998740/15_union_intersection_difference_symmetric.png\"/\u003e\u003c/p\u003e\n\u003cp\u003ePython sets have methods that allow you to perform these mathematical operations as well as operators that give you equivalent results.\u003c/p\u003e\n\u003cp\u003eBefore exploring these methods, let\u0026#39;s start by initializing two sets dataScientist and dataEngineer.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003edataScientist = set([\u0026#39;Python\u0026#39;, \u0026#39;R\u0026#39;, \u0026#39;SQL\u0026#39;, \u0026#39;Git\u0026#39;, \u0026#39;Tableau\u0026#39;, \u0026#39;SAS\u0026#39;])\ndataEngineer = set([\u0026#39;Python\u0026#39;, \u0026#39;Java\u0026#39;, \u0026#39;Scala\u0026#39;, \u0026#39;Git\u0026#39;, \u0026#39;SQL\u0026#39;, \u0026#39;Hadoop\u0026#39;])\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id=\"union\"\u003eunion\u003c/h3\u003e\n\u003cp\u003eA union, denoted dataScientist  dataEngineer, is the set of all values that are values of dataScientist, or dataEngineer, or both. You can use the \u003ccode\u003eunion\u003c/code\u003e method to find out all the unique values in two sets.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# set built-in function union\ndataScientist.union(dataEngineer)\n\n# Equivalent Result\ndataScientist | dataEngineer\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1526998740/16_union_code.png\"/\u003e\u003c/p\u003e\n\u003cp\u003eThe set returned from the union can be visualized as the red part of the Venn diagram below.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1526998740/17_union_venn_diagram.png\"/\u003e\u003c/p\u003e\n\u003ch3 id=\"intersection\"\u003eintersection\u003c/h3\u003e\n\u003cp\u003eAn intersection of two sets dataScientist and dataEngineer, denoted dataScientist  dataEngineer, is the set of all values that are values of both dataScientist and dataEngineer.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# Intersection operation\ndataScientist.intersection(dataEngineer)\n\n# Equivalent Result\ndataScientist \u0026amp; dataEngineer\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1526998740/18_intersection_code.png\"/\u003e\u003c/p\u003e\n\u003cp\u003eThe set returned from the intersection can be visualized as the red part of the Venn diagram below.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1526998740/19_intersection_venn_diagram.png\"/\u003e\u003c/p\u003e\n\u003cp\u003eYou may find that you come across a case where you want to make sure that two sets have no value in common. In order words, you want two sets that have an intersection that is empty. These two sets are called disjoint sets. You can test for disjoint sets by using the \u003ccode\u003eisdisjoint\u003c/code\u003e  method.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# Initialize a set\ngraphicDesigner = {\u0026#39;Illustrator\u0026#39;, \u0026#39;InDesign\u0026#39;, \u0026#39;Photoshop\u0026#39;}\n\n# These sets have elements in common so it would return False\ndataScientist.isdisjoint(dataEngineer)\n\n# These sets have no elements in common so it would return True\ndataScientist.isdisjoint(graphicDesigner)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1526998740/20_isdisjoint.png\"/\u003e\u003c/p\u003e\n\u003cp\u003eYou can notice in the intersection shown in the Venn diagram below that the disjoint sets dataScientist and graphicDesigner have no values in common.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1526998740/21_isdisjoint_intersection_venn_diagram.png\"/\u003e\u003c/p\u003e\n\u003ch2 id=\"difference\"\u003edifference\u003c/h2\u003e\n\u003cp\u003eA difference of two sets dataScientist and dataEngineer, denoted dataScientist \\ dataEngineer, is the set of all values of dataScientist that are not values of dataEngineer.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# Difference Operation\ndataScientist.difference(dataEngineer)\n\n# Equivalent Result\ndataScientist - dataEngineer\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1526998740/22_difference_code.png\"/\u003e\u003c/p\u003e\n\u003cp\u003eThe set returned from the difference can be visualized as the red part of the Venn diagram below.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1526998740/22_difference_Venn_diagram.png\"/\u003e\u003c/p\u003e\n\u003ch2 id=\"symmetric_difference\"\u003esymmetric_difference\u003c/h2\u003e\n\u003cp\u003eA symmetric difference of two sets dataScientist and dataEngineer, denoted dataScientist  dataEngineer, is the set of all values that are values of exactly one of two sets, but not both.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# Symmetric Difference Operation\ndataScientist.symmetric_difference(dataEngineer)\n\n# Equivalent Result\ndataScientist ^ dataEngineer\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1526998740/23_symmetric_difference_code.png\"/\u003e\u003c/p\u003e\n\u003cp\u003eThe set returned from the symmetric difference can be visualized as the red part of the Venn diagram below.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1526998740/24_symmetric_difference_venn_diagram.png\"/\u003e\u003c/p\u003e\n\u003ch2 id=\"set-comprehension\"\u003eSet Comprehension\u003c/h2\u003e\n\u003cp\u003eYou may have previously have learned about \u003ca href=\"https://www.datacamp.com/community/tutorials/python-list-comprehension#plc\"\u003elist comprehensions\u003c/a\u003e, \u003ca href=\"https://www.datacamp.com/community/tutorials/python-dictionary-comprehension\"\u003edictionary comprehensions\u003c/a\u003e, and generator comprehensions. There is also set comprehensions. Set comprehensions are very similar. Set comprehensions in Python can be constructed as follows:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e{skill for skill in [\u0026#39;SQL\u0026#39;, \u0026#39;SQL\u0026#39;, \u0026#39;PYTHON\u0026#39;, \u0026#39;PYTHON\u0026#39;]}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1526998740/25_set_comprehension_code.png\"/\u003e\u003c/p\u003e\n\u003cp\u003eThe output above is a set of 2 values because sets cannot have multiple occurences of the same element.\u003c/p\u003e\n\u003cp\u003eThe idea  behind using set comprehensions is to let you write and reason in code the same way you would do mathematics by hand.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e{skill for skill in [\u0026#39;GIT\u0026#39;, \u0026#39;PYTHON\u0026#39;, \u0026#39;SQL\u0026#39;] if skill not in {\u0026#39;GIT\u0026#39;, \u0026#39;PYTHON\u0026#39;, \u0026#39;JAVA\u0026#39;}}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1526998740/26_set_comprehension_code_2.png\"/\u003e\u003c/p\u003e\n\u003cp\u003eThe code above is similar to a set difference you learned about earlier. It just looks a bit different.\u003c/p\u003e\n\u003ch2 id=\"membership-tests\"\u003eMembership Tests\u003c/h2\u003e\n\u003cp\u003eMembership tests check whether a specific element is contained in a sequence, such as strings, lists, tuples, or sets. One of the main advantages of using sets in Python is that they are highly optimized for membership tests. For example, sets do membership tests a lot more efficiently than lists. In case you are from a computer science background, this is because the \u003ca href=\"https://wiki.python.org/moin/TimeComplexity\"\u003eaverage case time complexity of membership tests in sets are O(1) vs O(n) for lists\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eThe code below shows a membership test using a list.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# Initialize a list\npossibleList = [\u0026#39;Python\u0026#39;, \u0026#39;R\u0026#39;, \u0026#39;SQL\u0026#39;, \u0026#39;Git\u0026#39;, \u0026#39;Tableau\u0026#39;, \u0026#39;SAS\u0026#39;, \u0026#39;Java\u0026#39;, \u0026#39;Spark\u0026#39;, \u0026#39;Scala\u0026#39;]\n\n# Membership test\n\u0026#39;Python\u0026#39; in possibleList\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1526998740/27_membership_tests_1.png\"/\u003e\u003c/p\u003e\n\u003cp\u003eSomething similar can be done for sets. Sets just happen to be more efficient.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# Initialize a set\npossibleSet = {\u0026#39;Python\u0026#39;, \u0026#39;R\u0026#39;, \u0026#39;SQL\u0026#39;, \u0026#39;Git\u0026#39;, \u0026#39;Tableau\u0026#39;, \u0026#39;SAS\u0026#39;, \u0026#39;Java\u0026#39;, \u0026#39;Spark\u0026#39;, \u0026#39;Scala\u0026#39;}\n\n# Membership test\n\u0026#39;Python\u0026#39; in possibleSet\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1526998740/28_membership_tests_2.png\"/\u003e\u003c/p\u003e\n\u003cp\u003eSince \u003ccode\u003epossibleSet\u003c/code\u003e is a set and the value \u003ccode\u003e\u0026#39;Python\u0026#39;\u003c/code\u003e is a value of \u003ccode\u003epossibleSet\u003c/code\u003e, this can be denoted as \u003ccode\u003e\u0026#39;Python\u0026#39;\u003c/code\u003e  \u003ccode\u003epossibleSet\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eIf you had a value that wasn\u0026#39;t part of the set, like \u003ccode\u003e\u0026#39;Fortran\u0026#39;\u003c/code\u003e, it would be denoted as \u003ccode\u003e\u0026#39;Fortran\u0026#39;\u003c/code\u003e  \u003ccode\u003epossibleSet\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"subset\"\u003eSubset\u003c/h2\u003e\n\u003cp\u003eA practical application of understanding membership is subsets.\u003c/p\u003e\n\u003cp\u003eLet\u0026#39;s first initialize two sets.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003epossibleSkills = {\u0026#39;Python\u0026#39;, \u0026#39;R\u0026#39;, \u0026#39;SQL\u0026#39;, \u0026#39;Git\u0026#39;, \u0026#39;Tableau\u0026#39;, \u0026#39;SAS\u0026#39;}\nmySkills = {\u0026#39;Python\u0026#39;, \u0026#39;R\u0026#39;}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIf every value of the set \u003ccode\u003emySkills\u003c/code\u003e is also a value of the set \u003ccode\u003epossibleSkills\u003c/code\u003e, then \u003ccode\u003emySkills\u003c/code\u003e is said to be a subset of \u003ccode\u003epossibleSkills\u003c/code\u003e, mathematically written \u003ccode\u003emySkills\u003c/code\u003e  \u003ccode\u003epossibleSkills\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eYou can check to see if one set is a subset of another using the method \u003ccode\u003eissubset\u003c/code\u003e.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003emySkills.issubset(possibleSkills)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1526998740/29_issubset_code.png\"/\u003e\u003c/p\u003e\n\u003cp\u003eSince the method returns True in this case, it is a subset. In the Venn diagram below, notice that every value of the set \u003ccode\u003emySkills\u003c/code\u003e is also a value of the set \u003ccode\u003epossibleSkills\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1526998740/30_subset_Venn_diagram.png\"/\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca id=\"frozenset\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"frozensets\"\u003eFrozensets\u003c/h2\u003e\n\u003cp\u003eYou have have encountered nested lists and tuples.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# Nested Lists and Tuples\nnestedLists = [[\u0026#39;the\u0026#39;, 12], [\u0026#39;to\u0026#39;, 11], [\u0026#39;of\u0026#39;, 9], [\u0026#39;and\u0026#39;, 7], [\u0026#39;that\u0026#39;, 6]]\nnestedTuples = ((\u0026#39;the\u0026#39;, 12), (\u0026#39;to\u0026#39;, 11), (\u0026#39;of\u0026#39;, 9), (\u0026#39;and\u0026#39;, 7), (\u0026#39;that\u0026#39;, 6))\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1526998740/31_nested_tuples_code.png\"/\u003e\u003c/p\u003e\n\u003cp\u003eThe problem with nested sets is that you cannot normally have nested sets as sets cannot contain mutable values including sets.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1526998740/32_unhashable_type.png\"/\u003e\u003c/p\u003e\n\u003cp\u003eThis is one situation where you may wish to use a frozenset. A frozenset is very similar to a set except that a frozenset is immutable.\u003c/p\u003e\n\u003cp\u003eYou make a frozenset by using \u003ccode\u003efrozenset()\u003c/code\u003e.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# Initialize a frozenset\nimmutableSet = frozenset()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1526998740/33_initialize_frozenset.png\"/\u003e\u003c/p\u003e\n\u003cp\u003eYou can make a nested set if you utilize a frozenset similar to the code below.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003enestedSets = set([frozenset()])\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1526998740/34_nested_set_frozenset.png\"/\u003e\u003c/p\u003e\n\u003cp\u003eIt is important to keep in mind that a major disadvantage of a frozenset is that since they are immutable, it means that you cannot add or remove values.\u003c/p\u003e\n\u003ch1 id=\"conclusion\"\u003eConclusion\u003c/h1\u003e\n\u003cp\u003eThe Python sets are highly useful to efficiently remove duplicate values from a collection like a list and to perform common math operations like unions and intersections. Some of the challenges people often encounter are when to use the various data types. For example, if you feel like you aren\u0026#39;t sure when it is advantageous to use a dictionary versus a set, I encourage you to check out DataCamp\u0026#39;s \u003ca href=\"https://www.datacamp.com/community/blog/introducing-daily-practice-mode\"\u003edaily practice mode\u003c/a\u003e. If you any questions or thoughts on the tutorial, feel free to reach out in the comments below or through \u003ca href=\"https://twitter.com/GalarnykMichael\"\u003eTwitter\u003c/a\u003e.\u003c/p\u003e\n","contentUrl":"https://www.datacamp.com/community/tutorials/sets-in-python","userContentUrl":null,"illustrationUrl":null,"seoTitle":"Python Sets and Set Theory","seoMetaDescription":"Learn about Python sets: what they are, how to create them, when to use them, built-in functions, and their relationship to set theory operations.","seoKeyword":"Set Theory in Python","mustRead":false,"programmingLanguage":null,"submissionDate":"2018-05-22T14:24:21.564Z","publishDate":"2018-05-29T10:00:00.000Z","episode":null,"isLatest":null,"externalUrl":null,"transcriptUrl":null,"guests":[],"links":null,"isSpam":false,"xp":0,"flaggingUsers":[],"isDisabled":false,"connectedInternalContentId":10075,"createdAt":"2018-05-22T14:24:21.560Z","updatedAt":"2018-06-05T12:08:21.212Z","upvoting":{"voteCount":18,"voted":false},"tags":["python"],"author":{"id":1782418,"slug":"mgalarny-9d736b5c-bc15-4424-b6e2-2171c0af2e4a","avatarUrlSquare":"https://assets.datacamp.com/users/avatars/001/782/418/square/0_PGUE8F8TgCL-M4md.jpg?1512569472","fullName":"Michael Galarnyk","nameFromEmail":"mgalarny","isAdmin":false}},{"id":9949,"externalId":null,"type":"Tutorial","status":"published","authorId":"mgalarny-9d736b5c-bc15-4424-b6e2-2171c0af2e4a","title":"How to Install and Use Homebrew","slug":"homebrew-install-use","previewSlug":null,"description":"Discover Homebrew for data science: learn how you can use this package manager to install, update, and remove technologies such as Apache Spark and Graphviz.","articles":[],"courses":[],"redirectSlug":null,"contentHtml":"\u003cp\u003eThe creators of Homebrew say that it is the \u003ca href=\"\"\u003emissing package manager for macOS\u003c/a\u003e. Packages are collections of files that are bundled together that can be installed and removed as a group. A package manager is a tool which automates the process of installing, updating, and removing packages.\u003c/p\u003e\r\n\u003cp\u003eIf you are a Python user, you may have used the package manager pip or the package manager functionality of conda to install, update, or remove packages.\u003c/p\u003e\r\n\u003cp\u003eIf you are an R user, you may have used the RStudio Package Manager to install, update, or remove packages.\u003c/p\u003e\r\n\u003cp\u003eHomebrew is a package manager designed for Mac that is useful to install. You will find that you can utilize Homebrew for data science as it makes it a lot easier to install additional technologies on Mac such as Apache Spark and the software Graphviz.\u003c/p\u003e\r\n\u003cp\u003eWith that, lets get started.\u003c/p\u003e\r\n\u003ch2 id=\"install-command-line-tools\"\u003eInstall Command Line Tools\u003c/h2\u003e\r\n\u003cp\u003eIn order to install Homebrew, you need to install either the Xcode Command Line Tools (about 100 MB) or the full Xcode package (about 10 GB). In this tutorial, you will install Command Line Tools as they are a more reasonable size. Command Line Tools gives Mac users many commonly used tools, utilities, and compilers. One advantage of this is that when you install Command Line Tools, it installs Git which you need as Homebrew is essentially all Git and Ruby scripts underneath.\u003c/p\u003e\r\n\u003cp\u003e1. Open a new terminal. You can do this by clicking on the Spotlight magnifying glass at the top right of the screen, type terminal and then click on the Terminal icon. You can check if Command Line Tools or Xcode is installed by typing the command below in your terminal.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003excode-select -p\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1524568329/1_hog4X7taISlaG1p5Sl5FNg_kgrldn.gif\"/\u003e\u003c/p\u003e\r\n\u003cp\u003eIf you see a path output like in the image above, please skip to the \u0026quot;Install Homebrew\u0026quot; section of the tutorial. You already have Xcode or Xcode Command Line Tools installed.\u003c/p\u003e\r\n\u003cp\u003eIf you see no output, proceed to step 3.\u003c/p\u003e\r\n\u003cp\u003e2. Type the following into your terminal to install Command Line Tools. If you see a prompt like the one in the image below, click on Install.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003excode-select --install\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1524568329/1_qKBu_EJqy--2pAi1T0Bn3w_ewabvq.png\"/\u003e\u003c/p\u003e\r\n\u003cp\u003eIf a License Agreement appears, please read it and then click Agree.\u003c/p\u003e\r\n\u003cp\u003e3. Check again to see if Xcode Command Line Tools is installed. You can do this by opening a new terminal and typing in the command below.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003excode-select -p\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1524568328/1_K9Yx5y6fjOBnFoYmrsx3Iw_lhbcs7.png\"/\u003e\u003c/p\u003e\r\n\u003ch2 id=\"install-homebrew\"\u003eInstall Homebrew\u003c/h2\u003e\r\n\u003cp\u003eOpen a terminal and type the command below. Youll be prompted to give your password, which is usually the one that you also use to unlock your Mac when you start it up. After you enter your password, the installation will start.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003e/usr/bin/ruby -e \u0026quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\u0026quot;\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1524568327/1_DRvBUeaxQX4X_7OvnuYtlw_tnrq9p.png\"/\u003e\u003c/p\u003e\r\n\u003ch2 id=\"homebrew-commands\"\u003eHomebrew Commands\u003c/h2\u003e\r\n\u003ch3 id=\"install-package\"\u003eInstall Package\u003c/h3\u003e\r\n\u003cp\u003eThe command below installs the package \u003ccode\u003ewget\u003c/code\u003e. You can substitute \u003ccode\u003ewget\u003c/code\u003e for the package you want to install.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003ebrew install wget\r\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"uninstall-package\"\u003eUninstall Package\u003c/h3\u003e\r\n\u003cp\u003eThe command below uninstalls the package \u003ccode\u003ewget\u003c/code\u003e. You can substitute \u003ccode\u003ewget\u003c/code\u003e for the package you want to uninstall.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003ebrew rm wget\r\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"list-packages-you-can-install\"\u003eList Packages you can Install\u003c/h3\u003e\r\n\u003cp\u003ebrew search lists all the possible packages that you can install. The image below shows the output of using \u003ccode\u003ebrew search\u003c/code\u003e.\u003c/p\u003e\r\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1524568327/1_d3LTu6a2XQ1ZIQ9z8NkLBw_elw4fq.png\"/\u003e\u003c/p\u003e\r\n\u003cp\u003eA more practical usage of the \u003ccode\u003ebrew search\u003c/code\u003e command is to use a more refined query. For example, if you are are interested in installing Apache Spark, you can use the command below to see if there is a Apache Spark package to install.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003ebrew search spark\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1524568328/1_nnbmuWPvMpPc2l4GIlk5yA_m9hku4.png\"/\u003e\u003c/p\u003e\r\n\u003cp\u003eFrom the image above, there is a potential Apache Spark package called \u003ccode\u003eapache-spark\u003c/code\u003e that might be useful to install. It might be be helpful to get more information on \u003ccode\u003eapache-spark\u003c/code\u003e which is where the command \u003ccode\u003ebrew info\u003c/code\u003e comes in handy.\u003c/p\u003e\r\n\u003ch3 id=\"get-information-on-a-package\"\u003eGet Information on a Package\u003c/h3\u003e\r\n\u003cp\u003eThe command \u003ccode\u003ebrew info\u003c/code\u003e is really useful to get more information on a package and to see the requirements of a package.\u003c/p\u003e\r\n\u003cp\u003eThe command below gets more information on the package \u003ccode\u003eapache-spark\u003c/code\u003e.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003ebrew info apache-spark\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1524568328/1_freFrRb8ij-SlvB5WPSPUA_1_uabkzs.png\"/\u003e\u003c/p\u003e\r\n\u003cp\u003eNotice that it lists that this package requires java version 1.8 and gives couple links to places where you can get more information on the specific package. The next section goes into more detail on how to install Apache Spark.\u003c/p\u003e\r\n\u003ch2 id=\"integration-with-other-technologies\"\u003eIntegration with Other Technologies\u003c/h2\u003e\r\n\u003cp\u003eYou will often find that Homebrew can be used to assist you in working with other technologies. This section includes two examples on how to use Homebrew for data science:\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli\u003eHow to install Apache Spark using Homebrew\u003c/li\u003e\r\n\u003cli\u003eHow to utilize Homebrew to help visualize decision trees.\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003ch4 id=\"install-apache-spark-using-homebrew\"\u003eInstall Apache Spark using Homebrew\u003c/h4\u003e\r\n\u003cp\u003eHomebrew can be used to install other technologies like Apache Spark. Apache Spark is not the easiest to install, but Homebrew makes it easier. The steps below go over how to install Apache Spark using Homebrew.\u003c/p\u003e\r\n\u003cp\u003e1. Look to see if there is a Apache Spark package on Homebrew using the command below.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003ebrew search spark\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1524568329/1_keyxN8cUmBos_ZTcAAxNgA_t3fdtw.png\"/\u003e\u003c/p\u003e\r\n\u003cp\u003e2. Look for more information about the apache-spark to see if you have all the necessary dependencies.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003ebrew info apache-spark\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eIf the output of your command shows that you have Java, continue to step 3.\u003c/p\u003e\r\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1524568328/1_freFrRb8ij-SlvB5WPSPUA_ok70tx.png\"/\u003e\u003c/p\u003e\r\n\u003cp\u003eIf the output of your command shows that you dont meet the requirements, you will need to install Java before you proceed to step 3.\u003c/p\u003e\r\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1524568328/1_d50PLQQavIgT7zT-w_wcOg_ptct74.png\"/\u003e\u003c/p\u003e\r\n\u003cp\u003eYou can type the command below to see if you have Java. The image below shows the output if you dont have Java installed. It is important to note that if you have an older version of Java, you will need to upgrade.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003ejava -version\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1524568327/1_2QU8k-qj5dehG6ptQ2Kbog_izs4pc.png\"/\u003e\u003c/p\u003e\r\n\u003cp\u003eYou can install Java using Cask. Cask is an extension to brew that allows management of graphical applications through the Cask project.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003ebrew tap caskroom/versions\r\nbrew cask install java8\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eAfter installing Java, check that you have an appropriate version of Java.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003ejava -version\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1524568329/1_xx4I076Hs6YgDW7p7sfpLw_jzjkg5.png\"/\u003e\u003c/p\u003e\r\n\u003cp\u003e3. Use the command below to install \u003ccode\u003eapache-spark\u003c/code\u003e.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003ebrew install apache-spark\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1524568327/1_7AVcPD6hVpdHewT7KVRF5A_a4l0k9.png\"/\u003e\u003c/p\u003e\r\n\u003cp\u003e4. You can now open PySpark with the command below.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003epyspark\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1524568328/1_CLub53qT-l51ZAqb2AV5Gg_bq1qrc.png\"/\u003e\u003c/p\u003e\r\n\u003cp\u003e5. You can close pyspark with \u003ccode\u003eexit()\u003c/code\u003e.\u003c/p\u003e\r\n\u003cp\u003eIf you want to learn about PySpark, please see the \u003ca href=\"https://www.datacamp.com/community/tutorials/apache-spark-tutorial-machine-learning\"\u003eApache Spark Tutorial: ML with PySpark\u003c/a\u003e.\u003c/p\u003e\r\n\u003ch4 id=\"homebrew-to-help-visualize-decision-trees\"\u003eHomebrew to Help Visualize Decision Trees\u003c/h4\u003e\r\n\u003cp\u003e\u003ccode\u003eGraphviz\u003c/code\u003e is open source graph visualization software. Graph visualization is a way of representing structural information as diagrams of abstract graphs and networks. In data science, one use of \u003ccode\u003eGraphviz\u003c/code\u003e is to visualize decision trees (you can learn about decision trees \u003ca href=\"https://www.datacamp.com/community/tutorials/kaggle-tutorial-machine-learning\"\u003ehere\u003c/a\u003e).\u003c/p\u003e\r\n\u003cp\u003eYou can install \u003ccode\u003eGraphViz\u003c/code\u003e by using the command below.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003ebrew install graphviz\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eThe python code below fits a decision tree on the famous Iris Dataset and exports a dot file (\u003ccode\u003edecisionTree.dot\u003c/code\u003e) of the decision tree you fit.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003efrom sklearn.datasets import load_iris\r\nfrom sklearn import tree\r\niris = load_iris()\r\nclf = tree.DecisionTreeClassifier(max_depth=3)\r\nclf = clf.fit(iris.data, iris.target)\r\ntree.export_graphviz(clf,\r\n                     out_file=\u0026quot;decisionTree.dot\u0026quot;,\r\n                     feature_names=iris.feature_names,\r\n                     class_names=iris.target_names,\r\n                     filled = True)\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eOne of the strengths of decision trees is that they are easily interpretable. You can more easily interpret a decision tree by viewing it. This is where \u003ccode\u003eGraphviz\u003c/code\u003e comes in. In a terminal, you can type the command below to convert \u003ccode\u003edecisionTree.dot\u003c/code\u003e to an easy to view \u003ccode\u003e.png\u003c/code\u003e file.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003edot -Tpng decisionTree.dot -o decisionTree.png\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eYou can then open the \u003ccode\u003e.png\u003c/code\u003e file you created you view your decision tree.\u003c/p\u003e\r\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1524568329/1_t515EApCU5bD3oiYF9gXGA_p3fluk.png\"/\u003e\u003c/p\u003e\r\n\u003cp\u003eIt is imporantant to note that sometimes package manager functionalities overlap. For example, it is also possible to install \u003ccode\u003eGraphviz\u003c/code\u003e through the package manager functionality of conda if you have \u003ca href=\"https://medium.com/@GalarnykMichael/install-python-on-mac-anaconda-ccd9f2014072\"\u003eAnaconda installed\u003c/a\u003e by using the command below.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003econda install python-graphviz\r\n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"conclusion\"\u003eConclusion\u003c/h2\u003e\r\n\u003cp\u003eThis tutorial provides a quick guide on how to install and use Homebrew for data science. I hope you find this tutorial useful when you want to install Apache Spark or Graphviz. Homebrew has a \u003ca href=\"https://brew.sh/\"\u003ewonderful website\u003c/a\u003e that you can look at for further commands. If you any questions or thoughts on the tutorial, feel free to reach out in the comments below or through \u003ca href=\"https://twitter.com/GalarnykMichael\"\u003eTwitter\u003c/a\u003e.\u003c/p\u003e\r\n","contentUrl":"https://www.datacamp.com/community/tutorials/homebrew-install-use","userContentUrl":null,"illustrationUrl":null,"seoTitle":"How to Install and Use Homebrew","seoMetaDescription":"Discover Homebrew for data science: learn how you can use this package manager to install, update, and remove technologies such as Apache Spark and Graphviz.","seoKeyword":"homebrew","mustRead":false,"programmingLanguage":null,"submissionDate":"2018-04-24T11:22:42.503Z","publishDate":"2018-05-23T10:00:00.000Z","episode":null,"isLatest":null,"externalUrl":null,"transcriptUrl":null,"guests":[],"links":null,"isSpam":false,"xp":0,"flaggingUsers":[],"isDisabled":false,"connectedInternalContentId":null,"createdAt":"2018-04-24T11:22:42.501Z","updatedAt":"2018-05-28T15:07:49.414Z","upvoting":{"voteCount":7,"voted":false},"tags":["spark","machine learning"],"author":{"id":1782418,"slug":"mgalarny-9d736b5c-bc15-4424-b6e2-2171c0af2e4a","avatarUrlSquare":"https://assets.datacamp.com/users/avatars/001/782/418/square/0_PGUE8F8TgCL-M4md.jpg?1512569472","fullName":"Michael Galarnyk","nameFromEmail":"mgalarny","isAdmin":false}},{"id":9962,"externalId":null,"type":"Tutorial","status":"published","authorId":"pathakmanish2605","title":"Handling Categorical Data in Python","slug":"categorical-data","previewSlug":null,"description":"Learn the common tricks to handle categorical data and preprocess it to build machine learning models!","articles":[],"courses":[],"redirectSlug":null,"contentHtml":"\u003cp\u003eIf you are familiar with machine learning, you will probably have encountered categorical features in many datasets. These generally include different categories or levels associated with the observation, which are non-numerical and thus need to be converted so the computer can process them.\u003c/p\u003e\n\u003cp\u003eIn this tutorial, youll learn the common tricks to handle this type of data and preprocess it to build machine learning models with them. More specifically, you will learn:\u003c/p\u003e\n\u003cnav\u003e\n\n\u003cul\u003e\n\u003cli\u003eThe difference between \u003ca href=\"#categorical\"\u003ecategorical and continuous data\u003c/a\u003e in your dataset and identifying the type of data.\u003c/li\u003e\n\u003cli\u003eto do \u003ca href=\"#exploration\"\u003ebasic exploration\u003c/a\u003e of such data to extract information from it.\u003c/li\u003e\n\u003cli\u003eYou will learn more about various \u003ca href=\"#encoding\"\u003eencoding techniques\u003c/a\u003e in machine learning for categorical data in Python.\u003c/li\u003e\n\u003cli\u003eLastly, you\u0026#39;ll explore how you can deal with categorical features in big data with Spark: you\u0026#39;ll see how you can apply the encoding techniques in \u003ca href=\"#spark\"\u003ePySpark\u003c/a\u003e.\n\u003c/nav\u003e\n\u003cdiv id=\"scoped-content\"\u003e\n\u003cstyle type=\"text/css\"\u003e:target:before { content:\u0026quot;\u0026quot;; display:block; height:150px; margin:-150px 0 0; } h3 {font-weight:normal; margin-top:.5em} h4 { font-weight:lighter }\n\u003c/style\u003e\n\u003cbr\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThis tutorial covers the operations you have perform on categorical data before it can be used in an ML algorithm. But there is more to it. You will also have to clean your data. If you would like to know more about this process, be sure to take a look at DataCamp\u0026#39;s \u003ca href=\"https://www.datacamp.com/courses/cleaning-data-in-python\"\u003eCleaning Data in Python\u003c/a\u003e course.\u003c/p\u003e\n\u003cp\u003e\u003ca id=\"categorical\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"identifying-categorical-data-nominal-ordinal-and-continuous\"\u003eIdentifying Categorical Data: Nominal, Ordinal and Continuous\u003c/h2\u003e\n\u003cp\u003eCategorical features can only take on a limited, and usually fixed, number of possible values. For example, if a dataset is about information related to users, then you will typically find features like country, gender, age group, etc. Alternatively, if the data you\u0026#39;re working with is related to products, you will find features like product type, manufacturer, seller and so on.\u003c/p\u003e\n\u003cp\u003eThese are all categorical features in your dataset. These features are typically stored as text values which represent various traits of the observations. For example, gender is described as Male (M) or Female (F), product type could be described as electronics, apparels, food etc.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eNote\u003c/strong\u003e that these type of features where the categories are only labeled without any order of precedence are called nominal features.\u003c/p\u003e\n\u003cp\u003eFeatures which have some order associated with them are called ordinal features. For example, a feature like economic status, with three categories: low, medium and high, which have an order associated with them.\u003c/p\u003e\n\u003cp\u003eThere are also continuous features. These are numeric variables that have an infinite number of values between any two values. A continuous variable can be numeric or a date/time.\u003c/p\u003e\n\u003cp\u003eRegardless of what the value is used for, the challenge is determining how to use this data in the analysis because of the following constraints:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eCategorical features may have a very large number of levels, known as high cardinality, (for example, cities or URLs), where most of the levels appear in a relatively small number of instances.\u003c/li\u003e\n\u003cli\u003eMany machine learning models, such as regression or SVM, are algebraic. This means that their input must be numerical. To use these models, categories must be transformed into numbers first, before you can apply the learning algorithm on them.\u003c/li\u003e\n\u003cli\u003eWhile some ML packages or libraries might transform categorical data to numeric automatically based on some default embedding method, many other ML packages dont support such inputs.\u003c/li\u003e\n\u003cli\u003eFor the machine, categorical data doesnt contain the same context or information that humans can easily associate and understand. For example, when looking at a feature called \u003ccode\u003eCity\u003c/code\u003e with three cities \u003ccode\u003eNew York\u003c/code\u003e, \u003ccode\u003eNew Jersey\u003c/code\u003e and \u003ccode\u003eNew Delhi\u003c/code\u003e, humans can infer that New York is closely related to New Jersey as they are from same country, while New York and New Delhi are much different. But for the model, New York, New Jersey and New Delhi, are just three different levels (possible values) of the same feature \u003ccode\u003eCity\u003c/code\u003e. If you dont specify the additional contextual information, it will be impossible for the model to differentiate between highly different levels.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eYou therefore are faced with the challenge of figuring out how to turn these text values into numerical values for further processing and unmask lots of interesting information which these features might hide.\nTypically, any standard work-flow in feature engineering involves some form of transformation of these categorical values into numeric labels and then applying some encoding scheme on these values.\u003c/p\u003e\n\u003cp\u003e\u003ca id=\"exploration\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"general-exploration-steps-for-categorical-data\"\u003eGeneral Exploration steps for Categorical Data\u003c/h2\u003e\n\u003cp\u003eIn this section, you\u0026#39;ll focus on dealing with categorical features in the \u003ccode\u003epnwflights14\u003c/code\u003e dataset, but you can apply the same procedure to all kinds of datasets. \u003ccode\u003epnwflights14\u003c/code\u003e is a modified version of Hadley Wickham\u0026#39;s \u003ccode\u003enycflights13\u003c/code\u003e dataset and contains information about all flights that departed from the two major airports of the Pacific Northwest (PNW), SEA in Seattle and PDX in Portland, in 2014: 162,049 flights in total.\u003c/p\u003e\n\u003cp\u003eTo help understand what causes delays, it also includes a number of other useful datasets:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eweather\u003c/code\u003e: the hourly meterological data for each airport\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eplanes\u003c/code\u003e: constructor information about each plane\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eairports\u003c/code\u003e: airport names and locations\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eairlines\u003c/code\u003e: translation between two letter carrier codes and names\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe datasets can be found \u003ca href=\"https://github.com/ismayc/pnwflights14\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eSince it\u0026#39;s always a good idea to understand before starting working on it, you\u0026#39;ll briefly explore the data! To do this, you will first import the basic libraries that you will be using throughout the tutorial, namely \u003ccode\u003epandas\u003c/code\u003e, \u003ccode\u003enumpy\u003c/code\u003e and \u003ccode\u003ecopy\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eAlso make sure that you set Matplotlib to plot inline, which means that the outputted plot will appear immediately under each code cell.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003eimport pandas as pd\nimport numpy as np\nimport copy\n%matplotlib inline\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNext you will read the \u003ccode\u003eflights\u003c/code\u003e dataset in a pandas DataFrame with \u003ccode\u003eread_csv()\u003c/code\u003e and check the contents with the \u003ccode\u003e.head()\u003c/code\u003e method.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003edf_flights = pd.read_csv(\u0026#39;https://raw.githubusercontent.com/ismayc/pnwflights14/master/data/flights.csv\u0026#39;)\n\ndf_flights.head()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1527000503/categorical_table_1.png\" /\u003e\u003c/p\u003e\n\u003cp\u003eAs you will probably notice, the DataFrame above contains all kinds of information about flights like year, departure delay, arrival time, carrier, destination, etc.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eNote\u003c/strong\u003e if you are reading the \u003ccode\u003eRDS\u003c/code\u003e file formats you can do so by installing \u003ccode\u003erpy2\u003c/code\u003e library. Checkout \u003ca href=\"https://pypi.python.org/pypi/rpy2\"\u003ethis\u003c/a\u003e link to install the library on your system. The simplest way to install the library is using \u003ccode\u003epip install rpy2\u003c/code\u003e command on command line terminal.\u003c/p\u003e\n\u003cp\u003eRunning the following code would read the \u003ccode\u003eflights.RDS\u003c/code\u003e file and load it in a pandas DataFrame. \u003cstrong\u003eRemember\u003c/strong\u003e that you already imported \u003ccode\u003epandas\u003c/code\u003e earlier.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003eimport rpy2.robjects as robjects\nfrom rpy2.robjects import pandas2ri\npandas2ri.activate()\nreadRDS = robjects.r[\u0026#39;readRDS\u0026#39;]\nRDSlocation = \u0026#39;Downloads/datasets/nyc_flights/flights.RDS\u0026#39; #location of the file\ndf_rds = readRDS(RDSlocation)\ndf_rds = pandas2ri.ri2py(df_rds)\n\ndf_rds.head(2)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1527000503/categorical_table_2.png\" /\u003e\u003c/p\u003e\n\u003cp\u003eThe same \u003ccode\u003erpy2\u003c/code\u003e library can also be used to read \u003ccode\u003erda\u003c/code\u003e file formats. The code below reads and loads \u003ccode\u003eflights.rda\u003c/code\u003e into a \u003ccode\u003epandas\u003c/code\u003e DataFrame:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003efrom rpy2.robjects import r\nimport rpy2.robjects.pandas2ri as pandas2ri\nfile=\u0026quot;~/Downloads/datasets/nyc_flights/flights.rda\u0026quot; #location of the file\nrf=r[\u0026#39;load\u0026#39;](file)\ndf_rda=pandas2ri.ri2py_dataframe(r[rf[0]])\n\ndf_rda.head(2)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1527000503/categorical_table_3.png\" /\u003e\u003c/p\u003e\n\u003cp\u003eThe next step is to gather some information about different column in your DataFrame. You can do so by using \u003ccode\u003e.info()\u003c/code\u003e, which basically gives you information about the number of rows, columns, column data types, memory usage, etc.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003eprint(df_flights.info())\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode\u003e\u0026lt;class \u0026#39;pandas.core.frame.DataFrame\u0026#39;\u0026gt;\nRangeIndex: 162049 entries, 0 to 162048\nData columns (total 16 columns):\nyear         162049 non-null int64\nmonth        162049 non-null int64\nday          162049 non-null int64\ndep_time     161192 non-null float64\ndep_delay    161192 non-null float64\narr_time     161061 non-null float64\narr_delay    160748 non-null float64\ncarrier      162049 non-null object\ntailnum      161801 non-null object\nflight       162049 non-null int64\norigin       162049 non-null object\ndest         162049 non-null object\nair_time     160748 non-null float64\ndistance     162049 non-null int64\nhour         161192 non-null float64\nminute       161192 non-null float64\ndtypes: float64(7), int64(5), object(4)\nmemory usage: 19.8+ MB\nNone\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eAs you can see, columns like \u003ccode\u003eyear\u003c/code\u003e, \u003ccode\u003emonth\u003c/code\u003e and \u003ccode\u003eday\u003c/code\u003e are read as integers, and \u003ccode\u003edep_time\u003c/code\u003e, \u003ccode\u003edep_delay\u003c/code\u003e etc. are read as floats.\u003c/p\u003e\n\u003cp\u003eThe columns with object \u003ccode\u003edtype\u003c/code\u003e are the possible categorical features in your dataset.\u003c/p\u003e\n\u003cp\u003eThe reason why you would say that these categorical features are \u0026#39;possible\u0026#39; is because you shouldn\u0026#39;t not completely rely on \u003ccode\u003e.info()\u003c/code\u003e to get the real data type of the values of a feature, as some missing values that are represented as strings in a continuous feature can coerce it to read them as \u003ccode\u003eobject\u003c/code\u003e dtypes.\u003c/p\u003e\n\u003cp\u003eThat\u0026#39;s why it\u0026#39;s always a good idea to investigate your raw dataset thoroughly and then think about cleaning it.  \u003c/p\u003e\n\u003cp\u003eOne of the most common ways to analyze the relationship between a categorical feature and a continuous feature is to plot a boxplot. The boxplot is a simple way of representing statistical data on a plot in which a rectangle is drawn to represent the second and third quartiles, usually with a vertical line inside to indicate the median value. The lower and upper quartiles are shown as horizontal lines at either side of the rectangle.\u003c/p\u003e\n\u003cp\u003eYou can plot a boxplot by invoking \u003ccode\u003e.boxplot()\u003c/code\u003e on your DataFrame. Here, you will plot a boxplot of the \u003ccode\u003edep_time\u003c/code\u003e column with respect to the two \u003ccode\u003eorigin\u003c/code\u003e of the flights from \u003ccode\u003ePDX\u003c/code\u003e and \u003ccode\u003eSEA\u003c/code\u003e.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003edf_flights.boxplot(\u0026#39;dep_time\u0026#39;,\u0026#39;origin\u0026#39;,rot = 30,figsize=(5,6))\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode\u003e\u0026lt;matplotlib.axes._subplots.AxesSubplot at 0x7f32ee10f550\u0026gt;\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1524729071/Unknown_w8etkn.png\"/\u003e\u003c/p\u003e\n\u003cp\u003eAs you will only be dealing with categorical features in this tutorial, it\u0026#39;s better to filter them out. You can create a separate DataFrame consisting of only these features by running the following command. The method \u003ccode\u003e.copy()\u003c/code\u003e is used here so that any changes made in new DataFrame don\u0026#39;t get reflected in the original one.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003ecat_df_flights = df_flights.select_dtypes(include=[\u0026#39;object\u0026#39;]).copy()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eAgain, use the \u003ccode\u003e.head()\u003c/code\u003e method to check if you have filtered the required columns.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003ecat_df_flights.head()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1527000503/categorical_table_4.png\" /\u003e\u003c/p\u003e\n\u003cp\u003eOne of the most common data pre-processing steps is to check for null values in the dataset. You can get the total number of missing values in the DataFrame by the following one liner code:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003eprint(cat_df_flights.isnull().values.sum())\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode\u003e248\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eLet\u0026#39;s also check the column-wise distribution of null values:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003eprint(cat_df_flights.isnull().sum())\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode\u003ecarrier      0\ntailnum    248\norigin       0\ndest         0\ndtype: int64\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eIt seems that only the \u003ccode\u003etailnum\u003c/code\u003e column has null values. You can do a mode imputation for those null values. The function \u003ccode\u003efillna()\u003c/code\u003e is handy for such operations.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eNote\u003c/strong\u003e the chaining of method \u003ccode\u003e.value_counts()\u003c/code\u003e in the code below. This returns the frequency distribution of each category in the feature, and then selecting the top category, which is the mode, with the \u003ccode\u003e.index\u003c/code\u003e attribute.   \u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003ecat_df_flights = cat_df_flights.fillna(cat_df_flights[\u0026#39;tailnum\u0026#39;].value_counts().index[0])\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eTip\u003c/strong\u003e: read more about method chaining with pandas \u003ca href=\"https://www.datacamp.com/community/tutorials/pandas-idiomatic\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eLet\u0026#39;s check the number of null values after imputation should result in a zero count.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003eprint(cat_df_flights.isnull().values.sum())\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode\u003e0\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eAnother Exploratory Data Analysis (EDA) step that you might want to do on categorical features is the frequency distribution of categories within the feature, which can be done with the \u003ccode\u003e.value_counts()\u003c/code\u003e method as described earlier.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003eprint(cat_df_flights[\u0026#39;carrier\u0026#39;].value_counts())\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode\u003eAS    62460\nWN    23355\nOO    18710\nDL    16716\nUA    16671\nAA     7586\nUS     5946\nB6     3540\nVX     3272\nF9     2698\nHA     1095\nName: carrier, dtype: int64\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eTo know the count of distinct categories within the feature you can chain the previous code with the \u003ccode\u003e.count()\u003c/code\u003e method:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003eprint(cat_df_flights[\u0026#39;carrier\u0026#39;].value_counts().count())\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode\u003e11\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eVisual exploration is the most effective way to extract information between variables.\u003c/p\u003e\n\u003cp\u003eBelow is a basic template to plot a barplot of the frequency distribution of a categorical feature using the \u003ccode\u003eseaborn\u003c/code\u003e package, which shows the frequency distribution of the \u003ccode\u003ecarrier\u003c/code\u003e column. You can play with different arguments to change the look of the plot. If you want to learn more about seaborn, you can take a look at this \u003ca href=\"https://www.datacamp.com/community/tutorials/seaborn-python-tutorial\"\u003etutorial\u003c/a\u003e.   \u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e%matplotlib inline\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ncarrier_count = cat_df_flights[\u0026#39;carrier\u0026#39;].value_counts()\nsns.set(style=\u0026quot;darkgrid\u0026quot;)\nsns.barplot(carrier_count.index, carrier_count.values, alpha=0.9)\nplt.title(\u0026#39;Frequency Distribution of Carriers\u0026#39;)\nplt.ylabel(\u0026#39;Number of Occurrences\u0026#39;, fontsize=12)\nplt.xlabel(\u0026#39;Carrier\u0026#39;, fontsize=12)\nplt.show()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1524655927/output_35_0_to0ppk.png\"/\u003e\u003c/p\u003e\n\u003cp\u003eSimilarly, you could plot a pie chart with the \u003ccode\u003ematplotlib\u003c/code\u003e library to get the same information. The \u003ccode\u003elabels\u003c/code\u003e list below holds the category names from the \u003ccode\u003ecarrier\u003c/code\u003e column:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003elabels = cat_df_flights[\u0026#39;carrier\u0026#39;].astype(\u0026#39;category\u0026#39;).cat.categories.tolist()\ncounts = cat_df_flights[\u0026#39;carrier\u0026#39;].value_counts()\nsizes = [counts[var_cat] for var_cat in labels]\nfig1, ax1 = plt.subplots()\nax1.pie(sizes, labels=labels, autopct=\u0026#39;%1.1f%%\u0026#39;, shadow=True) #autopct is show the % on plot\nax1.axis(\u0026#39;equal\u0026#39;)\nplt.show()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1524655927/output_37_0_kxo9c8.png\"/\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca id=\"encoding\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"encoding-categorical-data\"\u003eEncoding Categorical Data\u003c/h2\u003e\n\u003cp\u003eYou will now learn different techniques to encode the categorical features to numeric quantities. To keep it simple, you will apply these encoding methods only on the \u003ccode\u003ecarrier\u003c/code\u003e column. However, the same approach can be extended to all columns.\u003c/p\u003e\n\u003cp\u003eThe techniques that you\u0026#39;ll cover are the following:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eReplacing values\u003c/li\u003e\n\u003cli\u003eEncoding labels\u003c/li\u003e\n\u003cli\u003eOne-Hot encoding\u003c/li\u003e\n\u003cli\u003eBinary encoding\u003c/li\u003e\n\u003cli\u003eBackward difference encoding\u003c/li\u003e\n\u003cli\u003eMiscellaneous features\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"replace-values\"\u003eReplace Values\u003c/h3\u003e\n\u003cp\u003eLet\u0026#39;s start with the most basic method, which is just replacing the categories with the desired numbers. This can be achieved with the help of the \u003ccode\u003ereplace()\u003c/code\u003e function in \u003ccode\u003epandas\u003c/code\u003e. The idea is that you have the liberty to choose whatever numbers you want to assign to the categories according to the business use case.\u003c/p\u003e\n\u003cp\u003eYou will now create a dictionary which contains mapping numbers for each category in the \u003ccode\u003ecarrier\u003c/code\u003e column:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003ereplace_map = {\u0026#39;carrier\u0026#39;: {\u0026#39;AA\u0026#39;: 1, \u0026#39;AS\u0026#39;: 2, \u0026#39;B6\u0026#39;: 3, \u0026#39;DL\u0026#39;: 4,\n                                  \u0026#39;F9\u0026#39;: 5, \u0026#39;HA\u0026#39;: 6, \u0026#39;OO\u0026#39;: 7 , \u0026#39;UA\u0026#39;: 8 , \u0026#39;US\u0026#39;: 9,\u0026#39;VX\u0026#39;: 10,\u0026#39;WN\u0026#39;: 11}}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eNote\u003c/strong\u003e that defining a mapping via a hard coded dictionary is easy when the number of categories is low, like in this case which is 11. You can achieve the same mapping with the help of \u003ca href=\"https://www.datacamp.com/community/tutorials/python-dictionary-comprehension\"\u003edictionary comprehensions\u003c/a\u003e as shown below. This will be useful when the categories count is high and you don\u0026#39;t want to type out each mapping. You will store the category names in a list called \u003ccode\u003elabels\u003c/code\u003e and then \u003ccode\u003ezip\u003c/code\u003e it to a seqeunce of numbers and iterate over it.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003elabels = cat_df_flights[\u0026#39;carrier\u0026#39;].astype(\u0026#39;category\u0026#39;).cat.categories.tolist()\nreplace_map_comp = {\u0026#39;carrier\u0026#39; : {k: v for k,v in zip(labels,list(range(1,len(labels)+1)))}}\n\nprint(replace_map_comp)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode\u003e{\u0026#39;carrier\u0026#39;: {\u0026#39;AA\u0026#39;: 1, \u0026#39;OO\u0026#39;: 7, \u0026#39;DL\u0026#39;: 4, \u0026#39;F9\u0026#39;: 5, \u0026#39;B6\u0026#39;: 3, \u0026#39;US\u0026#39;: 9, \u0026#39;AS\u0026#39;: 2, \u0026#39;WN\u0026#39;: 11, \u0026#39;VX\u0026#39;: 10, \u0026#39;HA\u0026#39;: 6, \u0026#39;UA\u0026#39;: 8}}\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eThroughout this tutorial, you will be making a copy of the dataset via the \u003ccode\u003e.copy()\u003c/code\u003e method to practice each encoding technique to ensure that the original DataFrame stays intact and whatever changes you are doing happen only in the copied one.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003ecat_df_flights_replace = cat_df_flights.copy()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eUse the \u003ccode\u003ereplace()\u003c/code\u003e function on the DataFrame by passing the mapping dictionary as argument:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003ecat_df_flights_replace.replace(replace_map_comp, inplace=True)\n\nprint(cat_df_flights_replace.head())\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1527000503/categorical_table_5.png\" /\u003e\u003c/p\u003e\n\u003cp\u003eAs you can observe, you have encoded the categories with the mapped numbers in your DataFrame.\u003c/p\u003e\n\u003cp\u003eYou can also check the dtype of the newly encoded column, which is now converted to integers.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003eprint(cat_df_flights_replace[\u0026#39;carrier\u0026#39;].dtypes)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode\u003eint64\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cstrong\u003eTip\u003c/strong\u003e: in Python, it\u0026#39;s a good practice to typecast categorical features to a \u003ccode\u003ecategory\u003c/code\u003e \u003ccode\u003edtype\u003c/code\u003e because they make the operations on such columns much faster than the \u003ccode\u003eobject\u003c/code\u003e dtype. You can do the typecasting by using \u003ccode\u003e.astype()\u003c/code\u003e method on your columns like shown below:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003ecat_df_flights_lc = cat_df_flights.copy()\ncat_df_flights_lc[\u0026#39;carrier\u0026#39;] = cat_df_flights_lc[\u0026#39;carrier\u0026#39;].astype(\u0026#39;category\u0026#39;)\ncat_df_flights_lc[\u0026#39;origin\u0026#39;] = cat_df_flights_lc[\u0026#39;origin\u0026#39;].astype(\u0026#39;category\u0026#39;)                                                              \n\nprint(cat_df_flights_lc.dtypes)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode\u003ecarrier    category\ntailnum      object\norigin     category\ndest         object\ndtype: object\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eYou can validate the faster operation of the \u003ccode\u003ecategory\u003c/code\u003e dtype by timing the execution time of the same operation done on a DataFrame with columns as \u003ccode\u003ecategory\u003c/code\u003e dtype and \u003ccode\u003eobject\u003c/code\u003e dtype by using the \u003ccode\u003etime\u003c/code\u003e library.\u003c/p\u003e\n\u003cp\u003eLet\u0026#39;s say you want to calculate the number of flights for each \u003ccode\u003ecarrier\u003c/code\u003e from each \u003ccode\u003eorigin\u003c/code\u003e places, you can use the \u003ccode\u003e.groupby()\u003c/code\u003e and \u003ccode\u003e.count()\u003c/code\u003e methods on your DataFrame to do so.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003eimport time\n%timeit cat_df_flights.groupby([\u0026#39;origin\u0026#39;,\u0026#39;carrier\u0026#39;]).count() #DataFrame with object dtype columns\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode\u003e10 loops, best of 3: 28.6 ms per loop\n\u003c/code\u003e\u003c/pre\u003e\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e%timeit cat_df_flights_lc.groupby([\u0026#39;origin\u0026#39;,\u0026#39;carrier\u0026#39;]).count() #DataFrame with category dtype columns\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode\u003e10 loops, best of 3: 20.1 ms per loop\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cstrong\u003eNote\u003c/strong\u003e that the DataFrame with \u003ccode\u003ecategory dtype\u003c/code\u003e is much faster.\u003c/p\u003e\n\u003ch3 id=\"label-encoding\"\u003eLabel Encoding\u003c/h3\u003e\n\u003cp\u003eAnother approach is to encode categorical values with a technique called \u0026quot;label encoding\u0026quot;, which allows you to convert each value in a column to a number. Numerical labels are always between 0 and n_categories-1.\u003c/p\u003e\n\u003cp\u003eYou can do label encoding via attributes \u003ccode\u003e.cat.codes\u003c/code\u003e on your DataFrame\u0026#39;s column.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003ecat_df_flights_lc[\u0026#39;carrier\u0026#39;] = cat_df_flights_lc[\u0026#39;carrier\u0026#39;].cat.codes\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003ecat_df_flights_lc.head() #alphabetically labeled from 0 to 10\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1527000503/categorical_table_6.png\" /\u003e\u003c/p\u003e\n\u003cp\u003eSometimes, you might just want to encode a bunch of categories within a feature to some numeric value and encode all the other categories to some other numeric value.\u003c/p\u003e\n\u003cp\u003eYou could do this by using \u003ccode\u003enumpy\u003c/code\u003e\u0026#39;s \u003ccode\u003ewhere()\u003c/code\u003e function like shown below. You will encode all the \u003ccode\u003eUS\u003c/code\u003e carrier flights to value \u003ccode\u003e1\u003c/code\u003e and other carriers to value \u003ccode\u003e0\u003c/code\u003e. This will create a new column in your DataFrame with the encodings. Later, if you want to drop the original column, you can do so by using the \u003ccode\u003edrop()\u003c/code\u003e function in \u003ccode\u003epandas\u003c/code\u003e.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003ecat_df_flights_specific = cat_df_flights.copy()\ncat_df_flights_specific[\u0026#39;US_code\u0026#39;] = np.where(cat_df_flights_specific[\u0026#39;carrier\u0026#39;].str.contains(\u0026#39;US\u0026#39;), 1, 0)\n\ncat_df_flights_specific.head()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1527000503/categorical_table_7.png\" /\u003e\u003c/p\u003e\n\u003cp\u003eYou can achieve the same label encoding using \u003ccode\u003escikit-learn\u003c/code\u003e\u0026#39;s \u003ccode\u003eLabelEncoder\u003c/code\u003e:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003ecat_df_flights_sklearn = cat_df_flights.copy()\n\nfrom sklearn.preprocessing import LabelEncoder\n\nlb_make = LabelEncoder()\ncat_df_flights_sklearn[\u0026#39;carrier_code\u0026#39;] = lb_make.fit_transform(cat_df_flights[\u0026#39;carrier\u0026#39;])\n\ncat_df_flights_sklearn.head() #Results in appending a new column to df\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1527000503/categorical_table_8.png\" /\u003e\u003c/p\u003e\n\u003cp\u003eLabel encoding is pretty much intuitive and straight-forward and may give you a good performance from your learning algorithm, but it has as disadvantage that the numerical values can be misinterpreted by the algorithm. Should the carrier \u003ccode\u003eUS\u003c/code\u003e (encoded to 8) be given 8x more weight than the carrier \u003ccode\u003eAS\u003c/code\u003e (encoded to 1) ?\u003c/p\u003e\n\u003cp\u003eTo solve this issue there is another popular way to encode the categories via something called one-hot encoding.\u003c/p\u003e\n\u003ch3 id=\"one-hot-encoding\"\u003eOne-Hot encoding\u003c/h3\u003e\n\u003cp\u003eThe basic strategy is to convert each category value into a new column and assign a \u003ccode\u003e1\u003c/code\u003e or \u003ccode\u003e0\u003c/code\u003e (True/False) value to the column. This has the benefit of not weighting a value improperly.\u003c/p\u003e\n\u003cp\u003eThere are many libraries out there that support one-hot encoding but the simplest one is using \u003ccode\u003epandas\u003c/code\u003e\u0026#39; \u003ccode\u003e.get_dummies()\u003c/code\u003e method.\u003c/p\u003e\n\u003cp\u003eThis function is named this way because it creates dummy/indicator variables (1 or 0). There are mainly three arguments important here, the first one is the DataFrame you want to encode on, second being the \u003ccode\u003ecolumns\u003c/code\u003e argument which lets you specify the columns you want to do encoding on, and third, the \u003ccode\u003eprefix\u003c/code\u003e argument which lets you specify the prefix for the new columns that will be created after encoding.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003ecat_df_flights_onehot = cat_df_flights.copy()\ncat_df_flights_onehot = pd.get_dummies(cat_df_flights_onehot, columns=[\u0026#39;carrier\u0026#39;], prefix = [\u0026#39;carrier\u0026#39;])\n\nprint(cat_df_flights_onehot.head())\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1527000503/categorical_table_9.png\" /\u003e\u003c/p\u003e\n\u003cp\u003eAs you can see, the column \u003ccode\u003ecarrier_AS\u003c/code\u003e gets value \u003ccode\u003e1\u003c/code\u003e at the 0th and 4th observation points as those points had the \u003ccode\u003eAS\u003c/code\u003e category labeled in the original DataFrame. Likewise for other columns also.  \u003c/p\u003e\n\u003cp\u003e\u003ccode\u003escikit-learn\u003c/code\u003e also supports one hot encoding via \u003ccode\u003eLabelBinarizer\u003c/code\u003e and \u003ccode\u003eOneHotEncoder\u003c/code\u003e in its \u003ccode\u003epreprocessing\u003c/code\u003e module (check out the details \u003ca href=\"http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\"\u003ehere\u003c/a\u003e). Just for the sake of practicing you will do the same encoding via \u003ccode\u003eLabelBinarizer\u003c/code\u003e:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003ecat_df_flights_onehot_sklearn = cat_df_flights.copy()\n\nfrom sklearn.preprocessing import LabelBinarizer\n\nlb = LabelBinarizer()\nlb_results = lb.fit_transform(cat_df_flights_onehot_sklearn[\u0026#39;carrier\u0026#39;])\nlb_results_df = pd.DataFrame(lb_results, columns=lb_style.classes_)\n\nprint(lb_results_df.head())\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1527000503/categorical_table_10.png\" /\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eNote\u003c/strong\u003e that this \u003ccode\u003elb_results_df\u003c/code\u003e resulted in a new DataFrame with only the one hot encodings for the feature \u003ccode\u003ecarrier\u003c/code\u003e. This needs to be concatenated back with the original DataFrame, which can be done via \u003ccode\u003epandas\u003c/code\u003e\u0026#39; \u003ccode\u003e.concat()\u003c/code\u003e method. The \u003ccode\u003eaxis\u003c/code\u003e argument is set to \u003ccode\u003e1\u003c/code\u003e as you want to merge on columns.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003eresult_df = pd.concat([cat_df_flights_onehot_sklearn, lb_results_df], axis=1)\n\nprint(result_df.head())\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1527000503/categorical_table_11.png\" /\u003e\u003c/p\u003e\n\u003cp\u003eWhile one-hot encoding solves the problem of unequal weights given to categories within a feature, it is not very useful when there are many categories, as that will result in formation of as many new columns, which can result in the \u003ca href=\"https://en.wikipedia.org/wiki/Curse_of_dimensionality\"\u003ecurse of dimensionality\u003c/a\u003e. The concept of the curse of dimensionality discusses that in high-dimensional spaces some things just stop working properly.\u003c/p\u003e\n\u003ch3 id=\"binary-encoding\"\u003eBinary Encoding\u003c/h3\u003e\n\u003cp\u003eThis technique is not as intuitive as the previous ones. In this technique, first the categories are encoded as ordinal, then those integers are converted into binary code, then the digits from that binary string are split into separate columns.  This encodes the data in fewer dimensions than one-hot.\u003c/p\u003e\n\u003cp\u003eYou can do binary encoding via a number of ways but the simplest one is using the \u003ccode\u003ecategory_encoders\u003c/code\u003e library. You can install \u003ca href=\"https://pypi.python.org/pypi/category_encoders/1.2.6\"\u003ecategory_encoders\u003c/a\u003e via \u003ccode\u003epip install category_encoders\u003c/code\u003e on cmd or just download and extract the .tar.gz file from the site.\u003c/p\u003e\n\u003cp\u003eYou have to first import the \u003ccode\u003ecategory_encoders\u003c/code\u003e library after installing it. Invoke the \u003ccode\u003eBinaryEncoder\u003c/code\u003e function by specifying the columns you want to encode and then call the \u003ccode\u003e.fit_transform()\u003c/code\u003e method on it with the DataFrame as the argument.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003ecat_df_flights_ce = cat_df_flights.copy()\n\nimport category_encoders as ce\n\nencoder = ce.BinaryEncoder(cols=[\u0026#39;carrier\u0026#39;])\ndf_binary = encoder.fit_transform(cat_df_flights_ce)\n\ndf_binary.head()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1527000503/categorical_table_12.png\" /\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eNotice\u003c/strong\u003e that four new columns are created in place of the \u003ccode\u003ecarrier\u003c/code\u003e column with binary encoding for each category in the feature.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eNote\u003c/strong\u003e that \u003ccode\u003ecategory_encoders\u003c/code\u003e is a very useful library for encoding categorical columns. Not only does it support one-hot, binary and label encoding, but also other advanced encoding methods like Helmert contrast, polynomial contrast, backward difference, etc.\u003c/p\u003e\n\u003ch3 id=\"5-backward-difference-encoding\"\u003e5. Backward Difference Encoding\u003c/h3\u003e\n\u003cp\u003eThis technique falls under the contrast coding system for categorical features. A feature of K categories, or levels, usually enters a regression as a sequence of K-1 dummy variables. In backward difference coding, the mean of the dependent variable for a level is compared with the mean of the dependent variable for the prior level. This type of coding may be useful for a nominal or an ordinal variable.\u003c/p\u003e\n\u003cp\u003eIf you want to learn other contrast coding methods you can check out this \u003ca href=\"http://www.statsmodels.org/dev/contrasts.html\"\u003eresource\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eThe code structure is pretty much the same as any method in the \u003ccode\u003ecategory_encoders\u003c/code\u003e library, just this time you will call \u003ccode\u003eBackwardDifferenceEncoder\u003c/code\u003e from it:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003eencoder = ce.BackwardDifferenceEncoder(cols=[\u0026#39;carrier\u0026#39;])\ndf_bd = encoder.fit_transform(cat_df_flights_ce)\n\ndf_bd.head()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1527000503/categorical_table_13.png\" /\u003e\u003c/p\u003e\n\u003cp\u003eThe interesting thing here is that you can see that the results are not the standard 1s and 0s you saw in the dummy encoding examples but rather regressed continuous values.\u003c/p\u003e\n\u003ch3 id=\"miscellaneous-features\"\u003eMiscellaneous Features\u003c/h3\u003e\n\u003cp\u003eSometimes you may encounter categorical feature columns which specify the ranges of values for observation points, for example, the \u003ccode\u003eage\u003c/code\u003e column might be described in the form of categories like 0-20, 20-40 and so on.\u003c/p\u003e\n\u003cp\u003eWhile there can be a lot of ways to deal with such features, the most common ones are either split these ranges into two separate columns or replace them with some measure like the mean of that range.\u003c/p\u003e\n\u003cp\u003eYou will first create a dummy DataFrame which has just one feature \u003ccode\u003eage\u003c/code\u003e with ranges specified using the pandas \u003ccode\u003eDataFrame\u003c/code\u003e function. Then you will split the column on the delimeter \u003ccode\u003e-\u003c/code\u003e into two columns \u003ccode\u003estart\u003c/code\u003e and \u003ccode\u003eend\u003c/code\u003e using \u003ccode\u003esplit()\u003c/code\u003e with a \u003ccode\u003elambda()\u003c/code\u003e function. If you want to learn more about lambda functions, check out this \u003ca href=\"https://www.datacamp.com/community/tutorials/functions-python-tutorial\"\u003etutorial\u003c/a\u003e.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003edummy_df_age = pd.DataFrame({\u0026#39;age\u0026#39;: [\u0026#39;0-20\u0026#39;, \u0026#39;20-40\u0026#39;, \u0026#39;40-60\u0026#39;,\u0026#39;60-80\u0026#39;]})\ndummy_df_age[\u0026#39;start\u0026#39;], dummy_df_age[\u0026#39;end\u0026#39;] = zip(*dummy_df_age[\u0026#39;age\u0026#39;].map(lambda x: x.split(\u0026#39;-\u0026#39;)))\n\ndummy_df_age.head()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1527000503/categorical_table_14.png\" /\u003e\u003c/p\u003e\n\u003cp\u003eTo replace the range with its mean, you will write a \u003ccode\u003esplit_mean()\u003c/code\u003e function which basically takes one range at a time, splits it, then calculates the mean and returns it. To apply a certain function to all the entities of a column you will use the \u003ccode\u003e.apply()\u003c/code\u003e method:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003edummy_df_age = pd.DataFrame({\u0026#39;age\u0026#39;: [\u0026#39;0-20\u0026#39;, \u0026#39;20-40\u0026#39;, \u0026#39;40-60\u0026#39;,\u0026#39;60-80\u0026#39;]})\n\ndef split_mean(x):\n    split_list = x.split(\u0026#39;-\u0026#39;)\n    mean = (float(split_list[0])+float(split_list[1]))/2\n    return mean\n\ndummy_df_age[\u0026#39;age_mean\u0026#39;] = dummy_df_age[\u0026#39;age\u0026#39;].apply(lambda x: split_mean(x))\n\ndummy_df_age.head()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1527000503/categorical_table_15.png\" /\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca id=\"spark\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"dealing-with-categorical-features-in-big-data-with-spark\"\u003eDealing with Categorical Features in Big Data with Spark\u003c/h2\u003e\n\u003cp\u003eNow you will learn how to read a dataset in Spark and encode categorical variables in Apache Spark\u0026#39;s Python API, Pyspark. But before that it\u0026#39;s good to brush up on some basic knowledge about Spark.\u003c/p\u003e\n\u003cp\u003eSpark is a platform for cluster computing. It lets you spread data and computations over clusters with multiple nodes. Splitting up your data makes it easier to work with very large datasets because each node only works with a small amount of data.\u003c/p\u003e\n\u003cp\u003eAs each node works on its own subset of the total data, it also carries out a part of the total calculations required, so that both data processing and computations are performed in parallel over the nodes in the cluster.\u003c/p\u003e\n\u003cp\u003eDeciding whether or not Spark is the best solution for your problem takes some experience, but you can consider questions like:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eIs my data too big to work with on a single machine?\u003c/li\u003e\n\u003cli\u003eCan my calculations be easily parallelized?\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe first step in using Spark is connecting to a cluster. In practice, the cluster will be hosted on a remote machine that\u0026#39;s connected to all other nodes. There will be one computer, called the master that manages splitting up the data and the computations. The master is connected to the rest of the computers in the cluster, which are called slaves. The master sends the slaves data and calculations to run, and they send their results back to the master.\u003c/p\u003e\n\u003cp\u003eWhen you\u0026#39;re just getting started with Spark, it\u0026#39;s simpler to just run a cluster locally. If you wish to run Spark on a cluster and use Jupyter Notebook, you can check out this \u003ca href=\"https://blog.sicara.com/get-started-pyspark-jupyter-guide-tutorial-ae2fe84f594f\"\u003eblog\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eIf you wish to learn more about Spark, check out this great \u003ca href=\"https://www.datacamp.com/community/tutorials/apache-spark-tutorial-machine-learning#gs.cVl1_uk\"\u003etutorial\u003c/a\u003e which covers almost everything about it, or DataCamp\u0026#39;s \u003ca href=\"https://www.datacamp.com/courses/introduction-to-pyspark\"\u003eIntroduction to PySpark\u003c/a\u003e course.\u003c/p\u003e\n\u003cp\u003eThe first step in Spark programming is to create a SparkContext. SparkContext is required when you want to execute operations in a cluster. SparkContext tells Spark how and where to access a cluster. You\u0026#39;ll start by importing SparkContext.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003efrom pyspark import SparkContext\nsc = SparkContext()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eNote\u003c/strong\u003e that if you are working on Spark\u0026#39;s interactive shell then you don\u0026#39;t have to import SparkContext as it will already be in your environment as \u003ccode\u003esc\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eTo start working with Spark DataFrames, you first have to create a \u003ccode\u003eSparkSession\u003c/code\u003e object from your \u003ccode\u003eSparkContext\u003c/code\u003e. You can think of the SparkContext as your connection to the cluster and the SparkSession as your interface with that connection.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eNote\u003c/strong\u003e that if you are working in Spark\u0026#39;s interactive shell you\u0026#39;ll have a \u003ccode\u003eSparkSession\u003c/code\u003e called \u003ccode\u003espark\u003c/code\u003e available in your workspace!\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003efrom pyspark.sql import SparkSession as spark\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eOnce you\u0026#39;ve created a SparkSession, you can start poking around to see what data is in your cluster.\u003c/p\u003e\n\u003cp\u003eYour \u003ccode\u003eSparkSession\u003c/code\u003e has an attribute called \u003ccode\u003ecatalog\u003c/code\u003e which lists all the data inside the cluster. This attribute has a few methods for extracting different pieces of information.\u003c/p\u003e\n\u003cp\u003eOne of the most useful is the \u003ccode\u003e.listTables()\u003c/code\u003e method, which returns the names of all the tables in your cluster as a list.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003eprint(spark.catalog.listTables())\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode\u003e[]\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eYour catalog is currently empty!\u003c/p\u003e\n\u003cp\u003eYou will now load the flights dataset in the Spark DataFrame.\u003c/p\u003e\n\u003cp\u003eTo read a \u003ccode\u003e.csv\u003c/code\u003e file and create a Spark DataFrame you can use the \u003ccode\u003e.read\u003c/code\u003e attribute of your SparkSession object. Here, apart from reading the csv file, you have to additionally specify the \u003ccode\u003eheaders\u003c/code\u003e option to be \u003ccode\u003eTrue\u003c/code\u003e, since you have column names in the dataset. Also, the \u003ccode\u003einferSchema\u003c/code\u003e argument is set to \u003ccode\u003eTrue\u003c/code\u003e, which basically peeks at the first row of the data to determine the fields\u0026#39; names and types.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003espark_flights = spark.read.format(\u0026quot;csv\u0026quot;).option(\u0026#39;header\u0026#39;,True).load(\u0026#39;Downloads/datasets/nyc_flights/flights.csv\u0026#39;,inferSchema=True)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eTo check the contents of your DataFrame you can run the \u003ccode\u003e.show()\u003c/code\u003e method on the DataFrame.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003espark_flights.show(3)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode\u003e+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+----+------+\n|year|month|day|dep_time|dep_delay|arr_time|arr_delay|carrier|tailnum|flight|origin|dest|air_time|distance|hour|minute|\n+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+----+------+\n|2014|    1|  1|       1|       96|     235|       70|     AS| N508AS|   145|   PDX| ANC|     194|    1542|   0|     1|\n|2014|    1|  1|       4|       -6|     738|      -23|     US| N195UW|  1830|   SEA| CLT|     252|    2279|   0|     4|\n|2014|    1|  1|       8|       13|     548|       -4|     UA| N37422|  1609|   PDX| IAH|     201|    1825|   0|     8|\n+----+-----+---+--------+---------+--------+---------+-------+-------+------+------+----+--------+--------+----+------+\nonly showing top 3 rows\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eIf you wish to convert a pandas DataFrame to a Spark DataFrame, use the \u003ccode\u003e.createDataFrame()\u003c/code\u003e method on your SparkSession object with the DataFrame\u0026#39;s name as argument.\u003c/p\u003e\n\u003cp\u003eTo have a look at the schema of the DataFrame you can invoke \u003ccode\u003e.printSchema()\u003c/code\u003e as follows:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003espark_flights.printSchema()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode\u003eroot\n |-- year: integer (nullable = true)\n |-- month: integer (nullable = true)\n |-- day: integer (nullable = true)\n |-- dep_time: string (nullable = true)\n |-- dep_delay: string (nullable = true)\n |-- arr_time: string (nullable = true)\n |-- arr_delay: string (nullable = true)\n |-- carrier: string (nullable = true)\n |-- tailnum: string (nullable = true)\n |-- flight: integer (nullable = true)\n |-- origin: string (nullable = true)\n |-- dest: string (nullable = true)\n |-- air_time: string (nullable = true)\n |-- distance: integer (nullable = true)\n |-- hour: string (nullable = true)\n |-- minute: string (nullable = true)\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cstrong\u003eNote\u003c/strong\u003e that Spark doesn\u0026#39;t always guess the data type of the columns right and you can see that some of the columns (\u003ccode\u003earr_delay\u003c/code\u003e, \u003ccode\u003eair_time\u003c/code\u003e, etc.) which seem to have numeric values are read as strings rather than integers or floats, due to the presence of missing values.\u003c/p\u003e\n\u003cp\u003eAt this point, if you check the data in your cluster using the \u003ccode\u003e.catalog\u003c/code\u003e attribute and the \u003ccode\u003e.listTables()\u003c/code\u003e method like you did before, you will find it\u0026#39;s still empty. This is because you DataFrame is currently stored locally, not in the \u003ccode\u003eSparkSession\u003c/code\u003e catalog.\u003c/p\u003e\n\u003cp\u003eTo access the data in this way, you have to save it as a temporary table. You can do so by using the \u003ccode\u003e.createOrReplaceTempView()\u003c/code\u003e method. This method registers the DataFrame as a table in the catalog, but as this table is temporary, it can only be accessed from the specific \u003ccode\u003eSparkSession\u003c/code\u003e used to create the Spark DataFrame.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003espark_flights.createOrReplaceTempView(\u0026quot;flights_temp\u0026quot;)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003ePrint the tables in catalog again:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003eprint(spark.catalog.listTables())\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode\u003e[Table(name=u\u0026#39;flights_temp\u0026#39;, database=None, description=None, tableType=u\u0026#39;TEMPORARY\u0026#39;, isTemporary=True)]\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eNow you have registered the \u003ccode\u003eflight_temp\u003c/code\u003e table as a temporary table in your catalog.\u003c/p\u003e\n\u003cp\u003eNow that you have gotten your hands dirty with a little bit of PySpark code, it\u0026#39;s time to see how to encode categorical features. To keep things neat, you will create a new DataFrame which consists of only the \u003ccode\u003ecarrier\u003c/code\u003e column by using the \u003ccode\u003e.select()\u003c/code\u003e method.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003ecarrier_df = spark_flights.select(\u0026quot;carrier\u0026quot;)\ncarrier_df.show(5)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode\u003e+-------+\n|carrier|\n+-------+\n|     AS|\n|     US|\n|     UA|\n|     US|\n|     AS|\n+-------+\nonly showing top 5 rows\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eThe two most common ways to encode categorical features in Spark are using \u003ccode\u003eStringIndexer\u003c/code\u003e and \u003ccode\u003eOneHotEncoder\u003c/code\u003e.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eStringIndexer\u003c/code\u003e encodes a string column of labels to a column of label indices. The indices are in [0, numLabels] ordered by label frequencies, so the most frequent label gets index 0. This is similar to label encoding in pandas.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eYou will start by importing the \u003ccode\u003eStringIndexer\u003c/code\u003e class from the \u003ccode\u003epyspark.ml.feature\u003c/code\u003e module. The main arguments inside \u003ccode\u003eStringIndexer\u003c/code\u003e are \u003ccode\u003einputCol\u003c/code\u003e and \u003ccode\u003eoutputCol\u003c/code\u003e, which are self-explanatory. After you create the StringIndex object you call the \u003ccode\u003e.fit()\u003c/code\u003e and \u003ccode\u003e.transform()\u003c/code\u003e methods with the DataFrame as the argument passed as shown:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003efrom pyspark.ml.feature import StringIndexer\ncarr_indexer = StringIndexer(inputCol=\u0026quot;carrier\u0026quot;,outputCol=\u0026quot;carrier_index\u0026quot;)\ncarr_indexed = carr_indexer.fit(carrier_df).transform(carrier_df)\n\ncarr_indexed.show(7)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode\u003e+-------+-------------+\n|carrier|carrier_index|\n+-------+-------------+\n|     AS|          0.0|\n|     US|          6.0|\n|     UA|          4.0|\n|     US|          6.0|\n|     AS|          0.0|\n|     DL|          3.0|\n|     UA|          4.0|\n+-------+-------------+\nonly showing top 7 rows\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eSince \u003ccode\u003eAS\u003c/code\u003e was the most frequent category in the \u003ccode\u003ecarrier\u003c/code\u003e column, it got the index \u003ccode\u003e0.0\u003c/code\u003e.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eOneHotEncoder: as you already read before, one-hot encoding maps a categorical feature, represented as a label index, to a binary vector with at most a single one-value indicating the presence of a specific feature value from among the set of all feature values.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eFor example, with 5 categories, an input value of 2.0 would map to an output vector of [0.0, 0.0, 1.0, 0.0]. The last category is not included by default (configurable via OneHotEncoder \u003ccode\u003e.dropLast\u003c/code\u003e because it makes the vector entries sum up to one, and hence linearly dependent. That means that an input value of 4.0 would map to [0.0, 0.0, 0.0, 0.0].\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eNote\u003c/strong\u003e that this is different from scikit-learn\u0026#39;s OneHotEncoder, which keeps all categories. The output vectors are sparse.\u003c/p\u003e\n\u003cp\u003eFor a string type like in this case, it is common to encode features using \u003ccode\u003eStringIndexer\u003c/code\u003e first, here \u003ccode\u003ecarrier_index\u003c/code\u003e. Then pass that column to the \u003ccode\u003eOneHotEncoder\u003c/code\u003e class.\u003c/p\u003e\n\u003cp\u003eThe code is shown below.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003ecarrier_df_onehot = spark_flights.select(\u0026quot;carrier\u0026quot;)\n\nfrom pyspark.ml.feature import OneHotEncoder, StringIndexer\n\nstringIndexer = StringIndexer(inputCol=\u0026quot;carrier\u0026quot;, outputCol=\u0026quot;carrier_index\u0026quot;)\nmodel = stringIndexer.fit(carrier_df_onehot)\nindexed = model.transform(carrier_df_onehot)\nencoder = OneHotEncoder(dropLast=False, inputCol=\u0026quot;carrier_index\u0026quot;, outputCol=\u0026quot;carrier_vec\u0026quot;)\nencoded = encoder.transform(indexed)\n\nencoded.show(7)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode\u003e+-------+-------------+--------------+\n|carrier|carrier_index|   carrier_vec|\n+-------+-------------+--------------+\n|     AS|          0.0|(11,[0],[1.0])|\n|     US|          6.0|(11,[6],[1.0])|\n|     UA|          4.0|(11,[4],[1.0])|\n|     US|          6.0|(11,[6],[1.0])|\n|     AS|          0.0|(11,[0],[1.0])|\n|     DL|          3.0|(11,[3],[1.0])|\n|     UA|          4.0|(11,[4],[1.0])|\n+-------+-------------+--------------+\nonly showing top 7 rows\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cstrong\u003eNote\u003c/strong\u003e that \u003ccode\u003eOneHotEncoder\u003c/code\u003e has created a vector for each category which can then be processed further by your machine learning pipeline.\u003c/p\u003e\n\u003cp\u003eThere are some more methods available in Spark like \u003ccode\u003eVectorIndexer\u003c/code\u003e, but you have already mastered the most popular ones. If you wish to explore more, check out Spark\u0026#39;s fantastic \u003ca href=\"https://spark.apache.org/docs/latest/ml-features.html#vectorindexer\"\u003edocumentation\u003c/a\u003e.\u003c/p\u003e\n\u003ch2 id=\"conclusion\"\u003eConclusion\u003c/h2\u003e\n\u003cp\u003eHurray!! You have come a long way! You have explored most of the bits and pieces which are out there about dealing with categorical features in the machine learning realm. You started with basic EDA in pandas and then you practiced the different encoding methods available. You also learned a bit about Spark\u0026#39;s architecture and moved to encoding categorical data in PySpark. That\u0026#39;s a lot, but there is always so much more to learn. You will also have to make sure that you data is properly cleaned. To learn how to do so, take a look at our \u003ca href=\"https://www.datacamp.com/courses/cleaning-data-in-python\"\u003eCleaning Data in Python\u003c/a\u003e course. Happy exploring!!  \u003c/p\u003e\n","contentUrl":"https://www.datacamp.com/community/tutorials/categorical-data","userContentUrl":null,"illustrationUrl":null,"seoTitle":"Handling Categorical Data in Python","seoMetaDescription":"Learn the common tricks to handle categorical data and preprocess it to build machine learning models!","seoKeyword":"categorical data python","mustRead":false,"programmingLanguage":null,"submissionDate":"2018-04-26T07:54:35.142Z","publishDate":"2018-05-22T10:00:00.000Z","episode":null,"isLatest":null,"externalUrl":null,"transcriptUrl":null,"guests":[],"links":null,"isSpam":false,"xp":0,"flaggingUsers":[],"isDisabled":false,"connectedInternalContentId":10048,"createdAt":"2018-04-26T07:54:35.135Z","updatedAt":"2018-05-23T08:10:44.479Z","upvoting":{"voteCount":17,"voted":false},"tags":["data manipulation","python"],"author":{"id":412222,"slug":"pathakmanish2605","avatarUrlSquare":"https://assets.datacamp.com/users/avatars/000/412/222/square/index.jpg?1516993022","fullName":"Manish Pathak","nameFromEmail":"pathakmanish2605","isAdmin":false}},{"id":10013,"externalId":null,"type":"Tutorial","status":"published","authorId":"mauriciovargas","title":"How to install R on Windows, Mac OS X and Ubuntu","slug":"installing-R-windows-mac-ubuntu","previewSlug":null,"description":"This is a beginner guide that is designed to save yourself a headache and valuable time if you decide to install R yourself.","articles":[],"courses":[],"redirectSlug":null,"contentHtml":"\u003cp\u003eI am a professor and I don\u0026#39;t like to spend one hour of the class or workshop installing R. To tackle that problem I polished these instructions over time by doing experiments with different machines in order to maximize the in-classroom experience.\u003c/p\u003e\n\u003cp\u003eWhat you\u0026#39;ll find here is a collection of lines of code that work when installing R, and of course I tried a lot of things that didn\u0026#39;t work before obtaining the actual result.\u003c/p\u003e\n\u003cp\u003e\u003cnav\u003e\nThis tutorial covers the installation of R on \u003ca href=\"#windows\"\u003eMicrosoft Windows\u003c/a\u003e, \u003ca href=\"#mac\"\u003eMac OS X\u003c/a\u003e and \u003ca href=\"#ubuntu\"\u003eUbuntu Linux\u003c/a\u003e.\n\u003c/nav\u003e\u003c/p\u003e\n\u003cp\u003e\u003cdiv id=\"scoped-content\"\u003e\u003c/p\u003e\n\u003cstyle type=\"text/css\"\u003e:target:before { content:\"\"; display:block; height:150px; margin:-150px 0 0; } h3 {font-weight:normal; margin-top:.5em} h4 { font-weight:lighter }\n\u003c/style\u003e\n\n\u003ch1 id=\"r-and-rstudio\"\u003eR and RStudio\u003c/h1\u003e\n\u003cp\u003eThis setup aims to install both R and RStudio. You can think of installing R as buying car and of installing R and RStudio as buying a car with all the accessories for a better user experience.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://www.r-project.org/\"\u003eR\u003c/a\u003e refers to a software environment that comes with a GUI (Graphical User Interface). R GUI looks more similar to the old DOS console than to SPSS or Stata.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://www.rstudio.com/\"\u003eRStudio\u003c/a\u003e is an IDE (Integrated Development Environment) that makes R easier to use and is more similar to SPSS or Stata. It includes a code editor, debugging and visualization tools. Please use it to obtain a nice R experience.\u003c/p\u003e\n\u003ch1 id=\"the-tidyverse\"\u003eThe Tidyverse\u003c/h1\u003e\n\u003cp\u003eThe \u003ca href=\"https://www.tidyverse.org/\"\u003eTidyverse\u003c/a\u003e provides a set of packages that augment R capabilities and share an underlying design concept.\u003c/p\u003e\n\u003cp\u003eA remarkable example is \u003ccode\u003edplyr\u003c/code\u003e, a package that really simplifies data manipulation. Just as an example it provides, among other functions and capabilities, \u003ccode\u003egroup_by\u003c/code\u003e and \u003ccode\u003esummarise\u003c/code\u003e functions to perform operations such as \u003ccode\u003eSUMIF\u003c/code\u003e or \u003ccode\u003eSUMIFS\u003c/code\u003e from Microsoft Excel.\u003c/p\u003e\n\u003cp\u003eIf you want to create plots from R, the Tidyverse provides the \u003ccode\u003eggplot2\u003c/code\u003e package for plot creation. There are really good tutorials to learn \u003ccode\u003eggplot2\u003c/code\u003e.  Jodie Burchell and I wrote \u003ca href=\"https://leanpub.com/hitchhikers_ggplot2\"\u003eThe Hitchhiker\u0026#39;s Guide to Ggplot2\u003c/a\u003e that you can download for free.\u003c/p\u003e\n\u003cp\u003eAnother cool feature is that the Tidyverse provides the \u003ccode\u003ehaven\u003c/code\u003e package to import/export data by using SPSS, Stata, and SAS formats.\u003c/p\u003e\n\u003cp\u003eThe installation instructions are different, depending on your operating system; either \u003ca href=\"#windows\"\u003eMicrosoft Windows\u003c/a\u003e, \u003ca href=\"#mac\"\u003eMac OS X\u003c/a\u003e or \u003ca href=\"#ubuntu\"\u003eUbuntu Linux\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003e\u003ca id=\"windows\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003ch1 id=\"install-r-and-rstudio-on-windows\"\u003eInstall R and RStudio on Windows\u003c/h1\u003e\n\u003cp\u003eMy experience with Windows and R went from tragic to amazing. What made my R and Windows experience amazing was \u003ca href=\"https://mran.microsoft.com/open\"\u003eMicrosoft R Open\u003c/a\u003e, which is an R instance that comes with \u003ca href=\"https://software.intel.com/en-us/mkl\"\u003eIntel MKL\u003c/a\u003e, a numerical library that increases the speed of some operations, enabled by default.\u003c/p\u003e\n\u003cp\u003eIn any case you can always install Stock R. Please notice that here you may choose step one or two, but not both, as it would be quite unproductive. After you complete one of the two first steps, you can then go for the next steps.\u003c/p\u003e\n\u003ch2 id=\"step-1-install-microsoft-r-open\"\u003eStep 1: Install Microsoft R Open\u003c/h2\u003e\n\u003cp\u003eTo install R on Windows just download it from \u003ca href=\"https://mran.microsoft.com/download\"\u003eMRO Downloads\u003c/a\u003e and then execute the installer. The setup is straightforward, just hit \u0026#39;next\u0026#39; when required and be sure you mark the MKL option.\u003c/p\u003e\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Y916HiPf7XY\" frameborder=\"0\" allow=\"autoplay; encrypted-media\" allowfullscreen\u003e\u003c/iframe\u003e\n\n\u003ch2 id=\"step-2-install-cran-r\"\u003eStep 2: Install CRAN R\u003c/h2\u003e\n\u003cp\u003eAs an alternative to step one, you can also install from CRAN (The Comprehensive R Archive Network). Just visit \u003ca href=\"https://cran.r-project.org/\"\u003eCRAN downloads\u003c/a\u003e and get the last version.\u003c/p\u003e\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/G7u7cLiyi8o\" frameborder=\"0\" allow=\"autoplay; encrypted-media\" allowfullscreen\u003e\u003c/iframe\u003e\n\n\u003ch2 id=\"step-3-install-rstudio\"\u003eStep 3: Install RStudio\u003c/h2\u003e\n\u003cp\u003eTo install RStudio just visit \u003ca href=\"https://www.rstudio.com/products/rstudio/download/#download\"\u003eRStudio Downloads\u003c/a\u003e and download the last version. The setup should be straightforward.\u003c/p\u003e\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/fFjHbWhfn6s\" frameborder=\"0\" allow=\"autoplay; encrypted-media\" allowfullscreen\u003e\u003c/iframe\u003e\n\n\u003cp\u003e\u003ca id=\"mac\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003ch1 id=\"install-r-and-rstudio-on-mac-os-x\"\u003eInstall R and RStudio on Mac OS X\u003c/h1\u003e\n\u003cp\u003eInstalling R on OS X can be problematic. What I\u0026#39;ve heard from my students is that software dependencies can be a huge problem when installing not just R but also Python, Ruby and more tools.\u003c/p\u003e\n\u003cp\u003eDoes it have to be problematic? The easiest option to install R on OS X is to use \u003ca href=\"https://brew.sh/\"\u003eHomebrew\u003c/a\u003e, which is a package manager that will do everything for you when you input short commands such as \u003ccode\u003ebrew install r\u003c/code\u003e. In order to install R in this way you need to:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eInstall XCode Command Line Tools\u003c/li\u003e\n\u003cli\u003eInstall Homebrew\u003c/li\u003e\n\u003cli\u003eFinally install R\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eYou can download R for Mac from the \u003ca href=\"http://cran.us.r-project.org/bin/macosx/\"\u003eCRAN website\u003c/a\u003e, and \u003ca href=\"https://medium.com/@GalarnykMichael/install-r-and-rstudio-on-mac-e911606ce4f4\"\u003eMedium\u003c/a\u003e provides a good tutorial for that alternative, but my students complain about that installation method. Some of them have faced problems to complete the installation doing that but they had no difficulties when choosing the Homebrew alternative.\u003c/p\u003e\n\u003cp\u003eI highly recommend to install R with \u003ca href=\"http://www.openblas.net/\"\u003eOpenBLAS\u003c/a\u003e. In plain terms, OpenBLAS will boost some operations and I want you to be a happy user. You can ignore this advice if you are going to work with relatively small datasets.\u003c/p\u003e\n\u003cp\u003eBetween steps four or five, just choose what you think is more suitable for you. Don\u0026#39;t complete step four and then step five or you will waste time as step five will replace all what you did in step four.\u003c/p\u003e\n\u003ch2 id=\"step-1-install-xcode-command-line-tools\"\u003eStep 1: Install XCode Command Line Tools\u003c/h2\u003e\n\u003cp\u003eCompiling software on OS X requires \u003ca href=\"https://developer.apple.com/download/more/\"\u003eXCode CLT\u003c/a\u003e, and installing R requires compiling at some steps, so there is no escape from this part.\u003c/p\u003e\n\u003cp\u003eOpen the Terminal (cmd + space and search \u0026#39;Terminal\u0026#39;) and paste this command:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003excode-select --install\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eThen hit enter and wait a minute. If your computer already has this software you will see a message warning that XCode CLT is already installed, otherwise it will take a moment to automatically download and install the software.\u003c/p\u003e\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/mBAD9XsGIXA\" frameborder=\"0\" allow=\"autoplay; encrypted-media\" allowfullscreen\u003e\u003c/iframe\u003e\n\n\u003ch2 id=\"step-2-install-homebrew\"\u003eStep 2: Install Homebrew\u003c/h2\u003e\n\u003cp\u003eIn order to install Homebrew paste this command in the terminal:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e/usr/bin/ruby -e \u0026quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\u0026quot;\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eThen hit enter and watch a lot of code and emojis appear on the screen.\u003c/p\u003e\n\u003cp\u003eNow you would want to configure the Homebrew path. You just need to run this once and then experience the magic. The reason to do this is that this is the way to tell your system where Homebrew software can be found on your hard disk.\u003c/p\u003e\n\u003cp\u003ePaste this piece of code in the terminal:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e# Homebrew PATH\necho \u0026quot;export LC_ALL=en_US.UTF-8\u0026quot; \u0026gt;\u0026gt; ~/.bash_profile\necho \u0026quot;export LANG=en_US.UTF-8\u0026quot; \u0026gt;\u0026gt; ~/.bash_profile\necho \u0026quot;export PATH=/usr/local/bin:$PATH\u0026quot; \u0026gt;\u0026gt; ~/.bash_profile \u0026amp;\u0026amp; source ~/.bash_profile\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eAs you might guess, you need to hit enter after pasting it.\u003c/p\u003e\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/RAt3RP4_cY0\" frameborder=\"0\" allow=\"autoplay; encrypted-media\" allowfullscreen\u003e\u003c/iframe\u003e\n\n\u003ch2 id=\"step-3-install-r-without-openblas\"\u003eStep 3: Install R without OpenBLAS\u003c/h2\u003e\n\u003cp\u003eYou have already installed XCode CLT and Homebrew. So now paste this piece of code in the terminal:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ebrew install r\necho \u0026#39;Sys.setlocale(category=\u0026quot;LC_ALL\u0026quot;, locale = \u0026quot;en_US.UTF-8\u0026quot;)\u0026#39; \u0026gt;\u0026gt; ~/.bash_profile\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eHit enter and something good will happen.\u003c/p\u003e\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/wkrDeXfM83o\" frameborder=\"0\" allow=\"autoplay; encrypted-media\" allowfullscreen\u003e\u003c/iframe\u003e\n\n\u003ch2 id=\"step-4-install-r-with-openblas\"\u003eStep 4: Install R with OpenBLAS\u003c/h2\u003e\n\u003cp\u003eThis is very similar to the last step. Paste this piece of code in the terminal:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ebrew install openblas\nbrew install r --with-openblas\necho \u0026#39;Sys.setlocale(category=\u0026quot;LC_ALL\u0026quot;, locale = \u0026quot;en_US.UTF-8\u0026quot;)\u0026#39; \u0026gt;\u0026gt; ~/.bash_profile\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eHit enter and something good will happen.\u003c/p\u003e\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/wkrDeXfM83o\" frameborder=\"0\" allow=\"autoplay; encrypted-media\" allowfullscreen\u003e\u003c/iframe\u003e\n\n\u003ch2 id=\"step-5-install-rstudio\"\u003eStep 5: Install RStudio\u003c/h2\u003e\n\u003cp\u003eFinally paste this piece of code in the terminal:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ebrew cask install rstudio\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eHit enter and you\u0026#39;ll be ready.\u003c/p\u003e\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/LN07tm9YXXY\" frameborder=\"0\" allow=\"autoplay; encrypted-media\" allowfullscreen\u003e\u003c/iframe\u003e\n\n\u003cp\u003e\u003ca id=\"ubuntu\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003ch1 id=\"install-r-and-rstudio-on-ubuntu-linux\"\u003eInstall R and RStudio on Ubuntu Linux\u003c/h1\u003e\n\u003cp\u003eYou should install R with \u003ca href=\"http://www.openblas.net/\"\u003eOpenBLAS\u003c/a\u003e. In plain terms, OpenBLAS will boost some operations and I want you to be a happy user. You can ignore this advice if you are going to work with relatively small datasets.\u003c/p\u003e\n\u003cp\u003eInstalling R on Ubuntu is simple, amazingly simple! You can install R, RStudio and the Tidyverse in a super simple way compared to the Windows or OS X way.\u003c/p\u003e\n\u003cp\u003eBetween steps one or two just choose what you think is more suitable for you. Don\u0026#39;t complete step one and then step two or you will waste time as step two will replace all what you did on step one.\u003c/p\u003e\n\u003ch2 id=\"step-1-install-r-without-openblas\"\u003eStep 1: Install R without OpenBLAS\u003c/h2\u003e\n\u003cp\u003eOpen the terminal and paste this piece of code:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e# R with OpenBLAS\nsudo apt-get install r-base\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eThen press enter.\u003c/p\u003e\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/i_ikXnNsqCk\" frameborder=\"0\" allow=\"autoplay; encrypted-media\" allowfullscreen\u003e\u003c/iframe\u003e\n\n\u003ch2 id=\"step-2-install-r-with-openblas\"\u003eStep 2: Install R with OpenBLAS\u003c/h2\u003e\n\u003cp\u003eOpen the terminal and paste this piece of code:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e# R with OpenBLAS\nsudo apt-get install libopenblas-base r-base\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eThen press enter.\u003c/p\u003e\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/i_ikXnNsqCk\" frameborder=\"0\" allow=\"autoplay; encrypted-media\" allowfullscreen\u003e\u003c/iframe\u003e\n\n\u003ch2 id=\"step-3-install-rstudio\"\u003eStep 3: Install RStudio\u003c/h2\u003e\n\u003cp\u003eDon\u0026#39;t leave the terminal and paste this piece of code:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003esudo apt-get install gdebi\ncd ~/Downloads\nwget https://download1.rstudio.org/rstudio-xenial-1.1.419-amd64.deb\nsudo gdebi rstudio-xenial-1.1.379-amd64.deb\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eThen press enter.\u003c/p\u003e\n\u003cp\u003eAnother install option is to visit \u003ca href=\"https://www.rstudio.com\"\u003eRStudio\u003c/a\u003e to obtain the software and then install it from the desktop without needing commands.\u003c/p\u003e\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/y2TydzmtrlQ\" frameborder=\"0\" allow=\"autoplay; encrypted-media\" allowfullscreen\u003e\u003c/iframe\u003e\n\n\n\u003ch1 id=\"install-the-tidyverse\"\u003eInstall the Tidyverse\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003eNote\u003c/strong\u003e that this part is the same for all operating systems.\u003c/p\u003e\n\u003cp\u003eOpen RStudio. These steps are the same for any operating system.\u003c/p\u003e\n\u003cp\u003eIn the RStudio bottom left panel, you can type any valid command followed by enter and R will execute that command.\u003c/p\u003e\n\u003cp\u003ePaste the next line in the bottom left panel:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e{r install-tidyverse, eval = F}\ninstall.packages(\u0026quot;tidyverse\u0026quot;, repos = \u0026#39;https://cran.us.r-project.org\u0026#39;)\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eThen hit enter and you\u0026#39;ll get a nice R setup ready to rock!\u003c/p\u003e\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/dlDeBx6FFPY\" frameborder=\"0\" allow=\"autoplay; encrypted-media\" allowfullscreen\u003e\u003c/iframe\u003e\n\n\u003ch1 id=\"install-more-r-packages\"\u003eInstall More R Packages\u003c/h1\u003e\n\u003cp\u003eBeyond the Tidyverse are more useful packages.\u003c/p\u003e\n\u003cp\u003eSome of my daily use packages are:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eXML\u003c/code\u003e: Read and create XML documents with R.\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ejsonlite\u003c/code\u003e: Read and create JSON data tables with R.\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ehttr\u003c/code\u003e: A set of useful tools for working with http connections.\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ervest\u003c/code\u003e: Very useful for web scraping.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eYou might think that this is the way to install these packages:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e{r install-more-packages-1, eval = F}\ninstall.packages(\u0026quot;XML\u0026quot;, repos = \u0026#39;https://cran.us.r-project.org\u0026#39;)\ninstall.packages(\u0026quot;jsonlite\u0026quot;, repos = \u0026#39;https://cran.us.r-project.org\u0026#39;)\netc...\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eBut there is a more convenient way:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e{r install-more-packages-2, eval = F}\ninstall.packages(c(\u0026quot;XML\u0026quot;, \u0026quot;jsonlite\u0026quot;, \u0026quot;httr\u0026quot;, \u0026quot;rvest\u0026quot;))\n\u003c/code\u003e\u003c/pre\u003e\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/ZFhjnNHjJ1w\" frameborder=\"0\" allow=\"autoplay; encrypted-media\" allowfullscreen\u003e\u003c/iframe\u003e\n\n\u003ch1 id=\"rstudio-aesthetics\"\u003eRStudio Aesthetics\u003c/h1\u003e\n\u003cp\u003eI do recommend editing the colors to reduce eye strain. To edit the colors in RStudio go to Tools, then to Global Options, and finally to Appearance.\u003c/p\u003e\n\u003cp\u003eI personally like the Cobalt theme with the \u003ca href=\"https://fonts.google.com/specimen/Ubuntu+Mono\"\u003eUbuntu Mono\u003c/a\u003e font, provided I code all day long.\u003c/p\u003e\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/9Q9mxCm1eQA\" frameborder=\"0\" allow=\"autoplay; encrypted-media\" allowfullscreen\u003e\u003c/iframe\u003e\n\n\u003ch1 id=\"check-that-everything-works\"\u003eCheck that everything works\u003c/h1\u003e\n\u003cp\u003eIn RStudio, go to File, then to New File and then click R Script. In the new blank script, try to write this code:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e{r plot, warning = F}\nlibrary(ggplot2)\n\nggplot(airquality, aes(x = Day, y = Ozone)) +\n  geom_point()\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eWhat that code does is to load \u003ccode\u003eggplot2\u003c/code\u003e and instruct it to use \u003ccode\u003eairquality\u003c/code\u003e, a dataset that comes with R, to plot Day versus Ozone.\u003c/p\u003e\n\u003cp\u003eYou need to load the packages because if R fresh install would come with the more than 10,000 existing packages the download would be really large and loading all the package when opening RStudio would be extremely slow.\u003c/p\u003e\n\u003cp\u003eTo run your code select the lines and press ctrl + enter (or cmd + enter if you have a Mac). If everything worked the plot should appear on the bottom right panel.\u003c/p\u003e\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/TKHLIA2ZGuc\" frameborder=\"0\" allow=\"autoplay; encrypted-media\" allowfullscreen\u003e\u003c/iframe\u003e\n\n\u003ch1 id=\"take-the-most-out-of-this-tutorial\"\u003eTake the most out of this tutorial\u003c/h1\u003e\n\u003cp\u003e\u003ca href=\"https://www.datacamp.com/courses/free-introduction-to-r\"\u003eIntroduction to R\u003c/a\u003e will help you master the basics of R, including factors, lists and data frames. With the knowledge gained in this course, you will be ready to undertake your first very own data analysis. This course starts from zero and it\u0026#39;s perfect for novice users.\u003c/p\u003e\n\u003cp\u003eAfter taking that course, you can follow \u003ca href=\"https://www.datacamp.com/courses/introduction-to-the-tidyverse\"\u003eIntroduction to the Tidyverse\u003c/a\u003e. That is an introduction to the programming language R where you\u0026#39;ll learn the processes of data manipulation and visualization through the tools \u003ccode\u003edplyr\u003c/code\u003e and \u003ccode\u003eggplot2\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eYou\u0026#39;ll learn to:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eManipulate data by filtering, sorting and summarizing a real dataset of historical country data in order to answer exploratory questions.\u003c/li\u003e\n\u003cli\u003eTurn processed data into informative line plots, bar plots, histograms, and more with the \u003ccode\u003eggplot2\u003c/code\u003e package.\u003c/li\u003e\n\u003c/ul\u003e\n","contentUrl":"https://www.datacamp.com/community/tutorials/installing-R-windows-mac-ubuntu","userContentUrl":null,"illustrationUrl":null,"seoTitle":"Installing R on Windows, Mac and Ubuntu","seoMetaDescription":"This is a beginner guide that is designed to save yourself a headache and valuable time if you decide to install R yourself.","seoKeyword":"install R Windows, Mac OS X and Ubuntu Linux","mustRead":false,"programmingLanguage":null,"submissionDate":"2018-05-14T11:48:13.730Z","publishDate":"2018-05-17T10:00:00.000Z","episode":null,"isLatest":null,"externalUrl":null,"transcriptUrl":null,"guests":[],"links":null,"isSpam":false,"xp":0,"flaggingUsers":[],"isDisabled":false,"connectedInternalContentId":10026,"createdAt":"2018-05-14T11:48:13.720Z","updatedAt":"2018-05-17T21:25:35.344Z","upvoting":{"voteCount":7,"voted":false},"tags":["tidyverse","r documentation"],"author":{"id":2096785,"slug":"mauriciovargas","avatarUrlSquare":"https://graph.facebook.com/2006376832956301/picture?width=150\u0026height=150","fullName":"Mauricio Vargas","nameFromEmail":"mauriciovargas","isAdmin":false}},{"id":10024,"externalId":null,"type":"Tutorial","status":"published","authorId":"avinashnvln8","title":"Understanding Random Forests Classifiers in Python","slug":"random-forests-classifier-python","previewSlug":null,"description":"Learn about Random Forests and build your own model in Python, for both classification and regression.","articles":[],"courses":[],"redirectSlug":null,"contentHtml":"\u003cp\u003eRandom forests is a supervised learning algorithm. It can be used both for classification and regression. It is also the most flexible and easy to use algorithm. A forest is comprised of trees. It is said that the more trees it has, the more robust a forest is. Random forests creates decision trees on randomly selected data samples, gets prediction from each tree and selects the best solution by means of voting. It also provides a pretty good indicator of the feature importance.\u003c/p\u003e\r\n\u003cp\u003eRandom forests has a variety of applications, such as recommendation engines, image classification and feature selection. It can be used to classify loyal loan applicants, identify fraudulent activity and predict diseases. It lies at the base of the Boruta algorithm, which selects important features in a dataset.\u003c/p\u003e\r\n\u003cp\u003e\u003cnav\u003e\r\nIn this tutorial, you are going to learn about all of the following:\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli\u003e\u003ca href=\"#algorithm\"\u003eThe random forests algorithm\u003c/a\u003e\u003c/li\u003e\r\n\u003cli\u003e\u003ca href=\"#how\"\u003eHow does the classifier work?\u003c/a\u003e\u003c/li\u003e\r\n\u003cli\u003e\u003ca href=\"#advantages\"\u003eIts advantages and disadvantages\u003c/a\u003e\u003c/li\u003e\r\n\u003cli\u003e\u003ca href=\"#features\"\u003eFinding important features\u003c/a\u003e\u003c/li\u003e\r\n\u003cli\u003e\u003ca href=\"#comparison\"\u003eComparision between random forests and decision trees\u003c/a\u003e\u003c/li\u003e\r\n\u003cli\u003e\u003ca href=\"#building\"\u003eBuilding a classifier with scikit-learn\u003c/a\u003e\u003c/li\u003e\r\n\u003cli\u003e\u003ca href=\"#findingfeatures\"\u003eFinding important features with scikit-learn\u003c/a\u003e\r\n\u003c/nav\u003e\r\n\u003cdiv id=\"scoped-content\"\u003e\u003cstyle type=\"text/css\"\u003e:target:before { content:\"\"; display:block; height:150px; margin:-150px 0 0; } h3 {font-weight:normal; margin-top:.5em} h4 { font-weight:lighter }\r\n\u003c/style\u003e\r\n\r\n\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003eIf you are not yet familiar with Tree-Based Models in Machine Learning, you should take a look at our \u003ca href=\"https://www.datacamp.com/courses/machine-learning-with-tree-based-models-in-r\"\u003eR course\u003c/a\u003e on the subject.\u003c/p\u003e\r\n\u003cp\u003e\u003ca id=\"algorithm\"\u003e\u003c/a\u003e\u003c/p\u003e\r\n\u003ch2 id=\"the-random-forests-algorithm\"\u003eThe Random Forests Algorithm\u003c/h2\u003e\r\n\u003cp\u003eLets understand the algorithm in laymans terms. Suppose you want to go on a trip and you would like to travel to a place which you will enjoy.\u003c/p\u003e\r\n\u003cp\u003eSo what do you do to find a place that you will like? You can search online, read reviews on travel blogs and portals, or you can also ask your friends.\u003c/p\u003e\r\n\u003cp\u003eLets suppose you have decided to ask your friends, and talked with them about their past travel experience to various places. You will get some recommendations from every friend. Now you have to make a list of those recommended places. Then, you ask them to vote (or select one best place for the trip) from the list of recommended places you made. The place with the highest number of votes will be your final choice for the trip.\u003c/p\u003e\r\n\u003cp\u003eIn the above decision process, there are two parts. First, asking your friends about their individual travel experience and getting one recommendation out of multiple places they have visited. This part is like using the decision tree algorithm. Here, each friend makes a selection of the places he or she has visited so far.\u003c/p\u003e\r\n\u003cp\u003eThe second part, after collecting all the recommendations, is the voting procedure for selecting the best place in the list of recommendations. This whole process of getting recommendations from friends and voting on them to find the best place is known as the random forests algorithm.\u003c/p\u003e\r\n\u003cp\u003eIt technically is an ensemble method (based on the divide-and-conquer approach) of decision trees generated on a randomly split dataset. This collection of decision tree classifiers is also known as the forest. The individual decision trees are generated using an attribute selection indicator such as information gain, gain ratio, and Gini index for each attribute. Each tree depends on an independent random sample. In a classification problem, each tree votes and the most popular class is chosen as the final result. In the case of regression, the average of all the tree outputs is considered as the final result. It is simpler and more powerful compared to the other non-linear classification algorithms.\u003c/p\u003e\r\n\u003cp\u003e\u003ca id=\"how\"\u003e\u003c/a\u003e\u003c/p\u003e\r\n\u003ch2 id=\"how-does-the-algorithm-work-\"\u003eHow does the algorithm work?\u003c/h2\u003e\r\n\u003cp\u003eIt works in four steps:\u003c/p\u003e\r\n\u003col\u003e\r\n\u003cli\u003eSelect random samples from a given dataset.\u003c/li\u003e\r\n\u003cli\u003eConstruct a decision tree for each sample and get a prediction result from each decision tree.\u003c/li\u003e\r\n\u003cli\u003ePerform a vote for each predicted result.\u003c/li\u003e\r\n\u003cli\u003eSelect the prediction result with the most votes as the final prediction.\u003c/li\u003e\r\n\u003c/ol\u003e\r\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1526467744/voting_dnjweq.jpg\" alt=\"Voting\"/\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003ca id=\"advantages\"\u003e\u003c/a\u003e\u003c/p\u003e\r\n\u003ch2 id=\"advantages-\"\u003eAdvantages:\u003c/h2\u003e\r\n\u003cul\u003e\r\n\u003cli\u003eRandom forests is considered as a highly accurate and robust method because of the number of decision trees participating in the process.\u003c/li\u003e\r\n\u003cli\u003eIt does not suffer from the overfitting problem. The main reason is that it takes the average of all the predictions, which cancels out the biases.\u003c/li\u003e\r\n\u003cli\u003eThe algorithm can be used in both classification and regression problems.\u003c/li\u003e\r\n\u003cli\u003eRandom forests can also handle missing values. There are two ways to handle these: using median values to replace continuous variables, and computing the proximity-weighted average of missing values.\u003c/li\u003e\r\n\u003cli\u003eYou can get the relative feature importance, which helps in selecting the most contributing features for the classifier.\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003ch2 id=\"disadvantages-\"\u003eDisadvantages:\u003c/h2\u003e\r\n\u003cul\u003e\r\n\u003cli\u003eRandom forests is slow in generating predictions because it has multiple decision trees. Whenever it makes a prediction, all the trees in the forest have to make a prediction for the same given input and then perform voting on it. This whole process is time-consuming.  \u003c/li\u003e\r\n\u003cli\u003eThe model is difficult to interpret compared to a decision tree, where you can easily make a decision by following the path in the tree.\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003e\u003ca id=\"features\"\u003e\u003c/a\u003e\u003c/p\u003e\r\n\u003ch2 id=\"finding-important-features\"\u003eFinding important features\u003c/h2\u003e\r\n\u003cp\u003eRandom forests also offers a good feature selection indicator. Scikit-learn provides an extra variable with the model, which shows the relative importance or contribution of each feature in the prediction. It automatically computes the relevance score of each feature in the training phase. Then it scales the relevance down so that the sum of all scores is 1.\u003c/p\u003e\r\n\u003cp\u003eThis score will help you choose the most important features and drop the least important ones for model building.  \u003c/p\u003e\r\n\u003cp\u003eRandom forest uses gini importance or mean decrease in impurity (MDI) to calculate the importance of each feature. Gini importance is also known as the total decrease in node impurity. This is how much the model fit or accuracy decreases when you drop a variable. The larger the decrease, the more significant the variable is. Here, the mean decrease is a significant parameter for variable selection. The Gini index can describe the overall explanatory power of the variables.  \u003c/p\u003e\r\n\u003cp\u003e\u003ca id=\"comparison\"\u003e\u003c/a\u003e\u003c/p\u003e\r\n\u003ch2 id=\"random-forests-vs-decision-trees\"\u003eRandom Forests vs Decision Trees\u003c/h2\u003e\r\n\u003cul\u003e\r\n\u003cli\u003eRandom forests is a set of multiple decision trees.\u003c/li\u003e\r\n\u003cli\u003eDeep decision trees may suffer from overfitting, but random forests prevents overfitting by creating trees on random subsets.\u003c/li\u003e\r\n\u003cli\u003eDecision trees are computationally faster.\u003c/li\u003e\r\n\u003cli\u003eRandom forests is difficult to interpret, while a decision tree is easily interpretable and can be converted to rules.\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003e\u003ca id=\"building\"\u003e\u003c/a\u003e\u003c/p\u003e\r\n\u003ch2 id=\"building-a-classifier-using-scikit-learn\"\u003eBuilding a Classifier using Scikit-learn\u003c/h2\u003e\r\n\u003cp\u003eYou will be building a model on the iris flower dataset, which is a very famous classification set. It comprises the sepal length, sepal width, petal length, petal width, and type of flowers. There are three species or classes: setosa, versicolor, and virginia. You will build a model to classify the type of flower. The dataset is available in the scikit-learn library or you can download it from the UCI Machine Learning Repository.\u003c/p\u003e\r\n\u003cp\u003eStart by importing the datasets library from scikit-learn, and load the iris dataset with \u003ccode\u003eload_iris()\u003c/code\u003e.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e#Import scikit-learn dataset library\r\nfrom sklearn import datasets\r\n\r\n#Load dataset\r\niris = datasets.load_iris()\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eYou can print the target and feature names, to make sure you have the right dataset, as such:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# print the label species(setosa, versicolor,virginica)\r\nprint(iris.target_names)\r\n\r\n# print the names of the four features\r\nprint(iris.feature_names)\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e[\u0026#39;setosa\u0026#39; \u0026#39;versicolor\u0026#39; \u0026#39;virginica\u0026#39;]\r\n[\u0026#39;sepal length (cm)\u0026#39;, \u0026#39;sepal width (cm)\u0026#39;, \u0026#39;petal length (cm)\u0026#39;, \u0026#39;petal width (cm)\u0026#39;]\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eIt\u0026#39;s a good idea to always explore your data a bit, so you know what you\u0026#39;re working with. Here, you can see the first five rows of the dataset are printed, as well as the target variable for the whole dataset.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# print the iris data (top 5 records)\r\nprint(iris.data[0:5])\r\n\r\n# print the iris labels (0:setosa, 1:versicolor, 2:virginica)\r\nprint(iris.target)\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e[[ 5.1  3.5  1.4  0.2]\r\n [ 4.9  3.   1.4  0.2]\r\n [ 4.7  3.2  1.3  0.2]\r\n [ 4.6  3.1  1.5  0.2]\r\n [ 5.   3.6  1.4  0.2]]\r\n[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\r\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\r\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\r\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\r\n 2 2]\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eHere, you can create a DataFrame of the iris dataset the following way.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# Creating a DataFrame of given iris dataset.\r\nimport pandas as pd\r\ndata=pd.DataFrame({\r\n    \u0026#39;sepal length\u0026#39;:iris.data[:,0],\r\n    \u0026#39;sepal width\u0026#39;:iris.data[:,1],\r\n    \u0026#39;petal length\u0026#39;:iris.data[:,2],\r\n    \u0026#39;petal width\u0026#39;:iris.data[:,3],\r\n    \u0026#39;species\u0026#39;:iris.target\r\n})\r\ndata.head()\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cdiv\u003e\r\n\u003cstyle\u003e\r\n    .dataframe thead tr:only-child th {\r\n        text-align: right;\r\n    }\r\n\r\n    .dataframe thead th {\r\n        text-align: left;\r\n    }\r\n\r\n    .dataframe tbody tr th {\r\n        vertical-align: top;\r\n    }\r\n\u003c/style\u003e\r\n\u003ctable border=\"1\" class=\"dataframe\"\u003e\r\n  \u003cthead\u003e\r\n    \u003ctr style=\"text-align: right;\"\u003e\r\n      \u003cth\u003e\u003c/th\u003e\r\n      \u003cth\u003epetal length\u003c/th\u003e\r\n      \u003cth\u003epetal width\u003c/th\u003e\r\n      \u003cth\u003esepal length\u003c/th\u003e\r\n      \u003cth\u003esepal width\u003c/th\u003e\r\n      \u003cth\u003especies\u003c/th\u003e\r\n    \u003c/tr\u003e\r\n  \u003c/thead\u003e\r\n  \u003ctbody\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003e0\u003c/th\u003e\r\n      \u003ctd\u003e1.4\u003c/td\u003e\r\n      \u003ctd\u003e0.2\u003c/td\u003e\r\n      \u003ctd\u003e5.1\u003c/td\u003e\r\n      \u003ctd\u003e3.5\u003c/td\u003e\r\n      \u003ctd\u003e0\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003e1\u003c/th\u003e\r\n      \u003ctd\u003e1.4\u003c/td\u003e\r\n      \u003ctd\u003e0.2\u003c/td\u003e\r\n      \u003ctd\u003e4.9\u003c/td\u003e\r\n      \u003ctd\u003e3.0\u003c/td\u003e\r\n      \u003ctd\u003e0\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003e2\u003c/th\u003e\r\n      \u003ctd\u003e1.3\u003c/td\u003e\r\n      \u003ctd\u003e0.2\u003c/td\u003e\r\n      \u003ctd\u003e4.7\u003c/td\u003e\r\n      \u003ctd\u003e3.2\u003c/td\u003e\r\n      \u003ctd\u003e0\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003e3\u003c/th\u003e\r\n      \u003ctd\u003e1.5\u003c/td\u003e\r\n      \u003ctd\u003e0.2\u003c/td\u003e\r\n      \u003ctd\u003e4.6\u003c/td\u003e\r\n      \u003ctd\u003e3.1\u003c/td\u003e\r\n      \u003ctd\u003e0\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003e4\u003c/th\u003e\r\n      \u003ctd\u003e1.4\u003c/td\u003e\r\n      \u003ctd\u003e0.2\u003c/td\u003e\r\n      \u003ctd\u003e5.0\u003c/td\u003e\r\n      \u003ctd\u003e3.6\u003c/td\u003e\r\n      \u003ctd\u003e0\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n  \u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003c/div\u003e\r\n\r\n\r\n\r\n\u003cp\u003eFirst, you separate the columns into dependent and independent variables (or features and labels). Then you split those variables into a training and test set.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# Import train_test_split function\r\nfrom sklearn.model_selection import train_test_split\r\n\r\nX=data[[\u0026#39;sepal length\u0026#39;, \u0026#39;sepal width\u0026#39;, \u0026#39;petal length\u0026#39;, \u0026#39;petal width\u0026#39;]]  # Features\r\ny=data[\u0026#39;species\u0026#39;]  # Labels\r\n\r\n# Split dataset into training set and test set\r\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 70% training and 30% test\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eAfter splitting, you will train the model on the training set and perform predictions on the test set.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e#Import Random Forest Model\r\nfrom sklearn.ensemble import RandomForestClassifier\r\n\r\n#Create a Gaussian Classifier\r\nclf=RandomForestClassifier(n_estimators=100)\r\n\r\n#Train the model using the training sets y_pred=clf.predict(X_test)\r\nclf.fit(X_train,y_train)\r\n\r\ny_pred=clf.predict(X_test)\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eAfter training, check the accuracy using actual and predicted values.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e#Import scikit-learn metrics module for accuracy calculation\r\nfrom sklearn import metrics\r\n# Model Accuracy, how often is the classifier correct?\r\nprint(\u0026quot;Accuracy:\u0026quot;,metrics.accuracy_score(y_test, y_pred))\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e(\u0026#39;Accuracy:\u0026#39;, 0.93333333333333335)\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eYou can also make a prediction for a single item, for example:\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli\u003esepal length = 3\u003c/li\u003e\r\n\u003cli\u003esepal width = 5\u003c/li\u003e\r\n\u003cli\u003epetal length = 4\u003c/li\u003e\r\n\u003cli\u003epetal width = 2\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003eNow you can predict which type of flower it is.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003eclf.predict([[3, 5, 4, 2]])\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003earray([2])\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eHere, 2 indicates the flower type Virginica.\u003c/p\u003e\r\n\u003cp\u003e\u003ca id=\"findingfeatures\"\u003e\u003c/a\u003e\u003c/p\u003e\r\n\u003ch2 id=\"finding-important-features-in-scikit-learn\"\u003eFinding Important Features in Scikit-learn\u003c/h2\u003e\r\n\u003cp\u003eHere, you are finding important features or selecting features in the IRIS dataset. In scikit-learn, you can perform this task in the following steps:\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli\u003eFirst, you need to create a random forests model.\u003c/li\u003e\r\n\u003cli\u003eSecond, use the feature importance variable to see feature importance scores.\u003c/li\u003e\r\n\u003cli\u003eThird, visualize these scores using the seaborn library.\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003efrom sklearn.ensemble import RandomForestClassifier\r\n\r\n#Create a Gaussian Classifier\r\nclf=RandomForestClassifier(n_estimators=100)\r\n\r\n#Train the model using the training sets y_pred=clf.predict(X_test)\r\nclf.fit(X_train,y_train)\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003eRandomForestClassifier(bootstrap=True, class_weight=None, criterion=\u0026#39;gini\u0026#39;,\r\n            max_depth=None, max_features=\u0026#39;auto\u0026#39;, max_leaf_nodes=None,\r\n            min_impurity_decrease=0.0, min_impurity_split=None,\r\n            min_samples_leaf=1, min_samples_split=2,\r\n            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\r\n            oob_score=False, random_state=None, verbose=0,\r\n            warm_start=False)\r\n\u003c/code\u003e\u003c/pre\u003e\u003cpre\u003e\u003ccode class=\"lang-python\"\u003eimport pandas as pd\r\nfeature_imp = pd.Series(clf.feature_importances_,index=iris.feature_names).sort_values(ascending=False)\r\nfeature_imp\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003epetal width (cm)     0.458607\r\npetal length (cm)    0.413859\r\nsepal length (cm)    0.103600\r\nsepal width (cm)     0.023933\r\ndtype: float64\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eYou can also visualize the feature importance. Visualizations are easy to understand and interpretable.\u003c/p\u003e\r\n\u003cp\u003eFor visualization, you can use a combination of matplotlib and seaborn. Because seaborn is built on top of matplotlib, it offers a number of customized themes and provides additional plot types. Matplotlib is a superset of seaborn and both are equally important for good visualizations.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003eimport matplotlib.pyplot as plt\r\nimport seaborn as sns\r\n%matplotlib inline\r\n# Creating a bar plot\r\nsns.barplot(x=feature_imp, y=feature_imp.index)\r\n# Add labels to your graph\r\nplt.xlabel(\u0026#39;Feature Importance Score\u0026#39;)\r\nplt.ylabel(\u0026#39;Features\u0026#39;)\r\nplt.title(\u0026quot;Visualizing Important Features\u0026quot;)\r\nplt.legend()\r\nplt.show()\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1526467740/output_36_0_wi9scw.png\" /\u003e\u003c/p\u003e\r\n\u003ch2 id=\"generating-the-model-on-selected-features\"\u003eGenerating the Model on Selected Features\u003c/h2\u003e\r\n\u003cp\u003eHere, you can remove the \u0026quot;sepal width\u0026quot; feature because it has very low importance, and select the 3 remaining features.  \u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# Import train_test_split function\r\nfrom sklearn.cross_validation import train_test_split\r\n# Split dataset into features and labels\r\nX=data[[\u0026#39;petal length\u0026#39;, \u0026#39;petal width\u0026#39;,\u0026#39;sepal length\u0026#39;]]  # Removed feature \u0026quot;sepal length\u0026quot;\r\ny=data[\u0026#39;species\u0026#39;]                                       \r\n# Split dataset into training set and test set\r\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.70, random_state=5) # 70% training and 30% test\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eAfter spliting, you will generate a model on the selected training set features, perform predictions on the selected test set features, and compare actual and predicted values.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003efrom sklearn.ensemble import RandomForestClassifier\r\n\r\n#Create a Gaussian Classifier\r\nclf=RandomForestClassifier(n_estimators=100)\r\n\r\n#Train the model using the training sets y_pred=clf.predict(X_test)\r\nclf.fit(X_train,y_train)\r\n\r\n# prediction on test set\r\ny_pred=clf.predict(X_test)\r\n\r\n#Import scikit-learn metrics module for accuracy calculation\r\nfrom sklearn import metrics\r\n# Model Accuracy, how often is the classifier correct?\r\nprint(\u0026quot;Accuracy:\u0026quot;,metrics.accuracy_score(y_test, y_pred))\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e(\u0026#39;Accuracy:\u0026#39;, 0.95238095238095233)\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eYou can see that after removing the least important features (sepal length), the accuracy increased. This is because you removed misleading data and noise, resulting in an increased accuracy. A lesser amount of features also reduces the training time.\u003c/p\u003e\r\n\u003ch2 id=\"conclusion\"\u003eConclusion\u003c/h2\u003e\r\n\u003cp\u003eCongratulations, you have made it to the end of this tutorial!\u003c/p\u003e\r\n\u003cp\u003eIn this tutorial, you have learned what random forests is, how it works, finding important features, the comparison between random forests and decision trees, advantages and disadvantages. You have also learned model building, evaluation and finding important features in scikit-learn. B\u003c/p\u003e\r\n\u003cp\u003eIf you would like to learn more about machine learning, I recommend you take a look at our \u003ca href=\"https://www.datacamp.com/courses/supervised-learning-in-r-classification\"\u003eSupervised Learning in R: Classification\u003c/a\u003e course.\u003c/p\u003e\r\n","contentUrl":"https://www.datacamp.com/community/tutorials/random-forests-classifier-python","userContentUrl":null,"illustrationUrl":null,"seoTitle":"Random Forests Classifiers in Python","seoMetaDescription":"Learn about Random Forests and build your own model in Python, for both classification and regression.","seoKeyword":"Random Forests Classifier in Python","mustRead":false,"programmingLanguage":null,"submissionDate":"2018-05-16T10:38:11.915Z","publishDate":"2018-05-16T10:38:32.146Z","episode":null,"isLatest":null,"externalUrl":null,"transcriptUrl":null,"guests":[],"links":null,"isSpam":false,"xp":0,"flaggingUsers":[],"isDisabled":false,"connectedInternalContentId":null,"createdAt":"2018-05-16T10:38:11.909Z","updatedAt":"2018-05-16T10:53:28.912Z","upvoting":{"voteCount":16,"voted":false},"tags":["python"],"author":{"id":520621,"slug":"avinashnvln8","avatarUrlSquare":"https://assets.datacamp.com/users/avatars/000/520/621/square/10.jpg?1475318624","fullName":"Avinash Navlani","nameFromEmail":"avinashnvln8","isAdmin":false}},{"id":10002,"externalId":null,"type":"Tutorial","status":"published","authorId":"tommyjee","title":"Pandas Tutorial: Importing Data with read_csv()","slug":"pandas-read-csv","previewSlug":null,"description":"Importing data is the first step in any data science project. Learn why today's data scientists prefer pandas' read_csv() function to do this.","articles":[],"courses":[],"redirectSlug":null,"contentHtml":"\u003cscript src=\"https://cdn.datacamp.com/datacamp-light-latest.min.js\"\u003e\u003c/script\u003e\n\n\u003ch2 id=\"pandas-tutorial-importing-data-with-read_csv-\"\u003ePandas Tutorial: Importing Data with read_csv()\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eThe first step to any data science project is to import your data.\u003c/strong\u003e Often, you\u0026#39;ll work with data in Comma Separated Value (CSV) files and run into problems at the very start of your workflow. In this tutorial, you\u0026#39;ll see how you can use the \u003ccode\u003eread_csv()\u003c/code\u003e function from \u003ccode\u003epandas\u003c/code\u003e to deal with common problems when importing data and see why loading CSV files specifically with \u003ccode\u003epandas\u003c/code\u003e has become standard practice for working data scientists today.\u003c/p\u003e\n\u003ch3 id=\"the-filesystem\"\u003eThe filesystem\u003c/h3\u003e\n\u003cp\u003eBefore you can use \u003ccode\u003epandas\u003c/code\u003e to import your data, you need to know where your data is in your filesystem and what your current working directory is. You\u0026#39;ll see why this is important very soon, but let\u0026#39;s review some basic concepts:\u003c/p\u003e\n\u003cp\u003eEverything on the computer is stored in the filesystem. \u0026quot;Directories\u0026quot; is just another word for \u0026quot;folders\u0026quot;, and the \u0026quot;working directory\u0026quot; is simply the folder you\u0026#39;re currently in. The \u003ca href=\"https://www.datacamp.com/courses/introduction-to-shell-for-data-science\"\u003eIntroduction to Shell for Data Science\u003c/a\u003e course on DataCamp will give you a full, hands-on experience with its utility, but here are some basic Shell commands to navigate your way in the filesystem:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThe \u003ccode\u003els\u003c/code\u003e command lists all content in the current working directory.\u003c/li\u003e\n\u003cli\u003eThe \u003ccode\u003ecd\u003c/code\u003e command followed by:\u003cul\u003e\n\u003cli\u003ethe name of a sub-directory allows you to change your working directory to the sub-directory you specify.\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e..\u003c/code\u003e allows you to navigate back to the parent directory of your current working directory.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eThe \u003ccode\u003epwd\u003c/code\u003e command prints the path of your current working directory.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eIPython allows you to execute Shell commands directly from the IPython console via its magic commands. Here are the ones that correspond to the commands you saw above:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003e! ls\u003c/code\u003e in IPython is the same as \u003ccode\u003els\u003c/code\u003e in the command line.\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e%cd\u003c/code\u003e in IPython is the same as \u003ccode\u003ecd\u003c/code\u003e in the command line.\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e! pwd\u003c/code\u003e in IPython is the same as \u003ccode\u003epwd\u003c/code\u003e in the command line. The working directory is also printed after changing into it in IPython, which isn\u0026#39;t the case in the command line.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eIn your filesystem, there\u0026#39;s a file called \u003ccode\u003ecereal.csv\u003c/code\u003e that contains \u003ca href=\"https://www.kaggle.com/crawford/80-cereals\"\u003enutrition data on 80 cereals\u003c/a\u003e. Enter the magic commands one-by-one in the IPython Shell, and see if you can locate the dataset!\u003c/p\u003e\n\u003cdiv data-datacamp-exercise=\"\" data-height=\"300\" data-encoded=\"true\"\u003e\neyJsYW5ndWFnZSI6InB5dGhvbiIsInByZV9leGVyY2lzZV9jb2RlIjoiISBta2RpciBmb2xkZXIxXG4hIG1rZGlyIGZvbGRlcjJcbiEgbWtkaXIgZGF0YVxuaW1wb3J0IHBhbmRhcyBhcyBwZFxuY2VyZWFsID0gcGQucmVhZF9jc3YoXCJodHRwczovL2Fzc2V0cy5kYXRhY2FtcC5jb20vcHJvZHVjdGlvbi9yZXBvc2l0b3JpZXMvMjg3My9kYXRhc2V0cy85MDU5NDM0NjU4Y2VhZDdjZTE1OGZkN2U5OGEwZDkyOTQ4YWE5ODUzL2NlcmVhbC5jc3ZcIilcbmNlcmVhbC50b19jc3YoJ2NlcmVhbC5jc3YnKVxuISBtdiBjZXJlYWwuY3N2IGRhdGEiLCJzYW1wbGUiOiIjIExpc3QgY29udGVudHMgaW4gdGhlIGN1cnJlbnQgd29ya2luZyBkaXJlY3RvcnlcbiEgbHNcblxuIyBOYXZpZ2F0ZSBpbnRvIHRoZSBgZGF0YWAgc3ViLWRpcmVjdG9yeVxuJWNkIF9fX1xuXG4jIExpc3QgY29udGVudHMgb2YgYGRhdGFgXG4hIGxzXG5cbiMgUHJpbnQgbmV3IHdvcmtpbmcgZGlyZWN0b3J5XG4hIHB3ZCJ9\n\u003c/div\u003e\n\n\u003cp\u003eDid you find it in the \u003ccode\u003edata\u003c/code\u003e directory? Excellent work!\u003c/p\u003e\n\u003ch3 id=\"loading-your-data\"\u003eLoading your data\u003c/h3\u003e\n\u003cp\u003eNow that you know what your current working directory is and where the dataset is in your filesystem, you can specify the file path to it. You\u0026#39;re now ready to import the CSV file into Python using \u003ccode\u003eread_csv()\u003c/code\u003e from \u003ccode\u003epandas\u003c/code\u003e:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003eimport pandas as pd\ncereal_df = pd.read_csv(\u0026quot;/tmp/tmp07wuam09/data/cereal.csv\u0026quot;)\ncereal_df2 = pd.read_csv(\u0026quot;data/cereal.csv\u0026quot;)\n\n# Are they the same?\nprint(pd.DataFrame.equals(cereal_df, cereal_df2))\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode\u003eTrue\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eAs you can see in the code chunk above, the file path is the main argument to \u003ccode\u003eread_csv()\u003c/code\u003e and it was specified in two ways. You can use the full file path which is prefixed by a \u003ccode\u003e/\u003c/code\u003e and includes the working directory in the specification, or use the relative file path which doesn\u0026#39;t. The \u003ccode\u003eread_csv()\u003c/code\u003e function is smart enough to decipher whether it\u0026#39;s working with full or relative file paths and convert your flat file as a DataFrame without a problem. (\u003cstrong\u003eNote\u003c/strong\u003e: the environment for every DataCamp session is temporary, so the working directory you saw in the previous section may not be identical to the one you see in the code chunk above.)\u003c/p\u003e\n\u003cp\u003eContinue on and see how else \u003ccode\u003epandas\u003c/code\u003e makes importing CSV files easier. Let\u0026#39;s use some of the function\u0026#39;s customizable options, particularly for the way it deals with headers, incorrect data types, and missing data.\u003c/p\u003e\n\u003ch3 id=\"dealing-with-headers\"\u003eDealing with headers\u003c/h3\u003e\n\u003cp\u003eHeaders refer to the column names of your dataset. For some datasets you might encounter, the headers may be completely missing, partially missing, or they might exist, but you may want to rename them. How can you deal with such issues effectively with \u003ccode\u003epandas\u003c/code\u003e?\u003c/p\u003e\n\u003cp\u003eLet\u0026#39;s take a closer look at your data:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003edf = pd.read_csv(\u0026quot;data/cereal.csv\u0026quot;)\nprint(df.head(5))\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode\u003e                         X.1      X.2      X.3       X.4      X.5      X.6  \\\n0                       name      mfr     type  calories  protein      fat   \n1                  100% Bran        N        C        70        4        1   \n2          100% Natural Bran        Q  no info       120        3        5   \n3                   All-Bran  no info        C        70        4        1   \n4  All-Bran with Extra Fiber        K        C        50        4  no info   \n\n      X.7    X.8      X.9    X.10     X.11      X.12   X.13     X.14  X.15  \\\n0  sodium  fiber    carbo  sugars   potass  vitamins  shelf   weight  cups   \n1       .     10  no info       6      280        25      3        1  0.33   \n2      15      2        8       8      135         0      .        1     1   \n3     260      9        7       5  no info        25      3        1  0.33   \n4     140     14        8       0      330        25      3  no info   0.5   \n\n        X.16  \n0     rating  \n1  68.402973  \n2    no info  \n3  59.425505  \n4  93.704912\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eIt seems like more sensible columns names would be \u003ccode\u003ename\u003c/code\u003e, \u003ccode\u003emfr\u003c/code\u003e, ..., \u003ccode\u003erating\u003c/code\u003e, but they\u0026#39;re incorrectly imported as the first observation in the dataset! Let\u0026#39;s try to have these as the headers. The \u003ccode\u003eread_csv()\u003c/code\u003e function has an argument called \u003ccode\u003eskiprows\u003c/code\u003e that allows you to specify the number of lines to skip at the start of the file. In this case, you want to skip the first line, so let\u0026#39;s try importing your CSV file with \u003ccode\u003eskiprows\u003c/code\u003e set equal to 1:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003edf = pd.read_csv(\u0026quot;data/cereal.csv\u0026quot;, skiprows = 1)\nprint(df.head(5))\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode\u003e                        name      mfr     type  calories protein      fat  \\\n0                  100% Bran        N        C        70       4        1   \n1          100% Natural Bran        Q  no info       120       3        5   \n2                   All-Bran  no info        C        70       4        1   \n3  All-Bran with Extra Fiber        K        C        50       4  no info   \n4             Almond Delight        R        C       110       2        2   \n\n  sodium  fiber    carbo  sugars   potass vitamins shelf   weight  cups  \\\n0      .   10.0  no info       6      280       25     3        1  0.33   \n1     15    2.0        8       8      135        0     .        1  1.00   \n2    260    9.0        7       5  no info       25     3        1  0.33   \n3    140   14.0        8       0      330       25     3  no info  0.50   \n4    200    1.0       14       8       -1        .     3        1  0.75   \n\n      rating  \n0  68.402973  \n1    no info  \n2  59.425505  \n3  93.704912  \n4  34.384843\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eNice!\u003c/p\u003e\n\u003cp\u003eEven when you don\u0026#39;t specify the headers, the \u003ccode\u003eread_csv()\u003c/code\u003e function correctly infers that the first observation contains the headers for the dataset. Not only that, \u003ccode\u003eread_csv()\u003c/code\u003e can infer the data types for each column of your dataset as well. You can see below the \u003ccode\u003ecalories\u003c/code\u003e column is an integer column, whereas the \u003ccode\u003efiber\u003c/code\u003e column is a float column:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003eprint(df[\u0026#39;calories\u0026#39;].dtypes)\nprint(df[\u0026#39;fiber\u0026#39;].dtypes)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode\u003eint64\nfloat64\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"dealing-with-missing-values-and-incorrect-data-types\"\u003eDealing with missing values and incorrect data types\u003c/h3\u003e\n\u003cp\u003eIn \u003ccode\u003epandas\u003c/code\u003e, columns with a string value are stored as type \u003ccode\u003eobject\u003c/code\u003e by default. Because missing values in this dataset appear to be encoded as either \u003ccode\u003e\u0026#39;no info\u0026#39;\u003c/code\u003e or \u003ccode\u003e\u0026#39;.\u0026#39;\u003c/code\u003e, both string values, checking the data type for a column with missing values such as the \u003ccode\u003efat\u003c/code\u003e column, you can see that its data type isn\u0026#39;t ideal:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003eprint(df[\u0026#39;fat\u0026#39;].dtypes)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode\u003eobject\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eWhen the column\u0026#39;s data type is an \u003ccode\u003eobject\u003c/code\u003e, doing simple arithmetic results in unexpected results. This sort of behavior can be problematic when doing all sorts of tasksvisualizing distributions, finding outliers, training modelsbecause you expect Python to treat numbers as numbers.\u003c/p\u003e\n\u003cp\u003eRun the code below to see an example of this. Your dataset has been loaded as \u003ccode\u003edf\u003c/code\u003e.\u003c/p\u003e\n\u003cdiv data-datacamp-exercise=\"\" data-height=\"300\" data-encoded=\"true\"\u003e\neyJsYW5ndWFnZSI6InB5dGhvbiIsInByZV9leGVyY2lzZV9jb2RlIjoiaW1wb3J0IHBhbmRhcyBhcyBwZFxuZGYgPSBwZC5yZWFkX2NzdihcImh0dHBzOi8vYXNzZXRzLmRhdGFjYW1wLmNvbS9wcm9kdWN0aW9uL3JlcG9zaXRvcmllcy8yODczL2RhdGFzZXRzLzkwNTk0MzQ2NThjZWFkN2NlMTU4ZmQ3ZTk4YTBkOTI5NDhhYTk4NTMvY2VyZWFsLmNzdlwiLCBza2lwcm93cyA9IDEpIiwic2FtcGxlIjoiIyBQcmludCB0aGUgZmlyc3QgdmFsdWUgaW4gdGhlIGBmYXRgIGNvbHVtblxucHJpbnQoZGZbJ2ZhdCddWzBdKVxuXG4jIFByaW50IHRoZSBzZWNvbmQgdmFsdWUgaW4gdGhlIGBmYXRgIGNvbHVtblxucHJpbnQoZGZbJ2ZhdCddWzFdKVxuXG4jIFByaW50IHRoZSBzdW1cbnByaW50KGRmWydmYXQnXVswXSArIGRmWydmYXQnXVsxXSkifQ==\n\u003c/div\u003e\n\n\u003cp\u003eBut 1 + 5 is not 15!\u003c/p\u003e\n\u003cp\u003eIdeally, the \u003ccode\u003efat\u003c/code\u003e column should be treated as type \u003ccode\u003eint64\u003c/code\u003e or \u003ccode\u003efloat64\u003c/code\u003e, and missing data should be encoded as \u003ccode\u003eNaN\u003c/code\u003e so that you can apply statistics in a missing-value-friendly manner. Instead of parsing through each column and replacing \u003ccode\u003e\u0026#39;no info\u0026#39;\u003c/code\u003e and \u003ccode\u003e\u0026#39;.\u0026#39;\u003c/code\u003e with \u003ccode\u003eNaN\u003c/code\u003e values after the dataset is loaded, you can use the \u003ccode\u003ena_values\u003c/code\u003e argument to account for those before it\u0026#39;s loaded:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003edf = pd.read_csv(\u0026quot;data/cereal.csv\u0026quot;, skiprows = 1, na_values = [\u0026#39;no info\u0026#39;, \u0026#39;.\u0026#39;])\nprint(df.head(5))\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode\u003e                        name  mfr type  calories  protein  fat  sodium  fiber  \\\n0                  100% Bran    N    C        70      4.0  1.0     NaN   10.0   \n1          100% Natural Bran    Q  NaN       120      3.0  5.0    15.0    2.0   \n2                   All-Bran  NaN    C        70      4.0  1.0   260.0    9.0   \n3  All-Bran with Extra Fiber    K    C        50      4.0  NaN   140.0   14.0   \n4             Almond Delight    R    C       110      2.0  2.0   200.0    1.0   \n\n   carbo  sugars  potass  vitamins  shelf  weight  cups     rating  \n0    NaN       6   280.0      25.0    3.0     1.0  0.33  68.402973  \n1    8.0       8   135.0       0.0    NaN     1.0  1.00        NaN  \n2    7.0       5     NaN      25.0    3.0     1.0  0.33  59.425505  \n3    8.0       0   330.0      25.0    3.0     NaN  0.50  93.704912  \n4   14.0       8    -1.0       NaN    3.0     1.0  0.75  34.384843\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eNow try the same arithmetic you saw a moment ago:\u003c/p\u003e\n\u003cdiv data-datacamp-exercise=\"\" data-height=\"300\" data-encoded=\"true\"\u003e\neyJsYW5ndWFnZSI6InB5dGhvbiIsInByZV9leGVyY2lzZV9jb2RlIjoiaW1wb3J0IHBhbmRhcyBhcyBwZFxuZGYgPSBwZC5yZWFkX2NzdihcImh0dHBzOi8vYXNzZXRzLmRhdGFjYW1wLmNvbS9wcm9kdWN0aW9uL3JlcG9zaXRvcmllcy8yODczL2RhdGFzZXRzLzkwNTk0MzQ2NThjZWFkN2NlMTU4ZmQ3ZTk4YTBkOTI5NDhhYTk4NTMvY2VyZWFsLmNzdlwiLCBza2lwcm93cyA9IDEsIG5hX3ZhbHVlcyA9IFsnbm8gaW5mbycsICcuJ10pIiwic2FtcGxlIjoiIyBQcmludCB0aGUgZmlyc3QgdmFsdWUgaW4gdGhlIGBmYXRgIGNvbHVtblxucHJpbnQoZGZbJ2ZhdCddWzBdKVxuXG4jIFByaW50IHRoZSBzZWNvbmQgdmFsdWUgaW4gdGhlIGBmYXRgIGNvbHVtblxucHJpbnQoZGZbJ2ZhdCddWzFdKVxuXG4jIFByaW50IHRoZSBzdW1cbnByaW50KGRmWydmYXQnXVswXSArIGRmWydmYXQnXVsxXSkifQ==\n\u003c/div\u003e\n\n\u003cp\u003eAwesome. 1 + 5 is indeed 6. The values in the \u003ccode\u003efat\u003c/code\u003e column are now treated as numerics.\u003c/p\u003e\n\u003ch3 id=\"recap\"\u003eRecap\u003c/h3\u003e\n\u003cp\u003eNow that you have a better idea of what to watch out for when importing data, let\u0026#39;s recap. With a single line of code involving \u003ccode\u003eread_csv()\u003c/code\u003e from \u003ccode\u003epandas\u003c/code\u003e, you:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eLocated the CSV file you want to import from your filesystem.\u003c/li\u003e\n\u003cli\u003eCorrected the headers of your dataset.\u003c/li\u003e\n\u003cli\u003eDealt with missing values so that they\u0026#39;re encoded properly as \u003ccode\u003eNaN\u003c/code\u003es.\u003c/li\u003e\n\u003cli\u003eCorrected data types for every column in your dataset.\u003c/li\u003e\n\u003cli\u003eConverted a CSV file to a Pandas DataFrame (see why that\u0026#39;s important in \u003ca href=\"https://www.datacamp.com/community/tutorials/pandas-tutorial-dataframe-python\"\u003ethis Pandas tutorial\u003c/a\u003e).\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"final-thoughts\"\u003eFinal thoughts\u003c/h3\u003e\n\u003cp\u003eAlthough the CSV file is one of the most common formats for storing data, there are other file types that the modern-day data scientist must be familiar with. You now have a good sense of how useful \u003ccode\u003epandas\u003c/code\u003e is when importing the CSV file, and conveniently, \u003ccode\u003epandas\u003c/code\u003e offers other similar and equally handy functions to import Excel, SAS, and Stata files to name a few.\u003c/p\u003e\n\u003cp\u003eYet, due to the active community in open source software, there is constant activity in file formats and ways to import data. Lots of useful, high quality datasets are hosted on the web and accessed through APIs, for example. If you\u0026#39;re curious and want to know the state of the art, DataCamp\u0026#39;s \u003ca href=\"https://www.datacamp.com/courses/importing-data-in-python-part-1\"\u003eImporting Data in Python (Part 1)\u003c/a\u003e and \u003ca href=\"https://www.datacamp.com/courses/importing-data-in-python-part-2\"\u003eImporting Data in Python (Part 2)\u003c/a\u003e courses will teach you all the best practices.\u003c/p\u003e\n\u003cp\u003eHappy Learning!\u003c/p\u003e\n","contentUrl":"https://www.datacamp.com/community/tutorials/pandas-read-csv","userContentUrl":null,"illustrationUrl":null,"seoTitle":"Importing Data with Pandas' read_csv()","seoMetaDescription":"Importing Data is the first important step in any data science project. Learn how pandas' read_csv() function is perfect for this.","seoKeyword":"Pandas read_csv Tutorial","mustRead":false,"programmingLanguage":null,"submissionDate":"2018-05-09T21:05:03.663Z","publishDate":"2018-05-09T21:05:19.420Z","episode":null,"isLatest":null,"externalUrl":null,"transcriptUrl":null,"guests":[],"links":null,"isSpam":false,"xp":0,"flaggingUsers":[],"isDisabled":false,"connectedInternalContentId":null,"createdAt":"2018-05-09T21:05:03.661Z","updatedAt":"2018-05-21T09:17:11.179Z","upvoting":{"voteCount":28,"voted":false},"tags":["pandas","python"],"author":{"id":329323,"slug":"tommyjee","avatarUrlSquare":"https://assets.datacamp.com/users/avatars/000/329/323/square/tom.jpg?1465645479","fullName":"Tom Jeon","nameFromEmail":"tom","isAdmin":false}},{"id":9956,"externalId":null,"type":"Tutorial","status":"published","authorId":"stefanmhosein","title":"Demystifying Generative Adversarial Nets (GANs)","slug":"generative-adversarial-networks","previewSlug":null,"description":"Learn what Generative Adversarial Networks are without going into the details of the math and  code a simple GAN that can create digits!","articles":[],"courses":[],"redirectSlug":null,"contentHtml":"\u003cp\u003eIn this tutorial, you will learn what Generative Adversarial Networks (GANs) are without going into the details of the math. After, you will learn how to code a simple GAN which can create digits!\u003c/p\u003e\n\u003ch2 id=\"analogy\"\u003eAnalogy\u003c/h2\u003e\n\u003cp\u003eThe easiest way to understand what GANs are is through a simple analogy:\u003c/p\u003e\n\u003cp\u003eSuppose there is a shop which buys certain kinds of wine from customers which they will later resell.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1524648806/gan_real_ylxk5f.jpg\"/\u003e\u003c/p\u003e\n\u003cp\u003eHowever, there are nefarious customers who sell fake wine in order to get money. In this case, the shop owner has to be able to distinguish between the fake and authentic wines.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1524648806/gan_fake_mr7pd8.jpg\"/\u003e\u003c/p\u003e\n\u003cp\u003eYou can imagine that initially, the forger might make a lot of mistakes when trying to sell the fake wine and it will be easy for the shop owner to identify that the wine is not authentic. Because of these failures, the forger will keep on trying different techniques to simulate the authentic wines and some will eventually be successful. Now that the forger knows that certain techniques got past the shop owner\u0026#39;s checks, he can start to further improve the fake wines based on those techniques.\u003c/p\u003e\n\u003cp\u003eAt the same time, the shop owner would probably get some feedback from other shop owners or wine experts that some of the wines that she has are not original. This means that the shop owner would have to improve how she determines whether a wine is fake or authentic. The goal of the forger is to create wines that are indistinguishable from the authentic ones, and the goal of the shop owner is to accurately tell if a wine is real or not.\u003c/p\u003e\n\u003cp\u003eThis back-and-forth competition is the main idea behind GANs.\u003c/p\u003e\n\u003ch2 id=\"components-of-a-generative-adversarial-network\"\u003eComponents of a Generative Adversarial Network\u003c/h2\u003e\n\u003cp\u003eUsing the example above, we can come up with the architecture of a GAN.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1524648806/gan_network_eg_jcgooq.jpg\"/\u003e\u003c/p\u003e\n\u003cp\u003eThere are two major components within GANs: the generator and the discriminator. The shop owner in the example is known as a discriminator network and is usually a \u003ca href=\"https://www.datacamp.com/community/tutorials/convolutional-neural-networks-python\"\u003econvolutional neural network\u003c/a\u003e (since GANs are mainly used for image tasks) which assigns a probability that the image is real.\u003c/p\u003e\n\u003cp\u003eThe forger is known as the generative network, and is also typically a convolutional neural network (with \u003ca href=\"https://blog.openai.com/generative-models/\"\u003edeconvolution layers\u003c/a\u003e). This network takes some noise vector and outputs an image. When training the generative network, it learns which areas of the image to improve/change so that the discriminator would have a harder time differentiating its generated images from the real ones.\u003c/p\u003e\n\u003cp\u003eThe generative network keeps producing images that are closer in appearance to the real images while the discriminative network is trying to determine the differences between real and fake images. The ultimate goal is to have a generative network that can produce images which are indistinguishable from the real ones.\u003c/p\u003e\n\u003ch2 id=\"a-simple-generative-adversarial-network-with-keras\"\u003eA Simple Generative Adversarial Network with Keras\u003c/h2\u003e\n\u003cp\u003eNow that you understand what GANs are and the main components of them, we can now begin to code a very simple one. You will use \u003ccode\u003eKeras\u003c/code\u003e and if you are not familiar with this Python library you should read \u003ca href=\"https://www.datacamp.com/community/tutorials/deep-learning-python\"\u003ethis tutorial\u003c/a\u003e before you continue. This tutorial is based on the GAN developed \u003ca href=\"https://github.com/Zackory/Keras-MNIST-GAN/blob/master/mnist_gan.py\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eThe first thing you would need to do is install the following packages via \u003ccode\u003epip\u003c/code\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003ekeras\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ematplotlib\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003etensorflow\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003etqdm\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eYou will use \u003ccode\u003ematplotlib\u003c/code\u003e for plotting, \u003ccode\u003etensorflow\u003c/code\u003e as the Keras backend library and \u003ccode\u003etqdm\u003c/code\u003e to show a fancy progress bar for each epoch (iteration).\u003c/p\u003e\n\u003cp\u003eThe next step is to create a Python script. In this script, you will first need to import all the modules and functions you will use. An explanation of each will be given as they are used.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003eimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\n\n\nfrom keras.layers import Input\nfrom keras.models import Model, Sequential\nfrom keras.layers.core import Dense, Dropout\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.datasets import mnist\nfrom keras.optimizers import Adam\nfrom keras import initializers\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eYou now want to set some variables:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# Let Keras know that we are using tensorflow as our backend engine\nos.environ[\u0026quot;KERAS_BACKEND\u0026quot;] = \u0026quot;tensorflow\u0026quot;\n\n# To make sure that we can reproduce the experiment and get the same results\nnp.random.seed(10)\n\n# The dimension of our random noise vector.\nrandom_dim = 100\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eBefore you can start building the discriminator and generator, you should first gather and pre-process the data. You will use the popular MNIST dataset which has a set of images of single digits ranging from 0 to 9.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1524648807/MnistExamples_cuv7k6.png\"/\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003edef load_minst_data():\n    # load the data\n    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n    # normalize our inputs to be in the range[-1, 1]\n    x_train = (x_train.astype(np.float32) - 127.5)/127.5\n    # convert x_train with a shape of (60000, 28, 28) to (60000, 784) so we have\n    # 784 columns per row\n    x_train = x_train.reshape(60000, 784)\n    return (x_train, y_train, x_test, y_test)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eNote\u003c/strong\u003e that the \u003ccode\u003emnist.load_data()\u003c/code\u003e is part of Keras and allows you to easily import the MNIST dataset into your workspace.\u003c/p\u003e\n\u003cp\u003eNow, you can create your generator and discriminator networks. You will use the \u003ca href=\"https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/\"\u003eAdam optimizer\u003c/a\u003e for both networks. For both the generator and discriminator, you will create a neural network with three hidden layers with the activation function being the \u003ca href=\"https://www.quora.com/What-are-the-advantages-of-using-Leaky-Rectified-Linear-Units-Leaky-ReLU-over-normal-ReLU-in-deep-learning\"\u003eLeaky Relu\u003c/a\u003e. You should also add \u003ca href=\"https://medium.com/@amarbudhiraja/https-medium-com-amarbudhiraja-learning-less-to-learn-better-dropout-in-deep-machine-learning-74334da4bfc5\"\u003edropout layers\u003c/a\u003e for the discriminator to improve its robustness on unseen images.  \u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# You will use the Adam optimizer\ndef get_optimizer():\n    return Adam(lr=0.0002, beta_1=0.5)\n\ndef get_generator(optimizer):\n    generator = Sequential()\n    generator.add(Dense(256, input_dim=random_dim, kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n    generator.add(LeakyReLU(0.2))\n\n    generator.add(Dense(512))\n    generator.add(LeakyReLU(0.2))\n\n    generator.add(Dense(1024))\n    generator.add(LeakyReLU(0.2))\n\n    generator.add(Dense(784, activation=\u0026#39;tanh\u0026#39;))\n    generator.compile(loss=\u0026#39;binary_crossentropy\u0026#39;, optimizer=optimizer)\n    return generator\n\ndef get_discriminator(optimizer):\n    discriminator = Sequential()\n    discriminator.add(Dense(1024, input_dim=784, kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n    discriminator.add(LeakyReLU(0.2))\n    discriminator.add(Dropout(0.3))\n\n    discriminator.add(Dense(512))\n    discriminator.add(LeakyReLU(0.2))\n    discriminator.add(Dropout(0.3))\n\n    discriminator.add(Dense(256))\n    discriminator.add(LeakyReLU(0.2))\n    discriminator.add(Dropout(0.3))\n\n    discriminator.add(Dense(1, activation=\u0026#39;sigmoid\u0026#39;))\n    discriminator.compile(loss=\u0026#39;binary_crossentropy\u0026#39;, optimizer=optimizer)\n    return discriminator\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIt is finally time to bring the generator and discriminator together!\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003edef get_gan_network(discriminator, random_dim, generator, optimizer):\n    # We initially set trainable to False since we only want to train either the\n    # generator or discriminator at a time\n    discriminator.trainable = False\n    # gan input (noise) will be 100-dimensional vectors\n    gan_input = Input(shape=(random_dim,))\n    # the output of the generator (an image)\n    x = generator(gan_input)\n    # get the output of the discriminator (probability if the image is real or not)\n    gan_output = discriminator(x)\n    gan = Model(inputs=gan_input, outputs=gan_output)\n    gan.compile(loss=\u0026#39;binary_crossentropy\u0026#39;, optimizer=optimizer)\n    return gan\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eFor completeness, you can create a function which will save your generated images every 20 epochs. Since this is not at the core of this lesson, you do not need to fully understand the function.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# Create a wall of generated MNIST images\ndef plot_generated_images(epoch, generator, examples=100, dim=(10, 10), figsize=(10, 10)):\n    noise = np.random.normal(0, 1, size=[examples, random_dim])\n    generated_images = generator.predict(noise)\n    generated_images = generated_images.reshape(examples, 28, 28)\n\n    plt.figure(figsize=figsize)\n    for i in range(generated_images.shape[0]):\n        plt.subplot(dim[0], dim[1], i+1)\n        plt.imshow(generated_images[i], interpolation=\u0026#39;nearest\u0026#39;, cmap=\u0026#39;gray_r\u0026#39;)\n        plt.axis(\u0026#39;off\u0026#39;)\n    plt.tight_layout()\n    plt.savefig(\u0026#39;gan_generated_image_epoch_%d.png\u0026#39; % epoch)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eYou have now coded the majority of your network. All that remains is to train this network and take a look at the images that you created.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003edef train(epochs=1, batch_size=128):\n    # Get the training and testing data\n    x_train, y_train, x_test, y_test = load_minst_data()\n    # Split the training data into batches of size 128\n    batch_count = x_train.shape[0] / batch_size\n\n    # Build our GAN netowrk\n    adam = get_optimizer()\n    generator = get_generator(adam)\n    discriminator = get_discriminator(adam)\n    gan = get_gan_network(discriminator, random_dim, generator, adam)\n\n    for e in xrange(1, epochs+1):\n        print \u0026#39;-\u0026#39;*15, \u0026#39;Epoch %d\u0026#39; % e, \u0026#39;-\u0026#39;*15\n        for _ in tqdm(xrange(batch_count)):\n            # Get a random set of input noise and images\n            noise = np.random.normal(0, 1, size=[batch_size, random_dim])\n            image_batch = x_train[np.random.randint(0, x_train.shape[0], size=batch_size)]\n\n            # Generate fake MNIST images\n            generated_images = generator.predict(noise)\n            X = np.concatenate([image_batch, generated_images])\n\n            # Labels for generated and real data\n            y_dis = np.zeros(2*batch_size)\n            # One-sided label smoothing\n            y_dis[:batch_size] = 0.9\n\n            # Train discriminator\n            discriminator.trainable = True\n            discriminator.train_on_batch(X, y_dis)\n\n            # Train generator\n            noise = np.random.normal(0, 1, size=[batch_size, random_dim])\n            y_gen = np.ones(batch_size)\n            discriminator.trainable = False\n            gan.train_on_batch(noise, y_gen)\n\n        if e == 1 or e % 20 == 0:\n            plot_generated_images(e, generator)\n\nif __name__ == \u0026#39;__main__\u0026#39;:\n    train(400, 128)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eAfter training for 400 epochs, you can view the images that were generated. Looking at the images produced after the first epoch, you can see that it does not have any real structure, looking at the image after 40 epochs, the digits start to take shape and lastly, the images produced after 400 epochs show clear digits even though a couple are still unrecognizable.\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth style=\"text-align:center\"\u003eResults after 1 epoch\u003c/th\u003e\n\u003cth style=\"text-align:center\"\u003eResults after 40 epochs\u003c/th\u003e\n\u003cth style=\"text-align:center\"\u003eResults after 400 epochs\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd style=\"text-align:center\"\u003e!\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1524648806/gan_generated_image_epoch_1_umk4fy.png\"/\u003e\u003c/td\u003e\n\u003ctd style=\"text-align:center\"\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1524648806/gan_generated_image_epoch_40_bc030b.png\"/\u003e\u003c/td\u003e\n\u003ctd style=\"text-align:center\"\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1524648806/gan_generated_image_epoch_400_yaqm2q.png\"/\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003eThis code takes approximately 2 minutes per epoch on a CPU and that is the main reason this code was selected. You can experiment by using more epochs and by adding more (and different) layers to both the generator and discriminator. However, when using more complex and deep architectures the runtime will also increase if you are using only a CPU. However, do not let that stop you from experimenting!\u003c/p\u003e\n\u003ch2 id=\"conclusion\"\u003eConclusion\u003c/h2\u003e\n\u003cp\u003eCongrats, you\u0026#39;ve made it to the end of this tutorial, in which you learned the basics of Generative Adversarial Networks (GANs) in an intuitive way! Also, you implemented your first model with the help of the Keras library. If you want to know more about deep learning with Python, consider taking DataCamp\u0026#39;s \u003ca href=\"https://www.datacamp.com/courses/deep-learning-in-python\"\u003eDeep Learning in Python\u003c/a\u003e course.\u003c/p\u003e\n","contentUrl":"https://www.datacamp.com/community/tutorials/generative-adversarial-networks","userContentUrl":null,"illustrationUrl":null,"seoTitle":"Generative Adversarial Networks Tutorial","seoMetaDescription":"Learn what Generative Adversarial Networks are without going into the details of the math and  code a simple GAN that can create digits!","seoKeyword":"generative adversarial network","mustRead":false,"programmingLanguage":null,"submissionDate":"2018-04-25T09:37:32.487Z","publishDate":"2018-05-09T10:00:00.000Z","episode":null,"isLatest":null,"externalUrl":null,"transcriptUrl":null,"guests":[],"links":null,"isSpam":false,"xp":0,"flaggingUsers":[],"isDisabled":false,"connectedInternalContentId":null,"createdAt":"2018-04-25T09:37:32.486Z","updatedAt":"2018-05-09T22:47:17.951Z","upvoting":{"voteCount":26,"voted":false},"tags":["deep learning","neural networks","keras"],"author":{"id":2106167,"slug":"stefanmhosein","avatarUrlSquare":"https://assets.datacamp.com/users/avatars/002/106/167/square/IMG_1482.jpg?1525795589","fullName":"Stefan Hosein","nameFromEmail":"stefanmhosein","isAdmin":false}},{"id":9902,"externalId":null,"type":"Tutorial","status":"published","authorId":"kwonhyunkim","title":"Long to Wide Data in R","slug":"long-wide-data-R","previewSlug":null,"description":"Learn why you would transform your data from a long to a wide format and vice versa and explore how to do this in R with melt() and dcast()!","articles":[],"courses":[],"redirectSlug":null,"contentHtml":"\u003cp\u003eThere is a time when people need to convert data in the long format (you\r\ncall it \u0026quot;the long-form\u0026quot; and what it means will be clear later) to the\r\nwide format and the vice versa. The data in real life comes in all sorts\r\nof format, but most R functions are designed for one specific form. \u003c/p\u003e\r\n\u003cp\u003eFor instance, \u003ccode\u003elme4::lmer()\u003c/code\u003e for mixed linear modeling, \u003ccode\u003eggplot2::ggplot()\u003c/code\u003e\r\nfor visualization are deisgned for long-form. But there are other\r\nfunctions designed for wide-form such as \u003ccode\u003emosaicplot()\u003c/code\u003e. That means that you need to convert the form to do analysis or visualization unless the data is\r\nalready processed and in the right form. \u003c/p\u003e\r\n\u003cp\u003eThere are several options in R for format coversion but it can become quite confusing when you\u0026#39;re just starting out.\u003c/p\u003e\r\n\u003cp\u003eThis tutorial will show you how to understand the mechanics of\r\nconverting the data between the long-form and the wide-form. You\u0026#39;ll\r\nexplore the following topics: \u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli\u003eYou\u0026#39;ll learn more about the long form. \u003c/li\u003e\r\n\u003cli\u003eThen, you\u0026#39;ll get to know the wide form. \u003c/li\u003e\r\n\u003cli\u003eYou\u0026#39;ll recap the differences between the long and wide formats; \u003c/li\u003e\r\n\u003cli\u003eAfter which you\u0026#39;ll see which steps you\u0026#39;d need to undertake to go from one form to another. \u003c/li\u003e\r\n\u003cli\u003eLastly, you\u0026#39;ll implement all of this with the help of R. You\u0026#39;ll learn how to go from a long format to a wide format with the \u003ccode\u003emelt()\u003c/code\u003e and \u003ccode\u003edcast()\u003c/code\u003e functions.\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003ch2 id=\"the-data\"\u003eThe Data\u003c/h2\u003e\r\n\u003ctable class=\"table table-hover\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\"\u003e\r\n\u003ccaption\u003e\r\nTable 01\r\n\u003c/caption\u003e\r\n\u003cthead\u003e\r\n\u003ctr\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nname\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\ngender\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:right;\"\u003e\r\nyear2011\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:right;\"\u003e\r\nyear2012\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:right;\"\u003e\r\nyear2013\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:right;\"\u003e\r\nyear2014\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:right;\"\u003e\r\nyear2015\r\n\u003c/th\u003e\r\n\u003c/tr\u003e\r\n\u003c/thead\u003e\r\n\u003ctbody\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nJackson Smith\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n74.69\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n84.99\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n91.73\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n105.11\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n111.04\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nSophia Johnson\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n75.89\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n75.74\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n86.50\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n91.50\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nAiden Jones\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n71.89\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n81.42\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nLiam Brown\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n88.24\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n96.91\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n101.85\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n108.13\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n112.45\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nLucas Davis\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n70.60\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n83.78\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n94.17\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n100.03\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n106.35\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nOlivia Miller\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n64.78\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n80.76\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n87.30\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n97.13\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n103.80\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nAva Wilson\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n88.77\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n96.45\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n104.72\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n112.84\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003cp\u003eThis table shows the height of babies in a small local area. The heights\r\nwere measured from the year 2011 to the year 2015. As you might already\r\nknow, \u003ccode\u003eNA\u003c/code\u003e means Not Available. From the position of NAs, you can\r\nfigure out the babies ages, but the exact age of a baby is not\r\navailable from the table.\r\n\r\nThe table looks well-organized, but for anyone who wants to study the\r\ngrowth of babies, there is a problem: the important information is not\r\nthe absolute time at which a baby is measured but the age of a baby when\r\nhe or she was measured.\r\n\r\nCould you insert this information into the table? Below, you can see one\r\nway:\u003c/p\u003e\r\n\r\n\u003ctable class=\"table table-hover\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\"\u003e\r\n\u003ccaption\u003e\r\nTable 02\r\n\u003c/caption\u003e\r\n\u003cthead\u003e\r\n\u003ctr\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nname\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\ngender\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:right;\"\u003e\r\nage0\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:right;\"\u003e\r\nage1\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:right;\"\u003e\r\nage2\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:right;\"\u003e\r\nage3\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:right;\"\u003e\r\nage4\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:right;\"\u003e\r\nage5\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:right;\"\u003e\r\nage6\r\n\u003c/th\u003e\r\n\u003c/tr\u003e\r\n\u003c/thead\u003e\r\n\u003ctbody\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nJackson Smith\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n76.69\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n84.91\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n97.06\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n105.73\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n107.32\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nSophia Johnson\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n76.05\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n72.65\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n82.46\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n91.76\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nAiden Jones\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n69.76\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n79.89\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nLiam Brown\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n85.34\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n93.22\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n105.78\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n105.84\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n114.82\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nLucas Davis\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n71.59\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n84.87\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n92.10\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n100.73\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n104.21\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nOlivia Miller\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n62.74\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n81.39\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n92.02\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n98.32\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n106.44\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nAva Wilson\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n88.39\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n100.67\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n107.58\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n111.52\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003cp\u003eThe number of \u003ccode\u003eNA\u003c/code\u003e\u0026#39;s has increased.\r\n\r\n## Wide Form Data\r\n\r\nBut what would you do if you wanted to convey how many months a baby was\r\nold? It would be something like this:\u003c/p\u003e\r\n\r\n\u003ctable class=\"table table-hover\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\"\u003e\r\n\u003ccaption\u003e\r\nTable 03\r\n\u003c/caption\u003e\r\n\u003cthead\u003e\r\n\u003ctr\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nname\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\ngender\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:right;\"\u003e\r\nm4\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:right;\"\u003e\r\nm6\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:right;\"\u003e\r\nm7\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:right;\"\u003e\r\nm10\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:right;\"\u003e\r\nm12\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\n...\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:right;\"\u003e\r\nm55\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:right;\"\u003e\r\nm60\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:right;\"\u003e\r\nm65\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:right;\"\u003e\r\nm72\r\n\u003c/th\u003e\r\n\u003c/tr\u003e\r\n\u003c/thead\u003e\r\n\u003ctbody\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nJackson Smith\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n76.69\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n...\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n107.32\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nSophia Johnson\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n76.05\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n...\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n72.65\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n...\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nAiden Jones\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n69.76\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n...\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nLiam Brown\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n...\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n105.84\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n114.82\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nLucas Davis\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n71.59\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n...\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n104.21\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nOlivia Miller\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n62.74\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n...\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nAva Wilson\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n...\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n111.52\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003cp\u003eThere are tons of \u003ccode\u003eNA\u003c/code\u003es in the table above. If the babies differ in\r\ntheir relative measurement times, the wide form can waste a lot of\r\nspace.\r\n\r\nAnother option is to include the ages of the babies when it was the year\r\n2015, but that is only possible when the absolute measurement times are\r\nall the same. If the babies differ in their measurement time by months\r\nand you want to know the ages in months, it does not work. Then this\r\nexample seems to be the only way.\r\n\r\nIn this case, you can consider using long-form.\r\n\r\n## Data in Long Form\r\n\r\nWhereas all measurements from one baby were shown in one row in\r\nwide-form, you\u0026#39;ll only see one measurement from a baby in one row in\r\nlong-form. The simplest way to obtain the latter would be displaying a\r\nchild\u0026#39;s name, the measurement time, and the measurement (height) in one\r\nrow. This is exactly what this table shows:\u003c/p\u003e\r\n\r\n\u003ctable class=\"table table-hover\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\"\u003e\r\n\u003ccaption\u003e\r\nTable 04\r\n\u003c/caption\u003e\r\n\u003cthead\u003e\r\n\u003ctr\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nname\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\ngender\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nmonth\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nheight\r\n\u003c/th\u003e\r\n\u003c/tr\u003e\r\n\u003c/thead\u003e\r\n\u003ctbody\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nOlivia Miller\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n4\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n62.74\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nAiden Jones\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n6\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n69.76\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nLucas Davis\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n7\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n71.59\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n10\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n72.65\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nJackson Smith\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n12\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n76.69\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n...\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n...\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n...\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n...\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nLiam Brown\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n72\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n114.82\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003cp\u003eIf you arrange the data sorting the names, you\u0026#39;d get something like the\r\ntable you see below. Obviously, this table occupies smaller space than\r\nTable 3, which you can see above!\u003c/p\u003e\r\n\r\n\u003ctable class=\"table table-hover\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\"\u003e\r\n\u003ccaption\u003e\r\nTable 05\r\n\u003c/caption\u003e\r\n\u003cthead\u003e\r\n\u003ctr\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nname\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\ngender\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nmonth\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nheight\r\n\u003c/th\u003e\r\n\u003c/tr\u003e\r\n\u003c/thead\u003e\r\n\u003ctbody\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nJackson Smith\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n12\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n76.69\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nJackson Smith\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n24\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n84.91\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nJackson Smith\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n36\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n97.06\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nJackson Smith\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n48\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n105.73\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nJackson Smith\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n60\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n107.32\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nSophia Johnson\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n12\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n76.05\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n10\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n72.65\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n...\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n...\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n...\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n...\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nAva Wilson\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n65\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n111.52\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\r\n\u003ch2 id=\"long-versus-wide\"\u003eLong versus Wide\u003c/h2\u003e\r\n\u003cp\u003e\u003cstrong\u003eNote\u003c/strong\u003e again what the fundamental differences are between the\r\nwide-form and the long-form: one simple difference is that the wide-form\r\ndisplays many measurements from one individual in one row and the column\r\nnames show what the measurements are.\u003c/p\u003e\r\n\u003cp\u003eThis table shows Liam Browns heights in the year 2011-2015 in one row:\u003c/p\u003e\r\n\u003ctable class=\"table table-hover\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\"\u003e\r\n\u003ccaption\u003e\r\nTable 06\r\n\u003c/caption\u003e\r\n\u003cthead\u003e\r\n\u003ctr\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nname\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\ngender\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:right;\"\u003e\r\nyear2011\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:right;\"\u003e\r\nyear2012\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:right;\"\u003e\r\nyear2013\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:right;\"\u003e\r\nyear2014\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:right;\"\u003e\r\nyear2015\r\n\u003c/th\u003e\r\n\u003c/tr\u003e\r\n\u003c/thead\u003e\r\n\u003ctbody\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nLiam Brown\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n88.24\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n96.91\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n101.85\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n108.13\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n112.45\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003c/tbody\u003e\r\n\u003c/table\u003e\r\nIn long-form Liam Brown\u0026#39;s heights are shown in one column:\r\n\r\n\u003ctable class=\"table table-hover\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\"\u003e\r\n\u003ccaption\u003e\r\nTable 07\r\n\u003c/caption\u003e\r\n\u003cthead\u003e\r\n\u003ctr\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nname\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\ngender\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:right;\"\u003e\r\n_\r\n\u003c/th\u003e\r\n\u003c/tr\u003e\r\n\u003c/thead\u003e\r\n\u003ctbody\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nLiam Brown\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n85.34\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nLiam Brown\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n93.22\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nLiam Brown\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n105.78\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nLiam Brown\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n105.84\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nLiam Brown\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n114.82\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003c/tbody\u003e\r\n\u003c/table\u003e\r\nAs you can see, you can not know what the measurements are. If you write\r\ndown the column name, it would look like this:\r\n\r\n\u003ctable class=\"table table-hover\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\"\u003e\r\n\u003ccaption\u003e\r\nTable 08\r\n\u003c/caption\u003e\r\n\u003cthead\u003e\r\n\u003ctr\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nname\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\ngender\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:right;\"\u003e\r\nyear2011, 2012, 2013, 2014, 2015\r\n\u003c/th\u003e\r\n\u003c/tr\u003e\r\n\u003c/thead\u003e\r\n\u003ctbody\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nLiam Brown\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n85.34\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nLiam Brown\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n93.22\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nLiam Brown\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n105.78\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nLiam Brown\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n105.84\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nLiam Brown\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n114.82\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003c/tbody\u003e\r\n\u003c/table\u003e\r\nBut this one has its own problem. Sophia Johnsons height was not\r\nmeasured in the year 2011-2014. So as you can see below, the column name\r\ncannot be set easily:\r\n\r\n\u003ctable class=\"table table-hover\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\"\u003e\r\n\u003ccaption\u003e\r\nTable 09\r\n\u003c/caption\u003e\r\n\u003cthead\u003e\r\n\u003ctr\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nname\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\ngender\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:right;\"\u003e\r\n?\r\n\u003c/th\u003e\r\n\u003c/tr\u003e\r\n\u003c/thead\u003e\r\n\u003ctbody\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nLiam Brown\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n85.34\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nLiam Brown\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n93.22\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nLiam Brown\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n105.78\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nLiam Brown\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n105.84\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nLiam Brown\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n114.82\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nSophia Johnson\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n76.05\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\r\n\u003ch2 id=\"from-wide-form-to-long-form\"\u003eFrom Wide-Form to Long-Form\u003c/h2\u003e\r\n\u003cp\u003eConverting the wide-form into the long-form can be thought of as a\r\nstep-by-step process. Before converting the measurements in one row into\r\none column, you can make the table in such a way that it contains only\r\none measurement in each row. Let\u0026#39;s do that for this table:\u003c/p\u003e\r\n\u003ctable class=\"table table-hover\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\"\u003e\u003c/p\u003e\r\n\u003ccaption\u003e\r\nTable 10\r\n\u003c/caption\u003e\r\n\u003cthead\u003e\r\n\u003ctr\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nname\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\ngender\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nage0\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nage1\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nage2\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nage3\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nage4\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nage5\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nage6\r\n\u003c/th\u003e\r\n\u003c/tr\u003e\r\n\u003c/thead\u003e\r\n\u003ctbody\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: silver;\"\u003e72.65\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: silver;\"\u003e82.46\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: silver;\"\u003e91.76\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nAiden Jones\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: silver;\"\u003e69.76\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: silver;\"\u003e79.89\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003cp\u003eThe result is like the table below:\u003c/p\u003e\r\n\u003ctable class=\"table table-hover\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\"\u003e\u003c/p\u003e\r\n\u003ccaption\u003e\r\nTable 11\r\n\u003c/caption\u003e\r\n\u003cthead\u003e\r\n\u003ctr\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nname\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\ngender\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nage0\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nage1\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nage2\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nage3\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nage4\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nage5\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nage6\r\n\u003c/th\u003e\r\n\u003c/tr\u003e\r\n\u003c/thead\u003e\r\n\u003ctbody\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: silver;\"\u003e72.65\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: silver;\"\u003e82.46\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: silver;\"\u003e91.76\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nAiden Jones\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: silver;\"\u003e69.76\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nAiden Jones\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: silver;\"\u003e79.89\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003cp\u003eBefore gathering those measurements scattered through columns into one\r\ncolumn, you need to make an additional column that says what the\r\nmeasurements are, just like below:\u003c/p\u003e\r\n\u003ctable class=\"table table-hover\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\"\u003e\r\n\u003ccaption\u003e\r\nTable 12\r\n\u003c/caption\u003e\r\n\u003cthead\u003e\r\n\u003ctr\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nname\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\ngender\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nmeasure\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nage0\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nage1\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nage2\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nage3\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nage4\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nage5\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nage6\r\n\u003c/th\u003e\r\n\u003c/tr\u003e\r\n\u003c/thead\u003e\r\n\u003ctbody\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;font-weight: bold;\"\u003e\r\nage0\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: silver;\"\u003e72.65\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;font-weight: bold;\"\u003e\r\nage1\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: silver;\"\u003e82.46\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;font-weight: bold;\"\u003e\r\nage2\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: silver;\"\u003e91.76\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nAiden Jones\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;font-weight: bold;\"\u003e\r\nage0\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: silver;\"\u003e69.76\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nAiden Jones\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;font-weight: bold;\"\u003e\r\nage1\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: silver;\"\u003e79.89\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003cp\u003eThe column name is usually either \u003ccode\u003emeasure\u003c/code\u003e or \u003ccode\u003ekey\u003c/code\u003e. You can notice\r\nin the above table that there are \u003ccode\u003eage0\u003c/code\u003e, \u003ccode\u003eage1\u003c/code\u003e, \u003ccode\u003eage2\u003c/code\u003e,\r\n\u003ccode\u003eage3\u003c/code\u003e, \u003ccode\u003eage4\u003c/code\u003e, \u003ccode\u003eage5\u003c/code\u003e in both column names and one column. If you\r\nomit the column names, the table will be like below.\u003c/p\u003e\r\n\u003ctable class=\"table table-hover\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\"\u003e\r\n\u003ccaption\u003e\r\nTable 13\r\n\u003c/caption\u003e\r\n\u003cthead\u003e\r\n\u003ctr\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nname\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\ngender\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nmeasure\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\n_\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\n__\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\n___\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\n____\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\n_____\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\n______\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\n_______\r\n\u003c/th\u003e\r\n\u003c/tr\u003e\r\n\u003c/thead\u003e\r\n\u003ctbody\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nage0\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n72.65\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nage1\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n82.46\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nage2\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n91.76\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nAiden Jones\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nage0\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n69.76\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nAiden Jones\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nage1\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n79.89\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003cp\u003eSince there is only one measurement in each row, you can gather them in\r\none column and the result will be the following:\u003c/p\u003e\r\n\u003ctable class=\"table\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\"\u003e\r\n\u003ccaption\u003e\r\nTable 14\r\n\u003c/caption\u003e\r\n\u003cthead\u003e\r\n\u003ctr\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nname\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\ngender\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nmeasure\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:right;\"\u003e\r\n\u003c/th\u003e\r\n\u003c/tr\u003e\r\n\u003c/thead\u003e\r\n\u003ctbody\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nage0\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;color: black;background-color: silver;\"\u003e\r\n72.65\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nage1\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;color: black;background-color: silver;\"\u003e\r\n82.46\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nage2\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;color: black;background-color: silver;\"\u003e\r\n91.76\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nAiden Jones\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nage0\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;color: black;background-color: silver;\"\u003e\r\n69.76\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nAiden Jones\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nage1\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;color: black;background-color: silver;\"\u003e\r\n79.89\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003cp\u003eLet\u0026#39;s make new column name for all the measurements. Usually, it is\r\nnamed as \u0026quot;value\u0026quot;:\u003c/p\u003e\r\n\u003ctable class=\"table\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\"\u003e\r\n\u003ccaption\u003e\r\nTable 15\r\n\u003c/caption\u003e\r\n\u003cthead\u003e\r\n\u003ctr\u003e\r\n\u003cth style=\"text-align:left;font-weight: bold;\"\u003e\r\nname\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;font-weight: bold;\"\u003e\r\ngender\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;font-weight: bold;\"\u003e\r\nmeasure\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:right;font-weight: bold;\"\u003e\r\nvalue\r\n\u003c/th\u003e\r\n\u003c/tr\u003e\r\n\u003c/thead\u003e\r\n\u003ctbody\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nage0\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n72.65\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nage1\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n82.46\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nage2\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n91.76\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nAiden Jones\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nage0\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n69.76\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nAiden Jones\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nage1\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n79.89\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003cp\u003eLet\u0026#39;s look at the above table. Do you notice that \u0026quot;age\u0026quot; is repeating?\r\nYou can omit repeating entity, which will give you the following result:\u003c/p\u003e\r\n\u003ctable class=\"table\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\"\u003e\r\n\u003ccaption\u003e\r\nTable 16\r\n\u003c/caption\u003e\r\n\u003cthead\u003e\r\n\u003ctr\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nname\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\ngender\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:right;\"\u003e\r\nage\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:right;\"\u003e\r\nvalue\r\n\u003c/th\u003e\r\n\u003c/tr\u003e\r\n\u003c/thead\u003e\r\n\u003ctbody\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;color: black;background-color: silver;\"\u003e\r\n0\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n72.65\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;color: black;background-color: silver;\"\u003e\r\n1\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n82.46\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;color: black;background-color: silver;\"\u003e\r\n2\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n91.76\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nAiden Jones\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;color: black;background-color: silver;\"\u003e\r\n0\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n69.76\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nAiden Jones\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;color: black;background-color: silver;\"\u003e\r\n1\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n79.89\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003cp\u003e\r\n\u003ccode\u003eAge\u003c/code\u003e, which is repeating in every row is now a column name. Column name\r\n\u003ccode\u003evalue\u003c/code\u003e in the table above can be more specific. You replaced it with\r\n\u003ccode\u003eheight\u003c/code\u003e, which is more revealing. You can see the result in the table\r\nbelow:\u003c/p\u003e\r\n\u003ctable class=\"table\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\"\u003e\r\n\u003ccaption\u003e\r\nTable 17\r\n\u003c/caption\u003e\r\n\u003cthead\u003e\r\n\u003ctr\u003e\r\n\u003cth style=\"text-align:left;font-weight: bold;\"\u003e\r\nname\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;font-weight: bold;\"\u003e\r\ngender\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:right;font-weight: bold;\"\u003e\r\nage\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:right;font-weight: bold;\"\u003e\r\nheight\r\n\u003c/th\u003e\r\n\u003c/tr\u003e\r\n\u003c/thead\u003e\r\n\u003ctbody\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n0\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n72.65\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n1\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n82.46\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n2\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n91.76\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nAiden Jones\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n0\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n69.76\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nAiden Jones\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n1\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n79.89\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003cp\u003eLet\u0026#39;s compare Table 15 with Table 17. \u003ccode\u003evalue\u003c/code\u003e, one of the column names\r\nof Table 15, can mean anything, but \u003ccode\u003eheight\u003c/code\u003e of Table 17 has very\r\nspecific meaning: it can only designate the height whereas the value in\r\nTable 15 could be any value like height, weight, speed or color. Another\r\nway would be like the following:\u003c/p\u003e\r\n\u003ctable class=\"table\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\"\u003e\r\n\u003ccaption\u003e\r\nTable 18\r\n\u003c/caption\u003e\r\n\u003cthead\u003e\r\n\u003ctr\u003e\r\n\u003cth style=\"text-align:left;font-weight: bold;\"\u003e\r\nname\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;font-weight: bold;\"\u003e\r\ngender\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;font-weight: bold;\"\u003e\r\nmeasure\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:right;font-weight: bold;\"\u003e\r\nvalue\r\n\u003c/th\u003e\r\n\u003c/tr\u003e\r\n\u003c/thead\u003e\r\n\u003ctbody\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nheight.age0\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n72.65\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nheight.age1\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n82.46\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nheight.age2\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n91.76\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nAiden Jones\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nheight.age0\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n69.76\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nAiden Jones\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nheight.age1\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n79.89\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003cp\u003eLet\u0026#39;s consider the situation in which the measurements are diverse. If\r\nthe measurements are height, weight and BMI, it will be like table\r\nbelow. But in this case, the column \u003ccode\u003evalue\u003c/code\u003e has numerical values in the\r\ndifferent scale so it could be confusing reading them. In this table,\r\nheight was measured in centimeter, and weight in kilogram:\u003c/p\u003e\r\n\u003ctable class=\"table\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\"\u003e\r\n\u003ccaption\u003e\r\nTable 19\r\n\u003c/caption\u003e\r\n\u003cthead\u003e\r\n\u003ctr\u003e\r\n\u003cth style=\"text-align:left;font-weight: bold;\"\u003e\r\nname\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;font-weight: bold;\"\u003e\r\ngender\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;font-weight: bold;\"\u003e\r\nmeasure\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:right;font-weight: bold;\"\u003e\r\nvalue\r\n\u003c/th\u003e\r\n\u003c/tr\u003e\r\n\u003c/thead\u003e\r\n\u003ctbody\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nheight\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n72.65\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nweight\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n8.22\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nBMI\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n22.60\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nAiden Jones\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nheight\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n69.76\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nAiden Jones\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nweight\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n8.51\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003cp\u003eSo when converting the wide-form into the long-form, one needs to decide\r\nwhich values will be gathered into one column. After that, you can\r\ndecide the column name.\u003c/p\u003e\r\n\u003cp\u003eLet\u0026#39;s summarize what is been said so far: to convert the wide-from into\r\nthe long-form one need to decide which columns to modify that they are\r\nin one column. In doing so, many columns are being combined into one\r\ncolumn. So you need a column name for that column, which you can see in\r\nthe next tables:\u003c/p\u003e\r\n\u003ctable class=\"table\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\"\u003e\r\n\u003ccaption\u003e\r\nTable 20\r\n\u003c/caption\u003e\r\n\u003cthead\u003e\r\n\u003ctr\u003e\r\n\u003cth style=\"text-align:left;font-weight: bold;\"\u003e\r\nid1\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;font-weight: bold;\"\u003e\r\nid2\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:right;font-weight: bold;\"\u003e\r\nage0\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:right;font-weight: bold;\"\u003e\r\nage1\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:right;font-weight: bold;\"\u003e\r\nage2\r\n\u003c/th\u003e\r\n\u003c/tr\u003e\r\n\u003c/thead\u003e\r\n\u003ctbody\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;color: black;background-color: silver;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;color: black;background-color: silver;\"\u003e\r\n82.46\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;color: black;background-color: silver;\"\u003e\r\n91.76\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nAiden Jones\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;color: black;background-color: silver;\"\u003e\r\n69.76\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;color: black;background-color: silver;\"\u003e\r\n79.89\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;color: black;background-color: silver;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;color: black;background-color: silver;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;color: black;background-color: silver;\"\u003e\r\n82.46\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;color: black;background-color: silver;\"\u003e\r\n91.76\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003ctable class=\"table table-hover\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\"\u003e\r\n\u003ccaption\u003e\r\nTable 21\r\n\u003c/caption\u003e\r\n\u003cthead\u003e\r\n\u003ctr\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nid1\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nid2\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nage0\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nage1\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nage2\r\n\u003c/th\u003e\r\n\u003c/tr\u003e\r\n\u003c/thead\u003e\r\n\u003ctbody\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: silver;\"\u003eNA\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: silver;\"\u003e82.46\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: silver;\"\u003e91.76\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nAiden Jones\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: silver;\"\u003e69.76\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nAiden Jones\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: silver;\"\u003e79.89\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nAiden Jones\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: silver;\"\u003eNA\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: silver;\"\u003eNA\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: silver;\"\u003e82.46\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: silver;\"\u003e91.76\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003ctable class=\"table table-hover\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\"\u003e\r\n\u003ccaption\u003e\r\nTable 22\r\n\u003c/caption\u003e\r\n\u003cthead\u003e\r\n\u003ctr\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nid1\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nid2\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nage_\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nage0\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nage1\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nage2\r\n\u003c/th\u003e\r\n\u003c/tr\u003e\r\n\u003c/thead\u003e\r\n\u003ctbody\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: cadetblue;\"\u003eage0\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: silver;\"\u003eNA\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: orange;\"\u003eage1\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: silver;\"\u003e82.46\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: greenyellow;\"\u003eage2\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: silver;\"\u003e91.76\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nAiden Jones\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: cadetblue;\"\u003eage0\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: silver;\"\u003e69.76\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nAiden Jones\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: orange;\"\u003eage1\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: silver;\"\u003e79.89\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nAiden Jones\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: greenyellow;\"\u003eage2\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: silver;\"\u003eNA\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: cadetblue;\"\u003eage0\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: silver;\"\u003eNA\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: orange;\"\u003eage1\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: silver;\"\u003e82.46\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: greenyellow;\"\u003eage2\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: silver;\"\u003e91.76\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003ctable class=\"table table-hover\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\"\u003e\r\n\u003ccaption\u003e\r\nTable 23\r\n\u003c/caption\u003e\r\n\u003cthead\u003e\r\n\u003ctr\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nid1\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nid2\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nage_\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:right;\"\u003e\r\n\u003c/th\u003e\r\n\u003c/tr\u003e\r\n\u003c/thead\u003e\r\n\u003ctbody\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: cadetblue;\"\u003eage0\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: orange;\"\u003eage1\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n82.46\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: greenyellow;\"\u003eage2\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n91.76\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nAiden Jones\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: cadetblue;\"\u003eage0\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n69.76\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nAiden Jones\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: orange;\"\u003eage1\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n79.89\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nAiden Jones\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: greenyellow;\"\u003eage2\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: cadetblue;\"\u003eage0\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: orange;\"\u003eage1\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n82.46\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: greenyellow;\"\u003eage2\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n91.76\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003ctable class=\"table table-hover\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\"\u003e\r\n\u003ccaption\u003e\r\nTable 24\r\n\u003c/caption\u003e\r\n\u003cthead\u003e\r\n\u003ctr\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nid1\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nid2\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nkey\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:right;\"\u003e\r\nvalue\r\n\u003c/th\u003e\r\n\u003c/tr\u003e\r\n\u003c/thead\u003e\r\n\u003ctbody\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: cadetblue;\"\u003eage0\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: orange;\"\u003eage1\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n82.46\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: greenyellow;\"\u003eage2\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n91.76\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nAiden Jones\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: cadetblue;\"\u003eage0\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n69.76\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nAiden Jones\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: orange;\"\u003eage1\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n79.89\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nAiden Jones\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: greenyellow;\"\u003eage2\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: cadetblue;\"\u003eage0\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: orange;\"\u003eage1\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n82.46\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: greenyellow;\"\u003eage2\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n91.76\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003ctable class=\"table table-hover\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\"\u003e\r\n\u003ccaption\u003e\r\nTable 25\r\n\u003c/caption\u003e\r\n\u003cthead\u003e\r\n\u003ctr\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nid1\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nid2\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nkey\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:right;\"\u003e\r\nvalue\r\n\u003c/th\u003e\r\n\u003c/tr\u003e\r\n\u003c/thead\u003e\r\n\u003ctbody\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: orange;\"\u003eage1\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n82.46\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: greenyellow;\"\u003eage2\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n91.76\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nAiden Jones\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: cadetblue;\"\u003eage0\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n69.76\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nAiden Jones\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: orange;\"\u003eage1\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n79.89\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: orange;\"\u003eage1\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n82.46\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: greenyellow;\"\u003eage2\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n91.76\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003c/tbody\u003e\r\n\u003c/table\u003e\r\nLet\u0026#39;s look at the columns \u003ccode\u003eid1\u003c/code\u003e and \u003ccode\u003eid2\u003c/code\u003e in the above table. \u003ccode\u003eid2\u003c/code\u003e does\r\nnot specify an individual but it is the attribute(gender) of an\r\nindividual. In other words, you can say it is a measurement. So you can\r\nconvert it into the longer-form. The longest-form is made up of three\r\ncolumns, which are \u003ccode\u003eid\u003c/code\u003e, \u003ccode\u003ekey\u003c/code\u003e and \u003ccode\u003evalue\u003c/code\u003e.\u003c/p\u003e\r\n\u003ctable class=\"table table-hover\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\"\u003e\r\n\u003ccaption\u003e\r\nTable 26\r\n\u003c/caption\u003e\r\n\u003cthead\u003e\r\n\u003ctr\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nid\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nkey\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nvalue\r\n\u003c/th\u003e\r\n\u003c/tr\u003e\r\n\u003c/thead\u003e\r\n\u003ctbody\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: brown;\"\u003egender\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: orange;\"\u003eage1\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n82.46\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: greenyellow;\"\u003eage2\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n91.76\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nAiden Jones\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: brown;\"\u003egender\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nAiden Jones\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: cadetblue;\"\u003eage0\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n69.76\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nAiden Jones\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: orange;\"\u003eage1\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n79.89\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: brown;\"\u003egender\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: orange;\"\u003eage1\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n82.46\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: greenyellow;\"\u003eage2\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n91.76\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003cp\u003eThe above table shows the longest-form from table 25. But different\r\npeople can have the same name.\u003c/p\u003e\r\n\u003cp\u003eIn that case, long-form can be confusing since \u003ccode\u003eid\u003c/code\u003e can not specify one\r\nperson. You can put a number behind the name to ditinguish people(for\r\nexample, using R function \u003ccode\u003emake.unique()\u003c/code\u003e), but you can not\r\ndifferentiate the name that is altered and the original name with a\r\nnumber. Think of a person whose name is \u0026quot;John.2\u0026quot; for real!.\u003c/p\u003e\r\n\u003cp\u003eThe obvious way around this is to assign a different number ID for a\r\ndifferent person. In that case, names are another measurements.\u003c/p\u003e\r\n\u003cp\u003eThe next table shows that even the names are considered as measurements.\r\nIn a sense, this is the true longest-form.\u003c/p\u003e\r\n\u003ctable class=\"table table-hover\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\"\u003e\r\n\u003ccaption\u003e\r\nTable 27\r\n\u003c/caption\u003e\r\n\u003cthead\u003e\r\n\u003ctr\u003e\r\n\u003cth style=\"text-align:right;\"\u003e\r\nid\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nkey\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nvalue\r\n\u003c/th\u003e\r\n\u003c/tr\u003e\r\n\u003c/thead\u003e\r\n\u003ctbody\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n1\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: darksalmon;\"\u003ename\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n1\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: brown;\"\u003egender\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n1\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: orange;\"\u003eage1\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n82.46\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n1\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: greenyellow;\"\u003eage2\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n91.76\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n2\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: darksalmon;\"\u003ename\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nAiden Jones\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n2\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: brown;\"\u003egender\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n2\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: cadetblue;\"\u003eage0\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n69.76\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n2\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: orange;\"\u003eage1\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n79.89\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n3\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: darksalmon;\"\u003ename\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n3\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: brown;\"\u003egender\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n3\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: orange;\"\u003eage1\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n82.46\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n3\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: greenyellow;\"\u003eage2\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n91.76\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003cp\u003eThe longest-form is the easiest form for making a wide-form. If you\r\nreverse the process of converting the wide-form into the long-form,\r\nwhich is shown in tables 20 to 25, you get to the wide-form. The next\r\ntables below show this process:\u003c/p\u003e\r\n\u003ctable class=\"table table-hover\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\"\u003e\r\n\u003ccaption\u003e\r\nTable 28. Measurements in \u003cstrong\u003ekey\u003c/strong\u003e column are repeated on the column name\r\n\u003c/caption\u003e\r\n\u003cthead\u003e\r\n\u003ctr\u003e\r\n\u003cth style=\"text-align:right;\"\u003e\r\nid\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nkey\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nname\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\ngender\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nage0\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nage1\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nage2\r\n\u003c/th\u003e\r\n\u003c/tr\u003e\r\n\u003c/thead\u003e\r\n\u003ctbody\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n1\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: darksalmon;\"\u003ename\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n1\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: brown;\"\u003egender\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n1\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: orange;\"\u003eage1\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n82.46\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n1\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: greenyellow;\"\u003eage2\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n91.76\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n2\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: darksalmon;\"\u003ename\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nAiden Jones\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n2\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: brown;\"\u003egender\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n2\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: cadetblue;\"\u003eage0\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n69.76\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n2\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: orange;\"\u003eage1\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n79.89\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n3\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: darksalmon;\"\u003ename\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n3\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: brown;\"\u003egender\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n3\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: orange;\"\u003eage1\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n82.46\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n3\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003cspan\r\nstyle=\"     color: black;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: greenyellow;\"\u003eage2\u003c/span\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n91.76\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003ctable class=\"table table-hover\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\"\u003e\r\n\u003ccaption\u003e\r\nTable 29. \u003cstrong\u003ekey\u003c/strong\u003e column can be erased\r\n\u003c/caption\u003e\r\n\u003cthead\u003e\r\n\u003ctr\u003e\r\n\u003cth style=\"text-align:right;\"\u003e\r\nid\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nname\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\ngender\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nage0\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nage1\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nage2\r\n\u003c/th\u003e\r\n\u003c/tr\u003e\r\n\u003c/thead\u003e\r\n\u003ctbody\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n1\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n1\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n1\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n82.46\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n1\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n91.76\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n2\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nAiden Jones\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n2\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n2\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n69.76\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n2\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n79.89\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n3\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n3\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n3\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n82.46\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n3\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n91.76\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003ctable class=\"table table-hover\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\"\u003e\r\n\u003ccaption\u003e\r\nTable 30. The same \u003cstrong\u003eid\u003c/strong\u003e can be gathered into one row\r\n\u003c/caption\u003e\r\n\u003cthead\u003e\r\n\u003ctr\u003e\r\n\u003cth style=\"text-align:right;\"\u003e\r\nid\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nname\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\ngender\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nage0\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nage1\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nage2\r\n\u003c/th\u003e\r\n\u003c/tr\u003e\r\n\u003c/thead\u003e\r\n\u003ctbody\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n1\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n82.46\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n91.76\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n1\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n1\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n1\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n2\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nAiden Jones\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n69.76\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n79.89\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n2\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n2\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n2\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n3\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n82.46\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n91.76\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n3\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n3\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n3\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003ctable class=\"table table-hover\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\"\u003e\r\n\u003ccaption\u003e\r\nTable 31. Delete any row that has no measurements\r\n\u003c/caption\u003e\r\n\u003cthead\u003e\r\n\u003ctr\u003e\r\n\u003cth style=\"text-align:right;\"\u003e\r\nid\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nname\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\ngender\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nage0\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:right;\"\u003e\r\nage1\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nage2\r\n\u003c/th\u003e\r\n\u003c/tr\u003e\r\n\u003c/thead\u003e\r\n\u003ctbody\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n1\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n82.46\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n91.76\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n2\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nAiden Jones\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n69.76\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n79.89\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n3\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n82.46\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\n91.76\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003cp\u003eThe key factor in converting the wide-form into the long-form is\r\ndeciding which columns will be gathered into one column.\u003c/p\u003e\r\n\u003cp\u003eBut it does not have to be just one column. You could use two columns if\r\nthat is necessary, just like in the table below:\u003c/p\u003e\r\n\u003ctable class=\"table table-hover\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\"\u003e\r\n\u003ccaption\u003e\r\nTable 32\r\n\u003c/caption\u003e\r\n\u003cthead\u003e\r\n\u003ctr\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nname\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\ngender\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:right;\"\u003e\r\nh2011\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:right;\"\u003e\r\nh2012\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:right;\"\u003e\r\nw2011\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:right;\"\u003e\r\nw2012\r\n\u003c/th\u003e\r\n\u003c/tr\u003e\r\n\u003c/thead\u003e\r\n\u003ctbody\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nJackson Smith\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n74.69\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n84.99\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n9.60\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n12.0\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nOlivia Miller\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n80.76\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n7.15\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n10.7\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nAva Wilson\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n88.77\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n96.45\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n15.0\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003cp\u003eCan you make it into the long-form?\u003c/p\u003e\r\n\u003cp\u003eColumns \u003ccode\u003eh2011\u003c/code\u003e, \u003ccode\u003eh2012\u003c/code\u003e, \u003ccode\u003ew2011\u003c/code\u003e, \u003ccode\u003ew2012\u003c/code\u003e mean heights and weights in\r\nthe year 2011 and 2012. \u003ccode\u003eheight\u003c/code\u003e and \u003ccode\u003eweight\u003c/code\u003e are measured in the\r\ndifferent scales - cm, kg. So you can use only one column for both\r\nheight and weight or you can use two columns, just like in this table:\u003c/p\u003e\r\n\u003ctable class=\"table table-hover\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\"\u003e\r\n\u003ccaption\u003e\r\nTable 33\r\n\u003c/caption\u003e\r\n\u003cthead\u003e\r\n\u003ctr\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nname\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\ngender\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:right;\"\u003e\r\nyear\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:right;\"\u003e\r\nheight\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:right;\"\u003e\r\nweight\r\n\u003c/th\u003e\r\n\u003c/tr\u003e\r\n\u003c/thead\u003e\r\n\u003ctbody\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nJackson Smith\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n2011\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n74.69\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n9.60\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nJackson Smith\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n2012\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n84.99\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n12.00\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nOlivia Miller\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n2011\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n80.76\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nOlivia Miller\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n2012\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n7.15\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n10.70\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nAva Wilson\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n2011\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n88.77\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n96.45\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nAva Wilson\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n2012\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n15.00\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003cp\u003eIs this the long-form or the wide-form?\u003c/p\u003e\r\n\u003ch2 id=\"from-long-to-wide-data-in-r\"\u003eFrom Long to Wide Data in R\u003c/h2\u003e\r\n\u003cp\u003eLet\u0026#39;s do the coversion between the long-form and the wide-form with R.\r\nThere are many functions and packages available for this task.\u003c/p\u003e\r\n\u003ctable class=\"table table-hover\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\"\u003e\r\n\u003ccaption\u003e\r\nTable 34\r\n\u003c/caption\u003e\r\n\u003cthead\u003e\r\n\u003ctr\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nfunc\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\npackage\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nto_long_form\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nto_wide_form\r\n\u003c/th\u003e\r\n\u003c/tr\u003e\r\n\u003c/thead\u003e\r\n\u003ctbody\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;font-weight: bold;\"\u003e\r\nstack/unstack\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nutils\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nstack\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nunstack\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;font-weight: bold;\"\u003e\r\nreshape\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nstats\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nreshape(direction=\u0026quot;long\u0026quot;, ...)\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nreshape(direction=\u0026quot;wide\u0026quot;, ...)\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;font-weight: bold;\"\u003e\r\nmelt/dcast\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nreshape2\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nmelt\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\ndcast\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;font-weight: bold;\"\u003e\r\ngather/spread\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\ntidyr\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\ngather\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nspread\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003cp\u003eHere I will explain how to use the \u003ccode\u003emelt()\u003c/code\u003e and \u003ccode\u003edcast()\u003c/code\u003e functions of\r\nthe \u003ccode\u003ereshape2\u003c/code\u003e package. The reason is that \u003ccode\u003estack()\u003c/code\u003e and \u003ccode\u003eunstack()\u003c/code\u003e are\r\nbasic functions so one needs post-processing the result from them. Note\r\nthat the \u003ccode\u003egather()\u003c/code\u003e and \u003ccode\u003espread()\u003c/code\u003e are \u003ccode\u003etidyr\u003c/code\u003e functions that are also\r\nvery popular, but that won\u0026#39;t be covered in this tutorial.\u003c/p\u003e\r\n\u003cp\u003eAnother function that you might be able to use is \u003ccode\u003ereshape()\u003c/code\u003e, which\r\ncomes with the \u003ccode\u003estats\u003c/code\u003e package. In fact, don\u0026#39;t be confused by this\r\nfunction, as there\u0026#39;s also a package called \u003ccode\u003ereshape\u003c/code\u003e! This package,\r\ntogether with \u003ccode\u003ereshape2\u003c/code\u003e, was developed for those who were struggling\r\nwith \u003ccode\u003ereshape()\u003c/code\u003e. In addition, the function \u003ccode\u003ereshape()\u003c/code\u003e seems to have an\r\nassumption that the data are longitudinal, which means measurements are\r\nrepeated through time.\u003c/p\u003e\r\n\u003cp\u003eLet\u0026#39;s convert the data in table 35 into the long-form. Assume that the\r\ntable below stores a \u003ccode\u003edata.frame\u003c/code\u003e called \u003ccode\u003edat\u003c/code\u003e.\u003c/p\u003e\r\n\u003ctable class=\"table table-hover\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\"\u003e\r\n\u003ccaption\u003e\r\nTable 35\r\n\u003c/caption\u003e\r\n\u003cthead\u003e\r\n\u003ctr\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\nname\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:left;\"\u003e\r\ngender\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:right;\"\u003e\r\nyear2011\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:right;\"\u003e\r\nyear2012\r\n\u003c/th\u003e\r\n\u003cth style=\"text-align:right;\"\u003e\r\nyear2013\r\n\u003c/th\u003e\r\n\u003c/tr\u003e\r\n\u003c/thead\u003e\r\n\u003ctbody\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nJackson Smith\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n74.69\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n84.99\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n91.73\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nEmma Williams\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n75.74\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nLiam Brown\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nM\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n88.24\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n101.85\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003ctr\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nAva Wilson\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:left;\"\u003e\r\nF\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n88.77\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\n96.45\r\n\u003c/td\u003e\r\n\u003ctd style=\"text-align:right;\"\u003e\r\nNA\r\n\u003c/td\u003e\r\n\u003c/tr\u003e\r\n\u003c/tbody\u003e\r\n\u003c/table\u003e\r\n    \u003cp\u003ebabies = data.frame(name= c(\u0026quot;Jackson Smith\u0026quot;, \u0026quot;Emma Williams\u0026quot;, \u0026quot;Liam Brown\u0026quot;, \u0026quot;Ava Wilson\u0026quot;),\r\n                     gender = c(\u0026quot;M\u0026quot;, \u0026quot;F\u0026quot;, \u0026quot;M\u0026quot;, \u0026quot;F\u0026quot;),\r\n                     year2011= c(74.69, NA, 88.24, 88.77),\r\n                     year2012=c(84.99, NA, NA, 96.45),\r\n                     year2013=c(91.73, 75.74, 101.83, NA))\r\n    babies\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003e##            name gender year2011 year2012 year2013\r\n## 1 Jackson Smith      M    74.69    84.99    91.73\r\n## 2 Emma Williams      F       NA       NA    75.74\r\n## 3    Liam Brown      M    88.24       NA   101.83\r\n## 4    Ava Wilson      F    88.77    96.45       NA\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eThe question that you want to ask is: \u0026quot;which columns to combine into one\r\ncolumn?\u0026quot;.\u003c/p\u003e\r\n\u003cp\u003eThose would be \u003ccode\u003eyear2011\u003c/code\u003e, \u003ccode\u003eyear2012\u003c/code\u003e, \u003ccode\u003eyear2013\u003c/code\u003e. When you use function\r\n\u003ccode\u003emelt()\u003c/code\u003e, those columns should be listed for \u003ccode\u003emeasure.vars\u003c/code\u003e:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003emelt(babies, measure.vars = c(\u0026quot;year2011\u0026quot;, \u0026quot;year2012\u0026quot;, \u0026quot;year2013\u0026quot;))\r\n\r\n##             name gender variable  value\r\n## 1  Jackson Smith      M year2011  74.69\r\n## 2  Emma Williams      F year2011     NA\r\n## 3     Liam Brown      M year2011  88.24\r\n## 4     Ava Wilson      F year2011  88.77\r\n## 5  Jackson Smith      M year2012  84.99\r\n## 6  Emma Williams      F year2012     NA\r\n## 7     Liam Brown      M year2012     NA\r\n## 8     Ava Wilson      F year2012  96.45\r\n## 9  Jackson Smith      M year2013  91.73\r\n## 10 Emma Williams      F year2013  75.74\r\n## 11    Liam Brown      M year2013 101.83\r\n## 12    Ava Wilson      F year2013     NA\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003ccode\u003eyear2011\u003c/code\u003e, \u003ccode\u003eyear2012\u003c/code\u003e, \u003ccode\u003eyear2013\u003c/code\u003e are the columns placed in 3rd, 4th,\r\n5th so you can use that:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003emelt(babies, measure.vars = 3:5)\r\n\r\n##             name gender variable  value\r\n## 1  Jackson Smith      M year2011  74.69\r\n## 2  Emma Williams      F year2011     NA\r\n## 3     Liam Brown      M year2011  88.24\r\n## 4     Ava Wilson      F year2011  88.77\r\n## 5  Jackson Smith      M year2012  84.99\r\n## 6  Emma Williams      F year2012     NA\r\n## 7     Liam Brown      M year2012     NA\r\n## 8     Ava Wilson      F year2012  96.45\r\n## 9  Jackson Smith      M year2013  91.73\r\n## 10 Emma Williams      F year2013  75.74\r\n## 11    Liam Brown      M year2013 101.83\r\n## 12    Ava Wilson      F year2013     NA\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eThe result is in the table above. Note the column names \u003ccode\u003evariable\u003c/code\u003e and\r\n\u003ccode\u003evalue\u003c/code\u003e. Table 23 and table 24 showed that the new column names are\r\nneeded. Function \u003ccode\u003emelt()\u003c/code\u003e has default names for new columns- \u003ccode\u003evariable\u003c/code\u003e\r\nand \u003ccode\u003evalue\u003c/code\u003e. You can override the default value by using\r\n\u003ccode\u003evariable.name=\u003c/code\u003e and \u003ccode\u003evalue.name=\u003c/code\u003e arguement. Let\u0026#39;s do this below:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003emelt(babies, measure.vars=3:5, variable.name=\u0026quot;year\u0026quot;, value.name=\u0026quot;height\u0026quot;)\r\n\r\n##             name gender     year height\r\n## 1  Jackson Smith      M year2011  74.69\r\n## 2  Emma Williams      F year2011     NA\r\n## 3     Liam Brown      M year2011  88.24\r\n## 4     Ava Wilson      F year2011  88.77\r\n## 5  Jackson Smith      M year2012  84.99\r\n## 6  Emma Williams      F year2012     NA\r\n## 7     Liam Brown      M year2012     NA\r\n## 8     Ava Wilson      F year2012  96.45\r\n## 9  Jackson Smith      M year2013  91.73\r\n## 10 Emma Williams      F year2013  75.74\r\n## 11    Liam Brown      M year2013 101.83\r\n## 12    Ava Wilson      F year2013     NA\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eMeasurements were specified in the examples above. For those settings\r\nyou are dealing with, \u003ccode\u003eId\u003c/code\u003e can indirectly specify the measurements. So\r\nyou can choose columns for id rather than measurements.\u003c/p\u003e\r\n\u003cp\u003eThe results are the same for the both below. The first one chooses\r\ncolumns for id, the second one chooses columns to be gathered:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003emelt(babies, id.vars=c(\u0026quot;name\u0026quot;,\u0026quot;gender\u0026quot;))\r\n\r\nmelt(babies, measure.vars = c(\u0026quot;year2011\u0026quot;, \u0026quot;year2012\u0026quot;, \u0026quot;year2013\u0026quot;))\r\n\r\n##             name gender variable  value\r\n## 1  Jackson Smith      M year2011  74.69\r\n## 2  Emma Williams      F year2011     NA\r\n## 3     Liam Brown      M year2011  88.24\r\n## 4     Ava Wilson      F year2011  88.77\r\n## 5  Jackson Smith      M year2012  84.99\r\n## 6  Emma Williams      F year2012     NA\r\n## 7     Liam Brown      M year2012     NA\r\n## 8     Ava Wilson      F year2012  96.45\r\n## 9  Jackson Smith      M year2013  91.73\r\n## 10 Emma Williams      F year2013  75.74\r\n## 11    Liam Brown      M year2013 101.83\r\n## 12    Ava Wilson      F year2013     NA\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eIf you specify both \u003ccode\u003eid.vars\u003c/code\u003e and \u003ccode\u003emeasure.vars\u003c/code\u003e, columns not included\r\nin any of them are excluded from the result. For example, look at the\r\ncode chunk below:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003emelt(babies, id.vars=c(\u0026quot;name\u0026quot;), measure.vars=c(\u0026quot;year2011\u0026quot;, \u0026quot;year2012\u0026quot;))\r\n\r\n##            name variable value\r\n## 1 Jackson Smith year2011 74.69\r\n## 2 Emma Williams year2011    NA\r\n## 3    Liam Brown year2011 88.24\r\n## 4    Ava Wilson year2011 88.77\r\n## 5 Jackson Smith year2012 84.99\r\n## 6 Emma Williams year2012    NA\r\n## 7    Liam Brown year2012    NA\r\n## 8    Ava Wilson year2012 96.45\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eIn addition, \u003ccode\u003ena.rm=T\u003c/code\u003e can eliminate NAs:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003emelt(babies, id.vars=c(\u0026quot;name\u0026quot;), measure.vars=c(\u0026quot;year2011\u0026quot;, \u0026quot;year2012\u0026quot;), na.rm=T)\r\n\r\n##            name variable value\r\n## 1 Jackson Smith year2011 74.69\r\n## 3    Liam Brown year2011 88.24\r\n## 4    Ava Wilson year2011 88.77\r\n## 5 Jackson Smith year2012 84.99\r\n## 8    Ava Wilson year2012 96.45\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eThe \u003ccode\u003edcast()\u003c/code\u003e function does the reverse of \u003ccode\u003emelt()\u003c/code\u003e. \u003ccode\u003eid\u003c/code\u003e, \u003ccode\u003evariable\u003c/code\u003e,\r\nand \u003ccode\u003evalue\u003c/code\u003e are the columns of the longest-form.\r\n\u003ccode\u003edcast(data, id ~ variable, value.var=\u0026quot;value\u0026quot;)\u003c/code\u003e takes the longest-form\r\ninto the wide-form.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003ebabiesLong \u0026lt;- melt(babies, id.vars=c(\u0026quot;name\u0026quot;), measure.vars=c(\u0026quot;year2011\u0026quot;, \u0026quot;year2012\u0026quot;), na.rm=T)\r\nbabiesLong\r\n\r\n##            name variable value\r\n## 1 Jackson Smith year2011 74.69\r\n## 3    Liam Brown year2011 88.24\r\n## 4    Ava Wilson year2011 88.77\r\n## 5 Jackson Smith year2012 84.99\r\n## 8    Ava Wilson year2012 96.45\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003ccode\u003ebabiesLong\u003c/code\u003e has name for \u003ccode\u003eid\u003c/code\u003e, variable for \u003ccode\u003evariable\u003c/code\u003e, and value for\r\n\u003ccode\u003evalue\u003c/code\u003e. So you can use \u003ccode\u003edcast()\u003c/code\u003e to make it into long-form:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003edcast(babiesLong, name ~ variable, value.var=\u0026quot;value\u0026quot;)\r\n\r\n##            name year2011 year2012\r\n## 1    Ava Wilson    88.77    96.45\r\n## 2 Jackson Smith    74.69    84.99\r\n## 3    Liam Brown    88.24       NA\r\n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"conclusion\"\u003eConclusion\u003c/h2\u003e\r\n\u003cp\u003eThat seems about it. In this tutorial, you focused on understanding the\r\nlogic and the process of reshaping data. Usually, long-form is preferred\r\nfor analysis but there are execptions. Data presenation in wide-form can\r\nsave space when it is appropriate but as the number of missing values\r\ngrow, you would better convert to the long-form.\u003c/p\u003e\r\n\u003cp\u003eFor format conversion, you need to focus on what are the measurements.\r\nThe motto for the long-form is one measurement per one row and the\r\nwide-form has many measurements in one row. When you make measurements\r\nthroughout columns gathered in one column, the original column names\r\nneed to be preserved in one additional column. When you make\r\nmeasurements in one column spreaded out throughout columns, you need to\r\nfigure out what the column names should be from \u003ccode\u003evariable\u003c/code\u003e column.\u003c/p\u003e\r\n\u003cp\u003eOnce you understand the process, using functions such as \u003ccode\u003edcast()\u003c/code\u003e and\r\n\u003ccode\u003emelt()\u003c/code\u003e becomes a lot easier!\u003c/p\u003e\r\n","contentUrl":"https://www.datacamp.com/community/tutorials/long-wide-data-R","userContentUrl":null,"illustrationUrl":null,"seoTitle":"Long to Wide Data in R","seoMetaDescription":"Discover why you would reshape your data from a long format to wide one and learn how to use the melt() and dcast() functions in R to do this!","seoKeyword":"long wide data R","mustRead":false,"programmingLanguage":null,"submissionDate":"2018-04-18T08:58:49.111Z","publishDate":"2018-05-08T10:00:00.000Z","episode":null,"isLatest":null,"externalUrl":null,"transcriptUrl":null,"guests":[],"links":null,"isSpam":false,"xp":0,"flaggingUsers":[],"isDisabled":false,"connectedInternalContentId":null,"createdAt":"2018-04-18T08:58:49.103Z","updatedAt":"2018-05-08T13:30:16.450Z","upvoting":{"voteCount":12,"voted":false},"tags":["r programming","data manipulation"],"author":{"id":2396450,"slug":"kwonhyunkim","avatarUrlSquare":"about/placeholder.svg","fullName":"Kim Kwonhyun","nameFromEmail":"kwonhyunkim","isAdmin":false}},{"id":9888,"externalId":null,"type":"Tutorial","status":"published","authorId":"thushv","title":"Stock Market Predictions with LSTM in Python","slug":"lstm-python-stock-market","previewSlug":null,"description":"Discover Long Short-Term Memory (LSTM) networks in Python and how you can use them to make stock market predictions!","articles":[],"courses":[],"redirectSlug":null,"contentHtml":"\u003cp\u003eIn this tutorial, you will see how you can use a time-series model known as Long Short-Term Memory. LSTM models are powerful, especially for retaining a long-term memory, by design, as you will see later. You\u0026#39;ll tackle the following topics in this tutorial:\u003c/p\u003e\r\n\u003cp\u003e\u003cnav\u003e\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli\u003eUnderstand \u003ca href=\"#why\"\u003ewhy\u003c/a\u003e would you need to be able to predict stock price movements;\u003c/li\u003e\r\n\u003cli\u003e\u003ca href=\"#download\"\u003eDownload\u003c/a\u003e the data - You will be using stock market data gathered from Yahoo finance;\u003c/li\u003e\r\n\u003cli\u003e\u003ca href=\"#split\"\u003eSplit train-test data\u003c/a\u003e and also perform some data normalization;\u003c/li\u003e\r\n\u003cli\u003eGo over and apply a few \u003ca href=\"#average\"\u003eaveraging techniques\u003c/a\u003e that can be used for one-step ahead predictions;\u003c/li\u003e\r\n\u003cli\u003eMotivate and briefly discuss an \u003ca href=\"#lstm\"\u003eLSTM model\u003c/a\u003e as it allows to predict more than one-step ahead; \u003c/li\u003e\r\n\u003cli\u003e\u003ca href=\"#predict\"\u003ePredict\u003c/a\u003e and visualize future stock market with current data\r\n\u003c/nav\u003e\r\n\u003cdiv id=\"scoped-content\"\u003e\u003cstyle type=\"text/css\"\u003e:target:before { content:\"\"; display:block; height:150px; margin:-150px 0 0; } h3 {font-weight:normal; margin-top:.5em} h4 { font-weight:lighter }\r\n\u003c/style\u003e\r\n\r\n\r\n\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003eIf you\u0026#39;re not familiar with deep learning or neural networks, you should take a look at our \u003ca href=\"https://www.datacamp.com/courses/deep-learning-in-python\"\u003eDeep Learning in Python course\u003c/a\u003e. It covers the basics, as well as how to build a neural network on your own in Keras. This is a different package than TensorFlow, which will be used in this tutorial, but the idea is the same.\u003c/p\u003e\r\n\u003cp\u003e\u003ca id=\"why\"\u003e\u003c/a\u003e\u003c/p\u003e\r\n\u003ch2 id=\"why-do-you-need-time-series-models-\"\u003eWhy Do You Need Time Series Models?\u003c/h2\u003e\r\n\u003cp\u003eYou would like to model stock prices correctly, so as a stock buyer you can reasonably decide when to buy stocks and when to sell them to make a profit. This is where time series modelling comes in. You need good machine learning models that can look at the history of a sequence of data and correctly predict what the future elements of the sequence are going to be.\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eWarning\u003c/strong\u003e: Stock market prices are highly unpredictable and volatile. This means that there are no consistent patterns in the data that allow you to model stock prices over time near-perfectly. Don\u0026#39;t take it from me, take it from Princeton University economist Burton Malkiel, who argues in his 1973 book, \u0026quot;A Random Walk Down Wall Street,\u0026quot; that if the market is truly efficient and a share price reflects all factors immediately as soon as they\u0026#39;re made public, a blindfolded monkey throwing darts at a newspaper stock listing should do as well as any investment professional.\u003c/p\u003e\r\n\u003cp\u003eHowever, let\u0026#39;s not go all the way believing that this is just a stochastic or random process and that there is no hope for machine learning. Let\u0026#39;s see if you can at least model the data, so that the predictions you make correlate with the actual behavior of the data. In other words, you don\u0026#39;t need the exact stock values of the future, but the stock price movements (that is, if it is going to rise of fall in the near future).\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# Make sure that you have all these libaries available to run the code successfully\r\nfrom pandas_datareader import data\r\nimport matplotlib.pyplot as plt\r\nimport pandas as pd\r\nimport datetime as dt\r\nimport urllib.request, json\r\nimport os\r\nimport numpy as np\r\nimport tensorflow as tf # This code has been tested with TensorFlow 1.6\r\nfrom sklearn.preprocessing import MinMaxScaler\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003e\u003ca id=\"download\"\u003e\u003c/a\u003e\u003c/p\u003e\r\n\u003ch2 id=\"downloading-the-data\"\u003eDownloading the Data\u003c/h2\u003e\r\n\u003cp\u003eYou will be using data from the following sources:\u003c/p\u003e\r\n\u003col\u003e\r\n\u003cli\u003e\u003cp\u003eAlpha Vantage. Before you start, however, you will first need an API key, which you can obtain for free \u003ca href=\"https://www.alphavantage.co/support/#api-key\"\u003ehere\u003c/a\u003e. After that, you can assign that key to the \u003ccode\u003eapi_key\u003c/code\u003e variable.\u003c/p\u003e\r\n\u003c/li\u003e\r\n\u003cli\u003e\u003cp\u003eUse the data from \u003ca href=\"https://www.kaggle.com/borismarjanovic/price-volume-data-for-all-us-stocks-etfs\"\u003ethis page\u003c/a\u003e. You will need to copy the \u003cem\u003eStocks\u003c/em\u003e folder in the zip file to your project home folder.\u003c/p\u003e\r\n\u003c/li\u003e\r\n\u003c/ol\u003e\r\n\u003cp\u003eStock prices come in several different flavours. They are,\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli\u003eOpen: Opening stock price of the day\u003c/li\u003e\r\n\u003cli\u003eClose: Closing stock price of the day\u003c/li\u003e\r\n\u003cli\u003eHigh: Highest stock price of the data\u003c/li\u003e\r\n\u003cli\u003eLow: Lowest stock price of the day\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003ch3 id=\"getting-data-from-alphavantage\"\u003eGetting Data from Alphavantage\u003c/h3\u003e\r\n\u003cp\u003eYou will first load in the data from Alpha Vantage. Since you\u0026#39;re going to make use of the American Airlines Stock market prices to make your predictions, you set the ticker to \u003ccode\u003e\u0026quot;AAL\u0026quot;\u003c/code\u003e. Additionally, you also define a \u003ccode\u003eurl_string\u003c/code\u003e, which will return a JSON file with all the stock market data for American Airlines within the last 20 years, and a \u003ccode\u003efile_to_save\u003c/code\u003e, which will be the file to which you save the data. You\u0026#39;ll use the \u003ccode\u003eticker\u003c/code\u003e variable that you defined beforehand to help name this file.\u003c/p\u003e\r\n\u003cp\u003eNext, you\u0026#39;re going to specify a condition: if you haven\u0026#39;t already saved data, you will go ahead and grab the data from the URL that you set in \u003ccode\u003eurl_string\u003c/code\u003e; You\u0026#39;ll store the date, low, high, volume, close, open values to a pandas DataFrame \u003ccode\u003edf\u003c/code\u003e and you\u0026#39;ll save it to \u003ccode\u003efile_to_save\u003c/code\u003e. However, if the data is already there, you\u0026#39;ll just load it from the CSV.\u003c/p\u003e\r\n\u003ch3 id=\"getting-data-from-kaggle\"\u003eGetting Data from Kaggle\u003c/h3\u003e\r\n\u003cp\u003eData found on Kaggle is a collection of csv files and you don\u0026#39;t have to do any preprocessing, so you can directly load the data into a Pandas DataFrame.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003edata_source = \u0026#39;kaggle\u0026#39; # alphavantage or kaggle\r\n\r\nif data_source == \u0026#39;alphavantage\u0026#39;:\r\n    # ====================== Loading Data from Alpha Vantage ==================================\r\n\r\n    api_key = \u0026#39;\u0026lt;your API key\u0026gt;\u0026#39;\r\n\r\n    # American Airlines stock market prices\r\n    ticker = \u0026quot;AAL\u0026quot;\r\n\r\n    # JSON file with all the stock market data for AAL from the last 20 years\r\n    url_string = \u0026quot;https://www.alphavantage.co/query?function=TIME_SERIES_DAILY\u0026amp;symbol=%s\u0026amp;outputsize=full\u0026amp;apikey=%s\u0026quot;%(ticker,api_key)\r\n\r\n    # Save data to this file\r\n    file_to_save = \u0026#39;stock_market_data-%s.csv\u0026#39;%ticker\r\n\r\n    # If you haven\u0026#39;t already saved data,\r\n    # Go ahead and grab the data from the url\r\n    # And store date, low, high, volume, close, open values to a Pandas DataFrame\r\n    if not os.path.exists(file_to_save):\r\n        with urllib.request.urlopen(url_string) as url:\r\n            data = json.loads(url.read().decode())\r\n            # extract stock market data\r\n            data = data[\u0026#39;Time Series (Daily)\u0026#39;]\r\n            df = pd.DataFrame(columns=[\u0026#39;Date\u0026#39;,\u0026#39;Low\u0026#39;,\u0026#39;High\u0026#39;,\u0026#39;Close\u0026#39;,\u0026#39;Open\u0026#39;])\r\n            for k,v in data.items():\r\n                date = dt.datetime.strptime(k, \u0026#39;%Y-%m-%d\u0026#39;)\r\n                data_row = [date.date(),float(v[\u0026#39;3. low\u0026#39;]),float(v[\u0026#39;2. high\u0026#39;]),\r\n                            float(v[\u0026#39;4. close\u0026#39;]),float(v[\u0026#39;1. open\u0026#39;])]\r\n                df.loc[-1,:] = data_row\r\n                df.index = df.index + 1\r\n        print(\u0026#39;Data saved to : %s\u0026#39;%file_to_save)        \r\n        df.to_csv(file_to_save)\r\n\r\n    # If the data is already there, just load it from the CSV\r\n    else:\r\n        print(\u0026#39;File already exists. Loading data from CSV\u0026#39;)\r\n        df = pd.read_csv(file_to_save)\r\n\r\nelse:\r\n\r\n    # ====================== Loading Data from Kaggle ==================================\r\n    # You will be using HP\u0026#39;s data. Feel free to experiment with other data.\r\n    # But while doing so, be careful to have a large enough dataset and also pay attention to the data normalization\r\n    df = pd.read_csv(os.path.join(\u0026#39;Stocks\u0026#39;,\u0026#39;hpq.us.txt\u0026#39;),delimiter=\u0026#39;,\u0026#39;,usecols=[\u0026#39;Date\u0026#39;,\u0026#39;Open\u0026#39;,\u0026#39;High\u0026#39;,\u0026#39;Low\u0026#39;,\u0026#39;Close\u0026#39;])\r\n    print(\u0026#39;Loaded data from the Kaggle repository\u0026#39;)\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003eData saved to : stock_market_data-AAL.csv\r\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"data-exploration\"\u003eData Exploration\u003c/h3\u003e\r\n\u003cp\u003eHere you will print the data you collected in to the DataFrame. You should also make sure that the data is sorted by date, because the order of the data is crucial in time series modelling.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# Sort DataFrame by date\r\ndf = df.sort_values(\u0026#39;Date\u0026#39;)\r\n\r\n# Double check the result\r\ndf.head()\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cdiv\u003e\r\n\u003cstyle scoped\u003e\r\n    .dataframe tbody tr th:only-of-type {\r\n        vertical-align: middle;\r\n    }\r\n\r\n    .dataframe tbody tr th {\r\n        vertical-align: top;\r\n    }\r\n\r\n    .dataframe thead th {\r\n        text-align: right;\r\n    }\r\n\u003c/style\u003e\r\n\u003ctable border=\"1\" class=\"dataframe\"\u003e\r\n  \u003cthead\u003e\r\n    \u003ctr style=\"text-align: right;\"\u003e\r\n      \u003cth\u003e\u003c/th\u003e\r\n      \u003cth\u003eDate\u003c/th\u003e\r\n      \u003cth\u003eOpen\u003c/th\u003e\r\n      \u003cth\u003eHigh\u003c/th\u003e\r\n      \u003cth\u003eLow\u003c/th\u003e\r\n      \u003cth\u003eClose\u003c/th\u003e\r\n    \u003c/tr\u003e\r\n  \u003c/thead\u003e\r\n  \u003ctbody\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003e0\u003c/th\u003e\r\n      \u003ctd\u003e1970-01-02\u003c/td\u003e\r\n      \u003ctd\u003e0.30627\u003c/td\u003e\r\n      \u003ctd\u003e0.30627\u003c/td\u003e\r\n      \u003ctd\u003e0.30627\u003c/td\u003e\r\n      \u003ctd\u003e0.30627\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003e1\u003c/th\u003e\r\n      \u003ctd\u003e1970-01-05\u003c/td\u003e\r\n      \u003ctd\u003e0.30627\u003c/td\u003e\r\n      \u003ctd\u003e0.31768\u003c/td\u003e\r\n      \u003ctd\u003e0.30627\u003c/td\u003e\r\n      \u003ctd\u003e0.31385\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003e2\u003c/th\u003e\r\n      \u003ctd\u003e1970-01-06\u003c/td\u003e\r\n      \u003ctd\u003e0.31385\u003c/td\u003e\r\n      \u003ctd\u003e0.31385\u003c/td\u003e\r\n      \u003ctd\u003e0.30996\u003c/td\u003e\r\n      \u003ctd\u003e0.30996\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003e3\u003c/th\u003e\r\n      \u003ctd\u003e1970-01-07\u003c/td\u003e\r\n      \u003ctd\u003e0.31385\u003c/td\u003e\r\n      \u003ctd\u003e0.31385\u003c/td\u003e\r\n      \u003ctd\u003e0.31385\u003c/td\u003e\r\n      \u003ctd\u003e0.31385\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003e4\u003c/th\u003e\r\n      \u003ctd\u003e1970-01-08\u003c/td\u003e\r\n      \u003ctd\u003e0.31385\u003c/td\u003e\r\n      \u003ctd\u003e0.31768\u003c/td\u003e\r\n      \u003ctd\u003e0.31385\u003c/td\u003e\r\n      \u003ctd\u003e0.31385\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n  \u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003c/div\u003e\r\n\r\n\r\n\r\n\u003ch4 id=\"data-visualization\"\u003eData Visualization\u003c/h4\u003e\r\n\u003cp\u003eNow let\u0026#39;s see what sort of data you have. You want data with various patterns occurring over time.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003eplt.figure(figsize = (18,9))\r\nplt.plot(range(df.shape[0]),(df[\u0026#39;Low\u0026#39;]+df[\u0026#39;High\u0026#39;])/2.0)\r\nplt.xticks(range(0,df.shape[0],500),df[\u0026#39;Date\u0026#39;].loc[::500],rotation=45)\r\nplt.xlabel(\u0026#39;Date\u0026#39;,fontsize=18)\r\nplt.ylabel(\u0026#39;Mid Price\u0026#39;,fontsize=18)\r\nplt.show()\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1523953369/output_7_0_ovatau.png\"/\u003e\u003c/p\u003e\r\n\u003cp\u003eThis graph already says a lot of things. The specific reason I picked this company over others is that this graph is bursting with different behaviors of stock prices over time. This will make the learning more robust as well as give you a change to test how good the predictions are for a variety of situations.\u003c/p\u003e\r\n\u003cp\u003eAnother thing to notice is that the values close to 2017 are much higher and fluctuate more than the values close to the 1970s. Therefore you need to make sure that the data behaves in similar value ranges throughout the time frame. You will take care of this during the \u003cem\u003edata normalization\u003c/em\u003e phase.\u003c/p\u003e\r\n\u003cp\u003e\u003ca id=\"split\"\u003e\u003c/a\u003e\u003c/p\u003e\r\n\u003ch2 id=\"splitting-data-into-a-training-set-and-a-test-set\"\u003eSplitting Data into a Training set and a Test set\u003c/h2\u003e\r\n\u003cp\u003eYou will use the mid price calculated by taking the average of the highest and lowest recorded prices on a day.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# First calculate the mid prices from the highest and lowest\r\nhigh_prices = df.loc[:,\u0026#39;High\u0026#39;].as_matrix()\r\nlow_prices = df.loc[:,\u0026#39;Low\u0026#39;].as_matrix()\r\nmid_prices = (high_prices+low_prices)/2.0\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eNow you can split the training data and test data. The training data will be the first 11,000 data points of the time series and rest will be test data.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003etrain_data = mid_prices[:11000]\r\ntest_data = mid_prices[11000:]\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003ch1 id=\"normalizing-the-data\"\u003eNormalizing the Data\u003c/h1\u003e\r\n\u003cp\u003eNow you need to define a scaler to normalize the data. \u003ccode\u003eMinMaxScalar\u003c/code\u003e scales all the data to be in the region of 0 and 1. You can also reshape the training and test data to be in the shape \u003ccode\u003e[data_size, num_features]\u003c/code\u003e.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# Scale the data to be between 0 and 1\r\n# When scaling remember! You normalize both test and train data with respect to training data\r\n# Because you are not supposed to have access to test data\r\nscaler = MinMaxScaler()\r\ntrain_data = train_data.reshape(-1,1)\r\ntest_data = test_data.reshape(-1,1)\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eDue to the observation you made earlier, that is, different time periods of data have different value ranges, you normalize the data by splitting the full series into windows. If you don\u0026#39;t do this, the earlier data will be close to 0 and will not add much value to the learning process. Here you choose a window size of 2500.\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eTip\u003c/strong\u003e: when choosing the window size make sure it\u0026#39;s not too small, because when  you perform windowed-normalization, it can introduce a break at the very end of each window, as each window is normalized independently.\u003c/p\u003e\r\n\u003cp\u003eIn this example, 4 data points will be affected by this. But given you have 11,000 data points, 4 points will not cause any issue\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# Train the Scaler with training data and smooth data\r\nsmoothing_window_size = 2500\r\nfor di in range(0,10000,smoothing_window_size):\r\n    scaler.fit(train_data[di:di+smoothing_window_size,:])\r\n    train_data[di:di+smoothing_window_size,:] = scaler.transform(train_data[di:di+smoothing_window_size,:])\r\n\r\n# You normalize the last bit of remaining data\r\nscaler.fit(train_data[di+smoothing_window_size:,:])\r\ntrain_data[di+smoothing_window_size:,:] = scaler.transform(train_data[di+smoothing_window_size:,:])\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eReshape the data back to the shape of \u003ccode\u003e[data_size]\u003c/code\u003e\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# Reshape both train and test data\r\ntrain_data = train_data.reshape(-1)\r\n\r\n# Normalize test data\r\ntest_data = scaler.transform(test_data).reshape(-1)\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eYou can now smooth the data using the exponential moving average. This helps you to get rid of the inherent raggedness of the data in stock prices and produce a smoother curve.\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eNote\u003c/strong\u003e that you should only smooth training data.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# Now perform exponential moving average smoothing\r\n# So the data will have a smoother curve than the original ragged data\r\nEMA = 0.0\r\ngamma = 0.1\r\nfor ti in range(11000):\r\n  EMA = gamma*train_data[ti] + (1-gamma)*EMA\r\n  train_data[ti] = EMA\r\n\r\n# Used for visualization and test purposes\r\nall_mid_data = np.concatenate([train_data,test_data],axis=0)\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003e\u003ca id=\"average\"\u003e\u003c/a\u003e\u003c/p\u003e\r\n\u003ch2 id=\"one-step-ahead-prediction-via-averaging\"\u003eOne-Step Ahead Prediction via Averaging\u003c/h2\u003e\r\n\u003cp\u003eAveraging mechanisms allow you to predict (often one time step ahead) by representing the future stock price as an average of the previously observed stock prices. Doing this for more than one time step can produce quite bad results. You will look at two averaging techniques below; standard averaging and exponential moving average. You will evaluate both qualitatively (visual inspection) and quantitatively (Mean Squared Error) the results produced by the two algorithms.\u003c/p\u003e\r\n\u003cp\u003eThe Mean Squared Error (MSE) can be calculated by taking the Squared Error between the true value at one step ahead and the predicted value and averaging it over all the predictions.\u003c/p\u003e\r\n\u003ch3 id=\"standard-average\"\u003eStandard Average\u003c/h3\u003e\r\n\u003cp\u003eYou can understand the difficulty of this problem by first trying to model this as an average calculation problem. First you will try to predict the future stock market prices (for example, x\u003csub\u003et+1\u003c/sub\u003e) as an average of the previously observed stock market prices within a fixed size window (for example, x\u003csub\u003et-N\u003c/sub\u003e, ..., x\u003csub\u003et\u003c/sub\u003e) (say previous 100 days). Thereafter you will try a bit more fancier \u0026quot;exponential moving average\u0026quot; method and see how well that does. Then you will move on to the \u0026quot;holy-grail\u0026quot; of time-series prediction; Long Short-Term Memory models.\u003c/p\u003e\r\n\u003cp\u003eFirst you will see how normal averaging works. That is you say,\u003c/p\u003e\r\n\u003cimg src=\"https://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1525377205/sum_formula.png\" /\u003e\r\n\u003cp\u003eIn other words, you say the prediction at $t+1$ is the average value of all the stock prices you observed within a window of $t$ to $t-N$.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003ewindow_size = 100\r\nN = train_data.size\r\nstd_avg_predictions = []\r\nstd_avg_x = []\r\nmse_errors = []\r\n\r\nfor pred_idx in range(window_size,N):\r\n\r\n    if pred_idx \u0026gt;= N:\r\n        date = dt.datetime.strptime(k, \u0026#39;%Y-%m-%d\u0026#39;).date() + dt.timedelta(days=1)\r\n    else:\r\n        date = df.loc[pred_idx,\u0026#39;Date\u0026#39;]\r\n\r\n    std_avg_predictions.append(np.mean(train_data[pred_idx-window_size:pred_idx]))\r\n    mse_errors.append((std_avg_predictions[-1]-train_data[pred_idx])**2)\r\n    std_avg_x.append(date)\r\n\r\nprint(\u0026#39;MSE error for standard averaging: %.5f\u0026#39;%(0.5*np.mean(mse_errors)))\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003eMSE error for standard averaging: 0.00418\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eTake a look at the averaged results below. It follows the actual behavior of stock quite closely. Next, you will look at a more accurate one-step prediction method.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e\r\nplt.figure(figsize = (18,9))\r\nplt.plot(range(df.shape[0]),all_mid_data,color=\u0026#39;b\u0026#39;,label=\u0026#39;True\u0026#39;)\r\nplt.plot(range(window_size,N),std_avg_predictions,color=\u0026#39;orange\u0026#39;,label=\u0026#39;Prediction\u0026#39;)\r\n#plt.xticks(range(0,df.shape[0],50),df[\u0026#39;Date\u0026#39;].loc[::50],rotation=45)\r\nplt.xlabel(\u0026#39;Date\u0026#39;)\r\nplt.ylabel(\u0026#39;Mid Price\u0026#39;)\r\nplt.legend(fontsize=18)\r\nplt.show()\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1523953369/output_24_0_nz8zxp.png\"/\u003e\u003c/p\u003e\r\n\u003cp\u003eSo what do the above graphs (and the MSE) say?\u003c/p\u003e\r\n\u003cp\u003eIt seems that it is not too bad of a model for very short predictions (one day ahead). Given that stock prices don\u0026#39;t change from 0 to 100 overnight, this behavior is sensible. Next, you will look at a fancier averaging technique known as exponential moving average.\u003c/p\u003e\r\n\u003ch3 id=\"exponential-moving-average\"\u003eExponential Moving Average\u003c/h3\u003e\r\n\u003cp\u003eYou might have seen some articles on the internet using very complex models and predicting almost the exact behavior of the stock market. But \u003cstrong\u003ebeware!\u003c/strong\u003e These are just optical illusions and not due to learning something useful. You will see below how you can replicate that behavior with a simple averaging method.\u003c/p\u003e\r\n\u003cp\u003eIn the exponential moving average method, you calculate $x_{t+1}$ as,\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli\u003ex\u003csub\u003et+1\u003c/sub\u003e = EMA\u003csub\u003et\u003c/sub\u003e =   EMA\u003csub\u003et-1\u003c/sub\u003e + (1-) x\u003csub\u003et\u003c/sub\u003e where EMA\u003csub\u003e0\u003c/sub\u003e = 0 and EMA is the exponential moving average value you maintain over time.\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003eThe above equation basically calculates the exponential moving average from $t+1$ time step and uses that as the one step ahead prediction. $\\gamma$ decides what the contribution of the most recent prediction is to the EMA. For example, a $\\gamma=0.1$ gets only 10% of the current value into the EMA. Because you take only a very small fraction of the most recent, it allows to preserve much older values you saw very early in the average. See how good this looks when used to predict one-step ahead below.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003ewindow_size = 100\r\nN = train_data.size\r\n\r\nrun_avg_predictions = []\r\nrun_avg_x = []\r\n\r\nmse_errors = []\r\n\r\nrunning_mean = 0.0\r\nrun_avg_predictions.append(running_mean)\r\n\r\ndecay = 0.5\r\n\r\nfor pred_idx in range(1,N):\r\n\r\n    running_mean = running_mean*decay + (1.0-decay)*train_data[pred_idx-1]\r\n    run_avg_predictions.append(running_mean)\r\n    mse_errors.append((run_avg_predictions[-1]-train_data[pred_idx])**2)\r\n    run_avg_x.append(date)\r\n\r\nprint(\u0026#39;MSE error for EMA averaging: %.5f\u0026#39;%(0.5*np.mean(mse_errors)))\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003eMSE error for EMA averaging: 0.00003\r\n\u003c/code\u003e\u003c/pre\u003e\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e\r\nplt.figure(figsize = (18,9))\r\nplt.plot(range(df.shape[0]),all_mid_data,color=\u0026#39;b\u0026#39;,label=\u0026#39;True\u0026#39;)\r\nplt.plot(range(0,N),run_avg_predictions,color=\u0026#39;orange\u0026#39;, label=\u0026#39;Prediction\u0026#39;)\r\n#plt.xticks(range(0,df.shape[0],50),df[\u0026#39;Date\u0026#39;].loc[::50],rotation=45)\r\nplt.xlabel(\u0026#39;Date\u0026#39;)\r\nplt.ylabel(\u0026#39;Mid Price\u0026#39;)\r\nplt.legend(fontsize=18)\r\nplt.show()\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1523953369/output_27_0_n4h76v.png\"/\u003e\u003c/p\u003e\r\n\u003ch3 id=\"if-exponential-moving-average-is-this-good-why-do-you-need-better-models-\"\u003eIf Exponential Moving Average is this Good, Why do You Need Better Models?\u003c/h3\u003e\r\n\u003cp\u003eYou see that it fits a perfect line that follows the \u003ccode\u003eTrue\u003c/code\u003e distribution (and justified by the very low MSE). Practically speaking, you can\u0026#39;t do much with just the stock market value of the next day. Personally what I\u0026#39;d like is not the exact stock market price for the next day, but \u003cem\u003ewould the stock market prices go up or down in the next 30 days\u003c/em\u003e. Try to do this, and you will expose the incapability of the EMA method.\u003c/p\u003e\r\n\u003cp\u003eYou will now try to make predictions in windows (say you predict the next 2 days window, instead of just the next day). Then you will realize how wrong EMA can go. Here is an example:\u003c/p\u003e\r\n\u003ch3 id=\"predict-more-than-one-step-into-the-future\"\u003ePredict More Than One Step into the Future\u003c/h3\u003e\r\n\u003cp\u003eTo make things concrete, let\u0026#39;s assume values, say $x_t=0.4$, $EMA=0.5$ and $\\gamma = 0.5$\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli\u003eSay you get the output with the following equation\u003cul\u003e\r\n\u003cli\u003eX\u003csub\u003et+1\u003c/sub\u003e = EMA\u003csub\u003et\u003c/sub\u003e =   EMA\u003csub\u003et-1\u003c/sub\u003e + (1 - )X\u003csub\u003et\u003c/sub\u003e\u003c/li\u003e\r\n\u003cli\u003eSo you have $x_{t+1} = 0.5 \\times 0.5 + (1-0.5) \\times 0.4 = 0.45$\u003c/li\u003e\r\n\u003cli\u003eSo $x_{t+1} = EMA_t = 0.45$\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003c/li\u003e\r\n\u003cli\u003eSo the next prediction $x_{t+2}$ becomes,\u003cul\u003e\r\n\u003cli\u003eX\u003csub\u003et+2\u003c/sub\u003e =   EMA\u003csub\u003et\u003c/sub\u003e + (1-)X\u003csub\u003et+1\u003c/sub\u003e\u003c/li\u003e\r\n\u003cli\u003eWhich is $x_{t+2} = \\gamma \\times EMA_t + (1-\\gamma) EMA_t = EMA_t$\u003c/li\u003e\r\n\u003cli\u003eOr in this example, X\u003csub\u003et+2\u003c/sub\u003e = X\u003csub\u003et+1\u003c/sub\u003e = 0.45\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003eSo no matter how many steps you predict in to the future, you\u0026#39;ll keep getting the same answer for all the future prediction steps.\u003c/p\u003e\r\n\u003cp\u003eOne solution you have that will output useful information is to look at \u003cstrong\u003emomentum-based algorithms\u003c/strong\u003e. They make predictions based on whether the past recent values were going up or going down (not the exact values). For example, they will say the next day price is likely to be lower, if the prices have been dropping for the past days, which sounds reasonable. However, you will use a more complex model: an LSTM model.\u003c/p\u003e\r\n\u003cp\u003eThese models have taken the realm of time series prediction by storm, because they are so good at modelling time series data. You will see if there actually are patterns hidden in the data that you can exploit.\u003c/p\u003e\r\n\u003cp\u003e\u003ca id=\"lstm\"\u003e\u003c/a\u003e\u003c/p\u003e\r\n\u003ch2 id=\"introduction-to-lstms-making-stock-movement-predictions-far-into-the-future\"\u003eIntroduction to LSTMs: Making Stock Movement Predictions Far into the Future\u003c/h2\u003e\r\n\u003cp\u003eLong Short-Term Memory models are extremely powerful time-series models. They can predict an arbitrary number of steps into the future. An LSTM module (or cell) has 5 essential components which allows it to model both long-term and short-term data.\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli\u003eCell state ($c_t$) - This represents the internal memory of the cell which stores both short term memory and long-term memories\u003c/li\u003e\r\n\u003cli\u003eHidden state ($h_t$) - This is output state information calculated w.r.t. current input, previous hidden state and current cell input which you eventually use to predict the future stock market prices. Additionally, the hidden state can decide to only retrive the short or long-term or both types of memory stored in the cell state to make the next prediction.\u003c/li\u003e\r\n\u003cli\u003eInput gate ($i_t$) - Decides how much information from current input flows to the cell state\u003c/li\u003e\r\n\u003cli\u003eForget gate ($f_t$) - Decides how much information from the current input and the previous cell state flows into the current cell state\u003c/li\u003e\r\n\u003cli\u003eOutput gate ($o_t$) - Decides how much information from the current cell state flows into the hidden state, so that if needed LSTM can only pick the long-term memories or short-term memories and long-term memories\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003eA cell is pictured below.\u003c/p\u003e\r\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1523953369/lstm_xszk4d.png\" alt=\"Drawing\" style=\"width: 400px;\"/\u003e\u003c/p\u003e\r\n\u003cp\u003eAnd the equations for calculating each of these entities are as follows.\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli\u003e$i\u003cem\u003et = \\sigma(W\u003c/em\u003e{ix}x\u003cem\u003et + W\u003c/em\u003e{ih}h_{t-1}+b_i)$\u003c/li\u003e\r\n\u003cli\u003e$\\tilde{c}\u003cem\u003et = \\sigma(W\u003c/em\u003e{cx}x\u003cem\u003et + W\u003c/em\u003e{ch}h_{t-1} + b_c)$\u003c/li\u003e\r\n\u003cli\u003e$f\u003cem\u003et = \\sigma(W\u003c/em\u003e{fx}x\u003cem\u003et + W\u003c/em\u003e{fh}h_{t-1}+b_f)$\u003c/li\u003e\r\n\u003cli\u003e$c_t = f\u003cem\u003et c\u003c/em\u003e{t-1} + i_t \\tilde{c}_t$\u003c/li\u003e\r\n\u003cli\u003e$o\u003cem\u003et = \\sigma(W\u003c/em\u003e{ox}x\u003cem\u003et + W\u003c/em\u003e{oh}h_{t-1}+b_o)$\u003c/li\u003e\r\n\u003cli\u003e$h_t = o_t tanh(c_t)$\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003eFor a better (more technical) understanding about LSTMs you can refer to \u003ca href=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/\"\u003ethis article\u003c/a\u003e.\u003c/p\u003e\r\n\u003cp\u003eTensorFlow provides a nice sub API (called RNN API) for implementing time series models. You will be using that for your implementations.\u003c/p\u003e\r\n\u003ch3 id=\"data-generator\"\u003eData Generator\u003c/h3\u003e\r\n\u003cp\u003eYou are first going to implement a data generator to train your model. This data generator will have a method called \u003ccode\u003e.unroll_batches(...)\u003c/code\u003e which will output a set of \u003cem\u003enum_unrollings\u003c/em\u003e batches of input data obtained sequentially, where a batch of data is of size \u003ccode\u003e[batch_size, 1]\u003c/code\u003e. Then each batch of input data will have a corresponding output batch of data.\u003c/p\u003e\r\n\u003cp\u003eFor example if \u003ccode\u003enum_unrollings=3\u003c/code\u003e and \u003ccode\u003ebatch_size=4\u003c/code\u003e a set of unrolled batches it might look like,\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli\u003einput data: $[x_0,x_10,x_20,x_30], [x_1,x_11,x_21,x_31], [x_2,x_12,x_22,x_32]$\u003c/li\u003e\r\n\u003cli\u003eoutput data: $[x_1,x_11,x_21,x_31], [x_2,x_12,x_22,x_32], [x_3,x_13,x_23,x_33]$\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003ch4 id=\"data-augmentation\"\u003eData Augmentation\u003c/h4\u003e\r\n\u003cp\u003eAlso to make your model robust you will not make the output for $x\u003cem\u003et$ always $x\u003c/em\u003e{t+1}$. Rather you will randomly sample an output from the set $x\u003cem\u003e{t+1},x\u003c/em\u003e{t+2},\\ldots,x_{t+N}$ where $N$ is a small window size.\u003c/p\u003e\r\n\u003cp\u003eHere you are making the following assumption:\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli\u003e$x\u003cem\u003e{t+1},x\u003c/em\u003e{t+2},\\ldots,x_{t+N}$ will not be very far from each other\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003eI personally think this is a reasonable assumption for stock movement predictions.\u003c/p\u003e\r\n\u003cp\u003eBelow you illustrate how a batch of data is created visually.\u003c/p\u003e\r\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1523953369/batch_pno02e.png\" alt=\"Drawing\" style=\"width: 600px;\"/\u003e\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e\r\nclass DataGeneratorSeq(object):\r\n\r\n    def __init__(self,prices,batch_size,num_unroll):\r\n        self._prices = prices\r\n        self._prices_length = len(self._prices) - num_unroll\r\n        self._batch_size = batch_size\r\n        self._num_unroll = num_unroll\r\n        self._segments = self._prices_length //self._batch_size\r\n        self._cursor = [offset * self._segments for offset in range(self._batch_size)]\r\n\r\n    def next_batch(self):\r\n\r\n        batch_data = np.zeros((self._batch_size),dtype=np.float32)\r\n        batch_labels = np.zeros((self._batch_size),dtype=np.float32)\r\n\r\n        for b in range(self._batch_size):\r\n            if self._cursor[b]+1\u0026gt;=self._prices_length:\r\n                #self._cursor[b] = b * self._segments\r\n                self._cursor[b] = np.random.randint(0,(b+1)*self._segments)\r\n\r\n            batch_data[b] = self._prices[self._cursor[b]]\r\n            batch_labels[b]= self._prices[self._cursor[b]+np.random.randint(0,5)]\r\n\r\n            self._cursor[b] = (self._cursor[b]+1)%self._prices_length\r\n\r\n        return batch_data,batch_labels\r\n\r\n    def unroll_batches(self):\r\n\r\n        unroll_data,unroll_labels = [],[]\r\n        init_data, init_label = None,None\r\n        for ui in range(self._num_unroll):\r\n\r\n            data, labels = self.next_batch()    \r\n\r\n            unroll_data.append(data)\r\n            unroll_labels.append(labels)\r\n\r\n        return unroll_data, unroll_labels\r\n\r\n    def reset_indices(self):\r\n        for b in range(self._batch_size):\r\n            self._cursor[b] = np.random.randint(0,min((b+1)*self._segments,self._prices_length-1))\r\n\r\n\r\n\r\ndg = DataGeneratorSeq(train_data,5,5)\r\nu_data, u_labels = dg.unroll_batches()\r\n\r\nfor ui,(dat,lbl) in enumerate(zip(u_data,u_labels)):   \r\n    print(\u0026#39;\\n\\nUnrolled index %d\u0026#39;%ui)\r\n    dat_ind = dat\r\n    lbl_ind = lbl\r\n    print(\u0026#39;\\tInputs: \u0026#39;,dat )\r\n    print(\u0026#39;\\n\\tOutput:\u0026#39;,lbl)\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003eUnrolled index 0\r\n    Inputs:  [0.03143791 0.6904868  0.82829314 0.32585657 0.11600105]\r\n\r\n    Output: [0.08698314 0.68685144 0.8329321  0.33355275 0.11785509]\r\n\r\n\r\nUnrolled index 1\r\n    Inputs:  [0.06067836 0.6890754  0.8325337  0.32857886 0.11785509]\r\n\r\n    Output: [0.15261841 0.68685144 0.8325337  0.33421066 0.12106793]\r\n\r\n\r\nUnrolled index 2\r\n    Inputs:  [0.08698314 0.68685144 0.8329321  0.33078218 0.11946969]\r\n\r\n    Output: [0.11098009 0.6848606  0.83387965 0.33421066 0.12106793]\r\n\r\n\r\nUnrolled index 3\r\n    Inputs:  [0.11098009 0.6858036  0.83294916 0.33219692 0.12106793]\r\n\r\n    Output: [0.132895   0.6836884  0.83294916 0.33219692 0.12288672]\r\n\r\n\r\nUnrolled index 4\r\n    Inputs:  [0.132895   0.6848606  0.833369   0.33355275 0.12158521]\r\n\r\n    Output: [0.15261841 0.6836884  0.83383167 0.33355275 0.12230608]\r\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"defining-hyperparameters\"\u003eDefining Hyperparameters\u003c/h3\u003e\r\n\u003cp\u003eIn this section, you\u0026#39;ll define several hyperparameters. \u003ccode\u003eD\u003c/code\u003e is the dimensionality of the input. It\u0026#39;s straightforward, as you take the previous stock price as the input and predict the next one, which should be \u003ccode\u003e1\u003c/code\u003e.\u003c/p\u003e\r\n\u003cp\u003eThen you have \u003ccode\u003enum_unrollings\u003c/code\u003e, this is a hyperparameter related to the backpropagation through time (BPTT) that is used to optimize the LSTM model. This denotes how many continuous time steps you consider for a single optimization step. You can think of this as, instead of optimizing the model by looking at a single time step, you optimize the network by looking at \u003ccode\u003enum_unrollings\u003c/code\u003e time steps. The larger the better.\u003c/p\u003e\r\n\u003cp\u003eThen you have the \u003ccode\u003ebatch_size\u003c/code\u003e. Batch size is how many data samples you consider in a single time step.\u003c/p\u003e\r\n\u003cp\u003eNext you define \u003ccode\u003enum_nodes\u003c/code\u003e which represents the number of hidden neurons in each cell. You can see that there are three layers of LSTMs in this example.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003eD = 1 # Dimensionality of the data. Since your data is 1-D this would be 1\r\nnum_unrollings = 50 # Number of time steps you look into the future.\r\nbatch_size = 500 # Number of samples in a batch\r\nnum_nodes = [200,200,150] # Number of hidden nodes in each layer of the deep LSTM stack we\u0026#39;re using\r\nn_layers = len(num_nodes) # number of layers\r\ndropout = 0.2 # dropout amount\r\n\r\ntf.reset_default_graph() # This is important in case you run this multiple times\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003ch3 id=\"defining-inputs-and-outputs\"\u003eDefining Inputs and Outputs\u003c/h3\u003e\r\n\u003cp\u003eNext you define placeholders for training inputs and labels. This is very straightforward as you have a list of input placeholders, where each placeholder contains a single batch of data. And the list has \u003ccode\u003enum_unrollings\u003c/code\u003e placeholders, that will be used at once for a single optimization step.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# Input data.\r\ntrain_inputs, train_outputs = [],[]\r\n\r\n# You unroll the input over time defining placeholders for each time step\r\nfor ui in range(num_unrollings):\r\n    train_inputs.append(tf.placeholder(tf.float32, shape=[batch_size,D],name=\u0026#39;train_inputs_%d\u0026#39;%ui))\r\n    train_outputs.append(tf.placeholder(tf.float32, shape=[batch_size,1], name = \u0026#39;train_outputs_%d\u0026#39;%ui))\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003ch3 id=\"defining-parameters-of-the-lstm-and-regression-layer\"\u003eDefining Parameters of the LSTM and Regression layer\u003c/h3\u003e\r\n\u003cp\u003eYou will have a three layers of LSTMs and a linear regression layer, denoted by \u003ccode\u003ew\u003c/code\u003e and \u003ccode\u003eb\u003c/code\u003e, that takes the output of the last Long Short-Term Memory cell and output the prediction for the next time step. You can use the \u003ccode\u003eMultiRNNCell\u003c/code\u003e in TensorFlow to encapsulate the three \u003ccode\u003eLSTMCell\u003c/code\u003e objects you created. Additionally, you can have the dropout implemented LSTM cells, as they improve performance and reduce overfitting.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003elstm_cells = [\r\n    tf.contrib.rnn.LSTMCell(num_units=num_nodes[li],\r\n                            state_is_tuple=True,\r\n                            initializer= tf.contrib.layers.xavier_initializer()\r\n                           )\r\n for li in range(n_layers)]\r\n\r\ndrop_lstm_cells = [tf.contrib.rnn.DropoutWrapper(\r\n    lstm, input_keep_prob=1.0,output_keep_prob=1.0-dropout, state_keep_prob=1.0-dropout\r\n) for lstm in lstm_cells]\r\ndrop_multi_cell = tf.contrib.rnn.MultiRNNCell(drop_lstm_cells)\r\nmulti_cell = tf.contrib.rnn.MultiRNNCell(lstm_cells)\r\n\r\nw = tf.get_variable(\u0026#39;w\u0026#39;,shape=[num_nodes[-1], 1], initializer=tf.contrib.layers.xavier_initializer())\r\nb = tf.get_variable(\u0026#39;b\u0026#39;,initializer=tf.random_uniform([1],-0.1,0.1))\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003ch3 id=\"calculating-lstm-output-and-feeding-it-to-the-regression-layer-to-get-final-prediction\"\u003eCalculating LSTM output and Feeding it to the regression layer to get final prediction\u003c/h3\u003e\r\n\u003cp\u003eIn this section, you first create TensorFlow variables (\u003ccode\u003ec\u003c/code\u003e and \u003ccode\u003eh\u003c/code\u003e) that will hold the cell state and the hidden state of the Long Short-Term Memory cell. Then you transform the list of \u003ccode\u003etrain_inputs\u003c/code\u003e to have a shape of \u003ccode\u003e[num_unrollings, batch_size, D]\u003c/code\u003e, this is needed for calculating the outputs with the \u003ccode\u003etf.nn.dynamic_rnn\u003c/code\u003e function.  You then calculate the LSTM outputs with the \u003ccode\u003etf.nn.dynamic_rnn\u003c/code\u003e function and split the output back to a list of \u003ccode\u003enum_unrolling\u003c/code\u003e tensors. the loss between the predictions and true stock prices.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# Create cell state and hidden state variables to maintain the state of the LSTM\r\nc, h = [],[]\r\ninitial_state = []\r\nfor li in range(n_layers):\r\n  c.append(tf.Variable(tf.zeros([batch_size, num_nodes[li]]), trainable=False))\r\n  h.append(tf.Variable(tf.zeros([batch_size, num_nodes[li]]), trainable=False))\r\n  initial_state.append(tf.contrib.rnn.LSTMStateTuple(c[li], h[li]))\r\n\r\n# Do several tensor transofmations, because the function dynamic_rnn requires the output to be of\r\n# a specific format. Read more at: https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn\r\nall_inputs = tf.concat([tf.expand_dims(t,0) for t in train_inputs],axis=0)\r\n\r\n# all_outputs is [seq_length, batch_size, num_nodes]\r\nall_lstm_outputs, state = tf.nn.dynamic_rnn(\r\n    drop_multi_cell, all_inputs, initial_state=tuple(initial_state),\r\n    time_major = True, dtype=tf.float32)\r\n\r\nall_lstm_outputs = tf.reshape(all_lstm_outputs, [batch_size*num_unrollings,num_nodes[-1]])\r\n\r\nall_outputs = tf.nn.xw_plus_b(all_lstm_outputs,w,b)\r\n\r\nsplit_outputs = tf.split(all_outputs,num_unrollings,axis=0)\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003ch3 id=\"loss-calculation-and-optimizer\"\u003eLoss Calculation and Optimizer\u003c/h3\u003e\r\n\u003cp\u003eNow, you\u0026#39;ll calculate the loss. However, you should note that there is a unique characteristic when calculating the loss. For each batch of predictions and true outputs, you calculate the Mean Squared Error. And you sum (not average) all these mean squared losses together. Finally, you define the optimizer you\u0026#39;re going to use to optimize the neural network. In this case, you can use Adam, which is a very recent and well-performing optimizer.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# When calculating the loss you need to be careful about the exact form, because you calculate\r\n# loss of all the unrolled steps at the same time\r\n# Therefore, take the mean error or each batch and get the sum of that over all the unrolled steps\r\n\r\nprint(\u0026#39;Defining training Loss\u0026#39;)\r\nloss = 0.0\r\nwith tf.control_dependencies([tf.assign(c[li], state[li][0]) for li in range(n_layers)]+\r\n                             [tf.assign(h[li], state[li][1]) for li in range(n_layers)]):\r\n  for ui in range(num_unrollings):\r\n    loss += tf.reduce_mean(0.5*(split_outputs[ui]-train_outputs[ui])**2)\r\n\r\nprint(\u0026#39;Learning rate decay operations\u0026#39;)\r\nglobal_step = tf.Variable(0, trainable=False)\r\ninc_gstep = tf.assign(global_step,global_step + 1)\r\ntf_learning_rate = tf.placeholder(shape=None,dtype=tf.float32)\r\ntf_min_learning_rate = tf.placeholder(shape=None,dtype=tf.float32)\r\n\r\nlearning_rate = tf.maximum(\r\n    tf.train.exponential_decay(tf_learning_rate, global_step, decay_steps=1, decay_rate=0.5, staircase=True),\r\n    tf_min_learning_rate)\r\n\r\n# Optimizer.\r\nprint(\u0026#39;TF Optimization operations\u0026#39;)\r\noptimizer = tf.train.AdamOptimizer(learning_rate)\r\ngradients, v = zip(*optimizer.compute_gradients(loss))\r\ngradients, _ = tf.clip_by_global_norm(gradients, 5.0)\r\noptimizer = optimizer.apply_gradients(\r\n    zip(gradients, v))\r\n\r\nprint(\u0026#39;\\tAll done\u0026#39;)\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003eDefining training Loss\r\nLearning rate decay operations\r\nTF Optimization operations\r\n    All done\r\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"prediction-related-calculations\"\u003ePrediction Related Calculations\u003c/h3\u003e\r\n\u003cp\u003eHere you define the prediction related TensorFlow operations. First, define a placeholder for feeding in the input (\u003ccode\u003esample_inputs\u003c/code\u003e), then similar to the training stage, you define state variables for prediction (\u003ccode\u003esample_c\u003c/code\u003e and \u003ccode\u003esample_h\u003c/code\u003e). Finally you calculate the prediction with the \u003ccode\u003etf.nn.dynamic_rnn\u003c/code\u003e function and then sending the output through the regression layer (\u003ccode\u003ew\u003c/code\u003e and \u003ccode\u003eb\u003c/code\u003e). You also should define the \u003ccode\u003ereset_sample_state\u003c/code\u003e operation, which resets the cell state and the hidden state. You should execute this operation at the start, every time you make a sequence of predictions.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003eprint(\u0026#39;Defining prediction related TF functions\u0026#39;)\r\n\r\nsample_inputs = tf.placeholder(tf.float32, shape=[1,D])\r\n\r\n# Maintaining LSTM state for prediction stage\r\nsample_c, sample_h, initial_sample_state = [],[],[]\r\nfor li in range(n_layers):\r\n  sample_c.append(tf.Variable(tf.zeros([1, num_nodes[li]]), trainable=False))\r\n  sample_h.append(tf.Variable(tf.zeros([1, num_nodes[li]]), trainable=False))\r\n  initial_sample_state.append(tf.contrib.rnn.LSTMStateTuple(sample_c[li],sample_h[li]))\r\n\r\nreset_sample_states = tf.group(*[tf.assign(sample_c[li],tf.zeros([1, num_nodes[li]])) for li in range(n_layers)],\r\n                               *[tf.assign(sample_h[li],tf.zeros([1, num_nodes[li]])) for li in range(n_layers)])\r\n\r\nsample_outputs, sample_state = tf.nn.dynamic_rnn(multi_cell, tf.expand_dims(sample_inputs,0),\r\n                                   initial_state=tuple(initial_sample_state),\r\n                                   time_major = True,\r\n                                   dtype=tf.float32)\r\n\r\nwith tf.control_dependencies([tf.assign(sample_c[li],sample_state[li][0]) for li in range(n_layers)]+\r\n                              [tf.assign(sample_h[li],sample_state[li][1]) for li in range(n_layers)]):  \r\n  sample_prediction = tf.nn.xw_plus_b(tf.reshape(sample_outputs,[1,-1]), w, b)\r\n\r\nprint(\u0026#39;\\tAll done\u0026#39;)\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003eDefining prediction related TF functions\r\n    All done\r\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"running-the-lstm\"\u003eRunning the LSTM\u003c/h3\u003e\r\n\u003cp\u003eHere you will train and predict stock price movements for several epochs and see whether the predictions get better or worse over time. You follow the following procedure.\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli\u003eDefine a test set of starting points (\u003ccode\u003etest_points_seq\u003c/code\u003e) on the time series to evaluate the model on\u003c/li\u003e\r\n\u003cli\u003eFor each epoch\u003cul\u003e\r\n\u003cli\u003eFor full sequence length of training data\u003cul\u003e\r\n\u003cli\u003eUnroll a set of \u003ccode\u003enum_unrollings\u003c/code\u003e batches\u003c/li\u003e\r\n\u003cli\u003eTrain the neural network with the unrolled batches\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003c/li\u003e\r\n\u003cli\u003eCalculate the average training loss\u003c/li\u003e\r\n\u003cli\u003eFor each starting point in the test set\u003cul\u003e\r\n\u003cli\u003eUpdate the LSTM state by iterating through the previous \u003ccode\u003enum_unrollings\u003c/code\u003e data points found before the test point\u003c/li\u003e\r\n\u003cli\u003eMake predictions for \u003ccode\u003en_predict_once\u003c/code\u003e steps continuously, using the previous prediction as the current input\u003c/li\u003e\r\n\u003cli\u003eCalculate the MSE loss between the \u003ccode\u003en_predict_once\u003c/code\u003e points predicted and the true stock prices at those time stamps\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003eepochs = 30\r\nvalid_summary = 1 # Interval you make test predictions\r\n\r\nn_predict_once = 50 # Number of steps you continously predict for\r\n\r\ntrain_seq_length = train_data.size # Full length of the training data\r\n\r\ntrain_mse_ot = [] # Accumulate Train losses\r\ntest_mse_ot = [] # Accumulate Test loss\r\npredictions_over_time = [] # Accumulate predictions\r\n\r\nsession = tf.InteractiveSession()\r\n\r\ntf.global_variables_initializer().run()\r\n\r\n# Used for decaying learning rate\r\nloss_nondecrease_count = 0\r\nloss_nondecrease_threshold = 2 # If the test error hasn\u0026#39;t increased in this many steps, decrease learning rate\r\n\r\nprint(\u0026#39;Initialized\u0026#39;)\r\naverage_loss = 0\r\n\r\n# Define data generator\r\ndata_gen = DataGeneratorSeq(train_data,batch_size,num_unrollings)\r\n\r\nx_axis_seq = []\r\n\r\n# Points you start your test predictions from\r\ntest_points_seq = np.arange(11000,12000,50).tolist()\r\n\r\nfor ep in range(epochs):       \r\n\r\n    # ========================= Training =====================================\r\n    for step in range(train_seq_length//batch_size):\r\n\r\n        u_data, u_labels = data_gen.unroll_batches()\r\n\r\n        feed_dict = {}\r\n        for ui,(dat,lbl) in enumerate(zip(u_data,u_labels)):            \r\n            feed_dict[train_inputs[ui]] = dat.reshape(-1,1)\r\n            feed_dict[train_outputs[ui]] = lbl.reshape(-1,1)\r\n\r\n        feed_dict.update({tf_learning_rate: 0.0001, tf_min_learning_rate:0.000001})\r\n\r\n        _, l = session.run([optimizer, loss], feed_dict=feed_dict)\r\n\r\n        average_loss += l\r\n\r\n    # ============================ Validation ==============================\r\n    if (ep+1) % valid_summary == 0:\r\n\r\n      average_loss = average_loss/(valid_summary*(train_seq_length//batch_size))\r\n\r\n      # The average loss\r\n      if (ep+1)%valid_summary==0:\r\n        print(\u0026#39;Average loss at step %d: %f\u0026#39; % (ep+1, average_loss))\r\n\r\n      train_mse_ot.append(average_loss)\r\n\r\n      average_loss = 0 # reset loss\r\n\r\n      predictions_seq = []\r\n\r\n      mse_test_loss_seq = []\r\n\r\n      # ===================== Updating State and Making Predicitons ========================\r\n      for w_i in test_points_seq:\r\n        mse_test_loss = 0.0\r\n        our_predictions = []\r\n\r\n        if (ep+1)-valid_summary==0:\r\n          # Only calculate x_axis values in the first validation epoch\r\n          x_axis=[]\r\n\r\n        # Feed in the recent past behavior of stock prices\r\n        # to make predictions from that point onwards\r\n        for tr_i in range(w_i-num_unrollings+1,w_i-1):\r\n          current_price = all_mid_data[tr_i]\r\n          feed_dict[sample_inputs] = np.array(current_price).reshape(1,1)    \r\n          _ = session.run(sample_prediction,feed_dict=feed_dict)\r\n\r\n        feed_dict = {}\r\n\r\n        current_price = all_mid_data[w_i-1]\r\n\r\n        feed_dict[sample_inputs] = np.array(current_price).reshape(1,1)\r\n\r\n        # Make predictions for this many steps\r\n        # Each prediction uses previous prediciton as it\u0026#39;s current input\r\n        for pred_i in range(n_predict_once):\r\n\r\n          pred = session.run(sample_prediction,feed_dict=feed_dict)\r\n\r\n          our_predictions.append(np.asscalar(pred))\r\n\r\n          feed_dict[sample_inputs] = np.asarray(pred).reshape(-1,1)\r\n\r\n          if (ep+1)-valid_summary==0:\r\n            # Only calculate x_axis values in the first validation epoch\r\n            x_axis.append(w_i+pred_i)\r\n\r\n          mse_test_loss += 0.5*(pred-all_mid_data[w_i+pred_i])**2\r\n\r\n        session.run(reset_sample_states)\r\n\r\n        predictions_seq.append(np.array(our_predictions))\r\n\r\n        mse_test_loss /= n_predict_once\r\n        mse_test_loss_seq.append(mse_test_loss)\r\n\r\n        if (ep+1)-valid_summary==0:\r\n          x_axis_seq.append(x_axis)\r\n\r\n      current_test_mse = np.mean(mse_test_loss_seq)\r\n\r\n      # Learning rate decay logic\r\n      if len(test_mse_ot)\u0026gt;0 and current_test_mse \u0026gt; min(test_mse_ot):\r\n          loss_nondecrease_count += 1\r\n      else:\r\n          loss_nondecrease_count = 0\r\n\r\n      if loss_nondecrease_count \u0026gt; loss_nondecrease_threshold :\r\n            session.run(inc_gstep)\r\n            loss_nondecrease_count = 0\r\n            print(\u0026#39;\\tDecreasing learning rate by 0.5\u0026#39;)\r\n\r\n      test_mse_ot.append(current_test_mse)\r\n      print(\u0026#39;\\tTest MSE: %.5f\u0026#39;%np.mean(mse_test_loss_seq))\r\n      predictions_over_time.append(predictions_seq)\r\n      print(\u0026#39;\\tFinished Predictions\u0026#39;)\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003eInitialized\r\nAverage loss at step 1: 1.703350\r\n    Test MSE: 0.00318\r\n    Finished Predictions\r\n  ...\r\n  ...\r\n  ...\r\nAverage loss at step 30: 0.033753\r\n    Test MSE: 0.00243\r\n    Finished Predictions\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003ca id=\"predict\"\u003e\u003c/a\u003e\u003c/p\u003e\r\n\u003ch2 id=\"visualizing-the-predictions\"\u003eVisualizing the Predictions\u003c/h2\u003e\r\n\u003cp\u003eYou can see how the MSE loss is going down with the amount of training. This is good sign that the model is learning something useful. To quantify your findings, you can compare the network\u0026#39;s MSE loss to the MSE loss you obtained when doing the standard averaging (0.004). You can see that the LSTM is doing better than the standard averaging. And you know that standard averaging (though not perfect) followed the true stock prices movements reasonably.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003ebest_prediction_epoch = 28 # replace this with the epoch that you got the best results when running the plotting code\r\n\r\nplt.figure(figsize = (18,18))\r\nplt.subplot(2,1,1)\r\nplt.plot(range(df.shape[0]),all_mid_data,color=\u0026#39;b\u0026#39;)\r\n\r\n# Plotting how the predictions change over time\r\n# Plot older predictions with low alpha and newer predictions with high alpha\r\nstart_alpha = 0.25\r\nalpha  = np.arange(start_alpha,1.1,(1.0-start_alpha)/len(predictions_over_time[::3]))\r\nfor p_i,p in enumerate(predictions_over_time[::3]):\r\n    for xval,yval in zip(x_axis_seq,p):\r\n        plt.plot(xval,yval,color=\u0026#39;r\u0026#39;,alpha=alpha[p_i])\r\n\r\nplt.title(\u0026#39;Evolution of Test Predictions Over Time\u0026#39;,fontsize=18)\r\nplt.xlabel(\u0026#39;Date\u0026#39;,fontsize=18)\r\nplt.ylabel(\u0026#39;Mid Price\u0026#39;,fontsize=18)\r\nplt.xlim(11000,12500)\r\n\r\nplt.subplot(2,1,2)\r\n\r\n# Predicting the best test prediction you got\r\nplt.plot(range(df.shape[0]),all_mid_data,color=\u0026#39;b\u0026#39;)\r\nfor xval,yval in zip(x_axis_seq,predictions_over_time[best_prediction_epoch]):\r\n    plt.plot(xval,yval,color=\u0026#39;r\u0026#39;)\r\n\r\nplt.title(\u0026#39;Best Test Predictions Over Time\u0026#39;,fontsize=18)\r\nplt.xlabel(\u0026#39;Date\u0026#39;,fontsize=18)\r\nplt.ylabel(\u0026#39;Mid Price\u0026#39;,fontsize=18)\r\nplt.xlim(11000,12500)\r\nplt.show()\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1523953369/output_47_0_gmxsj3.png\"/\u003e\u003c/p\u003e\r\n\u003cp\u003eThough not perfect, LSTMs seem to be able to predict stock price behavior correctly most of the time. Note that you are making predictions roughly in the range of 0 and 1.0 (that is, not the true stock prices). This is okay, because you\u0026#39;re predicting the stock price movement, not the prices themselves.\u003c/p\u003e\r\n\u003cp\u003e\u003ca id=\"remarks\"\u003e\u003c/a\u003e\u003c/p\u003e\r\n\u003ch2 id=\"final-remarks\"\u003eFinal Remarks\u003c/h2\u003e\r\n\u003cp\u003eI\u0026#39;m hoping that you found this tutorial useful. I should mention that this was a rewarding experience for me. In this tutorial, I learnt how difficult it can be to device a model that is able to correctly predict stock price movements. You started with a motivation for why you need to model stock prices. This was followed by an explanation and code for downloading data. Then you looked at two averaging techniques that allow you to make predictions one step into the future. You next saw that these methods are futile when you need to predict more than one step into the future. Thereafter you discussed how you can use LSTMs to make predictions many steps into the future. Finally you visualized the results and saw that your model (though not perfect) is quite good at correctly predicting stock price movements.\u003c/p\u003e\r\n\u003cp\u003eIf you would like to learn more about deep learning, be sure to take a look at our \u003ca href=\"https://www.datacamp.com/courses/deep-learning-in-python\"\u003eDeep Learning in Python course\u003c/a\u003e. It covers the basics, as well as how to build a neural network on your own in Keras. This is a different package than TensorFlow, which will be used in this tutorial, but the idea is the same.\u003c/p\u003e\r\n\u003cp\u003eHere, I\u0026#39;m stating several takeaways of this tutorial.\u003c/p\u003e\r\n\u003col\u003e\r\n\u003cli\u003e\u003cp\u003eStock price/movement prediction is an extremely difficult task. Personally I don\u0026#39;t think any of the stock prediction models out there shouldn\u0026#39;t be taken for granted and blindly rely on them. However models might be able to predict stock price movement correctly most of the time, but not always.\u003c/p\u003e\r\n\u003c/li\u003e\r\n\u003cli\u003e\u003cp\u003eDo not be fooled by articles out there that shows predictions curves that perfectly overlaps the true stock prices. This can be replicated with a simple averaging technique and in practice it\u0026#39;s useless. A more sensible thing to do is predicting the stock price movements.\u003c/p\u003e\r\n\u003c/li\u003e\r\n\u003cli\u003e\u003cp\u003eThe model\u0026#39;s hyperparameters are extremely sensitive to the results you obtain. So a very good thing to do would be to run some hyperparameter optimization technique (for example, Grid search / Random search) on the hyperparameters. Below I listed some of the most critical hyperparameters\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli\u003eThe learning rate of the optimizer\u003c/li\u003e\r\n\u003cli\u003eNumber of layers and the number of hidden units in each layer\u003c/li\u003e\r\n\u003cli\u003eThe optimizer. I found Adam to perform the best\u003c/li\u003e\r\n\u003cli\u003eType of the model. You can try GRU/ Standard LSTM/ LSTM with Peepholes and evaluation performance difference\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003c/li\u003e\r\n\u003cli\u003e\u003cp\u003eIn this tutorial you did something faulty (due to the small size of data)! That is you used the test loss to decay the learning rate. This indirectly leaks information about test set into the training procedure. A better way of handling this is to have a separate validation set (apart from the test set) and decay learning rate with respect to performance of the validation set.\u003c/p\u003e\r\n\u003c/li\u003e\r\n\u003c/ol\u003e\r\n\u003cp\u003eIf you\u0026#39;d like to get in touch with me, you can drop me an e-mail at thushv@gmail.com or connect with me via \u003ca href=\"https://www.linkedin.com/in/thushanganegedara/\"\u003eLinkedIn\u003c/a\u003e.\u003c/p\u003e\r\n\u003ch2 id=\"references\"\u003eReferences\u003c/h2\u003e\r\n\u003cp\u003eI referred to \u003ca href=\"https://github.com/jaungiers/LSTM-Neural-Network-for-Time-Series-Prediction\"\u003ethis repository\u003c/a\u003e to get an understanding about how to use LSTMs for stock predictions. But details can be vastly different from the implementation found in the reference.\u003c/p\u003e\r\n","contentUrl":"https://www.datacamp.com/community/tutorials/lstm-python-stock-market","userContentUrl":null,"illustrationUrl":null,"seoTitle":"LSTM in Python: Stock Market Predictions","seoMetaDescription":"Discover Long Short-Term Memory (LSTM) networks in Python and how you can use them to make stock market predictions!","seoKeyword":"LSTM python","mustRead":false,"programmingLanguage":null,"submissionDate":"2018-04-16T08:32:46.804Z","publishDate":"2018-05-03T10:00:00.000Z","episode":null,"isLatest":null,"externalUrl":null,"transcriptUrl":null,"guests":[],"links":null,"isSpam":false,"xp":0,"flaggingUsers":[],"isDisabled":false,"connectedInternalContentId":9978,"createdAt":"2018-04-16T08:32:46.799Z","updatedAt":"2018-05-07T09:54:54.797Z","upvoting":{"voteCount":45,"voted":false},"tags":["deep learning","python","neural networks"],"author":{"id":2125563,"slug":"thushv","avatarUrlSquare":"https://assets.datacamp.com/users/avatars/002/125/563/square/profile.jpeg?1518563443","fullName":"Thushan Ganegedara","nameFromEmail":"thushv","isAdmin":false}},{"id":9972,"externalId":null,"type":"Tutorial","status":"published","authorId":"cjsejal","title":"Markov Chains in Python: Beginner Tutorial","slug":"markov-chains-python-tutorial","previewSlug":null,"description":"Learn about Markov Chains, their properties, transition matrices, and implement one yourself in Python!","articles":[],"courses":[],"redirectSlug":null,"contentHtml":"\u003cp\u003eA Markov chain is a mathematical system usually defined as a collection of random variables, that transition from one state to another according to certain probabilistic rules. These set of transition satisfies the \u003cstrong\u003eMarkov Property\u003c/strong\u003e, which states that the probability of transitioning to any particular state is dependent solely on the current state and time elapsed, and not on the sequence of state that preceded it. This unique characteristic of Markov processes render them \u003cstrong\u003ememoryless\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003e\u003cnav\u003e\nIn this tutorial, you will discover when you can use markov chains, what the \u003ca href=\"#dtmc\"\u003eDiscrete Time Markov chain\u003c/a\u003e is. You\u0026#39;ll also learn about the components that are needed to build a (Discrete-time) \u003ca href=\"#model\"\u003eMarkov chain model\u003c/a\u003e and some of its common properties. Next, you\u0026#39;ll implement one such simple model with Python using its \u003ccode\u003enumpy\u003c/code\u003e and \u003ccode\u003erandom\u003c/code\u003e libraries. You will also learn some of the ways to represent a Markov chain like a state diagram and \u003ca href=\"#transitionmatrix\"\u003etransition matrix\u003c/a\u003e.\n\u003c/nav\u003e\u003c/p\u003e\n\u003cp\u003e\u003cdiv id=\"scoped-content\"\u003e\u003c/p\u003e\n\u003cstyle type=\"text/css\"\u003e:target:before { content:\"\"; display:block; height:150px; margin:-150px 0 0; } h3 {font-weight:normal; margin-top:.5em} h4 { font-weight:lighter }\n\u003c/style\u003e\n\n\u003cp\u003eWant to tackle more statistics topics with Python? Check out DataCamp\u0026#39;s \u003ca href=\"https://www.datacamp.com/courses/statistical-thinking-in-python-part-1\"\u003eStatistical Thinking in Python\u003c/a\u003e course!\u003c/p\u003e\n\u003cp\u003eLet\u0026#39;s transition...\u003c/p\u003e\n\u003ch2 id=\"why-markov-chains-\"\u003eWhy Markov Chains?\u003c/h2\u003e\n\u003cp\u003eMarkov Chains have prolific usage in mathematics. They are widely employed in economics, game theory, communication theory, genetics and finance. They arise broadly in statistical specially Bayesian statistics and information-theoretical contexts. When it comes real-world problems, they are used to postulate solutions to study cruise control systems in motor vehicles, queues or lines of customers arriving at an airport, exchange rates of currencies, etc. The algorithm known as PageRank, which was originally proposed for the internet search engine Google, is based on a Markov process. \u003ca href=\"https://www.reddit.com/r/SubredditSimulator/comments/3g9ioz/what_is_rsubredditsimulator/\"\u003eReddit\u0026#39;s Subreddit Simulator\u003c/a\u003e is a fully-automated subreddit that generates random submissions and comments using markov chains, so cool!\u003c/p\u003e\n\u003cp\u003e\u003ca id='MarkovChain'\u003e\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"markov-chain\"\u003eMarkov Chain\u003c/h2\u003e\n\u003cp\u003eA Markov chain is a random process with the Markov property. A random process or often called stochastic property is a mathematical object defined as a collection of random variables. A Markov chain has either discrete state space (set of possible values of the random variables) or discrete index set (often representing time) - given the fact, many variations for a Markov chain exists. Usually the term \u0026quot;Markov chain\u0026quot; is reserved for a process with a discrete set of times, that is a Discrete Time Markov chain (DTMC).\u003c/p\u003e\n\u003cp\u003e\u003ca id=\"dtmc\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"discrete-time-markov-chain\"\u003eDiscrete Time Markov chain\u003c/h2\u003e\n\u003cp\u003eA discrete-time Markov chain involves a system which is in a certain state at each step, with the state changing randomly between steps. The steps are often thought of as moments in time (But you might as well refer to physical distance or any other discrete measurement). A discrete time Markov chain is a sequence of random variables X\u003csub\u003e1\u003c/sub\u003e, X\u003csub\u003e2\u003c/sub\u003e, X\u003csub\u003e3\u003c/sub\u003e, ... with the Markov property, such that the probability of moving to the next state depends only on the present state and not on the previous states. Putting this is mathematical probabilistic formula:\u003c/p\u003e\n\u003cp\u003ePr( X\u003csub\u003en+1\u003c/sub\u003e = x | X\u003csub\u003e1\u003c/sub\u003e = x\u003csub\u003e1\u003c/sub\u003e, X\u003csub\u003e2\u003c/sub\u003e = x\u003csub\u003e2\u003c/sub\u003e, , X\u003csub\u003en\u003c/sub\u003e = x\u003csub\u003en\u003c/sub\u003e) = Pr( X\u003csub\u003en+1\u003c/sub\u003e = x | X\u003csub\u003en\u003c/sub\u003e = x\u003csub\u003en\u003c/sub\u003e)\u003c/p\u003e\n\u003cp\u003eAs you can see, the probability of X\u003csub\u003en+1\u003c/sub\u003e only depends on the probability of X\u003csub\u003en\u003c/sub\u003e that precedes it. Which means the knowledge of the previous state is all that is necessary to determine the probability distribution of the current state, satisfying the rule of conditional independence (or said other way: you only need to know the current state to determine the next state).\u003c/p\u003e\n\u003cp\u003eThe possible values of X\u003csub\u003ei\u003c/sub\u003e form a countable set S called the \u003cstrong\u003estate space\u003c/strong\u003e of the chain. The state space can be anything: letters, numbers, basketball scores or weather conditions. While the time parameter is usually discrete, the state space of a discrete time Markov chain does not have any widely agreed upon restrictions, and rather refers to a process on an arbitrary state space. However, many applications of Markov chains employ finite or countably infinite state spaces, because they have a more straightforward statistical analysis.\u003c/p\u003e\n\u003cp\u003e\u003ca id=\"model\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"model\"\u003eModel\u003c/h2\u003e\n\u003cp\u003eA Markov chain is represented using a probabilistic automaton (It only sounds complicated!). The changes of state of the system are called transitions. The probabilities associated with various state changes are called transition probabilities. A probabilistic automaton includes the probability of a given transition into the transition function, turning it into a transition matrix.\u003c/p\u003e\n\u003cp\u003eYou can think of it as a sequence of directed graphs, where the edges of graph n are labeled by the probabilities of going from one state at time n to the other states at time n+1, Pr(X\u003csub\u003en+1\u003c/sub\u003e = x | X\u003csub\u003en\u003c/sub\u003e = x\u003csub\u003en\u003c/sub\u003e). You can read this as, probability of going to state X\u003csub\u003en+1\u003c/sub\u003e given value of state X\u003csub\u003en\u003c/sub\u003e. The same information is represented by the \u003ca id='transitionmatrix'\u003e\u003cstrong\u003etransition matrix\u003c/strong\u003e\u003c/a\u003e from time n to time n+1. Every state in the state space is included once as a row and again as a column, and each cell in the matrix tells you the probability of transitioning from its row\u0026#39;s state to its column\u0026#39;s state.\u003c/p\u003e\n\u003cp\u003eIf the Markov chain has N possible states, the matrix will be an N x N matrix, such that entry (I, J) is the probability of transitioning from state I to state J. Additionally, the transition matrix must be a stochastic matrix, a matrix whose entries in each row must add up to exactly 1. Why? Since each row represents its own probability distribution.\u003c/p\u003e\n\u003cp\u003eSo, the model is characterized by a state space, a transition matrix describing the probabilities of particular transitions, and an initial state across the state space, given in the initial distribution.\u003c/p\u003e\n\u003cp\u003eWhole lot of words eh?\u003c/p\u003e\n\u003cp\u003eLet\u0026#39;s check out a simple example to understand the concepts:\u003c/p\u003e\n\u003cp\u003eWhen Cj is sad, which isn\u0026#39;t very usual: she either goes for a run, goobles down icecream or takes a nap.\u003c/p\u003e\n\u003cp\u003eFrom historic data, if she spent sleeping a sad day away. The next day it is 60% likely she will go for a run, 20% she will stay in bed the next day and 20% chance she will pig out on icecream.\u003c/p\u003e\n\u003cp\u003eWhen she is sad and goes for a run, there is a 60% chances she\u0026#39;ll go for a run the next day, 30% she gorges on icecream and only 10% chances she\u0026#39;ll spend sleeping the next day.\u003c/p\u003e\n\u003cp\u003eFinally, when she indulges on icecream on a sad day, there is a mere 10% chance she continues to have icecream the next day as well, 70% she is likely to go for a run and 20% chance that she spends sleeping the next day.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1523011817/state_diagram_pfkfld.png\"/\u003e\u003c/p\u003e\n\u003cp\u003eThe Markov Chain depicted in the \u003cstrong\u003estate diagram\u003c/strong\u003e has 3 possible states: sleep, run, icecream. So, the transition matrix will be 3 x 3 matrix. Notice, the arrows exiting a state always sums up to exactly 1, similarly the entries in each row in the transition matrix must add up to exactly 1 - representing probability distribution. In the transition matrix, the cells do the same job that the arrows do in the state diagram.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1523011817/transition_matrix_gj27nq.png\"/\u003e\u003c/p\u003e\n\u003cp\u003eNow that you have seen the example, this should give you an idea of the different concepts related to a Markov chain. But, how and where can you use these theory in real life?\u003c/p\u003e\n\u003cp\u003eWith the example that you have seen, you can now answer questions like: \u0026quot;Starting from the state: sleep, what is the probability that Cj will be running (state: run) at the end of a sad 2-day duration?\u0026quot;\u003c/p\u003e\n\u003cp\u003eLet\u0026#39;s work this one out: In order to move from state: sleep to state: run, Cj must either stay on state: sleep the first move (or day), then move to state: run the next (second) move (0.2 $\\cdot$ 0.6); or move to state: run the first day and then stay there the second (0.6 $\\cdot$ 0.6) or she could transition to state: icecream on the first move and then to state: run in the second (0.2 $\\cdot$ 0.7). So the probability: ((0.2 $\\cdot$ 0.6) + (0.6 $\\cdot$ 0.6) + (0.2 $\\cdot$ 0.7)) = 0.62. So, we can now say that there is a 62% chance that Cj will move to state: run after two days of being sad, if she started out in the state: sleep.\u003c/p\u003e\n\u003cp\u003eHopefully, this gave you an idea of the various questions you can answer using a Markov Chain network.\u003c/p\u003e\n\u003cp\u003eAlso, with this clear in mind, it becomes easier to understand some important properties of Markov chains:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eReducibility: a Markov chain is said to be irreducible if it is possible to get to any state from any state. In other words, a Markov chain is irreducible if there exists a chain of steps between any two states that has positive probability.\u003c/li\u003e\n\u003cli\u003ePeriodicity: a state in a Markov chain is periodic if the chain can return to the state only at multiples of some integer larger than 1. Thus, starting in state \u0026#39;i\u0026#39;, the chain can return to \u0026#39;i\u0026#39; only at multiples of the period \u0026#39;k\u0026#39;, and k is the largest such integer. State \u0026#39;i\u0026#39; is aperiodic if k = 1 and periodic if k \u0026gt; 1.\u003c/li\u003e\n\u003cli\u003eTransience and Recurrence: A state \u0026#39;i\u0026#39; is said to be transient if, given that we start in state \u0026#39;i\u0026#39;, there is a non-zero probability that we will never return to \u0026#39;i\u0026#39;. State i is recurrent (or persistent) if it is not transient. A recurrent state is known as positive recurrent if it is expected to return within a finite number of steps and null recurrent otherwise.\u003c/li\u003e\n\u003cli\u003eErgodicity: a state \u0026#39;i\u0026#39; is said to be ergodic if it is aperiodic and positive recurrent. If all states in an irreducible Markov chain are ergodic, then the chain is said to be ergodic.\u003c/li\u003e\n\u003cli\u003eAbsorbing State: a state i is called absorbing if it is impossible to leave this state. Therefore, the state \u0026#39;i\u0026#39; is absorbing if p\u003csub\u003eii\u003c/sub\u003e = 1 and p\u003csub\u003eij\u003c/sub\u003e = 0 for i  j. If every state can reach an absorbing state, then the Markov chain is an absorbing Markov chain.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eTip\u003c/strong\u003e: if you want to also see a visual explanation of Markov chains, make sure to visit \u003ca href=\"http://setosa.io/ev/markov-chains/\"\u003ethis page\u003c/a\u003e.\u003c/p\u003e\n\u003ch2 id=\"markov-chains-in-python\"\u003eMarkov Chains in Python\u003c/h2\u003e\n\u003cp\u003eLet\u0026#39;s try to code the example above in Python. And although in real life, you would probably use a library that encodes Markov Chains in a much efficient manner, the code should help you get started...\u003c/p\u003e\n\u003cp\u003eLet\u0026#39;s first import some of the libraries you will use.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003eimport numpy as np\nimport random as rm\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eLet\u0026#39;s now define the states and their probability: the transition matrix. Remember, the matrix is going to be a 3 X 3 matrix since you have three states. Also, you will have to define the transition paths, you can do this using matrices as well.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# The statespace\nstates = [\u0026quot;Sleep\u0026quot;,\u0026quot;Icecream\u0026quot;,\u0026quot;Run\u0026quot;]\n\n# Possible sequences of events\ntransitionName = [[\u0026quot;SS\u0026quot;,\u0026quot;SR\u0026quot;,\u0026quot;SI\u0026quot;],[\u0026quot;RS\u0026quot;,\u0026quot;RR\u0026quot;,\u0026quot;RI\u0026quot;],[\u0026quot;IS\u0026quot;,\u0026quot;IR\u0026quot;,\u0026quot;II\u0026quot;]]\n\n# Probabilities matrix (transition matrix)\ntransitionMatrix = [[0.2,0.6,0.2],[0.1,0.6,0.3],[0.2,0.7,0.1]]\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eOh, always make sure the probabilities sum up to 1. And it doesn\u0026#39;t hurt to leave error messages, at least when coding!\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003eif sum(transitionMatrix[0])+sum(transitionMatrix[1])+sum(transitionMatrix[1]) != 3:\n    print(\u0026quot;Somewhere, something went wrong. Transition matrix, perhaps?\u0026quot;)\nelse: print(\u0026quot;All is gonna be okay, you should move on!! ;)\u0026quot;)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode\u003eAll is gonna be okay, you should move on!! ;)\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eNow let\u0026#39;s code the real thing. You will use the \u003ccode\u003enumpy.random.choice\u003c/code\u003e to generate a random sample from the set of transitions possible. While most of its arguments are self-explanatory, the \u003ccode\u003ep\u003c/code\u003e might not be. It is an optional argument that lets you enter the probability distribution for the sampling set, which is the transition matrix in this case.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# A function that implements the Markov model to forecast the state/mood.\ndef activity_forecast(days):\n    # Choose the starting state\n    activityToday = \u0026quot;Sleep\u0026quot;\n    print(\u0026quot;Start state: \u0026quot; + activityToday)\n    # Shall store the sequence of states taken. So, this only has the starting state for now.\n    activityList = [activityToday]\n    i = 0\n    # To calculate the probability of the activityList\n    prob = 1\n    while i != days:\n        if activityToday == \u0026quot;Sleep\u0026quot;:\n            change = np.random.choice(transitionName[0],replace=True,p=transitionMatrix[0])\n            if change == \u0026quot;SS\u0026quot;:\n                prob = prob * 0.2\n                activityList.append(\u0026quot;Sleep\u0026quot;)\n                pass\n            elif change == \u0026quot;SR\u0026quot;:\n                prob = prob * 0.6\n                activityToday = \u0026quot;Run\u0026quot;\n                activityList.append(\u0026quot;Run\u0026quot;)\n            else:\n                prob = prob * 0.2\n                activityToday = \u0026quot;Icecream\u0026quot;\n                activityList.append(\u0026quot;Icecream\u0026quot;)\n        elif activityToday == \u0026quot;Run\u0026quot;:\n            change = np.random.choice(transitionName[1],replace=True,p=transitionMatrix[1])\n            if change == \u0026quot;RR\u0026quot;:\n                prob = prob * 0.5\n                activityList.append(\u0026quot;Run\u0026quot;)\n                pass\n            elif change == \u0026quot;RS\u0026quot;:\n                prob = prob * 0.2\n                activityToday = \u0026quot;Sleep\u0026quot;\n                activityList.append(\u0026quot;Sleep\u0026quot;)\n            else:\n                prob = prob * 0.3\n                activityToday = \u0026quot;Icecream\u0026quot;\n                activityList.append(\u0026quot;Icecream\u0026quot;)\n        elif activityToday == \u0026quot;Icecream\u0026quot;:\n            change = np.random.choice(transitionName[2],replace=True,p=transitionMatrix[2])\n            if change == \u0026quot;II\u0026quot;:\n                prob = prob * 0.1\n                activityList.append(\u0026quot;Icecream\u0026quot;)\n                pass\n            elif change == \u0026quot;IS\u0026quot;:\n                prob = prob * 0.2\n                activityToday = \u0026quot;Sleep\u0026quot;\n                activityList.append(\u0026quot;Sleep\u0026quot;)\n            else:\n                prob = prob * 0.7\n                activityToday = \u0026quot;Run\u0026quot;\n                activityList.append(\u0026quot;Run\u0026quot;)\n        i += 1  \n    print(\u0026quot;Possible states: \u0026quot; + str(activityList))\n    print(\u0026quot;End state after \u0026quot;+ str(days) + \u0026quot; days: \u0026quot; + activityToday)\n    print(\u0026quot;Probability of the possible sequence of states: \u0026quot; + str(prob))\n\n# Function that forecasts the possible state for the next 2 days\nactivity_forecast(2)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode\u003eStart state: Sleep\nPossible states: [\u0026#39;Sleep\u0026#39;, \u0026#39;Sleep\u0026#39;, \u0026#39;Run\u0026#39;]\nEnd state after 2 days: Run\nProbability of the possible sequence of states: 0.12\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eYou get a random set of transitions possible along with the probability of it happening, starting from state: Sleep. Extend the program further to maybe iterate it for a couple of hundred times with the same starting state, you can then see the expected probability of ending at any particular state along with its probability. Let\u0026#39;s rewrite the function \u003ccode\u003eactivity_forecast\u003c/code\u003e and add a fresh set of loops to do this...\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003edef activity_forecast(days):\n    # Choose the starting state\n    activityToday = \u0026quot;Sleep\u0026quot;\n    activityList = [activityToday]\n    i = 0\n    prob = 1\n    while i != days:\n        if activityToday == \u0026quot;Sleep\u0026quot;:\n            change = np.random.choice(transitionName[0],replace=True,p=transitionMatrix[0])\n            if change == \u0026quot;SS\u0026quot;:\n                prob = prob * 0.2\n                activityList.append(\u0026quot;Sleep\u0026quot;)\n                pass\n            elif change == \u0026quot;SR\u0026quot;:\n                prob = prob * 0.6\n                activityToday = \u0026quot;Run\u0026quot;\n                activityList.append(\u0026quot;Run\u0026quot;)\n            else:\n                prob = prob * 0.2\n                activityToday = \u0026quot;Icecream\u0026quot;\n                activityList.append(\u0026quot;Icecream\u0026quot;)\n        elif activityToday == \u0026quot;Run\u0026quot;:\n            change = np.random.choice(transitionName[1],replace=True,p=transitionMatrix[1])\n            if change == \u0026quot;RR\u0026quot;:\n                prob = prob * 0.5\n                activityList.append(\u0026quot;Run\u0026quot;)\n                pass\n            elif change == \u0026quot;RS\u0026quot;:\n                prob = prob * 0.2\n                activityToday = \u0026quot;Sleep\u0026quot;\n                activityList.append(\u0026quot;Sleep\u0026quot;)\n            else:\n                prob = prob * 0.3\n                activityToday = \u0026quot;Icecream\u0026quot;\n                activityList.append(\u0026quot;Icecream\u0026quot;)\n        elif activityToday == \u0026quot;Icecream\u0026quot;:\n            change = np.random.choice(transitionName[2],replace=True,p=transitionMatrix[2])\n            if change == \u0026quot;II\u0026quot;:\n                prob = prob * 0.1\n                activityList.append(\u0026quot;Icecream\u0026quot;)\n                pass\n            elif change == \u0026quot;IS\u0026quot;:\n                prob = prob * 0.2\n                activityToday = \u0026quot;Sleep\u0026quot;\n                activityList.append(\u0026quot;Sleep\u0026quot;)\n            else:\n                prob = prob * 0.7\n                activityToday = \u0026quot;Run\u0026quot;\n                activityList.append(\u0026quot;Run\u0026quot;)\n        i += 1    \n    return activityList\n\n# To save every activityList\nlist_activity = []\ncount = 0\n\n# `Range` starts from the first count up until but excluding the last count\nfor iterations in range(1,10000):\n        list_activity.append(activity_forecast(2))\n\n# Check out all the `activityList` we collected    \n#print(list_activity)\n\n# Iterate through the list to get a count of all activities ending in state:\u0026#39;Run\u0026#39;\nfor smaller_list in list_activity:\n    if(smaller_list[2] == \u0026quot;Run\u0026quot;):\n        count += 1\n\n# Calculate the probability of starting from state:\u0026#39;Sleep\u0026#39; and ending at state:\u0026#39;Run\u0026#39;\npercentage = (count/10000) * 100\nprint(\u0026quot;The probability of starting at state:\u0026#39;Sleep\u0026#39; and ending at state:\u0026#39;Run\u0026#39;= \u0026quot; + str(percentage) + \u0026quot;%\u0026quot;)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode\u003eThe probability of starting at state:\u0026#39;Sleep\u0026#39; and ending at state:\u0026#39;Run\u0026#39;= 62.419999999999995%\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eHow did we approximate towards the desired 62%?\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eNote\u003c/strong\u003e This is actually the \u0026quot;law of large numbers\u0026quot;, which is a principle of probability that states that the frequencies of events with the same likelihood of occurrence even out, but only if there are enough trials or instances. In other words, as the number of experiments increases, the actual ratio of outcomes will converge on a theoretical or expected ratio of outcomes.\u003c/p\u003e\n\u003ch2 id=\"markov-state-of-mind\"\u003eMarkov State of Mind\u003c/h2\u003e\n\u003cp\u003eThis concludes the tutorial on Markov Chains. You have been introduced to Markov Chains and seen some of its properties. Simple Markov chains are one of the required, foundational topics to get started with data science in Python. If you\u0026#39;d like more resources to get started with statistics in Python, make sure to check out \u003ca href=\"https://www.datacamp.com/community/tutorials/python-statistics-data-science\"\u003ethis page\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eAre you interested in exploring more practical case studies with statistics in Python? Check out DataCamp\u0026#39;s \u003ca href=\"https://www.datacamp.com/courses/case-studies-in-statistical-thinking\"\u003eCase Studies in Statistical Thinking\u003c/a\u003e or \u003ca href=\"https://www.datacamp.com/courses/network-analysis-in-python-part-1\"\u003eNetwork Analysis in Python\u003c/a\u003e courses.\u003c/p\u003e\n","contentUrl":"https://www.datacamp.com/community/tutorials/markov-chains-python-tutorial","userContentUrl":null,"illustrationUrl":null,"seoTitle":"Python Markov Chains Beginner Tutorial","seoMetaDescription":"Learn about Markov Chains, their properties, transition matrices, and implement one yourself in Python!","seoKeyword":"Python Markov Chains Tutorial","mustRead":false,"programmingLanguage":null,"submissionDate":"2018-05-01T11:33:47.653Z","publishDate":"2018-05-01T11:39:36.342Z","episode":null,"isLatest":null,"externalUrl":null,"transcriptUrl":null,"guests":[],"links":null,"isSpam":false,"xp":0,"flaggingUsers":[],"isDisabled":false,"connectedInternalContentId":null,"createdAt":"2018-05-01T11:33:47.650Z","updatedAt":"2018-05-02T20:33:35.625Z","upvoting":{"voteCount":51,"voted":false},"tags":["python","statistical modeling"],"author":{"id":259429,"slug":"cjsejal","avatarUrlSquare":"https://assets.datacamp.com/users/avatars/000/259/429/square/AAEAAQAAAAAAAAbiAAAAJDcxMjBiNjIwLTZhODMtNGMzMS04NTE4LTZlMDkzMGVlNGIwNg.jpg?1512740950","fullName":"Sejal Jaiswal","nameFromEmail":"cjsejal","isAdmin":false}},{"id":9887,"externalId":null,"type":"Tutorial","status":"published","authorId":"DanielSchuette","title":"Survival Analysis in R For Beginners","slug":"survival-analysis-R","previewSlug":null,"description":"In this tutorial, you'll learn about the statistical concepts behind survival analysis and you'll implement a real-world application of these methods in R.","articles":[],"courses":[],"redirectSlug":null,"contentHtml":"\u003cp\u003eData mining or machine learning techniques can oftentimes be utilized at\r\nearly stages of biomedical research to analyze large datasets, for\r\nexample, to aid the identification of candidate genes or predictive\r\ndisease biomarkers in high-throughput sequencing datasets. However, data\r\nfrom clinical trials usually include survival data that require a\r\nquite different approach to analysis.\u003c/p\u003e\r\n\u003cp\u003eIn this type of analysis, the time to a specific event, such as death or\r\ndisease recurrence, is of interest and two (or more) groups of patients\r\nare compared with respect to this time. Three core concepts can be used\r\nto derive meaningful results from such a dataset and the aim of this\r\ntutorial is to introduce the statistical concepts, their interpretation,\r\nas well as a real-world application of these methods along with their\r\nimplementation in R:\u003c/p\u003e\r\n\u003cp\u003eIn this post, you\u0026#39;ll tackle the following topics:\u003c/p\u003e\r\n\u003cp\u003e\u003cnav\u003e\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli\u003e\u003ca href=\"#second\"\u003eThe Statistics behind Survival Analysis\u003c/a\u003e\u003cul\u003e\r\n\u003cli\u003e\u003ca href=\"#third\"\u003eKaplan-Meier Method and Log-Rank Test\u003c/a\u003e\u003c/li\u003e\r\n\u003cli\u003e\u003ca href=\"#fourth\"\u003eCox Proportional Hazards Models\u003c/a\u003e\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003c/li\u003e\r\n\u003cli\u003e\u003ca href=\"#fifth\"\u003eImplementation of a Survival Analysis in R\u003c/a\u003e\r\n\u003c/nav\u003e\r\n\u003cdiv id=\"scoped-content\"\u003e\u003cstyle type=\"text/css\"\u003e:target:before { content:\"\"; display:block; height:150px; margin:-150px 0 0; } h3 {font-weight:normal; margin-top:.5em} h4 { font-weight:lighter }\r\n\u003c/style\u003e\r\n\r\n\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003eIn this tutorial, you are also going to use the \u003ccode\u003esurvival\u003c/code\u003e and\r\n\u003ccode\u003esurvminer\u003c/code\u003e packages in R and the \u003ccode\u003eovarian\u003c/code\u003e dataset (Edmunson J.H. et al., 1979) that comes with the \u003ccode\u003esurvival\u003c/code\u003e package. You\u0026#39;ll read more about this dataset later on in this tutorial!\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eTip:\u003c/strong\u003e check out \u003ca href=\"https://www.rstudio.com/wp-content/uploads/2015/01/survminer-1.png\"\u003ethis \u003ccode\u003esurvminer\u003c/code\u003e cheat sheet\u003c/a\u003e\u003c/p\u003e\r\n\u003cp\u003eAfter this tutorial, you will be able to take advantage of these\r\ndata to answer questions such as the following: do patients benefit from\r\ntherapy regimen A as opposed to regimen B? Do patients age and fitness\r\nsignificantly influence the outcome? Is residual disease a prognostic\r\nbiomarker in terms of survival?\u003c/p\u003e\r\n\u003cp\u003e\u003ca id=\"second\"\u003e\u003c/a\u003e\u003c/p\u003e\r\n\u003ch2 id=\"survival-analysis-the-statistics\"\u003eSurvival Analysis: The Statistics\u003c/h2\u003e\r\n\u003cp\u003eBefore you go into detail with the statistics, you might want to learn\r\nabout some useful terminology:\u003c/p\u003e\r\n\u003cp\u003eThe term \u0026quot;censoring\u0026quot; refers to incomplete data. Although different types\r\nexist, you might want to restrict yourselves to right-censored data at\r\nthis point since this is the most common type of censoring in survival\r\ndatasets. \u003c/p\u003e\r\n\u003cp\u003eFor some patients, you might know that he or she was\r\nfollowed-up on for a certain time without an event occurring, but you\r\nmight not know whether the patient ultimately survived or not. This can\r\nbe the case if the patient was either lost to follow-up or a subject\r\nwithdrew from the study. The data on this particular patient is going to\r\nbe censored after the last time point at which you know for sure that\r\nyour patient did not experience the event you are looking for. An\r\nevent is the pre-specified endpoint of your study, for instance death or\r\ndisease recurrence. Also, all patients who do not experience the event\r\nuntil the study ends will be censored at that last time point.\u003c/p\u003e\r\n\u003cp\u003eBasically, these are the three reason why data could be censored.\u003c/p\u003e\r\n\u003cp\u003eThus, the number of censored observations is always \u003ccode\u003en \u0026gt;= 0\u003c/code\u003e. All these\r\nexamples are instances of right-censoring and one can further classify\r\ninto either fixed or random type I censoring and type II censoring, but\r\nthese classifications are relevant mostly from the standpoint of\r\nstudy-design and will not concern you in this introductory tutorial.\u003c/p\u003e\r\n\u003cp\u003eSomething you should keep in mind is that all types of censoring are\r\ncases of non-information and censoring is never caused by the event\r\nthat defines the endpoint of your study. That also implies that none of\r\nthe censored patients in the \u003ccode\u003eovarian\u003c/code\u003e dataset were censored because the\r\nrespective patient died.\u003c/p\u003e\r\n\u003cp\u003e\u003ca id=\"third\"\u003e\u003c/a\u003e\u003c/p\u003e\r\n\u003ch3 id=\"kaplan-meier-method-and-log-rank-test\"\u003eKaplan-Meier Method and Log Rank Test\u003c/h3\u003e\r\n\u003cp\u003eNow, how does a survival function that describes patient survival over\r\ntime look like? \u003c/p\u003e\r\n\u003cp\u003eThe Kaplan-Meier estimator, independently described by\r\nEdward Kaplan and Paul Meier and conjointly published in 1958 in the\r\nJournal of the American Statistical Association, is a non-parametric\r\nstatistic that allows us to estimate the survival function.\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eRemember\u003c/strong\u003e that a non-parametric statistic is not based on the\r\nassumption of an underlying probability distribution, which makes sense\r\nsince survival data has a skewed distribution.\u003c/p\u003e\r\n\u003cp\u003eThis statistic gives the probability that an individual patient will\r\nsurvive past a particular time \u003ccode\u003et\u003c/code\u003e. At \u003ccode\u003et = 0\u003c/code\u003e, the Kaplan-Meier\r\nestimator is \u003ccode\u003e1\u003c/code\u003e and with \u003ccode\u003et\u003c/code\u003e going to infinity, the estimator goes to\r\n\u003ccode\u003e0\u003c/code\u003e. In theory, with an infinitely large dataset and t measured to the\r\nsecond, the corresponding function of \u003ccode\u003et\u003c/code\u003e versus survival probability is\r\nsmooth. Later, you will see how it looks like in practice.\u003c/p\u003e\r\n\u003cp\u003eIt is further based on the assumption that the probability of surviving\r\npast a certain time point \u003ccode\u003et\u003c/code\u003e is equal to the product of the observed\r\nsurvival rates until time point \u003ccode\u003et\u003c/code\u003e. More precisely,\r\n\u003ccode\u003eS(t) #the survival probability at time t\u003c/code\u003e is given by\r\n\u003ccode\u003eS(t) = p.1 * p.2 *  * p.t\u003c/code\u003e with \u003ccode\u003ep.1\u003c/code\u003e being the proportion of all\r\npatients surviving past the first time point, \u003ccode\u003ep.2\u003c/code\u003e being the proportion\r\nof patients surviving past the second time point, and so forth until\r\ntime point \u003ccode\u003et\u003c/code\u003e is reached. \u003c/p\u003e\r\n\u003cp\u003eIt is important to notice that, starting with\r\n\u003ccode\u003ep.2\u003c/code\u003e and up to \u003ccode\u003ep.t\u003c/code\u003e, you take only those patients into account who\r\nsurvived past the previous time point when calculating the proportions\r\nfor every next time point; thus, \u003ccode\u003ep.2\u003c/code\u003e, \u003ccode\u003ep.3\u003c/code\u003e, \u003ccode\u003e\u003c/code\u003e, \u003ccode\u003ep.t\u003c/code\u003e are\r\nproportions that are conditional on the previous proportions.\u003c/p\u003e\r\n\u003cp\u003eIn practice, you want to organize the survival times in order of\r\nincreasing duration first. This includes the censored values. You then\r\nwant to calculate the proportions as described above and sum them up to\r\nderive \u003ccode\u003eS(t)\u003c/code\u003e. Censored patients are omitted after the time point of\r\ncensoring, so they do not influence the proportion of surviving\r\npatients. For detailed information on the method, refer to (Swinscow and\r\nCampbell, 2002). \u003c/p\u003e\r\n\u003cp\u003eAs a last note, you can use the log-rank test to\r\ncompare survival curves of two groups. The log-rank test is a\r\nstatistical hypothesis test that tests the null hypothesis that survival\r\ncurves of two populations do not differ. A certain probability\r\ndistribution, namely a chi-squared distribution, can be used to derive a\r\np-value. Briefly, p-values are used in statistical hypothesis testing to\r\nquantify statistical significance. A result with \u003ccode\u003ep \u0026lt; 0.05\u003c/code\u003e is usually\r\nconsidered significant. In our case, \u003ccode\u003ep \u0026lt; 0.05\u003c/code\u003e would indicate that the\r\ntwo treatment groups are significantly different in terms of survival.\u003c/p\u003e\r\n\u003cp\u003e\u003ca id=\"fourth\"\u003e\u003c/a\u003e\u003c/p\u003e\r\n\u003ch3 id=\"cox-proportional-hazards-models\"\u003eCox Proportional Hazards Models\u003c/h3\u003e\r\n\u003cp\u003eAnother useful function in the context of survival analyses is the\r\nhazard function \u003ccode\u003eh(t)\u003c/code\u003e. It describes the probability of an event or its\r\nhazard \u003ccode\u003eh\u003c/code\u003e (again, survival in this case) if the subject survived up to\r\nthat particular time point \u003ccode\u003et\u003c/code\u003e. It is a bit more difficult to illustrate\r\nthan the Kaplan-Meier estimator because it measures the instantaneous\r\nrisk of death. Nevertheless, you need the hazard function to consider\r\ncovariates when you compare survival of patient groups. Covariates, also\r\ncalled explanatory or independent variables in regression analysis, are\r\nvariables that are possibly predictive of an outcome or that you might\r\nwant to adjust for to account for interactions between variables.\u003c/p\u003e\r\n\u003cp\u003eWhereas the log-rank test compares two Kaplan-Meier survival curves,\r\nwhich might be derived from splitting a patient population into\r\ntreatment subgroups, Cox proportional hazards models are derived from\r\nthe underlying baseline hazard functions of the patient populations in\r\nquestion and an arbitrary number of dichotomized covariates. Again, it\r\ndoes not assume an underlying probability distribution but it assumes\r\nthat the hazards of the patient groups you compare are constant over\r\ntime. That is why it is called proportional hazards model. Later, you\r\nwill see an example that illustrates these theoretical considerations.\u003c/p\u003e\r\n\u003cp\u003eNow, lets try to analyze the \u003ccode\u003eovarian\u003c/code\u003e dataset!\u003c/p\u003e\r\n\u003cp\u003e\u003ca id=\"fifth\"\u003e\u003c/a\u003e\u003c/p\u003e\r\n\u003ch2 id=\"implementation-of-a-survival-analysis-in-r\"\u003eImplementation of a Survival Analysis in R\u003c/h2\u003e\r\n\u003cp\u003eWith these concepts at hand, you can now start to analyze an actual\r\ndataset and try to answer some of the questions above. Lets start by\r\nloading the two packages required for the analyses and the \u003ccode\u003edplyr\u003c/code\u003e\r\npackage that comes with some useful functions for managing data frames.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003e# Load required packages\r\nlibrary(survival)\r\nlibrary(survminer)\r\nlibrary(dplyr)\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cstrong\u003eTip\u003c/strong\u003e: don\u0026#39;t forget to use \u003ccode\u003einstall.packages()\u003c/code\u003e to install any\r\npackages that might still be missing in your workspace!\u003c/p\u003e\r\n\u003cp\u003eThe next step is to load the dataset and examine its structure. As you read in the beginning of this tutorial, you\u0026#39;ll work with the \u003ccode\u003eovarian\u003c/code\u003e data set. This dataset comprises a cohort of ovarian cancer patients and respective clinical information, including the time patients were tracked until they either died or were lost to follow-up (\u003ccode\u003efutime\u003c/code\u003e), whether patients were censored or not (\u003ccode\u003efustat\u003c/code\u003e), patient age, treatment group assignment, presence of residual disease and performance status. \u003c/p\u003e\r\n\u003cp\u003eAs you can already see, some of the variables names are a little cryptic, you might also want to consult the help page.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003e# Import the ovarian cancer dataset and have a look at it\r\ndata(ovarian)\r\nglimpse(ovarian)\r\n## Observations: 26\r\n## Variables: 6\r\n## $ futime   \u0026lt;dbl\u0026gt; 59, 115, 156, 421, 431, 448, 464, 475, 477, 563, 638,...\r\n## $ fustat   \u0026lt;dbl\u0026gt; 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,...\r\n## $ age      \u0026lt;dbl\u0026gt; 72.3315, 74.4932, 66.4658, 53.3644, 50.3397, 56.4301,...\r\n## $ resid.ds \u0026lt;dbl\u0026gt; 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 1, 1, 2, 2, 1, 1, 2, 1,...\r\n## $ rx       \u0026lt;dbl\u0026gt; 1, 1, 1, 2, 1, 1, 2, 2, 1, 2, 1, 2, 2, 2, 1, 1, 1, 1,...\r\n## $ ecog.ps  \u0026lt;dbl\u0026gt; 1, 1, 2, 1, 1, 2, 2, 2, 1, 2, 2, 1, 2, 1, 1, 2, 2, 1,...\r\nhelp(ovarian)\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eThe \u003ccode\u003efutime\u003c/code\u003e column holds the survival times. This is the response\r\nvariable. \u003ccode\u003efustat\u003c/code\u003e, on the other hand, tells you if an individual\r\npatients survival time is censored. Apparently, the 26 patients in this\r\nstudy received either one of two therapy regimens (\u003ccode\u003erx\u003c/code\u003e) and the\r\nattending physician assessed the regression of tumors (\u003ccode\u003eresid.ds\u003c/code\u003e) and\r\npatients performance (according to the standardized ECOG criteria;\r\n\u003ccode\u003eecog.ps\u003c/code\u003e) at some point.\u003c/p\u003e\r\n\u003cp\u003eFurthermore, you get information on patients age and if you want to\r\ninclude this as a predictive variable eventually, you have to\r\ndichotomize continuous to binary values. But what cutoff should you\r\nchoose for that? Let us look at the overall distribution of age values:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003e# Dichotomize age and change data labels\r\novarian$rx \u0026lt;- factor(ovarian$rx, \r\n                     levels = c(\u0026quot;1\u0026quot;, \u0026quot;2\u0026quot;), \r\n                     labels = c(\u0026quot;A\u0026quot;, \u0026quot;B\u0026quot;))\r\novarian$resid.ds \u0026lt;- factor(ovarian$resid.ds, \r\n                           levels = c(\u0026quot;1\u0026quot;, \u0026quot;2\u0026quot;), \r\n                           labels = c(\u0026quot;no\u0026quot;, \u0026quot;yes\u0026quot;))\r\novarian$ecog.ps \u0026lt;- factor(ovarian$ecog.ps, \r\n                          levels = c(\u0026quot;1\u0026quot;, \u0026quot;2\u0026quot;), \r\n                          labels = c(\u0026quot;good\u0026quot;, \u0026quot;bad\u0026quot;))\r\n\r\n# Data seems to be bimodal\r\nhist(ovarian$age) \r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1522843408/survival_lhlkdg.png\"/\u003e\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003eovarian \u0026lt;- ovarian %\u0026gt;% mutate(age_group = ifelse(age \u0026gt;=50, \u0026quot;old\u0026quot;, \u0026quot;young\u0026quot;))\r\novarian$age_group \u0026lt;- factor(ovarian$age_group)\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eThe obviously bi-modal distribution suggests a cutoff of 50 years. You\r\ncan use the \u003ccode\u003emutate\u003c/code\u003e function to add an additional \u003ccode\u003eage_group\u003c/code\u003e column to\r\nthe data frame that will come in handy later on. Also, you should\r\nconvert the future covariates into factors.\u003c/p\u003e\r\n\u003cp\u003eNow, you are prepared to create a survival object. That is basically a\r\ncompiled version of the \u003ccode\u003efutime\u003c/code\u003e and \u003ccode\u003efustat\u003c/code\u003e columns that can be\r\ninterpreted by the \u003ccode\u003esurvfit\u003c/code\u003e function. A \u003ccode\u003e+\u003c/code\u003e behind survival times\r\nindicates censored data points.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003e# Fit survival data using the Kaplan-Meier method\r\nsurv_object \u0026lt;- Surv(time = ovarian$futime, event = ovarian$fustat)\r\nsurv_object \r\n##  [1]   59   115   156   421+  431   448+  464   475   477+  563   638 \r\n## [12]  744+  769+  770+  803+  855+ 1040+ 1106+ 1129+ 1206+ 1227+  268 \r\n## [23]  329   353   365   377+\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eThe next step is to fit the Kaplan-Meier curves. You can easily do that\r\nby passing the \u003ccode\u003esurv_object\u003c/code\u003e to the \u003ccode\u003esurvfit\u003c/code\u003e function. You can also\r\nstratify the curve depending on the treatment regimen \u003ccode\u003erx\u003c/code\u003e that patients\r\nwere assigned to. A \u003ccode\u003esummary()\u003c/code\u003e of the resulting \u003ccode\u003efit1\u003c/code\u003e object shows,\r\namong other things, survival times, the proportion of surviving patients\r\nat every time point, namely your \u003ccode\u003ep.1\u003c/code\u003e, \u003ccode\u003ep.2\u003c/code\u003e, \u003ccode\u003e...\u003c/code\u003e from above, and\r\ntreatment groups.\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003efit1 \u0026lt;- survfit(surv_object ~ rx, data = ovarian)\r\nsummary(fit1)\r\n## Call: survfit(formula = surv_object ~ rx, data = ovarian)\r\n## \r\n##                 rx=A \r\n##  time n.risk n.event survival std.err lower 95% CI upper 95% CI\r\n##    59     13       1    0.923  0.0739        0.789        1.000\r\n##   115     12       1    0.846  0.1001        0.671        1.000\r\n##   156     11       1    0.769  0.1169        0.571        1.000\r\n##   268     10       1    0.692  0.1280        0.482        0.995\r\n##   329      9       1    0.615  0.1349        0.400        0.946\r\n##   431      8       1    0.538  0.1383        0.326        0.891\r\n##   638      5       1    0.431  0.1467        0.221        0.840\r\n## \r\n##                 rx=B \r\n##  time n.risk n.event survival std.err lower 95% CI upper 95% CI\r\n##   353     13       1    0.923  0.0739        0.789        1.000\r\n##   365     12       1    0.846  0.1001        0.671        1.000\r\n##   464      9       1    0.752  0.1256        0.542        1.000\r\n##   475      8       1    0.658  0.1407        0.433        1.000\r\n##   563      7       1    0.564  0.1488        0.336        0.946\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eYou can examine the corresponding survival curve by passing the survival\r\nobject to the \u003ccode\u003eggsurvplot\u003c/code\u003e function. The \u003ccode\u003epval = TRUE\u003c/code\u003e argument is very\r\nuseful, because it plots the p-value of a log rank test as well!\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003eggsurvplot(fit1, data = ovarian, pval = TRUE)\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1522843408/survival1_g30vej.png\"/\u003e\u003c/p\u003e\r\n\u003cp\u003eBy convention, vertical lines indicate censored data, their\r\ncorresponding x values the time at which censoring occurred.\u003c/p\u003e\r\n\u003cp\u003eThe log-rank p-value of 0.3 indicates a non-significant result if you\r\nconsider \u003ccode\u003ep \u0026lt; 0.05\u003c/code\u003e to indicate statistical significance. In this study,\r\nnone of the treatments examined were significantly superior, although\r\npatients receiving treatment B are doing better in the first month of\r\nfollow-up. What about the other variables?\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003e# Examine prdictive value of residual disease status\r\nfit2 \u0026lt;- survfit(surv_object ~ resid.ds, data = ovarian)\r\nggsurvplot(fit2, data = ovarian, pval = TRUE)\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1522843408/survival2_komvqh.png\"/\u003e\u003c/p\u003e\r\n\u003cp\u003eThe Kaplan-Meier plots stratified according to residual disease status\r\nlook a bit different: The curves diverge early and the log-rank test is\r\nalmost significant. You might want to argue that a follow-up study with\r\nan increased sample size could validate these results, that is, that\r\npatients with positive residual disease status have a significantly\r\nworse prognosis compared to patients without residual disease.\u003c/p\u003e\r\n\u003cp\u003eBut is there a more systematic way to look at the different covariates?\r\nAs you might remember from one of the previous passages, Cox\r\nproportional hazards models allow you to include covariates. You can\r\nbuild Cox proportional hazards models using the \u003ccode\u003ecoxph\u003c/code\u003e function and\r\nvisualize them using the \u003ccode\u003eggforest\u003c/code\u003e. These type of plot is called a\r\nforest plot. It shows so-called hazard ratios (HR) which are derived\r\nfrom the model for all covariates that we included in the formula in\r\n\u003ccode\u003ecoxph\u003c/code\u003e. Briefly, an HR \u0026gt; 1 indicates an increased risk of death\r\n(according to the definition of \u003ccode\u003eh(t)\u003c/code\u003e) if a specific condition is met\r\nby a patient. An HR \u0026lt; 1, on the other hand, indicates a decreased\r\nrisk. Let\u0026#39;s look at the output of the model:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode\u003e# Fit a Cox proportional hazards model\r\nfit.coxph \u0026lt;- coxph(surv_object ~ rx + resid.ds + age_group + ecog.ps, \r\n                   data = ovarian)\r\nggforest(fit.coxph, data = ovarian)\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1522843408/survival3_t8aocz.png\"/\u003e\u003c/p\u003e\r\n\u003cp\u003eEvery HR represents a relative risk of death that compares one instance\r\nof a binary feature to the other instance. For example, a hazard ratio\r\nof 0.25 for treatment groups tells you that patients who received\r\ntreatment B have a reduced risk of dying compared to patients who\r\nreceived treatment A (which served as a reference to calculate the\r\nhazard ratio). As shown by the forest plot, the respective 95%\r\nconfidence interval is 0.071 - 0.89 and this result is significant.\u003c/p\u003e\r\n\u003cp\u003eUsing this model, you can see that the treatment group, residual disease\r\nstatus, and age group variables significantly influence the patients\u0026#39;\r\nrisk of death in this study. This is quite different from what you saw\r\nwith the Kaplan-Meier estimator and the log-rank test. Whereas the\r\nformer estimates the survival probability, the latter calculates the\r\nrisk of death and respective hazard ratios. Your analysis shows that the\r\nresults that these methods yield can differ in terms of significance.\u003c/p\u003e\r\n\u003ch2 id=\"conclusion\"\u003eConclusion\u003c/h2\u003e\r\n\u003cp\u003eThe examples above show how easy it is to implement the statistical\r\nconcepts of survival analysis in R. In this introduction, you have\r\nlearned how to build respective models, how to visualize them, and also\r\nsome of the statistical background information that helps to understand\r\nthe results of your analyses. Hopefully, you can now start to use these\r\ntechniques to analyze your own datasets. Thanks for reading this\r\ntutorial!\u003c/p\u003e\r\n","contentUrl":"https://www.datacamp.com/community/tutorials/survival-analysis-R","userContentUrl":null,"illustrationUrl":null,"seoTitle":"Survival Analysis in R Tutorial","seoMetaDescription":"In this tutorial, you'll learn about the statistical concepts behind survival analysis and you'll implement a real-world application of these methods in R.","seoKeyword":"survival analysis R ","mustRead":false,"programmingLanguage":null,"submissionDate":"2018-04-16T08:18:49.146Z","publishDate":"2018-04-26T10:00:00.000Z","episode":null,"isLatest":null,"externalUrl":null,"transcriptUrl":null,"guests":[],"links":null,"isSpam":false,"xp":0,"flaggingUsers":[],"isDisabled":false,"connectedInternalContentId":9963,"createdAt":"2018-04-16T08:18:49.144Z","updatedAt":"2018-04-26T07:20:16.757Z","upvoting":{"voteCount":41,"voted":false},"tags":["statistical modeling","r programming"],"author":{"id":808444,"slug":"DanielSchuette","avatarUrlSquare":"https://assets.datacamp.com/users/avatars/000/808/444/square/profile_picture_DC.jpg?1514071847","fullName":"Daniel Schuette","nameFromEmail":"dschuette","isAdmin":false}}],"TutorialTotal":141},"menu":{"isSidebarMenuOpen":false},"notifications":{"isFetched":false,"isFetching":false,"isReadFetched":false,"isReadFetching":false,"statusMessage":"","readStatusMessage":"","Notifications":[],"NotificationsTotal":0,"unReadCount":0},"preview":{"isFetching":false,"isFetched":false,"statusMessage":"","content":{}},"recommendCS":{"isPosting":false,"isPosted":false,"statusMessage":"","isModalOpen":false,"currentStep":"form"},"spam":{"isFlagging":false,"isSucceeded":false,"statusMessage":"","isSpamModalOpen":false,"isUnSpamModalOpen":false},"tag":{"isRequesting":false,"isSucceeded":false,"statusMessage":"","isDeleteTagModalOpen":false},"tagList":{"isFetched":false,"isFetching":false,"statusMessage":"","list":[],"total":0},"tagSearch":{"isFetching":false,"isFetched":false,"statusMessage":"","content":{}},"user":{"isFetching":false,"isFetched":false,"statusMessage":"","unBan":{"isUnBanning":false,"isSucceeded":false,"statusMessage":"","isUnBanUserModalOpen":false},"ban":{"isBanning":false,"isSucceeded":false,"statusMessage":"","isBanUserModalOpen":false}},"writeTutorial":{"isPosting":false,"isPosted":false,"statusMessage":"","isModalOpen":false,"currentStep":"form"},"submitArticle":{"isPosting":false,"isPosted":false,"statusMessage":"","timer":0,"articleSlug":"","isModalOpen":false,"currentStep":"form","slug":"","externalUrl":""},"rss":{"isCreating":false,"isSucceeded":false,"statusMessage":""},"rssFeedList":{"isFetched":false,"isFetching":false,"statusMessage":"","list":[],"disconnectModal":{"isFetched":true,"isFetching":false,"isOpen":false,"rssFeedIdToDisconnect":null,"statusMessage":""}},"setAsHomePage":{"isSetAsHomePageModalOpen":false},"analytics":{}},"initialProps":{"asPath":"/community/tutorials","mustRead":false,"page":1}},"pathname":"/community/tutorials","query":{},"buildId":"c3b2e90b-fb20-4ba5-a772-ba56fb48a509","buildStats":{"app.js":{"hash":"311d80e8002eb39a0e03612aa30d2813"}},"assetPrefix":"/community","nextExport":false,"err":null,"chunks":[]}
          module={}
          __NEXT_LOADED_PAGES__ = []
          __NEXT_LOADED_CHUNKS__ = []

          __NEXT_REGISTER_PAGE = function (route, fn) {
            __NEXT_LOADED_PAGES__.push({ route: route, fn: fn })
          }

          __NEXT_REGISTER_CHUNK = function (chunkName, fn) {
            __NEXT_LOADED_CHUNKS__.push({ chunkName: chunkName, fn: fn })
          }
        </script>
<script type="text/javascript" id="">!function(b,e,f,g,a,c,d){b.fbq||(a=b.fbq=function(){a.callMethod?a.callMethod.apply(a,arguments):a.queue.push(arguments)},b._fbq||(b._fbq=a),a.push=a,a.loaded=!0,a.version="2.0",a.queue=[],c=e.createElement(f),c.async=!0,c.src=g,d=e.getElementsByTagName(f)[0],d.parentNode.insertBefore(c,d))}(window,document,"script","https://connect.facebook.net/en_US/fbevents.js");fbq("init","286618111707433");fbq("track","PageView");</script>
<noscript><img height="1" width="1" style="display:none" src="https://www.facebook.com/tr?id=286618111707433&amp;ev=PageView&amp;noscript=1"></noscript>




<script type="text/javascript" id="">!function(d,e,f,a,b,c){d.qp||(a=d.qp=function(){a.qp?a.qp.apply(a,arguments):a.queue.push(arguments)},a.queue=[],b=document.createElement(e),b.async=!0,b.src=f,c=document.getElementsByTagName(e)[0],c.parentNode.insertBefore(b,c))}(window,"script","https://a.quora.com/qevents.js");qp("init","22bfea26b11042efa6e75ebd5c7e82b4");qp("track","ViewContent");</script>
<noscript><img height="1" width="1" style="display:none" src="https://q.quora.com/_/ad/22bfea26b11042efa6e75ebd5c7e82b4/pixel?tag=ViewContent&amp;noscript=1"></noscript>

<script type="text/javascript" id="">qp("track","Generic");</script>
<script type="text/javascript" id="">!function(d,e){var b="001b340da40499a7b1f011e1db6e25ce11";if(d.obApi){var c=function(a){return"[object Array]"===Object.prototype.toString.call(a)?a:[a]};d.obApi.marketerId=c(d.obApi.marketerId).concat(c(b))}else{var a=d.obApi=function(){a.dispatch?a.dispatch.apply(a,arguments):a.queue.push(arguments)};a.version="1.1";a.loaded=!0;a.marketerId=b;a.queue=[];b=e.createElement("script");b.async=!0;b.src="//amplify.outbrain.com/cp/obtp.js";b.type="text/javascript";c=e.getElementsByTagName("script")[0];
c.parentNode.insertBefore(b,c)}}(window,document);obApi("track","PAGE_VIEW");</script>
<script type="text/javascript" id="">"yes"==navigator.doNotTrack||"1"==navigator.doNotTrack||"1"==navigator.msDoNotTrack||"yes"==window.doNotTrack||"1"==window.doNotTrack||"1"==window.msDoNotTrack?ga("set","dimension5","yes"):ga("set","dimension5","no");</script><div style="width:0px; height:0px; display:none; visibility:hidden;" id="batBeacon0.7116504814639493"><img style="width:0px; height:0px; display:none; visibility:hidden;" id="batBeacon0.9250239691051914" width="0" height="0" alt="" src="./LSTM in Python_ Stock Market Predictions (article) - DataCamp_files/0"></div><script async="" id="__NEXT_PAGE__/community/tutorials" type="text/javascript" src="./LSTM in Python_ Stock Market Predictions (article) - DataCamp_files/tutorials.js"></script><script async="" id="__NEXT_PAGE__/_error" type="text/javascript" src="./LSTM in Python_ Stock Market Predictions (article) - DataCamp_files/_error.js"></script><script type="text/javascript" src="./LSTM in Python_ Stock Market Predictions (article) - DataCamp_files/app.js" async=""></script><script src="./LSTM in Python_ Stock Market Predictions (article) - DataCamp_files/saved_resource" type="text/javascript"></script><script type="text/javascript" async="" src="./LSTM in Python_ Stock Market Predictions (article) - DataCamp_files/113036.js"></script><div id="wisepop-main-container" style="">  <style type="text/css"> </style> <div id="wisepop-modal-113036" style="line-height: normal; visibility: hidden;"> <div id="wisepop-overlay-113036" class="wisepop-overlay" style="position: fixed; width: 100%; height: 100%; top: 0px; left: 0px; z-index: 9999999; background-color: rgb(61, 66, 81); opacity: 0;" data-close-on-click="1"> <img src="./LSTM in Python_ Stock Market Predictions (article) - DataCamp_files/_.gif" style="display: none;"></div> <div id="wisepop-113036" class="wisepop-popin" style="box-sizing: content-box; border-style: solid; padding: 20px; position: fixed; top: 397.5px; margin: 0px auto; left: 0px; z-index: 10000000; width: 460px; border-width: 0px; border-radius: 15px; background-color: rgb(255, 255, 255); border-color: rgb(234, 234, 234); opacity: 0; right: 0px; overflow: auto; bottom: auto;"> <a class="wisepop-close" id="close-wisepop-113036" href="https://www.datacamp.com/community/tutorials/lstm-python-stock-market#" style=""> <img style="border:none" src="./LSTM in Python_ Stock Market Predictions (article) - DataCamp_files/wisepop-close-button2.png" alt="Close this popin"> </a> <div id="wisepop-content" class="wisepop-content">  <div class="" style="line-height: 20px;min-height: 30px;margin-bottom: 15px;"> <span style="font-size:12px;"><h1 style="text-align:center;"><span style="color:#3d4251;"><span style="font-family:lato;">The Smartest Way to Learn Data Science Online</span></span></h1> <div></div> <div></div> <div></div> <div></div> <div></div> <div></div></span></div><div style="margin-bottom: 15px;"> <div> <a href="https://www.datacamp.com/" target="_blank"> <img src="./LSTM in Python_ Stock Market Predictions (article) - DataCamp_files/3d74cb72065be963e74ca47487470f0c.png" style="display: block; margin: auto; margin-bottom:10px;max-width:100%;"> </a> <p style="text-align:center;"><span style="font-family:lato;"><font style="font-family:Raleway;"><span style="font-size:18px;">Over 100 Intuitive Courses on R, Python, and SQL</span></font></span></p> <div></div> <div></div> <div></div> <div></div> <div style="display: block;height: 0;clear: both;visibility: hidden;"></div> </div> </div> <div class="" style="margin-bottom: 15px;;text-align:center"> <a class="wisepop-building-block-action" href="https://www.datacamp.com/courses" target="_self" style="border-bottom:2px solid rgb(21,77,97);border-bottom: 2px solid rgba(39,65,90, 0.3);zoom:1;border-radius:2px;display:inline-block;text-decoration:none;min-height:22px;line-height:22px;padding:14px 20px;color:#ffffff;background-color:#195a72;font-family:Lato;font-size:22px" data-ignore-tracking="0"> See All Courses </a> </div> </div> </div> </div> </div><script src="./LSTM in Python_ Stock Market Predictions (article) - DataCamp_files/tutorial.js" type="text/javascript"></script><script type="text/javascript" src="./LSTM in Python_ Stock Market Predictions (article) - DataCamp_files/script-8fa338a2dc.js" charset="utf-8"></script><div style="position: absolute; width: 0px; height: 0px; overflow: hidden; padding: 0px; border: 0px; margin: 0px;"><div id="MathJax_Font_Test" style="position: absolute; visibility: hidden; top: 0px; left: 0px; width: auto; padding: 0px; border: 0px; margin: 0px; white-space: nowrap; text-align: left; text-indent: 0px; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; font-size: 40px; font-weight: normal; font-style: normal; font-family: STIXSizeOneSym, sans-serif;"></div></div><div class="ReactModalPortal"></div><div class="ReactModalPortal"></div><div class="ReactModalPortal"></div><div class="ReactModalPortal"></div><div class="ReactModalPortal"></div><div class="ReactModalPortal"></div><div class="ReactModalPortal"></div><div class="ReactModalPortal"></div></body></html>